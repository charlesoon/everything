{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:startup","command":"entire hooks claude-code session-start"},"parentToolUseID":"f3f07527-ded1-4db3-9831-14c3ce9d19ad","toolUseID":"f3f07527-ded1-4db3-9831-14c3ce9d19ad","timestamp":"2026-02-22T08:16:53.213Z","uuid":"77ef38c0-f0f6-4119-ab9d-19ce0ed23534"}
{"type":"file-history-snapshot","messageId":"d21bd882-d4b7-4245-8b90-df7cecf1f692","snapshot":{"messageId":"d21bd882-d4b7-4245-8b90-df7cecf1f692","trackedFileBackups":{},"timestamp":"2026-02-22T09:29:21.012Z"},"isSnapshotUpdate":false}
{"parentUuid":"77ef38c0-f0f6-4119-ab9d-19ce0ed23534","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","type":"user","message":{"role":"user","content":"system dark theme에서 light theme로 설정한 뒤에 타이틀바 더블클릭(전체화면)으로 동작할 때 배경이 dark theme로 창이 확대되다가 웹 화면이 커지는 이슈가 있어. 어떻게 수정할까?"},"uuid":"d21bd882-d4b7-4245-8b90-df7cecf1f692","timestamp":"2026-02-22T09:29:15.128Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"d21bd882-d4b7-4245-8b90-df7cecf1f692","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is describing a visual issue where:\n1. System is set to dark theme\n2. They switch to light theme\n3. When they double-click the title bar (to maximize/fullscreen)\n4. The background appears dark (dark theme) during the window expansion animation, then the web content appears larger\n\nThis sounds like a flash of wrong theme/background color during window resize animation. Let me look at the codebase to understand how theming is handled.\n\nLet me check the relevant files first.","signature":"EooFCkYICxgCKkANNZBD6nnWCe0mIgOuETG5qDgVF/e8vdSS+CFRVh/WqU3YaoAFgOnKpxtwYg+kZDCGcwF2y06/Q0RHrQOTWzBkEgxvWQGiqBKM8ATa+vAaDL/h6aGV/A71tyS8HCIwmU4LHDQjkhsPRqpSjiP3rkzQ9IblXg2SafpxJDqPzQ9ukONQ4IxO2D8Uauxe1fDxKvED6yYLd/0K+NWkekMOPc51VjhjXqe+ixMYyXdVJejqAvZxDxC5pEWON+njTrXZWFdCVXyymCF1gUvvizblfJbSdjLRGT3ggjdszFlF78BedvO/0UvMnOgy2sjOoBcqypsDxUZk9SFy2WIQFpdVXMLad6d2+tKHVysGfwfqKWbVkX1VPHsUNf1MBd+bMRcMbB70fppLaz4CqUpVOXUvwkjKlmzC5Zk8oAc2j+1dN0NvDl9PCee1aRtTyiElQ2GeKPl6I/3PASXQrvcYtQQawsZfPauvrmU3bLOp+wwPkP08+hg+lGzwMEn0QfMBCMKGfOQTOa5OmT/T6KoJ8//EDDzHVv25wnRKR5dPH/3DPp7WdSd8C9duMYutxATJTbIXxlrbIHIY1INlZYbl/KMvBhTp5HQlNM56hCmW0SAXT2UbY3qm3KGtqnmnhMUkjhK5BgDQ05aZkIHy67hV3SvXLDhd4YTJv2hCt+K0dv9tOH9izvsMWialhI0pcVHAbGxEDMy4R2k3K6i8npEmwBcgBoZQQ0sazA6KyAOuRenzex8JMRECKf2IvBUx06/5BCSMokkQkjn1+oTlmCCmioS6X7cIf3VFDVGHrt7Ak5R7YQXCELHqPhxWQnsjijnvx/5//hisZvC6eQMTVqg7pT9g05vrfVwYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"2dd64469-5520-4873-b5bb-ffa4e5024a3b","timestamp":"2026-02-22T09:29:25.665Z"}
{"parentUuid":"2dd64469-5520-4873-b5bb-ffa4e5024a3b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"text","text":"현재 코드를 먼저 파악해볼게요."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"173f2d8f-7762-4e34-ab26-e374d445e594","timestamp":"2026-02-22T09:29:26.143Z"}
{"parentUuid":"173f2d8f-7762-4e34-ab26-e374d445e594","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BMsU1C6wcZM1N9Kj4saf9L","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"321b7d9e-15dc-4e22-a8b7-a901c84719a5","timestamp":"2026-02-22T09:29:26.588Z"}
{"parentUuid":"321b7d9e-15dc-4e22-a8b7-a901c84719a5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"File content (27568 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","is_error":true,"tool_use_id":"toolu_01BMsU1C6wcZM1N9Kj4saf9L"}]},"uuid":"eac28fc2-1024-4be0-ac93-7901c1ccc5aa","timestamp":"2026-02-22T09:29:26.932Z","toolUseResult":"Error: File content (27568 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","sourceToolAssistantUUID":"321b7d9e-15dc-4e22-a8b7-a901c84719a5"}
{"parentUuid":"eac28fc2-1024-4be0-ac93-7901c1ccc5aa","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JTqFHdacDxk4RLWazwLQMi","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/tauri.conf.json"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"fa76f54e-94c1-4378-ba86-153a82055ea3","timestamp":"2026-02-22T09:29:27.013Z"}
{"parentUuid":"fa76f54e-94c1-4378-ba86-153a82055ea3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>Sibling tool call errored</tool_use_error>","is_error":true,"tool_use_id":"toolu_01JTqFHdacDxk4RLWazwLQMi"}]},"uuid":"56b023ba-a7cd-4715-bab2-8209030ebd4c","timestamp":"2026-02-22T09:29:27.013Z","toolUseResult":"Sibling tool call errored","sourceToolAssistantUUID":"fa76f54e-94c1-4378-ba86-153a82055ea3"}
{"parentUuid":"56b023ba-a7cd-4715-bab2-8209030ebd4c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_014QXgWU3qd72wF6zvr1GNEk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VELqzGSnYuzXzWArFZqhzb","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte","offset":1,"limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":389,"cache_read_input_tokens":33779,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":389},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYNVAjcbmjgDpvMNqM","type":"assistant","uuid":"61941bf2-fd5f-4be7-b409-7258c4f5dd36","timestamp":"2026-02-22T09:29:29.379Z"}
{"parentUuid":"61941bf2-fd5f-4be7-b409-7258c4f5dd36","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01VELqzGSnYuzXzWArFZqhzb","toolUseID":"toolu_01VELqzGSnYuzXzWArFZqhzb","timestamp":"2026-02-22T09:29:29.388Z","uuid":"c7be933a-db97-4f47-a1c8-92b5e44d3389"}
{"parentUuid":"61941bf2-fd5f-4be7-b409-7258c4f5dd36","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VELqzGSnYuzXzWArFZqhzb","type":"tool_result","content":"     1→<script>\n     2→  import { onDestroy, onMount, tick } from 'svelte';\n     3→  import { invoke } from '@tauri-apps/api/core';\n     4→  import { listen } from '@tauri-apps/api/event';\n     5→  import { getCurrentWindow } from '@tauri-apps/api/window';\n     6→  import { startDrag } from '@crabnebula/tauri-plugin-drag';\n     7→  import 'overlayscrollbars/overlayscrollbars.css';\n     8→  import { OverlayScrollbars } from 'overlayscrollbars';\n     9→  import {\n    10→    SEARCH_DEBOUNCE_MS,\n    11→    computeSearchFetchLimit,\n    12→    extractLeafQuery,\n    13→    shouldApplyPreserveResults\n    14→  } from './search-utils';\n    15→  let osInstance = null;\n    16→  let osViewport = null;\n    17→  let scrollCleanup = null;\n    18→  function getScrollEl() {\n    19→    return osViewport || tableContainer;\n    20→  }\n    21→\n    22→  const rowHeight = 26;\n    23→  const PAGE_SIZE = 500;\n    24→  let homePrefix = '';\n    25→  const COL_WIDTHS_KEY = 'REDACTED';\n    26→  const THEME_KEY = 'everything-theme';\n    27→  const columnKeys = ['name', 'path', 'size', 'modified'];\n    28→  const minColumnWidth = {\n    29→    name: 180,\n    30→    path: 240,\n    31→    size: 62,\n    32→    modified: 150\n    33→  };\n    34→  const defaultColumnRatios = {\n    35→    name: 0.32,\n    36→    path: 0.48,\n    37→    size: 0.05\n    38→  };\n    39→  const DEBUG_STARTUP = false;\n    40→\n    41→  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n    42→  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n    43→  function cycleTheme() {\n    44→    theme = theme === 'dark' ? 'light' : 'dark';\n    45→    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n    46→    invoke('set_native_theme', { theme });\n    47→  }\n    48→\n    49→  function sortIconHtml(dir) {\n    50→    const d = dir === 'asc' ? 'M2.5 6.5 L5 4 L7.5 6.5' : 'M2.5 3.5 L5 6 L7.5 3.5';\n    51→    return `<svg class=\"sort-icon\" viewBox=\"0 0 10 10\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"${d}\"/></svg>`;\n    52→  }\n    53→\n    54→  let query = '';\n    55→  let results = [];\n    56→  let totalResults = 0;\n    57→  let totalResultsKnown = false;\n    58→\n    59→  let dbLatencyMs = null;\n    60→  let dbLastQuery = '';\n    61→  let searchModeLabel = '';\n    62→  let selectedIndices = new Set();\n    63→  let selectionAnchor = -1;\n    64→  let lastSelectedIndex = -1;\n    65→  let editing = {\n    66→    active: false,\n    67→    path: '',\n    68→    index: -1,\n    69→    draftName: ''\n    70→  };\n    71→\n    72→  let renameOverlay = { top: 0, left: 0, maxWidth: 0 };\n    73→\n    74→  let indexStatus = {\n    75→    state: 'Indexing',\n    76→    entriesCount: 0,\n    77→    lastUpdated: null,\n    78→    permissionErrors: 0,\n    79→    message: null,\n    80→    isCatchup: false\n    81→  };\n    82→\n    83→  let indexingStartTime = null;\n    84→  let indexingElapsed = '';\n    85→  let indexingFinishedAt = '';\n    86→\n    87→  let sortBy = 'name';\n    88→  let sortDir = 'asc';\n    89→\n    90→  let hasMore = true;\n    91→  let loadingMore = false;\n    92→  let searchGeneration = 0;\n    93→  let scheduleGeneration = 0;\n    94→  let searchPending = false;\n    95→\n    96→  let scanned = 0;\n    97→  let indexed = 0;\n    98→  let currentPath = '';\n    99→\n   100→  let searchInputEl;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1b1648c4-8867-4a64-8206-0602115acee0","timestamp":"2026-02-22T09:29:29.387Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src/App.svelte","content":"<script>\n  import { onDestroy, onMount, tick } from 'svelte';\n  import { invoke } from '@tauri-apps/api/core';\n  import { listen } from '@tauri-apps/api/event';\n  import { getCurrentWindow } from '@tauri-apps/api/window';\n  import { startDrag } from '@crabnebula/tauri-plugin-drag';\n  import 'overlayscrollbars/overlayscrollbars.css';\n  import { OverlayScrollbars } from 'overlayscrollbars';\n  import {\n    SEARCH_DEBOUNCE_MS,\n    computeSearchFetchLimit,\n    extractLeafQuery,\n    shouldApplyPreserveResults\n  } from './search-utils';\n  let osInstance = null;\n  let osViewport = null;\n  let scrollCleanup = null;\n  function getScrollEl() {\n    return osViewport || tableContainer;\n  }\n\n  const rowHeight = 26;\n  const PAGE_SIZE = 500;\n  let homePrefix = '';\n  const COL_WIDTHS_KEY = 'REDACTED';\n  const THEME_KEY = 'everything-theme';\n  const columnKeys = ['name', 'path', 'size', 'modified'];\n  const minColumnWidth = {\n    name: 180,\n    path: 240,\n    size: 62,\n    modified: 150\n  };\n  const defaultColumnRatios = {\n    name: 0.32,\n    path: 0.48,\n    size: 0.05\n  };\n  const DEBUG_STARTUP = false;\n\n  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n  function cycleTheme() {\n    theme = theme === 'dark' ? 'light' : 'dark';\n    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n    invoke('set_native_theme', { theme });\n  }\n\n  function sortIconHtml(dir) {\n    const d = dir === 'asc' ? 'M2.5 6.5 L5 4 L7.5 6.5' : 'M2.5 3.5 L5 6 L7.5 3.5';\n    return `<svg class=\"sort-icon\" viewBox=\"0 0 10 10\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"${d}\"/></svg>`;\n  }\n\n  let query = '';\n  let results = [];\n  let totalResults = 0;\n  let totalResultsKnown = false;\n\n  let dbLatencyMs = null;\n  let dbLastQuery = '';\n  let searchModeLabel = '';\n  let selectedIndices = new Set();\n  let selectionAnchor = -1;\n  let lastSelectedIndex = -1;\n  let editing = {\n    active: false,\n    path: '',\n    index: -1,\n    draftName: ''\n  };\n\n  let renameOverlay = { top: 0, left: 0, maxWidth: 0 };\n\n  let indexStatus = {\n    state: 'Indexing',\n    entriesCount: 0,\n    lastUpdated: null,\n    permissionErrors: 0,\n    message: null,\n    isCatchup: false\n  };\n\n  let indexingStartTime = null;\n  let indexingElapsed = '';\n  let indexingFinishedAt = '';\n\n  let sortBy = 'name';\n  let sortDir = 'asc';\n\n  let hasMore = true;\n  let loadingMore = false;\n  let searchGeneration = 0;\n  let scheduleGeneration = 0;\n  let searchPending = false;\n\n  let scanned = 0;\n  let indexed = 0;\n  let currentPath = '';\n\n  let searchInputEl;","numLines":100,"startLine":1,"totalLines":2738}},"sourceToolAssistantUUID":"61941bf2-fd5f-4be7-b409-7258c4f5dd36"}
{"parentUuid":"1b1648c4-8867-4a64-8206-0602115acee0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_014QXgWU3qd72wF6zvr1GNEk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013k1TE5VL2VMq5iM1BmDoh1","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/tauri.conf.json"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":389,"cache_read_input_tokens":33779,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":389},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYNVAjcbmjgDpvMNqM","type":"assistant","uuid":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7","timestamp":"2026-02-22T09:29:29.681Z"}
{"parentUuid":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013k1TE5VL2VMq5iM1BmDoh1","toolUseID":"toolu_013k1TE5VL2VMq5iM1BmDoh1","timestamp":"2026-02-22T09:29:29.688Z","uuid":"bb48db25-1b00-44b7-aca8-74e852fbaa1e"}
{"parentUuid":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013k1TE5VL2VMq5iM1BmDoh1","type":"tool_result","content":"     1→{\n     2→  \"$schema\": \"../node_modules/@tauri-apps/cli/config.schema.json\",\n     3→  \"productName\": \"Everything\",\n     4→  \"version\": \"0.2.0\",\n     5→  \"identifier\": \"com.everything.app\",\n     6→  \"build\": {\n     7→    \"beforeDevCommand\": \"npm run dev\",\n     8→    \"devUrl\": \"http://127.0.0.1:1420\",\n     9→    \"beforeBuildCommand\": \"npm run build\",\n    10→    \"frontendDist\": \"../dist\"\n    11→  },\n    12→  \"app\": {\n    13→    \"macOSPrivateApi\": true,\n    14→    \"windows\": [\n    15→      {\n    16→        \"title\": \"\",\n    17→        \"label\": \"main\",\n    18→        \"width\": 600,\n    19→        \"height\": 380,\n    20→        \"transparent\": true,\n    21→        \"titleBarStyle\": \"Overlay\",\n    22→        \"trafficLightPosition\": {\n    23→          \"x\": 12,\n    24→          \"y\": 12\n    25→        },\n    26→        \"visible\": false,\n    27→        \"minWidth\": 400,\n    28→        \"minHeight\": 300,\n    29→        \"resizable\": true,\n    30→        \"fullscreen\": false\n    31→      }\n    32→    ],\n    33→    \"security\": {\n    34→      \"csp\": \"default-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; script-src 'self'\"\n    35→    }\n    36→  },\n    37→  \"bundle\": {\n    38→    \"active\": true,\n    39→    \"targets\": \"all\",\n    40→    \"category\": \"DeveloperTool\",\n    41→    \"icon\": [\n    42→      \"icons/32x32.png\",\n    43→      \"icons/128x128.png\",\n    44→      \"icons/icon.png\",\n    45→      \"icons/icon.icns\",\n    46→      \"icons/icon.ico\"\n    47→    ],\n    48→    \"resources\": {\n    49→      \"../everything.icon\": \"everything.icon\"\n    50→    },\n    51→    \"macOS\": {\n    52→      \"signingIdentity\": null,\n    53→      \"entitlements\": \"Entitlements.plist\",\n    54→      \"minimumSystemVersion\": \"11.0\",\n    55→      \"infoPlist\": \"Info.plist\"\n    56→    },\n    57→    \"windows\": {\n    58→      \"nsis\": {\n    59→        \"displayLanguageSelector\": false,\n    60→        \"languages\": [\n    61→          \"Korean\",\n    62→          \"English\"\n    63→        ],\n    64→        \"installerIcon\": \"icons/icon.ico\"\n    65→      }\n    66→    }\n    67→  }\n    68→}\n    69→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"207acb11-bba8-40cc-8ae8-481a219a69d7","timestamp":"2026-02-22T09:29:29.688Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/tauri.conf.json","content":"{\n  \"$schema\": \"../node_modules/@tauri-apps/cli/config.schema.json\",\n  \"productName\": \"Everything\",\n  \"version\": \"0.2.0\",\n  \"identifier\": \"com.everything.app\",\n  \"build\": {\n    \"beforeDevCommand\": \"npm run dev\",\n    \"devUrl\": \"http://127.0.0.1:1420\",\n    \"beforeBuildCommand\": \"npm run build\",\n    \"frontendDist\": \"../dist\"\n  },\n  \"app\": {\n    \"macOSPrivateApi\": true,\n    \"windows\": [\n      {\n        \"title\": \"\",\n        \"label\": \"main\",\n        \"width\": 600,\n        \"height\": 380,\n        \"transparent\": true,\n        \"titleBarStyle\": \"Overlay\",\n        \"trafficLightPosition\": {\n          \"x\": 12,\n          \"y\": 12\n        },\n        \"visible\": false,\n        \"minWidth\": 400,\n        \"minHeight\": 300,\n        \"resizable\": true,\n        \"fullscreen\": false\n      }\n    ],\n    \"security\": {\n      \"csp\": \"default-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; script-src 'self'\"\n    }\n  },\n  \"bundle\": {\n    \"active\": true,\n    \"targets\": \"all\",\n    \"category\": \"DeveloperTool\",\n    \"icon\": [\n      \"icons/32x32.png\",\n      \"icons/128x128.png\",\n      \"icons/icon.png\",\n      \"icons/icon.icns\",\n      \"icons/icon.ico\"\n    ],\n    \"resources\": {\n      \"../everything.icon\": \"everything.icon\"\n    },\n    \"macOS\": {\n      \"signingIdentity\": null,\n      \"entitlements\": \"Entitlements.plist\",\n      \"minimumSystemVersion\": \"11.0\",\n      \"infoPlist\": \"Info.plist\"\n    },\n    \"windows\": {\n      \"nsis\": {\n        \"displayLanguageSelector\": false,\n        \"languages\": [\n          \"Korean\",\n          \"English\"\n        ],\n        \"installerIcon\": \"icons/icon.ico\"\n      }\n    }\n  }\n}\n","numLines":69,"startLine":1,"totalLines":69}},"sourceToolAssistantUUID":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7"}
{"parentUuid":"207acb11-bba8-40cc-8ae8-481a219a69d7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TS3aks6UCP71tyPtf5Z6h2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YZPLK72DthRzVrGcQSrAsk","name":"Grep","input":{"pattern":"background|--bg|body|html|theme|color-scheme","path":"/Users/al02402336/everything/src/App.svelte","output_mode":"content","-n":true,"head_limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2496,"cache_read_input_tokens":34168,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2496},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYZkax6o6wVGYqgZmm","type":"assistant","uuid":"35560c70-6d59-4696-abdd-29e023370e2f","timestamp":"2026-02-22T09:29:33.221Z"}
{"parentUuid":"35560c70-6d59-4696-abdd-29e023370e2f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TS3aks6UCP71tyPtf5Z6h2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2496,"cache_read_input_tokens":34168,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2496},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYZkax6o6wVGYqgZmm","type":"assistant","uuid":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d","timestamp":"2026-02-22T09:29:33.885Z"}
{"parentUuid":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","toolUseID":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","timestamp":"2026-02-22T09:29:33.894Z","uuid":"5627621f-4b04-4e26-a0a5-ca8d04405ab1"}
{"parentUuid":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","type":"tool_result","content":"     1→#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n     2→\n     3→use std::{\n     4→    cmp::Ordering,\n     5→    collections::{HashMap, HashSet},\n     6→    fs,\n     7→    hash::{Hash, Hasher},\n     8→    io::{self, BufRead, BufReader, Write},\n     9→    path::{Path, PathBuf},\n    10→    process::{Command, Stdio},\n    11→    sync::{\n    12→        atomic::{AtomicBool, Ordering as AtomicOrdering},\n    13→        Arc, OnceLock,\n    14→    },\n    15→    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n    16→};\n    17→\n    18→use parking_lot::{Mutex, RwLock};\n    19→use rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\n    20→use serde::Serialize;\n    21→use tauri::{AppHandle, Emitter, Manager, State};\n    22→#[cfg(target_os = \"macos\")]\n    23→use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n    24→#[cfg(target_os = \"windows\")]\n    25→use std::os::windows::process::CommandExt;\n    26→use walkdir::WalkDir;\n    27→\n    28→mod fd_search;\n    29→mod gitignore_filter;\n    30→#[cfg(target_os = \"macos\")]\n    31→mod mac;\n    32→mod mem_search;\n    33→mod query;\n    34→#[cfg(target_os = \"windows\")]\n    35→mod win;\n    36→use fd_search::{FdSearchCache, FdSearchResultDto};\n    37→use query::{escape_like, parse_query, SearchMode};\n    38→\n    39→const DEFAULT_LIMIT: u32 = 300;\n    40→const SHORT_QUERY_LIMIT: u32 = 100;\n    41→const MAX_LIMIT: u32 = 1000;\n    42→pub(crate) const BATCH_SIZE: usize = 10_000;\n    43→const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n    44→pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n    45→const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n    46→const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n    47→const DB_VERSION: i32 = 5;\n    48→const DEFERRED_DIR_NAMES: &[&str] = &[\n    49→    \"Library\", \".Trash\", \".Trashes\",\n    50→    // Windows system directories (deferred when scan_root is C:\\)\n    51→    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    52→    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n    53→];\n    54→const SHALLOW_SCAN_DEPTH: usize = 6;\n    55→fn jwalk_num_threads() -> usize {\n    56→    std::thread::available_parallelism()\n    57→        .map(|n| (n.get() / 2).max(4).min(16))\n    58→        .unwrap_or(8)\n    59→}\n    60→\n    61→fn jwalk_num_threads_fresh() -> usize {\n    62→    std::thread::available_parallelism()\n    63→        .map(|n| n.get().max(4).min(16))\n    64→        .unwrap_or(8)\n    65→}\n    66→\n    67→pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    68→    \".git\",\n    69→    \"node_modules\",\n    70→    \".Trash\",\n    71→    \".Trashes\",\n    72→    \".npm\",\n    73→    \".cache\",\n    74→    \"CMakeFiles\",\n    75→    \".qtc_clangd\",\n    76→    \"__pycache__\",\n    77→    \".gradle\",\n    78→    \"DerivedData\",\n    79→];\n    80→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"503aabe2-57cb-4a06-8c6a-c276744c9617","timestamp":"2026-02-22T09:29:33.893Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n","numLines":80,"startLine":1,"totalLines":5880}},"sourceToolAssistantUUID":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d"}
{"parentUuid":"503aabe2-57cb-4a06-8c6a-c276744c9617","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01YZPLK72DthRzVrGcQSrAsk","toolUseID":"toolu_01YZPLK72DthRzVrGcQSrAsk","timestamp":"2026-02-22T09:29:33.966Z","uuid":"9d1ba3e7-ce06-4823-aeb6-ffbae38da024"}
{"parentUuid":"35560c70-6d59-4696-abdd-29e023370e2f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YZPLK72DthRzVrGcQSrAsk","type":"tool_result","content":"26:  const THEME_KEY = 'everything-theme';\n41:  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n42:  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n44:    theme = theme === 'dark' ? 'light' : 'dark';\n45:    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n46:    invoke('set_native_theme', { theme });\n454:      document.body.style.cursor = '';\n455:      document.body.style.userSelect = '';\n464:    document.body.style.cursor = 'col-resize';\n465:    document.body.style.userSelect = 'none';\n811:    const isDark = theme === 'dark';\n1452:    invoke('set_native_theme', { theme });\n1596:          theme: 'os-theme-dark',\n1689:<div class=\"app-shell\" data-theme={theme} data-platform={platform}>\n1743:            Name{#if sortBy === 'name'}{@html sortIconHtml(sortDir)}{/if}\n1756:            Path{#if sortBy === 'dir'}{@html sortIconHtml(sortDir)}{/if}\n1769:            Size{#if sortBy === 'size'}{@html sortIconHtml(sortDir)}{/if}\n1775:            Modified{#if sortBy === 'mtime'}{@html sortIconHtml(sortDir)}{/if}\n1782:      class=\"table-body\"\n1845:      <button class=\"status-btn\" on:click={cycleTheme} title=\"Switch theme\">\n1846:        {#if theme === 'dark'}\n1847:[Omitted long matching line]\n1850:          <svg class=\"theme-icon\" viewBox=\"0 0 16 16\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.3\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M13.5 9.2A5.5 5.5 0 0 1 6.8 2.5 5.5 5.5 0 1 0 13.5 9.2z\"/></svg>\n1908:    color-scheme: light dark;\n1909:    --bg-app: transparent;\n1935:  @media (prefers-color-scheme: dark) {\n1937:      --bg-app: transparent;\n1965:  :global([data-theme=\"dark\"]) {\n1966:    color-scheme: dark;\n1967:    --bg-app: #1E1E21;\n1974:    --bg-input: #161618;\n1996:  :global([data-theme=\"light\"]) {\n1997:    color-scheme: light;\n1998:    --bg-app: #F5F5F7;\n2005:    --bg-input: #FFFFFF;\n2027:  :global([data-theme]) {\n2028:    background: var(--bg-app);\n2032:  :global([data-theme]) .search-bar {\n2035:    background: var(--bg-app);\n2039:  :global([data-theme]) .search-input {\n2049:  :global([data-theme]) .table-header {\n2050:    background: var(--bg-app);\n2053:  :global([data-theme]) .col-button {\n2057:  :global([data-theme]) .col.name .col-button {\n2062:  :global([data-theme]) .cell {\n2066:  :global([data-theme]) .cell.name {\n2073:  :global([data-theme]) .cell.path {\n2078:  :global([data-theme]) .cell.size {\n2082:  :global([data-theme]) .cell.modified {\n2088:  :global([data-theme]) .row.selected {\n2092:  /* Dim path/size/date cells in themed mode */\n2093:  :global([data-theme]) .cell.path,\n2094:  :global([data-theme]) .cell.size,\n2095:  :global([data-theme]) .cell.modified {\n2100:    background: transparent;\n2103:  :global(html, body) {\n2108:    background: transparent;\n2132:    background: var(--surface-header);\n2185:    background: transparent;\n2193:    background: var(--row-hover);\n\n[Showing results with pagination = limit: 60, offset: 0]"}]},"uuid":"defc7995-d0a5-4099-b1be-3c0c9a9a8140","timestamp":"2026-02-22T09:29:33.964Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"26:  const THEME_KEY = 'everything-theme';\n41:  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n42:  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n44:    theme = theme === 'dark' ? 'light' : 'dark';\n45:    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n46:    invoke('set_native_theme', { theme });\n454:      document.body.style.cursor = '';\n455:      document.body.style.userSelect = '';\n464:    document.body.style.cursor = 'col-resize';\n465:    document.body.style.userSelect = 'none';\n811:    const isDark = theme === 'dark';\n1452:    invoke('set_native_theme', { theme });\n1596:          theme: 'os-theme-dark',\n1689:<div class=\"app-shell\" data-theme={theme} data-platform={platform}>\n1743:            Name{#if sortBy === 'name'}{@html sortIconHtml(sortDir)}{/if}\n1756:            Path{#if sortBy === 'dir'}{@html sortIconHtml(sortDir)}{/if}\n1769:            Size{#if sortBy === 'size'}{@html sortIconHtml(sortDir)}{/if}\n1775:            Modified{#if sortBy === 'mtime'}{@html sortIconHtml(sortDir)}{/if}\n1782:      class=\"table-body\"\n1845:      <button class=\"status-btn\" on:click={cycleTheme} title=\"Switch theme\">\n1846:        {#if theme === 'dark'}\n1847:[Omitted long matching line]\n1850:          <svg class=\"theme-icon\" viewBox=\"0 0 16 16\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.3\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M13.5 9.2A5.5 5.5 0 0 1 6.8 2.5 5.5 5.5 0 1 0 13.5 9.2z\"/></svg>\n1908:    color-scheme: light dark;\n1909:    --bg-app: transparent;\n1935:  @media (prefers-color-scheme: dark) {\n1937:      --bg-app: transparent;\n1965:  :global([data-theme=\"dark\"]) {\n1966:    color-scheme: dark;\n1967:    --bg-app: #1E1E21;\n1974:    --bg-input: #161618;\n1996:  :global([data-theme=\"light\"]) {\n1997:    color-scheme: light;\n1998:    --bg-app: #F5F5F7;\n2005:    --bg-input: #FFFFFF;\n2027:  :global([data-theme]) {\n2028:    background: var(--bg-app);\n2032:  :global([data-theme]) .search-bar {\n2035:    background: var(--bg-app);\n2039:  :global([data-theme]) .search-input {\n2049:  :global([data-theme]) .table-header {\n2050:    background: var(--bg-app);\n2053:  :global([data-theme]) .col-button {\n2057:  :global([data-theme]) .col.name .col-button {\n2062:  :global([data-theme]) .cell {\n2066:  :global([data-theme]) .cell.name {\n2073:  :global([data-theme]) .cell.path {\n2078:  :global([data-theme]) .cell.size {\n2082:  :global([data-theme]) .cell.modified {\n2088:  :global([data-theme]) .row.selected {\n2092:  /* Dim path/size/date cells in themed mode */\n2093:  :global([data-theme]) .cell.path,\n2094:  :global([data-theme]) .cell.size,\n2095:  :global([data-theme]) .cell.modified {\n2100:    background: transparent;\n2103:  :global(html, body) {\n2108:    background: transparent;\n2132:    background: var(--surface-header);\n2185:    background: transparent;\n2193:    background: var(--row-hover);","numLines":60,"appliedLimit":60},"sourceToolAssistantUUID":"35560c70-6d59-4696-abdd-29e023370e2f"}
{"parentUuid":"defc7995-d0a5-4099-b1be-3c0c9a9a8140","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01EtPJL8svMGXqifYyVe8vr4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019YQoxDW3bcejaAxzjLxFVD","name":"Grep","input":{"pattern":"set_native_theme|background_color|window_background","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1250,"cache_creation_input_tokens":1427,"cache_read_input_tokens":36664,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1427},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYtAMrRNfsNjWMzoqj","type":"assistant","uuid":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5","timestamp":"2026-02-22T09:29:37.229Z"}
{"parentUuid":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_019YQoxDW3bcejaAxzjLxFVD","toolUseID":"toolu_019YQoxDW3bcejaAxzjLxFVD","timestamp":"2026-02-22T09:29:37.900Z","uuid":"3c34ff4b-3a45-4ff8-9f37-b20235f11ac4"}
{"parentUuid":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019YQoxDW3bcejaAxzjLxFVD","type":"tool_result","content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n5068:        let _ = window.set_background_color(Some(bg));\n5082:        let _ = window.set_background_color(Some(bg));\n5389:            set_native_theme,"}]},"uuid":"0468735c-82c4-4dce-9e8e-b29415a91bd5","timestamp":"2026-02-22T09:29:37.899Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n5068:        let _ = window.set_background_color(Some(bg));\n5082:        let _ = window.set_background_color(Some(bg));\n5389:            set_native_theme,","numLines":4},"sourceToolAssistantUUID":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5"}
{"parentUuid":"0468735c-82c4-4dce-9e8e-b29415a91bd5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01EtPJL8svMGXqifYyVe8vr4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte","offset":1900,"limit":120},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1250,"cache_creation_input_tokens":1427,"cache_read_input_tokens":36664,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1427},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYtAMrRNfsNjWMzoqj","type":"assistant","uuid":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a","timestamp":"2026-02-22T09:29:38.118Z"}
{"parentUuid":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","toolUseID":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","timestamp":"2026-02-22T09:29:38.126Z","uuid":"538696e4-33b3-4150-9cab-7a0c01899e58"}
{"parentUuid":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","type":"tool_result","content":"  1900→\n  1901→  {#if toast}\n  1902→    <div class=\"toast\">{toast}</div>\n  1903→  {/if}\n  1904→</div>\n  1905→\n  1906→<style>\n  1907→  :global(:root) {\n  1908→    color-scheme: light dark;\n  1909→    --bg-app: transparent;\n  1910→    --text-primary: #0d1826;\n  1911→    --text-muted: #48596c;\n  1912→    --bar-grad-top: rgba(255, 255, 255, 0.48);\n  1913→    --bar-grad-bottom: rgba(248, 250, 253, 0.42);\n  1914→    --surface-header: rgba(252, 252, 255, 0.40);\n  1915→    --surface: rgba(255, 255, 255, 0.22);\n  1916→    --border-soft: rgba(0, 0, 0, 0.07);\n  1917→    --border-input: rgba(0, 0, 0, 0.13);\n  1918→    --focus-ring: #6f96e6;\n  1919→    --row-border: rgba(0, 0, 0, 0.032);\n  1920→    --row-hover: rgba(0, 0, 0, 0.06);\n  1921→    --row-selected: rgba(0, 0, 0, 0.12);\n  1922→    --button-bg: rgba(255, 255, 255, 0.62);\n  1923→    --button-border: rgba(0, 0, 0, 0.10);\n  1924→    --button-text: #2c3e50;\n  1925→    --menu-bg: rgba(240, 241, 248, 0.90);\n  1926→    --menu-border: rgba(0, 0, 0, 0.06);\n  1927→    --menu-hover: rgba(255, 255, 255, 0.62);\n  1928→    --menu-text: #1a2a38;\n  1929→    --error-text: #b64545;\n  1930→    --warning-text: #8f6500;\n  1931→    --toast-bg: rgba(18, 22, 32, 0.90);\n  1932→    --toast-text: #ffffff;\n  1933→  }\n  1934→\n  1935→  @media (prefers-color-scheme: dark) {\n  1936→    :global(:root) {\n  1937→      --bg-app: transparent;\n  1938→      --text-primary: #e6e6ea;\n  1939→      --text-muted: #9494a4;\n  1940→      --bar-grad-top: rgba(38, 38, 46, 0.52);\n  1941→      --bar-grad-bottom: rgba(30, 30, 38, 0.46);\n  1942→      --surface-header: rgba(32, 32, 40, 0.46);\n  1943→      --surface: rgba(18, 18, 26, 0.32);\n  1944→      --border-soft: rgba(255, 255, 255, 0.065);\n  1945→      --border-input: rgba(255, 255, 255, 0.14);\n  1946→      --focus-ring: #5b8bd9;\n  1947→      --row-border: rgba(255, 255, 255, 0.026);\n  1948→      --row-hover: rgba(255, 255, 255, 0.08);\n  1949→      --row-selected: rgba(255, 255, 255, 0.14);\n  1950→      --button-bg: rgba(255, 255, 255, 0.072);\n  1951→      --button-border: rgba(255, 255, 255, 0.11);\n  1952→      --button-text: #d6d6e0;\n  1953→      --menu-bg: rgba(36, 36, 46, 0.90);\n  1954→      --menu-border: rgba(255, 255, 255, 0.066);\n  1955→      --menu-hover: rgba(255, 255, 255, 0.062);\n  1956→      --menu-text: #e0e0e8;\n  1957→      --error-text: #ff9d9d;\n  1958→      --warning-text: #e0c670;\n  1959→      --toast-bg: rgba(10, 10, 16, 0.93);\n  1960→      --toast-text: #f2f2f6;\n  1961→    }\n  1962→  }\n  1963→\n  1964→  /* Theme: Dark */\n  1965→  :global([data-theme=\"dark\"]) {\n  1966→    color-scheme: dark;\n  1967→    --bg-app: #1E1E21;\n  1968→    --text-primary: #B8BDC5;\n  1969→    --text-muted: #94A3B8;\n  1970→    --bar-grad-top: #1E1E21;\n  1971→    --bar-grad-bottom: #1E1E21;\n  1972→    --surface-header: #1E1E21;\n  1973→    --surface: #1E1E21;\n  1974→    --bg-input: #161618;\n  1975→    --border-soft: #2A2A2D;\n  1976→    --border-input: rgba(255, 255, 255, 0.06);\n  1977→    --focus-ring: #4DA8FF;\n  1978→    --accent: #4DA8FF;\n  1979→    --row-border: rgba(255, 255, 255, 0.02);\n  1980→    --row-hover: #282828;\n  1981→    --row-selected: rgba(77, 168, 255, 0.10);\n  1982→    --button-bg: rgba(255, 255, 255, 0.05);\n  1983→    --button-border: #2A2A2D;\n  1984→    --button-text: #94A3B8;\n  1985→    --menu-bg: #252528;\n  1986→    --menu-border: #2A2A2D;\n  1987→    --menu-hover: rgba(255, 255, 255, 0.04);\n  1988→    --menu-text: #E2E8F0;\n  1989→    --error-text: #ff9d9d;\n  1990→    --warning-text: #e0c670;\n  1991→    --toast-bg: rgba(10, 10, 16, 0.93);\n  1992→    --toast-text: #f2f2f6;\n  1993→  }\n  1994→\n  1995→  /* Theme: Light */\n  1996→  :global([data-theme=\"light\"]) {\n  1997→    color-scheme: light;\n  1998→    --bg-app: #F5F5F7;\n  1999→    --text-primary: #1C1C1E;\n  2000→    --text-muted: #6E6E7A;\n  2001→    --bar-grad-top: #F5F5F7;\n  2002→    --bar-grad-bottom: #F5F5F7;\n  2003→    --surface-header: #F5F5F7;\n  2004→    --surface: #F5F5F7;\n  2005→    --bg-input: #FFFFFF;\n  2006→    --border-soft: #D1D1D6;\n  2007→    --border-input: rgba(0, 0, 0, 0.10);\n  2008→    --focus-ring: #3A8BF5;\n  2009→    --accent: #3A8BF5;\n  2010→    --row-border: rgba(0, 0, 0, 0.04);\n  2011→    --row-hover: rgba(0, 0, 0, 0.04);\n  2012→    --row-selected: rgba(58, 139, 245, 0.10);\n  2013→    --button-bg: #FFFFFF;\n  2014→    --button-border: #D1D1D6;\n  2015→    --button-text: #3C3C43;\n  2016→    --menu-bg: #FFFFFF;\n  2017→    --menu-border: #D1D1D6;\n  2018→    --menu-hover: rgba(0, 0, 0, 0.05);\n  2019→    --menu-text: #1C1C1E;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d955d1bf-a95f-47da-8ac2-a009a2a0334c","timestamp":"2026-02-22T09:29:38.125Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src/App.svelte","content":"\n  {#if toast}\n    <div class=\"toast\">{toast}</div>\n  {/if}\n</div>\n\n<style>\n  :global(:root) {\n    color-scheme: light dark;\n    --bg-app: transparent;\n    --text-primary: #0d1826;\n    --text-muted: #48596c;\n    --bar-grad-top: rgba(255, 255, 255, 0.48);\n    --bar-grad-bottom: rgba(248, 250, 253, 0.42);\n    --surface-header: rgba(252, 252, 255, 0.40);\n    --surface: rgba(255, 255, 255, 0.22);\n    --border-soft: rgba(0, 0, 0, 0.07);\n    --border-input: rgba(0, 0, 0, 0.13);\n    --focus-ring: #6f96e6;\n    --row-border: rgba(0, 0, 0, 0.032);\n    --row-hover: rgba(0, 0, 0, 0.06);\n    --row-selected: rgba(0, 0, 0, 0.12);\n    --button-bg: rgba(255, 255, 255, 0.62);\n    --button-border: rgba(0, 0, 0, 0.10);\n    --button-text: #2c3e50;\n    --menu-bg: rgba(240, 241, 248, 0.90);\n    --menu-border: rgba(0, 0, 0, 0.06);\n    --menu-hover: rgba(255, 255, 255, 0.62);\n    --menu-text: #1a2a38;\n    --error-text: #b64545;\n    --warning-text: #8f6500;\n    --toast-bg: rgba(18, 22, 32, 0.90);\n    --toast-text: #ffffff;\n  }\n\n  @media (prefers-color-scheme: dark) {\n    :global(:root) {\n      --bg-app: transparent;\n      --text-primary: #e6e6ea;\n      --text-muted: #9494a4;\n      --bar-grad-top: rgba(38, 38, 46, 0.52);\n      --bar-grad-bottom: rgba(30, 30, 38, 0.46);\n      --surface-header: rgba(32, 32, 40, 0.46);\n      --surface: rgba(18, 18, 26, 0.32);\n      --border-soft: rgba(255, 255, 255, 0.065);\n      --border-input: rgba(255, 255, 255, 0.14);\n      --focus-ring: #5b8bd9;\n      --row-border: rgba(255, 255, 255, 0.026);\n      --row-hover: rgba(255, 255, 255, 0.08);\n      --row-selected: rgba(255, 255, 255, 0.14);\n      --button-bg: rgba(255, 255, 255, 0.072);\n      --button-border: rgba(255, 255, 255, 0.11);\n      --button-text: #d6d6e0;\n      --menu-bg: rgba(36, 36, 46, 0.90);\n      --menu-border: rgba(255, 255, 255, 0.066);\n      --menu-hover: rgba(255, 255, 255, 0.062);\n      --menu-text: #e0e0e8;\n      --error-text: #ff9d9d;\n      --warning-text: #e0c670;\n      --toast-bg: rgba(10, 10, 16, 0.93);\n      --toast-text: #f2f2f6;\n    }\n  }\n\n  /* Theme: Dark */\n  :global([data-theme=\"dark\"]) {\n    color-scheme: dark;\n    --bg-app: #1E1E21;\n    --text-primary: #B8BDC5;\n    --text-muted: #94A3B8;\n    --bar-grad-top: #1E1E21;\n    --bar-grad-bottom: #1E1E21;\n    --surface-header: #1E1E21;\n    --surface: #1E1E21;\n    --bg-input: #161618;\n    --border-soft: #2A2A2D;\n    --border-input: rgba(255, 255, 255, 0.06);\n    --focus-ring: #4DA8FF;\n    --accent: #4DA8FF;\n    --row-border: rgba(255, 255, 255, 0.02);\n    --row-hover: #282828;\n    --row-selected: rgba(77, 168, 255, 0.10);\n    --button-bg: rgba(255, 255, 255, 0.05);\n    --button-border: #2A2A2D;\n    --button-text: #94A3B8;\n    --menu-bg: #252528;\n    --menu-border: #2A2A2D;\n    --menu-hover: rgba(255, 255, 255, 0.04);\n    --menu-text: #E2E8F0;\n    --error-text: #ff9d9d;\n    --warning-text: #e0c670;\n    --toast-bg: rgba(10, 10, 16, 0.93);\n    --toast-text: #f2f2f6;\n  }\n\n  /* Theme: Light */\n  :global([data-theme=\"light\"]) {\n    color-scheme: light;\n    --bg-app: #F5F5F7;\n    --text-primary: #1C1C1E;\n    --text-muted: #6E6E7A;\n    --bar-grad-top: #F5F5F7;\n    --bar-grad-bottom: #F5F5F7;\n    --surface-header: #F5F5F7;\n    --surface: #F5F5F7;\n    --bg-input: #FFFFFF;\n    --border-soft: #D1D1D6;\n    --border-input: rgba(0, 0, 0, 0.10);\n    --focus-ring: #3A8BF5;\n    --accent: #3A8BF5;\n    --row-border: rgba(0, 0, 0, 0.04);\n    --row-hover: rgba(0, 0, 0, 0.04);\n    --row-selected: rgba(58, 139, 245, 0.10);\n    --button-bg: #FFFFFF;\n    --button-border: #D1D1D6;\n    --button-text: #3C3C43;\n    --menu-bg: #FFFFFF;\n    --menu-border: #D1D1D6;\n    --menu-hover: rgba(0, 0, 0, 0.05);\n    --menu-text: #1C1C1E;","numLines":120,"startLine":1900,"totalLines":2738}},"sourceToolAssistantUUID":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a"}
{"parentUuid":"d955d1bf-a95f-47da-8ac2-a009a2a0334c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Tr7kHTbK3JdCNfYeoHJrTq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":4650,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3975,"cache_read_input_tokens":38091,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3975},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZBwgpwH6AWKoETPiD","type":"assistant","uuid":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba","timestamp":"2026-02-22T09:29:40.673Z"}
{"parentUuid":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","toolUseID":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","timestamp":"2026-02-22T09:29:40.699Z","uuid":"3a098788-20e2-4ae3-a464-b7e9a6b8012a"}
{"parentUuid":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","type":"tool_result","content":"  4650→    .await\n  4651→    .map_err(|e| e.to_string())?\n  4652→}\n  4653→\n  4654→#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n  4655→#[tauri::command]\n  4656→async fn show_context_menu(\n  4657→    _paths: Vec<String>,\n  4658→    _x: f64,\n  4659→    _y: f64,\n  4660→    _single_selection: bool,\n  4661→    _app: AppHandle,\n  4662→) -> AppResult<()> {\n  4663→    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n  4664→}\n  4665→\n  4666→#[tauri::command]\n  4667→async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n  4668→    let window = app\n  4669→        .get_webview_window(\"main\")\n  4670→        .ok_or_else(|| \"Main window not found\".to_string())?;\n  4671→    let t = if theme == \"light\" {\n  4672→        tauri::Theme::Light\n  4673→    } else {\n  4674→        tauri::Theme::Dark\n  4675→    };\n  4676→    window.set_theme(Some(t)).map_err(|e| e.to_string())\n  4677→}\n  4678→\n  4679→#[tauri::command]\n  4680→async fn get_file_icon(\n  4681→    path: Option<String>,\n  4682→    ext: String,\n  4683→    state: State<'_, AppState>,\n  4684→) -> AppResult<Vec<u8>> {\n  4685→    let state = state.inner().clone();\n  4686→    Ok(tauri::async_runtime::spawn_blocking(move || {\n  4687→        let ext_lower = if ext.trim().is_empty() {\n  4688→            \"__default__\".to_string()\n  4689→        } else {\n  4690→            ext.to_lowercase()\n  4691→        };\n  4692→\n  4693→        #[cfg(target_os = \"windows\")]\n  4694→        let cache_key = {\n  4695→            if is_per_file_icon_ext(&ext_lower) {\n  4696→                path.as_deref().unwrap_or(&ext_lower).to_string()\n  4697→            } else {\n  4698→                ext_lower.clone()\n  4699→            }\n  4700→        };\n  4701→        #[cfg(not(target_os = \"windows\"))]\n  4702→        let cache_key = ext_lower.clone();\n  4703→\n  4704→        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n  4705→            return cached;\n  4706→        }\n  4707→\n  4708→        #[cfg(target_os = \"windows\")]\n  4709→        let icon = {\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"cefc6ea9-5ed8-49e5-95da-d6e87e6314fc","timestamp":"2026-02-22T09:29:40.696Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {","numLines":60,"startLine":4650,"totalLines":5880}},"sourceToolAssistantUUID":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba"}
{"parentUuid":"cefc6ea9-5ed8-49e5-95da-d6e87e6314fc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Tr7kHTbK3JdCNfYeoHJrTq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LP4AYdW9tSLrciZetrFgho","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":5055,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3975,"cache_read_input_tokens":38091,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3975},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZBwgpwH6AWKoETPiD","type":"assistant","uuid":"78838d6e-ed24-4bf1-9e53-21a81123ab1d","timestamp":"2026-02-22T09:29:41.385Z"}
{"parentUuid":"78838d6e-ed24-4bf1-9e53-21a81123ab1d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01LP4AYdW9tSLrciZetrFgho","toolUseID":"toolu_01LP4AYdW9tSLrciZetrFgho","timestamp":"2026-02-22T09:29:41.400Z","uuid":"c1b23085-69be-4c51-a978-1ac8c3c015f3"}
{"parentUuid":"78838d6e-ed24-4bf1-9e53-21a81123ab1d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LP4AYdW9tSLrciZetrFgho","type":"tool_result","content":"  5055→\n  5056→    #[cfg(target_os = \"macos\")]\n  5057→    if let Some(window) = app.get_webview_window(\"main\") {\n  5058→        use tauri::window::Color;\n  5059→        let is_dark = window\n  5060→            .theme()\n  5061→            .map(|t| t == tauri::Theme::Dark)\n  5062→            .unwrap_or(false);\n  5063→        let bg = if is_dark {\n  5064→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5065→        } else {\n  5066→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5067→        };\n  5068→        let _ = window.set_background_color(Some(bg));\n  5069→        let _ = window.show();\n  5070→    }\n  5071→\n  5072→    #[cfg(target_os = \"windows\")]\n  5073→    if let Some(window) = app.get_webview_window(\"main\") {\n  5074→        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n  5075→        use tauri::window::Color;\n  5076→        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n  5077→        let bg = if is_dark {\n  5078→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5079→        } else {\n  5080→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5081→        };\n  5082→        let _ = window.set_background_color(Some(bg));\n  5083→        if let Err(e) = window.set_decorations(false) {\n  5084→            eprintln!(\n  5085→                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n  5086→                startup_elapsed_ms(),\n  5087→                e\n  5088→            );\n  5089→        }\n  5090→        let _ = window.show();\n  5091→        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n  5092→    }\n  5093→\n  5094→    let app_data_dir = app\n  5095→        .path()\n  5096→        .app_data_dir()\n  5097→        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n  5098→    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n  5099→\n  5100→    let db_path = app_data_dir.join(\"index.db\");\n  5101→    let home_dir = PathBuf::from(\n  5102→        std::env::var(\"HOME\")\n  5103→            .or_else(|_| std::env::var(\"USERPROFILE\"))\n  5104→            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ea584d30-9f4f-41db-964c-867a78dc9d14","timestamp":"2026-02-22T09:29:41.399Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),","numLines":50,"startLine":5055,"totalLines":5880}},"sourceToolAssistantUUID":"78838d6e-ed24-4bf1-9e53-21a81123ab1d"}
{"parentUuid":"ea584d30-9f4f-41db-964c-867a78dc9d14","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Si14DYjXLezbfNa8tjiTu2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the issue. Let me analyze what's happening:\n\n1. System dark theme → user switches to light theme in the app (via `cycleTheme()`)\n2. `cycleTheme()` calls `invoke('set_native_theme', { theme })` which calls the Rust `set_native_theme` command\n3. `set_native_theme` only calls `window.set_theme(Some(t))` - it does NOT update the window background color\n4. At app startup, `set_background_color` is called based on the system theme to avoid flash\n5. But when the user manually switches theme, `set_background_color` is never updated\n\n\n6. When the window is maximized/fullscreen via title bar double-click, the OS shows the native window background during the animation, and since it's still set to dark (from startup), it flashes against the new light theme\n\nThe solution is to update `set_native_theme` to also call `window.set_background_color()` with the appropriate color for the new theme.\n\nUpdating the Rust command... I need to use the CSS color values for consistency since there's a mismatch between what the startup code sets and what the user preference system should use. The real issue is that the startup only respects the system theme, so if a user's stored preference differs from their system theme, the background color won't update when they switch themes through the app.\n\nLooking at how the frontend initializes, it reads the stored theme preference from localStorage and calls `set_native_theme` on mount to sync with the native window, but since that function doesn't update the background color, there's a disconnect between what the native window shows and what the frontend displays.\n\nThe fix is straightforward: I need to update `set_native_theme` to also set the background color when the theme changes, so both the initial sync and any subsequent theme switches will keep everything in sync.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2190,"cache_read_input_tokens":42066,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2190},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZS1HBD1hy9yt4j51h","type":"assistant","uuid":"0e501162-31d4-42a8-a07a-b7a7cbe0f93f","timestamp":"2026-02-22T09:30:01.387Z"}
{"parentUuid":"0e501162-31d4-42a8-a07a-b7a7cbe0f93f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Si14DYjXLezbfNa8tjiTu2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte","offset":1440,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2190,"cache_read_input_tokens":42066,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2190},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZS1HBD1hy9yt4j51h","type":"assistant","uuid":"9d8b88d8-0218-4067-ba50-8fde16214449","timestamp":"2026-02-22T09:30:01.724Z"}
{"parentUuid":"9d8b88d8-0218-4067-ba50-8fde16214449","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","toolUseID":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","timestamp":"2026-02-22T09:30:01.735Z","uuid":"7cc3afb1-18a1-4010-8e52-9c2bf6b8c46c"}
{"parentUuid":"9d8b88d8-0218-4067-ba50-8fde16214449","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","type":"tool_result","content":"  1440→          `[startup/fe] +${ms()}ms ${name} failed (${Math.round(performance.now() - startedAt)}ms): ${String(err)}`\n  1441→        );\n  1442→        throw err;\n  1443→      }\n  1444→    };\n  1445→\n  1446→    startupLog('[startup/fe] onMount entered');\n  1447→    try {\n  1448→\n  1449→    updateViewportHeight();\n  1450→    startupLog(`[startup/fe] +${ms()}ms updateViewportHeight done`);\n  1451→\n  1452→    invoke('set_native_theme', { theme });\n  1453→\n  1454→    platform = await step('invoke(get_platform)', () => invoke('get_platform'));\n  1455→\n  1456→    let unlistenResized = null;\n  1457→    if (platform === 'windows') {\n  1458→      try {\n  1459→        isMaximized = await appWindow.isMaximized().catch(() => false);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1936f7b4-39db-4e43-976c-1d4b212eb925","timestamp":"2026-02-22T09:30:01.734Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src/App.svelte","content":"          `[startup/fe] +${ms()}ms ${name} failed (${Math.round(performance.now() - startedAt)}ms): ${String(err)}`\n        );\n        throw err;\n      }\n    };\n\n    startupLog('[startup/fe] onMount entered');\n    try {\n\n    updateViewportHeight();\n    startupLog(`[startup/fe] +${ms()}ms updateViewportHeight done`);\n\n    invoke('set_native_theme', { theme });\n\n    platform = await step('invoke(get_platform)', () => invoke('get_platform'));\n\n    let unlistenResized = null;\n    if (platform === 'windows') {\n      try {\n        isMaximized = await appWindow.isMaximized().catch(() => false);","numLines":20,"startLine":1440,"totalLines":2738}},"sourceToolAssistantUUID":"9d8b88d8-0218-4067-ba50-8fde16214449"}
{"parentUuid":"1936f7b4-39db-4e43-976c-1d4b212eb925","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01JdZA1L9b7aQeNMZ5pkCrVu","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I fully understand the issue:\n\n1. App starts with system dark theme\n2. `app.run()` (startup) calls `window.set_background_color(Color(0x1f, 0x1f, 0x1f, 0xff))` — dark background\n3. Frontend loads, reads localStorage and finds \"light\" theme preference\n4. `onMount` calls `invoke('set_native_theme', { theme: 'light' })` which changes window theme to light but does NOT call `set_background_color`\n5. Background color stays dark `0x1f, 0x1f, 0x1f`\n\n\n6. When user double-clicks title bar to fullscreen, the native macOS window expansion animation briefly shows the native background (dark) before the WebView content is drawn in the expanded size\n\nThe fix is to update `set_native_theme` to also call `set_background_color` with the appropriate color for each theme — `0xF5F5F7` for light mode and `0x1E1E21` for dark mode.\n\nI'm noticing the startup code uses slightly different values, but I think it's fine to keep those as-is and just ensure the theme switching uses the exact CSS colors for consistency. Actually, I should check if there's a similar flash issue happening at startup when the background color is first set.\n\nLooking at the sequence: the window gets a background color from the system theme before the frontend loads, then the frontend switches to the user's stored theme preference. There could be a flash there too if they differ, but that seems like expected behavior. The real issue the user is asking about is the title bar double-click problem, which I can fix by making sure `set_native_theme` also updates the background color to keep everything in sync.\n\nLet me implement that fix now.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1540,"cache_read_input_tokens":44256,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1540},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsavofTHtrzi3rHuJ8H","type":"assistant","uuid":"0655f213-dba3-45bc-b289-f9775a297026","timestamp":"2026-02-22T09:30:14.646Z"}
{"parentUuid":"0655f213-dba3-45bc-b289-f9775a297026","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01JdZA1L9b7aQeNMZ5pkCrVu","type":"message","role":"assistant","content":[{"type":"text","text":"원인 파악했습니다.\n\n**문제:**\n- 앱 시작 시 `app.run()`에서 시스템 테마(dark) 기준으로 `set_background_color(dark)`를 설정\n- 프론트엔드가 localStorage의 light 테마를 읽어 `set_native_theme(\"light\")` 호출\n- 그런데 `set_native_theme`은 `window.set_theme()`만 바꾸고 **`set_background_color`는 업데이트하지 않음**\n- 타이틀바 더블클릭 시 macOS 윈도우 확대 애니메이션 중에 네이티브 배경색(dark)이 잠깐 노출\n\n**수정:** `set_native_theme`에서 배경색도 함께 업데이트."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1540,"cache_read_input_tokens":44256,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1540},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsavofTHtrzi3rHuJ8H","type":"assistant","uuid":"2e462383-028c-4c26-aeb7-3030f31ceae7","timestamp":"2026-02-22T09:30:17.187Z"}
{"type":"file-history-snapshot","messageId":"c4c660b8-6144-48f3-8805-337c6c50fdb4","snapshot":{"messageId":"d21bd882-d4b7-4245-8b90-df7cecf1f692","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v1","version":1,"backupTime":"2026-02-22T09:30:20.781Z"}},"timestamp":"2026-02-22T09:29:21.012Z"},"isSnapshotUpdate":true}
{"parentUuid":"2e462383-028c-4c26-aeb7-3030f31ceae7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01JdZA1L9b7aQeNMZ5pkCrVu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}","new_string":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1540,"cache_read_input_tokens":44256,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1540},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsavofTHtrzi3rHuJ8H","type":"assistant","uuid":"c4c660b8-6144-48f3-8805-337c6c50fdb4","timestamp":"2026-02-22T09:30:20.774Z"}
{"parentUuid":"c4c660b8-6144-48f3-8805-337c6c50fdb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","toolUseID":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","timestamp":"2026-02-22T09:30:20.791Z","uuid":"e4f1ea7e-31ea-424b-9023-c9c0777b0be8"}
{"parentUuid":"c4c660b8-6144-48f3-8805-337c6c50fdb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"3008c51a-aff4-4a0b-863f-dd660d138e69","timestamp":"2026-02-22T09:30:20.790Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}","newString":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\n/// Phase 1: creates tables only. Fast even on large DBs.\nfn init_db_tables(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\n/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n/// when new indexes are added; runs after db_ready so it does not block startup.\nfn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n\n    conn.execute_batch(\n        r#\"\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n\n    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n        // range-scan optimization when an ESCAPE clause is present, causing a full\n        // table scan even though `path` has a UNIQUE (implicit) index.\n        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n        let lo = format!(\"{prefix}/\");\n        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n            params![prefix, lo, hi],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let conn = db_connection(&state.db_path)?;\n    let (entries_count, last_updated) = update_counts(&conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts so next startup can read them instantly\n    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_counts(conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(10),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":4668,"oldLines":12,"newStart":4668,"newLines":21,"lines":["     let window = app","         .get_webview_window(\"main\")","         .ok_or_else(|| \"Main window not found\".to_string())?;","-    let t = if theme == \"light\" {","+    let is_light = theme == \"light\";","+    let t = if is_light {","         tauri::Theme::Light","     } else {","         tauri::Theme::Dark","     };","-    window.set_theme(Some(t)).map_err(|e| e.to_string())","+    window.set_theme(Some(t)).map_err(|e| e.to_string())?;","+    use tauri::window::Color;","+    let bg = if is_light {","+        Color(0xF5, 0xF5, 0xF7, 0xFF)","+    } else {","+        Color(0x1E, 0x1E, 0x21, 0xFF)","+    };","+    let _ = window.set_background_color(Some(bg));","+    Ok(())"," }"," "," #[tauri::command]"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"c4c660b8-6144-48f3-8805-337c6c50fdb4"}
{"parentUuid":"3008c51a-aff4-4a0b-863f-dd660d138e69","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0128KRzFLRs85pzA4FdGQkX8","type":"message","role":"assistant","content":[{"type":"text","text":"이제 startup 코드의 배경색 값도 CSS와 일치시킵니다 (현재 `0x1f, 0x1f, 0x1f` vs CSS `#1E1E21`, `0xf4` vs `0xf5`):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1429,"cache_read_input_tokens":45796,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1429},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNscLH5RcD2f42pM5gLZ","type":"assistant","uuid":"9b6cbbb8-7419-49f2-a9bf-c6f8fa9904e8","timestamp":"2026-02-22T09:30:24.089Z"}
{"parentUuid":"9b6cbbb8-7419-49f2-a9bf-c6f8fa9904e8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0128KRzFLRs85pzA4FdGQkX8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":5056,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1429,"cache_read_input_tokens":45796,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1429},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNscLH5RcD2f42pM5gLZ","type":"assistant","uuid":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad","timestamp":"2026-02-22T09:30:24.751Z"}
{"parentUuid":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","toolUseID":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","timestamp":"2026-02-22T09:30:24.766Z","uuid":"dcb08923-676e-4802-9aa2-219ded61310b"}
{"parentUuid":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","type":"tool_result","content":"  5056→fn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n  5057→    Ok(())\n  5058→}\n  5059→\n  5060→fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n  5061→    let setup_started = std::time::Instant::now();\n  5062→    eprintln!(\"[startup] setup_app() entered\");\n  5063→    let bench_mode = bench_mode_enabled();\n  5064→\n  5065→    #[cfg(target_os = \"macos\")]\n  5066→    if let Some(window) = app.get_webview_window(\"main\") {\n  5067→        use tauri::window::Color;\n  5068→        let is_dark = window\n  5069→            .theme()\n  5070→            .map(|t| t == tauri::Theme::Dark)\n  5071→            .unwrap_or(false);\n  5072→        let bg = if is_dark {\n  5073→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5074→        } else {\n  5075→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5076→        };\n  5077→        let _ = window.set_background_color(Some(bg));\n  5078→        let _ = window.show();\n  5079→    }\n  5080→\n  5081→    #[cfg(target_os = \"windows\")]\n  5082→    if let Some(window) = app.get_webview_window(\"main\") {\n  5083→        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n  5084→        use tauri::window::Color;\n  5085→        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n  5086→        let bg = if is_dark {\n  5087→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5088→        } else {\n  5089→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5090→        };\n  5091→        let _ = window.set_background_color(Some(bg));\n  5092→        if let Err(e) = window.set_decorations(false) {\n  5093→            eprintln!(\n  5094→                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n  5095→                startup_elapsed_ms(),\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d6f21170-884c-4938-b0c1-1e9f6b2ac142","timestamp":"2026-02-22T09:30:24.764Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),","numLines":40,"startLine":5056,"totalLines":5889}},"sourceToolAssistantUUID":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad"}
{"parentUuid":"d6f21170-884c-4938-b0c1-1e9f6b2ac142","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01CpzYp7DGGFgWwfeFNhnEZF","type":"message","role":"assistant","content":[{"type":"text","text":"startup 색상 값도 CSS 값과 일치시켜 일관성을 높입니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":956,"cache_read_input_tokens":47225,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":956},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNscdHGxgaUCW8fSV6k5","type":"assistant","uuid":"6b39aa7e-140e-45d1-a836-7d6bf089ba19","timestamp":"2026-02-22T09:30:26.845Z"}
{"parentUuid":"6b39aa7e-140e-45d1-a836-7d6bf089ba19","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01CpzYp7DGGFgWwfeFNhnEZF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UcHinwxMZf82uTwy7z7jKh","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };","new_string":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":956,"cache_read_input_tokens":47225,"output_tokens":840,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":956,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNscdHGxgaUCW8fSV6k5","type":"assistant","uuid":"794f0db6-0dd0-44a0-b608-7d95f2967b6e","timestamp":"2026-02-22T09:30:32.155Z"}
{"parentUuid":"794f0db6-0dd0-44a0-b608-7d95f2967b6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01UcHinwxMZf82uTwy7z7jKh","toolUseID":"toolu_01UcHinwxMZf82uTwy7z7jKh","timestamp":"2026-02-22T09:30:32.170Z","uuid":"a5aa740a-d671-41ab-9a0f-1939400799e9"}
{"parentUuid":"794f0db6-0dd0-44a0-b608-7d95f2967b6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UcHinwxMZf82uTwy7z7jKh","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"11bcf2e2-0282-4ce5-a092-310124c01166","timestamp":"2026-02-22T09:30:32.168Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };","newString":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\n/// Phase 1: creates tables only. Fast even on large DBs.\nfn init_db_tables(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\n/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n/// when new indexes are added; runs after db_ready so it does not block startup.\nfn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n\n    conn.execute_batch(\n        r#\"\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n\n    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n        // range-scan optimization when an ESCAPE clause is present, causing a full\n        // table scan even though `path` has a UNIQUE (implicit) index.\n        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n        let lo = format!(\"{prefix}/\");\n        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n            params![prefix, lo, hi],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let conn = db_connection(&state.db_path)?;\n    let (entries_count, last_updated) = update_counts(&conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts so next startup can read them instantly\n    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_counts(conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(10),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":5070,"oldLines":9,"newStart":5070,"newLines":9,"lines":["             .map(|t| t == tauri::Theme::Dark)","             .unwrap_or(false);","         let bg = if is_dark {","-            Color(0x1f, 0x1f, 0x1f, 0xff)","+            Color(0x1E, 0x1E, 0x21, 0xFF)","         } else {","-            Color(0xf4, 0xf5, 0xf7, 0xff)","+            Color(0xF5, 0xF5, 0xF7, 0xFF)","         };","         let _ = window.set_background_color(Some(bg));","         let _ = window.show();"]},{"oldStart":5084,"oldLines":9,"newStart":5084,"newLines":9,"lines":["         use tauri::window::Color;","         let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);","         let bg = if is_dark {","-            Color(0x1f, 0x1f, 0x1f, 0xff)","+            Color(0x1E, 0x1E, 0x21, 0xFF)","         } else {","-            Color(0xf4, 0xf5, 0xf7, 0xff)","+            Color(0xF5, 0xF5, 0xF7, 0xFF)","         };","         let _ = window.set_background_color(Some(bg));","         if let Err(e) = window.set_decorations(false) {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"794f0db6-0dd0-44a0-b608-7d95f2967b6e"}
{"parentUuid":"11bcf2e2-0282-4ce5-a092-310124c01166","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TuAQDnuRHs18C1VEmcLRQz","type":"message","role":"assistant","content":[{"type":"text","text":"변경 내용을 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":897,"cache_read_input_tokens":48181,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsdB1VWVLrTnZ9T8gDP","type":"assistant","uuid":"f61f8998-8e6f-44af-8d2c-0215718949a2","timestamp":"2026-02-22T09:30:34.155Z"}
{"parentUuid":"f61f8998-8e6f-44af-8d2c-0215718949a2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TuAQDnuRHs18C1VEmcLRQz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HsXewPjEr7dkErMPdH3y25","name":"Grep","input":{"pattern":"set_background_color|set_native_theme|0x1E|0xF5","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":897,"cache_read_input_tokens":48181,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsdB1VWVLrTnZ9T8gDP","type":"assistant","uuid":"07e3890c-e830-43f2-8c7c-e61342a1bcc8","timestamp":"2026-02-22T09:30:35.380Z"}
{"parentUuid":"07e3890c-e830-43f2-8c7c-e61342a1bcc8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01HsXewPjEr7dkErMPdH3y25","toolUseID":"toolu_01HsXewPjEr7dkErMPdH3y25","timestamp":"2026-02-22T09:30:36.150Z","uuid":"94bf897e-72dd-42c0-80ce-c4186ecf253b"}
{"parentUuid":"07e3890c-e830-43f2-8c7c-e61342a1bcc8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HsXewPjEr7dkErMPdH3y25","type":"tool_result","content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n4680:        Color(0xF5, 0xF5, 0xF7, 0xFF)\n4682:        Color(0x1E, 0x1E, 0x21, 0xFF)\n4684:    let _ = window.set_background_color(Some(bg));\n5073:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5075:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5077:        let _ = window.set_background_color(Some(bg));\n5087:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5089:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5091:        let _ = window.set_background_color(Some(bg));\n5398:            set_native_theme,"}]},"uuid":"900d4755-6fb2-4c00-8807-b9cdc75e04ca","timestamp":"2026-02-22T09:30:36.149Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n4680:        Color(0xF5, 0xF5, 0xF7, 0xFF)\n4682:        Color(0x1E, 0x1E, 0x21, 0xFF)\n4684:    let _ = window.set_background_color(Some(bg));\n5073:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5075:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5077:        let _ = window.set_background_color(Some(bg));\n5087:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5089:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5091:        let _ = window.set_background_color(Some(bg));\n5398:            set_native_theme,","numLines":11},"sourceToolAssistantUUID":"07e3890c-e830-43f2-8c7c-e61342a1bcc8"}
{"parentUuid":"900d4755-6fb2-4c00-8807-b9cdc75e04ca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_011mfunRKFuZWvP39JN8EAR3","type":"message","role":"assistant","content":[{"type":"text","text":"정리하면:\n\n**수정 요약:**\n\n| 위치 | 변경 전 | 변경 후 |\n|------|---------|---------|\n| `set_native_theme()` | `set_theme()` 만 호출 | `set_theme()` + `set_background_color()` 함께 호출 |\n| startup 배경색 (macOS/Windows) | `0x1f,0x1f,0x1f` / `0xf4,0xf5,0xf7` | `#1E1E21` / `#F5F5F7` (CSS와 일치) |\n\n**동작 방식:**\n- 앱 시작 → 시스템 테마로 native 배경 설정 (기존)\n- `onMount`에서 `set_native_theme(stored_theme)` 호출 → 이제 배경색도 업데이트됨\n- 테마 버튼 클릭 → 배경색도 즉시 업데이트됨\n- 타이틀바 더블클릭 애니메이션 중에는 올바른 배경색이 노출됨"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":434,"cache_read_input_tokens":49078,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":434},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsdU3BDdtk8Z58yMLYd","type":"assistant","uuid":"a1688af8-bee0-4160-9240-79f48ae62eca","timestamp":"2026-02-22T09:30:42.944Z"}
{"parentUuid":"a1688af8-bee0-4160-9240-79f48ae62eca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6cbd0ca6-08bb-45b3-af9a-a3c6f580fcf0","toolUseID":"6cbd0ca6-08bb-45b3-af9a-a3c6f580fcf0","timestamp":"2026-02-22T09:30:42.980Z","uuid":"53fcf34b-ead0-43eb-86e7-b657a911b02f"}
{"parentUuid":"53fcf34b-ead0-43eb-86e7-b657a911b02f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":3974}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-22T09:30:46.955Z","uuid":"e00157cb-782e-4dc8-bc87-42a0eaf54a8f","toolUseID":"6cbd0ca6-08bb-45b3-af9a-a3c6f580fcf0"}
{"parentUuid":"e00157cb-782e-4dc8-bc87-42a0eaf54a8f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"turn_duration","durationMs":85946,"timestamp":"2026-02-22T09:30:46.960Z","uuid":"20ac3687-9112-4281-80be-73046c6c6842","isMeta":false}
{"type":"file-history-snapshot","messageId":"4246c5e2-49d3-44b4-8410-d3988349200b","snapshot":{"messageId":"4246c5e2-49d3-44b4-8410-d3988349200b","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-22T09:36:47.635Z"}},"timestamp":"2026-02-22T09:36:47.634Z"},"isSnapshotUpdate":false}
{"parentUuid":"20ac3687-9112-4281-80be-73046c6c6842","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":"commit"},"uuid":"4246c5e2-49d3-44b4-8410-d3988349200b","timestamp":"2026-02-22T09:36:43.123Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"4246c5e2-49d3-44b4-8410-d3988349200b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01HxSCSXUt8M2yC11e8TuskB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LM4socjeFeqWfAruHeVjQF","name":"Bash","input":{"command":"git diff src-tauri/src/main.rs","description":"Show diff of changes"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":114,"cache_read_input_tokens":49826,"output_tokens":94,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":114,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNt6s23YfBHiECX1tebW","type":"assistant","uuid":"ce50938d-006f-4365-a061-06b75685a6e5","timestamp":"2026-02-22T09:36:50.296Z"}
{"parentUuid":"ce50938d-006f-4365-a061-06b75685a6e5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LM4socjeFeqWfAruHeVjQF","type":"tool_result","content":"diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs\nindex bf73d63..2f873f9 100644\n--- a/src-tauri/src/main.rs\n+++ b/src-tauri/src/main.rs\n@@ -44,7 +44,7 @@ const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n-const DB_VERSION: i32 = 4;\n+const DB_VERSION: i32 = 5;\n const DEFERRED_DIR_NAMES: &[&str] = &[\n     \"Library\", \".Trash\", \".Trashes\",\n     // Windows system directories (deferred when scan_root is C:\\)\n@@ -58,6 +58,12 @@ fn jwalk_num_threads() -> usize {\n         .unwrap_or(8)\n }\n \n+fn jwalk_num_threads_fresh() -> usize {\n+    std::thread::available_parallelism()\n+        .map(|n| n.get().max(4).min(16))\n+        .unwrap_or(8)\n+}\n+\n pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n     \".git\",\n     \"node_modules\",\n@@ -93,6 +99,18 @@ pub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n ];\n \n type AppResult<T> = Result<T, String>;\n+\n+// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\n+static BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\n+fn builtin_skip_path_checks() -> &'static [(String, String)] {\n+    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n+        BUILTIN_SKIP_PATHS\n+            .iter()\n+            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n+            .collect()\n+    })\n+}\n+\n static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n@@ -281,10 +299,27 @@ pub(crate) struct RecentOp {\n \n #[derive(Debug, Clone, PartialEq, Eq)]\n pub(crate) enum IgnorePattern {\n-    AnySegment(String),\n+    /// Matches any path segment equal to `segment`.\n+    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n+    /// per-call format! allocations in the hot path.\n+    AnySegment {\n+        segment: String,\n+        suffix: String,\n+        infix: String,\n+    },\n     Glob(String),\n }\n \n+impl IgnorePattern {\n+    pub(crate) fn any_segment(segment: &str) -> Self {\n+        IgnorePattern::AnySegment {\n+            suffix: format!(\"/{segment}\"),\n+            infix: format!(\"/{segment}/\"),\n+            segment: segment.to_string(),\n+        }\n+    }\n+}\n+\n #[derive(Debug, Clone)]\n pub(crate) struct IgnoreRulesCache {\n     roots: Vec<PathBuf>,\n@@ -411,10 +446,10 @@ fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n     conn.execute_batch(\n         r#\"\n-        PRAGMA synchronous = NORMAL;\n-        PRAGMA cache_size = -65536;\n-        PRAGMA mmap_size = 268435456;\n-        PRAGMA wal_autocheckpoint = 10000;\n+        PRAGMA synchronous = OFF;\n+        PRAGMA cache_size = -131072;\n+        PRAGMA mmap_size = 536870912;\n+        PRAGMA wal_autocheckpoint = 0;\n         \"#,\n     )\n     .map_err(|e| e.to_string())\n@@ -430,12 +465,16 @@ pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n+    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n+    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n+    // when the next auto-checkpoint threshold is hit.\n+    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n         .map_err(|e| e.to_string())?;\n     Ok(())\n }\n \n-fn init_db(db_path: &Path) -> AppResult<()> {\n+/// Phase 1: creates tables only. Fast even on large DBs.\n+fn init_db_tables(db_path: &Path) -> AppResult<()> {\n     let t = Instant::now();\n     let conn = db_connection(db_path)?;\n     eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n@@ -474,11 +513,6 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n           run_id INTEGER NOT NULL DEFAULT 0\n         );\n \n-        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n-        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n-\n         CREATE TABLE IF NOT EXISTS meta (\n           key TEXT PRIMARY KEY,\n           value TEXT NOT NULL\n@@ -486,18 +520,39 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n+\n+    Ok(())\n+}\n+\n+/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n+/// when new indexes are added; runs after db_ready so it does not block startup.\n+fn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n+    let t = Instant::now();\n+    let conn = db_connection(db_path)?;\n+\n+    conn.execute_batch(\n+        r#\"\n+        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n+        \"#,\n+    )\n+    .map_err(|e| e.to_string())?;\n+    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n \n-    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n-    let migrated = get_meta(&conn, legacy_index_migration_key)\n+    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n+    let migrated = get_meta(&conn, legacy_key)\n         .map(|v| v == \"1\")\n         .unwrap_or(false);\n     if !migrated {\n         conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n             .map_err(|e| e.to_string())?;\n-        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n+        set_meta(&conn, legacy_key, \"1\")?;\n     }\n-    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n \n     Ok(())\n }\n@@ -520,9 +575,7 @@ pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<(\n     Ok(())\n }\n \n-fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let conn = db_connection(&state.db_path)?;\n-\n+fn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n     let entries_count = conn\n         .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n             row.get::<_, i64>(0)\n@@ -539,14 +592,6 @@ fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n     Ok((entries_count, last_updated))\n }\n \n-pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let (entries_count, last_updated) = update_counts(state)?;\n-    let mut status = state.status.lock();\n-    status.entries_count = entries_count;\n-    status.last_updated = last_updated;\n-    Ok((entries_count, last_updated))\n-}\n-\n pub(crate) fn invalidate_search_caches(state: &AppState) {\n     state.fd_search_cache.lock().take();\n     state.negative_name_cache.lock().clear();\n@@ -745,7 +790,7 @@ fn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n }\n \n fn normalize_slashes(s: String) -> String {\n-    s.replace('\\\\', \"/\")\n+    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n }\n \n fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n@@ -791,7 +836,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n     if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n         if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n-            return Some(IgnorePattern::AnySegment(segment.to_string()));\n+            return Some(IgnorePattern::any_segment(segment));\n         }\n     }\n \n@@ -802,7 +847,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n+        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n         IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n     }\n }\n@@ -1144,10 +1189,15 @@ fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult\n         }\n \n         let prefix = root_str.trim_end_matches('/');\n-        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n+        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n+        // range-scan optimization when an ESCAPE clause is present, causing a full\n+        // table scan even though `path` has a UNIQUE (implicit) index.\n+        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n+        let lo = format!(\"{prefix}/\");\n+        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n         conn.execute(\n-            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n-            params![prefix, descendant_like],\n+            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n+            params![prefix, lo, hi],\n         )\n         .map_err(|e| e.to_string())?;\n     }\n@@ -1208,10 +1258,8 @@ fn glob_match_path(pattern: &str, text: &str) -> bool {\n \n pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => {\n-            let suffix = format!(\"/{segment}\");\n-            let infix = format!(\"/{segment}/\");\n-            path.ends_with(&suffix) || path.contains(&infix)\n+        IgnorePattern::AnySegment { suffix, infix, .. } => {\n+            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n         }\n         IgnorePattern::Glob(glob) => {\n             let mut cur = path;\n@@ -1261,11 +1309,10 @@ pub(crate) fn should_skip_path_ext(\n     }\n \n     // Multi-component builtin paths\n-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n-        let infix = format!(\"/{pat}/\");\n-        let suffix = format!(\"/{pat}\");\n-        s.contains(&infix) || s.ends_with(&suffix)\n-    }) {\n+    if builtin_skip_path_checks()\n+        .iter()\n+        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n+    {\n         return true;\n     }\n \n@@ -1354,10 +1401,6 @@ fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n     index_row_from_path_and_metadata(entry.path(), &metadata)\n }\n \n-fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n-    let metadata = entry.metadata().ok()?;\n-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n-}\n \n fn collect_rows_recursive(\n     root: &Path,\n@@ -1839,13 +1882,17 @@ fn emit_status_counts(app: &AppHandle, state: &AppState) {\n }\n \n pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let conn = db_connection(&state.db_path)?;\n+    let (entries_count, last_updated) = update_counts(&conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts so next startup can read them instantly\n-    if let Ok(conn) = db_connection(&state.db_path) {\n-        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n-        if let Some(lu) = last_updated {\n-            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n-        }\n+    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n+    if let Some(lu) = last_updated {\n+        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n     }\n     emit_status_counts(app, state);\n     Ok(())\n@@ -2009,10 +2056,41 @@ fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n     let mut conn = db_connection(&state.db_path)?;\n     set_indexing_pragmas(&conn)?;\n \n+    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n+    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n+    // which can be 3-5x faster when loading hundreds of thousands of rows.\n+    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n+        .and_then(|v| v.parse::<i64>().ok())\n+        .unwrap_or(0)\n+        == 0;\n+    if is_fresh_run {\n+        let _ = conn.execute_batch(\n+            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_mtime;\n+             DROP INDEX IF EXISTS idx_entries_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n+        );\n+    }\n+\n     let result = run_incremental_index_inner(app, state, &mut conn);\n \n+    if is_fresh_run {\n+        let t_idx = Instant::now();\n+        let _ = conn.execute_batch(\n+            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n+        );\n+        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n+    }\n+\n+    let t_analyze = Instant::now();\n     let _ = conn.execute_batch(\"ANALYZE\");\n+    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n+    let t_checkpoint = Instant::now();\n     let _ = restore_normal_pragmas(&conn);\n+    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n \n     match &result {\n         Ok(_) => {\n@@ -2061,12 +2139,16 @@ fn run_incremental_index_inner(\n     // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n     let is_fresh = last_run_id == 0;\n \n+    // Fresh index has no secondary indexes to maintain, so we can use larger\n+    // batches to reduce transaction overhead (fewer commits = faster).\n+    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n+\n     let mut scanned: u64 = 0;\n     let mut indexed: u64 = 0;\n     let mut permission_errors: u64 = 0;\n     let mut current_path = String::new();\n-    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n-    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n+    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n+    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n     let mut last_emit = Instant::now();\n     let mut last_perf_emit = Instant::now();\n \n@@ -2135,7 +2217,7 @@ fn run_incremental_index_inner(\n \n \n     // Flush home-level stamp batch\n-    if stamp_batch.len() >= BATCH_SIZE {\n+    if stamp_batch.len() >= flush_batch_size {\n         stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n         stamp_batch.clear();\n     }\n@@ -2184,43 +2266,59 @@ fn run_incremental_index_inner(\n             let skip_roots = arc_ignored_roots.clone();\n             let skip_patterns = arc_ignored_patterns.clone();\n \n-            let mut builder = jwalk::WalkDir::new(root)\n+            // Use more threads for fresh index: stat() calls are the bottleneck,\n+            // more rayon threads = more parallel stat() calls.\n+            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n+            let current_pass = pass;\n+            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                 .follow_links(false)\n                 .skip_hidden(false)\n-                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n+                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n             // Fresh index: no depth limit -- walk everything in one pass\n             if pass == 0 && !is_fresh {\n                 builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n             }\n             let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n-                children.retain(|entry_result| {\n-                    entry_result\n-                        .as_ref()\n-                        .map(|entry| {\n+                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n+                // Running stat() here parallelizes it across rayon threads (one per directory).\n+                children.retain_mut(|entry_result| {\n+                    match entry_result {\n+                        Ok(entry) => {\n                             let full_path = path.join(&entry.file_name);\n                             let is_dir = Some(entry.file_type.is_dir());\n-                            !should_skip_path_ext(\n+                            if should_skip_path_ext(\n                                 &full_path,\n                                 &skip_roots,\n                                 &skip_patterns,\n                                 Some(&gi_ref),\n                                 is_dir,\n-                            )\n-                        })\n-                        .unwrap_or(false)\n+                            ) {\n+                                return false;\n+                            }\n+                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n+                            // main thread). Skip for pass-1 shallow entries that will be\n+                            // discarded in the main loop anyway.\n+                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n+                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n+                            }\n+                            true\n+                        }\n+                        Err(_) => false,\n+                    }\n                 });\n             });\n \n             for result in walker {\n                 match result {\n                     Ok(entry) => {\n+                        let entry_depth = entry.depth;\n                         let path = entry.path();\n                         if path == root.as_path() {\n                             continue;\n                         }\n \n                         // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n-                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n+                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                             continue;\n                         }\n \n@@ -2228,7 +2326,18 @@ fn run_incremental_index_inner(\n                         root_scanned += 1;\n                         current_path = path.to_string_lossy().to_string();\n \n-                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n+                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n+                        let metadata = match entry.client_state {\n+                            Some(m) => m,\n+                            None => {\n+                                // pre-fetch failed (permission error or race condition)\n+                                permission_errors += 1;\n+                                root_permission_errors += 1;\n+                                continue;\n+                            }\n+                        };\n+\n+                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                             row.run_id = current_run_id;\n                             if is_fresh {\n                                 // Fresh index: all entries are new, skip existing check\n@@ -2250,12 +2359,12 @@ fn run_incremental_index_inner(\n                             }\n                         }\n \n-                        if batch.len() >= BATCH_SIZE {\n+                        if batch.len() >= flush_batch_size {\n                             upsert_rows(conn, &batch)?;\n                             batch.clear();\n                         }\n \n-                        if stamp_batch.len() >= BATCH_SIZE {\n+                        if stamp_batch.len() >= flush_batch_size {\n                             stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                             stamp_batch.clear();\n                         }\n@@ -2373,7 +2482,12 @@ fn run_incremental_index_inner(\n         invalidate_search_caches(state);\n     }\n \n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let (entries_count, last_updated) = update_counts(conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts for instant startup next time\n     let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n     if let Some(lu) = last_updated {\n@@ -2645,7 +2759,7 @@ fn start_fsevent_watcher_worker(\n         let mut last_flush = Instant::now();\n         let mut last_status_emit = Instant::now();\n         let mut pending_status_emit = false;\n-        let mut last_count_refresh = Instant::now();\n+\n         let mut must_scan_count: usize = 0;\n         let mut replay_phase = conditional;\n         let mut full_scan_triggered = false;\n@@ -2660,7 +2774,7 @@ fn start_fsevent_watcher_worker(\n                         due - now\n                     }\n                 }\n-                None => Duration::from_secs(1),\n+                None => Duration::from_secs(10),\n             };\n             match rx.recv_timeout(wait) {\n                 Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n@@ -2771,11 +2885,6 @@ fn start_fsevent_watcher_worker(\n                 last_flush = Instant::now();\n             }\n \n-            // Periodic count refresh to keep in-memory counts accurate\n-            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n-                let _ = update_status_counts(&state);\n-                last_count_refresh = Instant::now();\n-            }\n         }\n \n         // Final flush on shutdown\n@@ -2953,6 +3062,10 @@ async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()\n         }\n \n         let conn = db_connection(&state.db_path)?;\n+        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n+        let _ = conn.execute_batch(\n+            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n+        );\n         conn.execute(\"DELETE FROM entries\", [])\n             .map_err(|e| e.to_string())?;\n         conn.execute(\"DELETE FROM meta\", [])\n@@ -4555,12 +4668,21 @@ async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n     let window = app\n         .get_webview_window(\"main\")\n         .ok_or_else(|| \"Main window not found\".to_string())?;\n-    let t = if theme == \"light\" {\n+    let is_light = theme == \"light\";\n+    let t = if is_light {\n         tauri::Theme::Light\n     } else {\n         tauri::Theme::Dark\n     };\n-    window.set_theme(Some(t)).map_err(|e| e.to_string())\n+    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n+    use tauri::window::Color;\n+    let bg = if is_light {\n+        Color(0xF5, 0xF5, 0xF7, 0xFF)\n+    } else {\n+        Color(0x1E, 0x1E, 0x21, 0xFF)\n+    };\n+    let _ = window.set_background_color(Some(bg));\n+    Ok(())\n }\n \n #[tauri::command]\n@@ -4948,9 +5070,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n             .map(|t| t == tauri::Theme::Dark)\n             .unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         let _ = window.show();\n@@ -4962,9 +5084,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         use tauri::window::Color;\n         let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         if let Err(e) = window.set_decorations(false) {\n@@ -5070,17 +5192,27 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         let thread_started = std::time::Instant::now();\n         eprintln!(\"[startup/thread] init thread started\");\n \n-        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n-        if let Err(err) = init_db(&state.db_path) {\n+        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n+        if let Err(err) = init_db_tables(&state.db_path) {\n             set_state(&state, IndexState::Error, Some(err.clone()));\n             emit_index_state(&app_handle, \"Error\", Some(err));\n             return;\n         }\n-        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n+        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n \n         state.db_ready.store(true, AtomicOrdering::Release);\n         eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n \n+        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n+        {\n+            let idx_db_path = state.db_path.clone();\n+            std::thread::spawn(move || {\n+                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n+                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n+                }\n+            });\n+        }\n+\n         // Deferred housekeeping -- purge + status counts run in background\n         {\n             let hk_app = app_handle.clone();\n@@ -5372,7 +5504,7 @@ mod tests {\n \n     #[test]\n     fn should_skip_path_for_glob_any_segment_target() {\n-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n+        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n \n         assert!(should_skip_path(\n             Path::new(\"/Users/al02402336/work/rust/target\"),\n@@ -5436,7 +5568,8 @@ mod tests {\n         fs::create_dir_all(&dir_b).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let mut conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5478,7 +5611,8 @@ mod tests {\n         fs::create_dir_all(&archived_src).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5606,7 +5740,8 @@ mod tests {\n         fs::create_dir_all(&sub_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5715,7 +5850,8 @@ mod tests {\n         fs::create_dir_all(&proj_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();","is_error":false}]},"uuid":"e3c047ed-3601-41e4-9898-c494e404f3ce","timestamp":"2026-02-22T09:36:50.891Z","toolUseResult":{"stdout":"diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs\nindex bf73d63..2f873f9 100644\n--- a/src-tauri/src/main.rs\n+++ b/src-tauri/src/main.rs\n@@ -44,7 +44,7 @@ const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n-const DB_VERSION: i32 = 4;\n+const DB_VERSION: i32 = 5;\n const DEFERRED_DIR_NAMES: &[&str] = &[\n     \"Library\", \".Trash\", \".Trashes\",\n     // Windows system directories (deferred when scan_root is C:\\)\n@@ -58,6 +58,12 @@ fn jwalk_num_threads() -> usize {\n         .unwrap_or(8)\n }\n \n+fn jwalk_num_threads_fresh() -> usize {\n+    std::thread::available_parallelism()\n+        .map(|n| n.get().max(4).min(16))\n+        .unwrap_or(8)\n+}\n+\n pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n     \".git\",\n     \"node_modules\",\n@@ -93,6 +99,18 @@ pub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n ];\n \n type AppResult<T> = Result<T, String>;\n+\n+// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\n+static BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\n+fn builtin_skip_path_checks() -> &'static [(String, String)] {\n+    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n+        BUILTIN_SKIP_PATHS\n+            .iter()\n+            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n+            .collect()\n+    })\n+}\n+\n static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n@@ -281,10 +299,27 @@ pub(crate) struct RecentOp {\n \n #[derive(Debug, Clone, PartialEq, Eq)]\n pub(crate) enum IgnorePattern {\n-    AnySegment(String),\n+    /// Matches any path segment equal to `segment`.\n+    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n+    /// per-call format! allocations in the hot path.\n+    AnySegment {\n+        segment: String,\n+        suffix: String,\n+        infix: String,\n+    },\n     Glob(String),\n }\n \n+impl IgnorePattern {\n+    pub(crate) fn any_segment(segment: &str) -> Self {\n+        IgnorePattern::AnySegment {\n+            suffix: format!(\"/{segment}\"),\n+            infix: format!(\"/{segment}/\"),\n+            segment: segment.to_string(),\n+        }\n+    }\n+}\n+\n #[derive(Debug, Clone)]\n pub(crate) struct IgnoreRulesCache {\n     roots: Vec<PathBuf>,\n@@ -411,10 +446,10 @@ fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n     conn.execute_batch(\n         r#\"\n-        PRAGMA synchronous = NORMAL;\n-        PRAGMA cache_size = -65536;\n-        PRAGMA mmap_size = 268435456;\n-        PRAGMA wal_autocheckpoint = 10000;\n+        PRAGMA synchronous = OFF;\n+        PRAGMA cache_size = -131072;\n+        PRAGMA mmap_size = 536870912;\n+        PRAGMA wal_autocheckpoint = 0;\n         \"#,\n     )\n     .map_err(|e| e.to_string())\n@@ -430,12 +465,16 @@ pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n+    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n+    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n+    // when the next auto-checkpoint threshold is hit.\n+    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n         .map_err(|e| e.to_string())?;\n     Ok(())\n }\n \n-fn init_db(db_path: &Path) -> AppResult<()> {\n+/// Phase 1: creates tables only. Fast even on large DBs.\n+fn init_db_tables(db_path: &Path) -> AppResult<()> {\n     let t = Instant::now();\n     let conn = db_connection(db_path)?;\n     eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n@@ -474,11 +513,6 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n           run_id INTEGER NOT NULL DEFAULT 0\n         );\n \n-        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n-        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n-\n         CREATE TABLE IF NOT EXISTS meta (\n           key TEXT PRIMARY KEY,\n           value TEXT NOT NULL\n@@ -486,18 +520,39 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n+\n+    Ok(())\n+}\n+\n+/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n+/// when new indexes are added; runs after db_ready so it does not block startup.\n+fn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n+    let t = Instant::now();\n+    let conn = db_connection(db_path)?;\n+\n+    conn.execute_batch(\n+        r#\"\n+        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n+        \"#,\n+    )\n+    .map_err(|e| e.to_string())?;\n+    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n \n-    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n-    let migrated = get_meta(&conn, legacy_index_migration_key)\n+    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n+    let migrated = get_meta(&conn, legacy_key)\n         .map(|v| v == \"1\")\n         .unwrap_or(false);\n     if !migrated {\n         conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n             .map_err(|e| e.to_string())?;\n-        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n+        set_meta(&conn, legacy_key, \"1\")?;\n     }\n-    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n \n     Ok(())\n }\n@@ -520,9 +575,7 @@ pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<(\n     Ok(())\n }\n \n-fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let conn = db_connection(&state.db_path)?;\n-\n+fn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n     let entries_count = conn\n         .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n             row.get::<_, i64>(0)\n@@ -539,14 +592,6 @@ fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n     Ok((entries_count, last_updated))\n }\n \n-pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let (entries_count, last_updated) = update_counts(state)?;\n-    let mut status = state.status.lock();\n-    status.entries_count = entries_count;\n-    status.last_updated = last_updated;\n-    Ok((entries_count, last_updated))\n-}\n-\n pub(crate) fn invalidate_search_caches(state: &AppState) {\n     state.fd_search_cache.lock().take();\n     state.negative_name_cache.lock().clear();\n@@ -745,7 +790,7 @@ fn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n }\n \n fn normalize_slashes(s: String) -> String {\n-    s.replace('\\\\', \"/\")\n+    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n }\n \n fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n@@ -791,7 +836,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n     if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n         if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n-            return Some(IgnorePattern::AnySegment(segment.to_string()));\n+            return Some(IgnorePattern::any_segment(segment));\n         }\n     }\n \n@@ -802,7 +847,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n+        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n         IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n     }\n }\n@@ -1144,10 +1189,15 @@ fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult\n         }\n \n         let prefix = root_str.trim_end_matches('/');\n-        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n+        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n+        // range-scan optimization when an ESCAPE clause is present, causing a full\n+        // table scan even though `path` has a UNIQUE (implicit) index.\n+        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n+        let lo = format!(\"{prefix}/\");\n+        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n         conn.execute(\n-            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n-            params![prefix, descendant_like],\n+            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n+            params![prefix, lo, hi],\n         )\n         .map_err(|e| e.to_string())?;\n     }\n@@ -1208,10 +1258,8 @@ fn glob_match_path(pattern: &str, text: &str) -> bool {\n \n pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => {\n-            let suffix = format!(\"/{segment}\");\n-            let infix = format!(\"/{segment}/\");\n-            path.ends_with(&suffix) || path.contains(&infix)\n+        IgnorePattern::AnySegment { suffix, infix, .. } => {\n+            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n         }\n         IgnorePattern::Glob(glob) => {\n             let mut cur = path;\n@@ -1261,11 +1309,10 @@ pub(crate) fn should_skip_path_ext(\n     }\n \n     // Multi-component builtin paths\n-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n-        let infix = format!(\"/{pat}/\");\n-        let suffix = format!(\"/{pat}\");\n-        s.contains(&infix) || s.ends_with(&suffix)\n-    }) {\n+    if builtin_skip_path_checks()\n+        .iter()\n+        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n+    {\n         return true;\n     }\n \n@@ -1354,10 +1401,6 @@ fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n     index_row_from_path_and_metadata(entry.path(), &metadata)\n }\n \n-fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n-    let metadata = entry.metadata().ok()?;\n-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n-}\n \n fn collect_rows_recursive(\n     root: &Path,\n@@ -1839,13 +1882,17 @@ fn emit_status_counts(app: &AppHandle, state: &AppState) {\n }\n \n pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let conn = db_connection(&state.db_path)?;\n+    let (entries_count, last_updated) = update_counts(&conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts so next startup can read them instantly\n-    if let Ok(conn) = db_connection(&state.db_path) {\n-        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n-        if let Some(lu) = last_updated {\n-            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n-        }\n+    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n+    if let Some(lu) = last_updated {\n+        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n     }\n     emit_status_counts(app, state);\n     Ok(())\n@@ -2009,10 +2056,41 @@ fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n     let mut conn = db_connection(&state.db_path)?;\n     set_indexing_pragmas(&conn)?;\n \n+    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n+    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n+    // which can be 3-5x faster when loading hundreds of thousands of rows.\n+    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n+        .and_then(|v| v.parse::<i64>().ok())\n+        .unwrap_or(0)\n+        == 0;\n+    if is_fresh_run {\n+        let _ = conn.execute_batch(\n+            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_mtime;\n+             DROP INDEX IF EXISTS idx_entries_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n+        );\n+    }\n+\n     let result = run_incremental_index_inner(app, state, &mut conn);\n \n+    if is_fresh_run {\n+        let t_idx = Instant::now();\n+        let _ = conn.execute_batch(\n+            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n+        );\n+        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n+    }\n+\n+    let t_analyze = Instant::now();\n     let _ = conn.execute_batch(\"ANALYZE\");\n+    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n+    let t_checkpoint = Instant::now();\n     let _ = restore_normal_pragmas(&conn);\n+    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n \n     match &result {\n         Ok(_) => {\n@@ -2061,12 +2139,16 @@ fn run_incremental_index_inner(\n     // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n     let is_fresh = last_run_id == 0;\n \n+    // Fresh index has no secondary indexes to maintain, so we can use larger\n+    // batches to reduce transaction overhead (fewer commits = faster).\n+    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n+\n     let mut scanned: u64 = 0;\n     let mut indexed: u64 = 0;\n     let mut permission_errors: u64 = 0;\n     let mut current_path = String::new();\n-    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n-    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n+    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n+    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n     let mut last_emit = Instant::now();\n     let mut last_perf_emit = Instant::now();\n \n@@ -2135,7 +2217,7 @@ fn run_incremental_index_inner(\n \n \n     // Flush home-level stamp batch\n-    if stamp_batch.len() >= BATCH_SIZE {\n+    if stamp_batch.len() >= flush_batch_size {\n         stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n         stamp_batch.clear();\n     }\n@@ -2184,43 +2266,59 @@ fn run_incremental_index_inner(\n             let skip_roots = arc_ignored_roots.clone();\n             let skip_patterns = arc_ignored_patterns.clone();\n \n-            let mut builder = jwalk::WalkDir::new(root)\n+            // Use more threads for fresh index: stat() calls are the bottleneck,\n+            // more rayon threads = more parallel stat() calls.\n+            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n+            let current_pass = pass;\n+            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                 .follow_links(false)\n                 .skip_hidden(false)\n-                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n+                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n             // Fresh index: no depth limit -- walk everything in one pass\n             if pass == 0 && !is_fresh {\n                 builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n             }\n             let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n-                children.retain(|entry_result| {\n-                    entry_result\n-                        .as_ref()\n-                        .map(|entry| {\n+                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n+                // Running stat() here parallelizes it across rayon threads (one per directory).\n+                children.retain_mut(|entry_result| {\n+                    match entry_result {\n+                        Ok(entry) => {\n                             let full_path = path.join(&entry.file_name);\n                             let is_dir = Some(entry.file_type.is_dir());\n-                            !should_skip_path_ext(\n+                            if should_skip_path_ext(\n                                 &full_path,\n                                 &skip_roots,\n                                 &skip_patterns,\n                                 Some(&gi_ref),\n                                 is_dir,\n-                            )\n-                        })\n-                        .unwrap_or(false)\n+                            ) {\n+                                return false;\n+                            }\n+                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n+                            // main thread). Skip for pass-1 shallow entries that will be\n+                            // discarded in the main loop anyway.\n+                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n+                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n+                            }\n+                            true\n+                        }\n+                        Err(_) => false,\n+                    }\n                 });\n             });\n \n             for result in walker {\n                 match result {\n                     Ok(entry) => {\n+                        let entry_depth = entry.depth;\n                         let path = entry.path();\n                         if path == root.as_path() {\n                             continue;\n                         }\n \n                         // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n-                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n+                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                             continue;\n                         }\n \n@@ -2228,7 +2326,18 @@ fn run_incremental_index_inner(\n                         root_scanned += 1;\n                         current_path = path.to_string_lossy().to_string();\n \n-                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n+                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n+                        let metadata = match entry.client_state {\n+                            Some(m) => m,\n+                            None => {\n+                                // pre-fetch failed (permission error or race condition)\n+                                permission_errors += 1;\n+                                root_permission_errors += 1;\n+                                continue;\n+                            }\n+                        };\n+\n+                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                             row.run_id = current_run_id;\n                             if is_fresh {\n                                 // Fresh index: all entries are new, skip existing check\n@@ -2250,12 +2359,12 @@ fn run_incremental_index_inner(\n                             }\n                         }\n \n-                        if batch.len() >= BATCH_SIZE {\n+                        if batch.len() >= flush_batch_size {\n                             upsert_rows(conn, &batch)?;\n                             batch.clear();\n                         }\n \n-                        if stamp_batch.len() >= BATCH_SIZE {\n+                        if stamp_batch.len() >= flush_batch_size {\n                             stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                             stamp_batch.clear();\n                         }\n@@ -2373,7 +2482,12 @@ fn run_incremental_index_inner(\n         invalidate_search_caches(state);\n     }\n \n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let (entries_count, last_updated) = update_counts(conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts for instant startup next time\n     let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n     if let Some(lu) = last_updated {\n@@ -2645,7 +2759,7 @@ fn start_fsevent_watcher_worker(\n         let mut last_flush = Instant::now();\n         let mut last_status_emit = Instant::now();\n         let mut pending_status_emit = false;\n-        let mut last_count_refresh = Instant::now();\n+\n         let mut must_scan_count: usize = 0;\n         let mut replay_phase = conditional;\n         let mut full_scan_triggered = false;\n@@ -2660,7 +2774,7 @@ fn start_fsevent_watcher_worker(\n                         due - now\n                     }\n                 }\n-                None => Duration::from_secs(1),\n+                None => Duration::from_secs(10),\n             };\n             match rx.recv_timeout(wait) {\n                 Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n@@ -2771,11 +2885,6 @@ fn start_fsevent_watcher_worker(\n                 last_flush = Instant::now();\n             }\n \n-            // Periodic count refresh to keep in-memory counts accurate\n-            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n-                let _ = update_status_counts(&state);\n-                last_count_refresh = Instant::now();\n-            }\n         }\n \n         // Final flush on shutdown\n@@ -2953,6 +3062,10 @@ async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()\n         }\n \n         let conn = db_connection(&state.db_path)?;\n+        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n+        let _ = conn.execute_batch(\n+            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n+        );\n         conn.execute(\"DELETE FROM entries\", [])\n             .map_err(|e| e.to_string())?;\n         conn.execute(\"DELETE FROM meta\", [])\n@@ -4555,12 +4668,21 @@ async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n     let window = app\n         .get_webview_window(\"main\")\n         .ok_or_else(|| \"Main window not found\".to_string())?;\n-    let t = if theme == \"light\" {\n+    let is_light = theme == \"light\";\n+    let t = if is_light {\n         tauri::Theme::Light\n     } else {\n         tauri::Theme::Dark\n     };\n-    window.set_theme(Some(t)).map_err(|e| e.to_string())\n+    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n+    use tauri::window::Color;\n+    let bg = if is_light {\n+        Color(0xF5, 0xF5, 0xF7, 0xFF)\n+    } else {\n+        Color(0x1E, 0x1E, 0x21, 0xFF)\n+    };\n+    let _ = window.set_background_color(Some(bg));\n+    Ok(())\n }\n \n #[tauri::command]\n@@ -4948,9 +5070,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n             .map(|t| t == tauri::Theme::Dark)\n             .unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         let _ = window.show();\n@@ -4962,9 +5084,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         use tauri::window::Color;\n         let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         if let Err(e) = window.set_decorations(false) {\n@@ -5070,17 +5192,27 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         let thread_started = std::time::Instant::now();\n         eprintln!(\"[startup/thread] init thread started\");\n \n-        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n-        if let Err(err) = init_db(&state.db_path) {\n+        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n+        if let Err(err) = init_db_tables(&state.db_path) {\n             set_state(&state, IndexState::Error, Some(err.clone()));\n             emit_index_state(&app_handle, \"Error\", Some(err));\n             return;\n         }\n-        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n+        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n \n         state.db_ready.store(true, AtomicOrdering::Release);\n         eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n \n+        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n+        {\n+            let idx_db_path = state.db_path.clone();\n+            std::thread::spawn(move || {\n+                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n+                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n+                }\n+            });\n+        }\n+\n         // Deferred housekeeping -- purge + status counts run in background\n         {\n             let hk_app = app_handle.clone();\n@@ -5372,7 +5504,7 @@ mod tests {\n \n     #[test]\n     fn should_skip_path_for_glob_any_segment_target() {\n-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n+        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n \n         assert!(should_skip_path(\n             Path::new(\"/Users/al02402336/work/rust/target\"),\n@@ -5436,7 +5568,8 @@ mod tests {\n         fs::create_dir_all(&dir_b).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let mut conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5478,7 +5611,8 @@ mod tests {\n         fs::create_dir_all(&archived_src).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5606,7 +5740,8 @@ mod tests {\n         fs::create_dir_all(&sub_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5715,7 +5850,8 @@ mod tests {\n         fs::create_dir_all(&proj_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"ce50938d-006f-4365-a061-06b75685a6e5"}
{"parentUuid":"e3c047ed-3601-41e4-9898-c494e404f3ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0117h9HwiHJBUPbvx6K2jET6","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"There are many other changes in the diff beyond what I just modified. These are pre-existing uncommitted changes from before. My changes are only the ones related to `set_native_theme` and the `0x1E/0xF5` color fixes. Let me commit just the relevant changes.\n\nLooking at the diff, the changes that are \"mine\" are:\n1. Lines at `4668-4688` (set_native_theme function)\n2. Lines at `5070-5092` (startup background colors)\n\nBut all the other changes were already in the working tree before my edit. The git status shows `M src-tauri/src/main.rs` as an unstaged modification - these were already there.\n\n\nSince the file has pre-existing modifications mixed in with my changes, I can't easily separate them with a partial commit. I should just commit all the changes in main.rs together, since the user is asking me to commit.\n\nLet me check what other files are modified as well.\n\nLooking at the git status output, I can see the staging and working tree states for each file. Most changes are unstaged in the working tree, but the macOS schema is already staged. Since the user wants to commit the theme fix and that's in main.rs, I should stage just that file and commit it separately from these other pending changes.","signature":"EtYWCkYICxgCKkAwvcbTLBY4grwSKpKnLFR/amC28RnvSqKKs4ZsduX8Mgd4M/1OD9RSwuB2vItsaHnqA6CvdUuPjbdpBpzJPRT9Egzx5T6DVf9iogeWYL4aDIPnq3EB2bALG5DYIiIwrYAc1A3yN7vJbZLRAuxk7UXuJRZ0QtS5rRLw1GryVS5w0LNo+7nUFH8WmHBPdPrVKr0V08bDxTKMTX1KtYcAna7q+/B3l8qVcv6iRlXS40ruVT95mcX6++vXT9pTgxApFJB62rTXIRzhIO3VnZCqRk6mhVueoWGDW7lJsUcLSIWHzkohfEt9NCIP6cOTmW7RN3LmZCrTDusfp/AmihLjezPWx5lBs0h9WykMnuEiG/+A76mfgNhBLhsLBk3UdF526gX3gbt20KZOKzvSOr8eSV4SLrc8fV6HuQ4ZM3+PqZTOx+gCSKs6cczreywCedCEglMn/eAktkWVKrXpzVctf9b+igoIfsCCXR0+uKPmtqKi9ZMJo8sMXTYLu7zPYhdDwTtrqNDLM1G/CRubAoYupFgefmvtrsznWj0FbYFd0e2YJ9uzfUcDrt0RbK1EoapMhN46io9VVjuIjOLX6hBNkeZFwaw8S0/RZowKHt3a2MqcPdKm/T9qB9+0MyXlIVAodWvuVLZTPdhOdHQc1kFIdwMHSeE4U6y4H1EliJ7JlbmN0QOnxw8ZpUZPEuFOPlUERzS1LRp6qAqiGEDBM9KRTDkg5uJYT2jOtfK7rv3+nNI6DsVBkGrwtqGYoNBRfRbi7nyuETbMqlIivBpVN8mRS6SiVkXCO2vpeR/dTRWq6APR/fOCbriUcMDRKDiSq3DoUJRA/QE5yi0zZmyKh8pg0GKpTPo9RMhWnq+K9fjtSvBjSdgpWs2TmS3Uu2OmDJkHDn8hY45V6ocpvaGuaco3p3/3DrZS0Eb5tzpu9OMGV3r42bwANQB1d6ApLpCzQhrAAwR8pbH44XZF6NbDN9i/0TCb5MOaX6fX5lNokvmtFHKY3vKM8PHhkWXSZwYdxiTLGYyCBglofyy9p2gGPrbUztFQd40q3+T5Hf17aKisat/3EvpPsa04ktq9heoDFRhsJXQ5LZTEFxa94BIWO6OF5FjGoR1/gUcC/e6VyOEMH6IX2nF1e/0ggw67M2ELDaG7DUtd5CiHheXOLOPKIZ/H7Qbj8txIKDFwm5drqXn2nlo3JGVWb6bVjjl0vIdU55EOsmt4FPA68hunlYfM6XAkFJrTi3D5UyCrxbtiQOHa6ruNcrwG7Dt3bbwUCnRbg8M+82fi97HZcXQ0w3f9m0Fzq5HTwtFSFuvwpp+qZjObxGmDiF19YTERrYa0Kc3woPf3mHoU7eBX9xj1LcKTHJCy9X4emoXHVvrQ/VFrvbIj2mARVHRajMoOHE3bv48keEHKvgrJykGo6wvUPdEUUXO19cxssZlfBvMBnRPSAe1TUeF9Fv6QxOWIEBltXo/eoM/y/Vdn8SuNlwORlDYpMpjm97A/6glfJrBigCjIZrxYVV8Gt7iycEN/hBfK7zPHXwAkSc2acPEXwuiAj60/Kxi13vUVtJdX7fcY+83jbwlct1yZfjLS3kZVhmsYXBa6pVjCbxtEVPx6Qz2rqX9kUNsV9+ggJ/y5P9f9W9hueYZxKhM6lrcsZHhGVaHfUA/paJr6l8t0TPc9DL+RYUBLu1dNM+nLY9gaRZtSkrDjgokUbUHZLaKAchhctizcbvltz49DG8NHxzREq2b61tT78i3p5RZHUG6amjuqlpoUr+WYVawuX+ETOk6gsFXwdlz8qAdvYgwy5j5hsNMRgk3D0m1UMmJXVBS0SaLVyjwWjtZwboA/mZLj//AIC7CEpA5xrEk1aMS02SWitIlO/5AXTIzc2bqj1G1xfr1J5246tt8nT436wIlxMl9sjMbS65bYOy7sY43q2FmFDvZDzuxz+criFXlLUfMy+aQ3/BCVTSWW4C/VmK2MI9LEvIhwlWXvSXyyFXNDjn08h4QnffYJGM2mxRfcim5I0XEnkPxEaUldYqHhaPoD5D6LOHlscy3sY6ASZxNcQs5cyNfStcCoIhoehmAU7v6QbR9X7DD7+360YU/HznHxrEnF9EKbxQJD2vm31f8f+csAWlX6WC5q5tC770PadHm3N2J2fr8PfvxIyJgxAgwVccALMkLnlwkFoeaN4+5ffGm8BfQcDivU0MCSa7q33keZttpdSuBmjOtEJcPLMai/j86AJFl9KFQtG3dzufY931Dm04cC3C+y/HZJjt2mtOwAQNNu2cuBt9x0WPGkmAte/1rXcwoXIbCs10Z/lDYDVTtTV7N7cx8kXMGHEazyVZvmUT8rTZP3h2mcqxUojRqxbPdt3uEANscHSql6J2Pgxg4fWk8IiyJahzwDA24yxnBKJO4J+3c/F8Fx5iWDuTYce/HQmhyNptKtNVog51MPNTso1l12/c011A9Nqfbg6Mb+Q22pjQYRyNEFqSM2ULGkd4XBDvwaul3hNaNFYJ3ysdIt3oRK5O6SNOQ/0A79Q77abbKuqfRC0NDquz8++MldyDDy5QnnsZo7E5yIce+5yL/4D6gIXUFXMxKj+KvjxV3M9CAxHOHlvMCcylnx7pB+Obw/GRlMi0NL+OqbS9yfd1oguMLlKPG21T+bLYMcUh7eSEqB6cObrNIb9RuPP6JGlAfgEQtydPBQ+pp8q2fVoVWBq3qQY0yT5Z+r3yiCXCnqrByTTljwUW3pdqmvZ8UpEyMoyjiYIjEAFhQsIEuCmCzYVN7IGvcliTBJ3BTH9CBULlGSV84OZPeZrMPGDFBpVL7eggWvB9w6J3K/fPBsGL6aJWghXBAHbARLARYHob2BnUYpTTOx1TN0vOEbxsPYKoNDgox4okTNj3O9nY7bwqFYlWhk1j7d/sukpr1VKHGZ1Tlq0fO9WLSgwAmA2CvD/ZX5B2SGCmiD+MzPvGd2OvOpXV7LRbH/h12oVaRCwMFd3gmn+DqU1vtkWpV31NcAG0w8DGhP0FV8NuoOyqoCaA3+2M+ZEJ9U5jOcBovDV5YbQO1beuvYDOzArytOJWGEOFJlZkStHmaVTQhK1RaICVrocnEiRrT8k8wVw4n0oUM7ZCzq2x/vT4L0M8NmM0K1tMElaYdh6RxTykn8pDUr1/dIV4WDYVBUPbWY6ccVVteyYmimESiqrXDyy+RiO7Z4wMvk9gQFQM1pog/mfxGdCLh9pIsh7kTdDThgWJLC1qQ4mv7UswhICWzzOcuu8EhTVoNP29DtOGtby2ZyseIvBfQsxY29OyoyLjG2x2SIE0Gt9/f3B0d+zadLrWQyvfUuz+wE0SpY8598YpqTmDreFg+HIIhInGJ6NdinbptsgO2i8ounv8xkCpp9OsxSQ8tOL/rSlcw3v9BAkhniyYfQXSW2YhQzB6/L4YlYaItASSGmz7okDj08L1b+Ft3C/cq3dio7Ir0yhRnP0UHITInmqTY94X5sDmDMQH9crOqWrb6uDL2qrwwkbTt5QJDHoSd40ICK4rFXkUStwg3UTgMRNKVx9dV/9rXdtHbTM5o7YmamdwKNzfo825WKouZ0sw/due3Jc3LXhbkm6KuMCZbzId6u2THfrJg/bh8WZ3ZCKDBuFZdACJxtsV20wRGjJ5ilOuM7vdVdyFGbn1rxT+dO/hkko7hA+vKvBRhRSxziwG2F7Su1DsD751pbPk23qKEeJuVXHd14mK3jLyXCvW0xdVFHFi7SEsbuEEWd1y4l+7sR9AXw1WBE2eBr0XCoX61JDGrv95jIjMp5OtlAhV1+YMAT+6OSfM4gihOy2QhBcPDw/hGef6iSYdxriycGDRF8esNdTukouUjYfLM5sjWuc/QZ4P0wAvP4khU8KxgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":9607,"cache_read_input_tokens":49940,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9607},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNt76NUMT1g7BWy2UmKr","type":"assistant","uuid":"e60ed2b6-0150-4d9f-9ee6-fba17a1d25e9","timestamp":"2026-02-22T09:37:07.587Z"}
{"parentUuid":"e60ed2b6-0150-4d9f-9ee6-fba17a1d25e9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0117h9HwiHJBUPbvx6K2jET6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EFUq6ukwRCUYHfk8pJSNRp","name":"Bash","input":{"command":"git log --oneline -3","description":"Show recent commits"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":9607,"cache_read_input_tokens":49940,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9607},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNt76NUMT1g7BWy2UmKr","type":"assistant","uuid":"86e73602-1a83-4d4f-9310-aba1f27087c3","timestamp":"2026-02-22T09:37:07.825Z"}
{"parentUuid":"86e73602-1a83-4d4f-9310-aba1f27087c3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EFUq6ukwRCUYHfk8pJSNRp","type":"tool_result","content":"64775cb Fix idle CPU, optimize search, add backslash path support\nd82d44a Fix Svelte 5 app mount: use mount() instead of class constructor\nbe6f315 Add Windows NSIS build support and CI/CD","is_error":false}]},"uuid":"ecd47a86-4765-4e27-a87f-9bd7dbe6a6c4","timestamp":"2026-02-22T09:37:08.011Z","toolUseResult":{"stdout":"64775cb Fix idle CPU, optimize search, add backslash path support\nd82d44a Fix Svelte 5 app mount: use mount() instead of class constructor\nbe6f315 Add Windows NSIS build support and CI/CD","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"86e73602-1a83-4d4f-9310-aba1f27087c3"}
{"parentUuid":"ecd47a86-4765-4e27-a87f-9bd7dbe6a6c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01MDK1nA4gUfcxAK1v2335gU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012BZHcEocggzjNkPVsvYPTH","name":"Bash","input":{"command":"git add src-tauri/src/main.rs && git commit -m \"$(cat <<'EOF'\nFix window background flash on fullscreen when theme differs from system\n\nset_native_theme() was only calling set_theme() without updating\nset_background_color(). On macOS, the native window background was set\nat startup based on the system theme, so when the user's stored theme\ndiffered (e.g. light vs system dark), the native background stayed dark.\nDouble-clicking the title bar to fullscreen revealed this stale color\nduring the expansion animation.\n\nAlso align startup background color values with CSS theme constants\n(#1E1E21 / #F5F5F7) across macOS and Windows.\nEOF\n)\"","description":"Commit theme background fix"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":944,"cache_read_input_tokens":59547,"output_tokens":238,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":944,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNt8MhzFx2sdapxieqNQ","type":"assistant","uuid":"7247d0f9-2699-4a51-83d5-0683b92a5277","timestamp":"2026-02-22T09:37:14.510Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T09:37:17.544Z","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","content":"{\"task_id\":\"b11349b\",\"tool_use_id\":\"toolu_012BZHcEocggzjNkPVsvYPTH\",\"description\":\"Commit theme background fix\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"7247d0f9-2699-4a51-83d5-0683b92a5277","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"b1d55df5-e8fa-4243-a38b-2d000e5a5ec6","timestamp":"2026-02-22T09:37:17.544Z"}
{"parentUuid":"b1d55df5-e8fa-4243-a38b-2d000e5a5ec6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":4,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-1","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"ef8aff97-2be5-477c-8e70-892e1c25a856","timestamp":"2026-02-22T09:37:18.545Z"}
{"parentUuid":"ef8aff97-2be5-477c-8e70-892e1c25a856","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":5,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-2","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"338150ec-c6d3-4c82-a558-e97f261b0b78","timestamp":"2026-02-22T09:37:19.545Z"}
{"parentUuid":"338150ec-c6d3-4c82-a558-e97f261b0b78","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":6,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-3","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"3653eebc-b950-4d35-9edb-16b2ee9e148c","timestamp":"2026-02-22T09:37:20.546Z"}
{"parentUuid":"3653eebc-b950-4d35-9edb-16b2ee9e148c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":7,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-4","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"2e93f579-0b2e-43ac-a03a-a93b18762952","timestamp":"2026-02-22T09:37:21.547Z"}
{"parentUuid":"2e93f579-0b2e-43ac-a03a-a93b18762952","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":8,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-5","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"da3a219f-afe9-42d8-bcd5-feaa03e778cf","timestamp":"2026-02-22T09:37:22.548Z"}
{"parentUuid":"da3a219f-afe9-42d8-bcd5-feaa03e778cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":9,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-6","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"ae4994a3-3ff6-4bcd-82a0-8d93ac31ef2e","timestamp":"2026-02-22T09:37:23.548Z"}
{"parentUuid":"ae4994a3-3ff6-4bcd-82a0-8d93ac31ef2e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":10,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-7","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"75cb8253-447a-4fef-8f86-69d4ced665cf","timestamp":"2026-02-22T09:37:24.549Z"}
{"parentUuid":"75cb8253-447a-4fef-8f86-69d4ced665cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":11,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-8","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"f831625d-5310-4371-a573-bf9b719168bc","timestamp":"2026-02-22T09:37:25.550Z"}
{"parentUuid":"f831625d-5310-4371-a573-bf9b719168bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":12,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-9","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"d62ef3e2-d54f-45ba-95b9-251b4cbbac6c","timestamp":"2026-02-22T09:37:26.551Z"}
{"parentUuid":"d62ef3e2-d54f-45ba-95b9-251b4cbbac6c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":13,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-10","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"5f84fbe4-b81b-4962-9535-76d96220cf88","timestamp":"2026-02-22T09:37:27.552Z"}
{"parentUuid":"5f84fbe4-b81b-4962-9535-76d96220cf88","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":14,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-11","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"248c97ac-5171-4dca-a978-7b689ed6efa6","timestamp":"2026-02-22T09:37:28.553Z"}
{"parentUuid":"248c97ac-5171-4dca-a978-7b689ed6efa6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":15,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-12","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"311b3874-eb3d-481d-a8e2-470a1a7c47a6","timestamp":"2026-02-22T09:37:29.556Z"}
{"parentUuid":"7247d0f9-2699-4a51-83d5-0683b92a5277","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012BZHcEocggzjNkPVsvYPTH","type":"tool_result","content":"[main 258c99b] Fix window background flash on fullscreen when theme differs from system\n 1 file changed, 229 insertions(+), 93 deletions(-)","is_error":false}]},"uuid":"776f50fd-447c-4173-b038-5b2bb565b74f","timestamp":"2026-02-22T09:37:30.048Z","toolUseResult":{"stdout":"[main 258c99b] Fix window background flash on fullscreen when theme differs from system\n 1 file changed, 229 insertions(+), 93 deletions(-)","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"7247d0f9-2699-4a51-83d5-0683b92a5277"}
{"parentUuid":"776f50fd-447c-4173-b038-5b2bb565b74f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01M2FrseuZvz2aTSaaVoNmmZ","type":"message","role":"assistant","content":[{"type":"text","text":"커밋 완료했습니다 (`258c99b`)."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":290,"cache_read_input_tokens":60491,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":290},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNt9ygyLoJquxyFZbEVb","type":"assistant","uuid":"4bb1ed2d-26ab-4d49-a973-3b799756472f","timestamp":"2026-02-22T09:37:31.893Z"}
{"parentUuid":"4bb1ed2d-26ab-4d49-a973-3b799756472f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"96912e0d-bc32-498f-9d4e-bf1321a3dde5","toolUseID":"96912e0d-bc32-498f-9d4e-bf1321a3dde5","timestamp":"2026-02-22T09:37:31.940Z","uuid":"f413e359-877e-43fb-9e28-fb1158259f1b"}
{"type":"queue-operation","operation":"remove","timestamp":"2026-02-22T09:37:34.904Z","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054"}
{"parentUuid":"f413e359-877e-43fb-9e28-fb1158259f1b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2946}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-22T09:37:34.887Z","uuid":"7beba192-aca3-4e37-98e6-f5a36128a643","toolUseID":"96912e0d-bc32-498f-9d4e-bf1321a3dde5"}
{"parentUuid":"7beba192-aca3-4e37-98e6-f5a36128a643","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"turn_duration","durationMs":47253,"timestamp":"2026-02-22T09:37:34.890Z","uuid":"fc29973f-5266-4f8d-9270-5ec5ba9cbdd1","isMeta":false}
{"type":"file-history-snapshot","messageId":"c0aa4cde-2c82-46ef-8cb5-17e7cc0aaea3","snapshot":{"messageId":"c0aa4cde-2c82-46ef-8cb5-17e7cc0aaea3","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-22T09:36:47.635Z"}},"timestamp":"2026-02-22T09:39:17.411Z"},"isSnapshotUpdate":false}
{"parentUuid":"fc29973f-5266-4f8d-9270-5ec5ba9cbdd1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":"Index: Error\nWatcher update failed: unable to open database file\n\n일시적으로 발생한거야? 원인 분석해줘\n\ning_active=false\n[watcher] db_connection FAILED after 0ms: unable to open database file (upsert=3 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=3 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 0ms: unable to open database file (upsert=6 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=6 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=4 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=4 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 4ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 0ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 3ms: unable to open database file (upsert=8 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=8 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=3 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=3 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 2ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[watcher] db_connection FAILED after 0ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=2 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=2 indexing_active=false\n[watcher] db_connection FAILED after 1ms: unable to open database file (upsert=1 delete=0 indexing_active=false)\n[watcher] process_watcher_paths ERROR: unable to open database file | batch_size=1 indexing_active=false\n[rpc/search] total=191.794ms execute=191.791ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=481.948ms execute=437.272ms total_count=44.673ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173929 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=74.257ms execute=74.251ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=114.971ms execute=76.294ms total_count=38.673ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173929 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=359.651ms execute=359.649ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=423.904ms execute=348.414ms total_count=75.487ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173929 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=102.730ms execute=102.728ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=254.705ms execute=204.235ms total_count=50.467ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173931 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=116.679ms execute=116.675ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=203.902ms execute=120.423ms total_count=83.476ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173932 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=73.025ms execute=73.021ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=148.425ms execute=89.733ms total_count=58.688ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173931 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=91.805ms execute=91.801ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=162.499ms execute=72.681ms total_count=89.815ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173931 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=61.325ms execute=61.323ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=80.451ms execute=58.159ms total_count=22.289ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173931 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=119.339ms execute=119.337ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=641.795ms execute=174.079ms total_count=467.711ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173932 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=605.949ms execute=605.945ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=441.891ms execute=404.287ms total_count=37.601ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=90.821ms execute=90.818ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=275.986ms execute=133.153ms total_count=142.829ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=116.710ms execute=116.704ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=241.390ms execute=116.659ms total_count=124.727ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=62.499ms execute=62.496ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=92.610ms execute=69.837ms total_count=22.770ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=77.025ms execute=77.021ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=118.686ms execute=81.998ms total_count=36.684ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=59.330ms execute=59.328ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=100.511ms execute=67.985ms total_count=32.523ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=67.280ms execute=67.277ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=134.697ms execute=79.880ms total_count=54.812ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=70.657ms execute=70.652ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=83.750ms execute=60.376ms total_count=23.371ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=58.599ms execute=58.596ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=76.068ms execute=55.969ms total_count=20.097ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173933 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=59.337ms execute=59.335ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=81.038ms execute=56.059ms total_count=24.976ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173934 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=62.032ms execute=62.021ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false\n[rpc/search] total=137.004ms execute=75.436ms total_count=61.566ms include_total=true query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=1173935 total_known=true db_ready=true indexing_active=false\n[rpc/search] total=81.023ms execute=81.020ms total_count=0.000ms include_total=false query=\"\" mode=empty sort=name/asc limit=500 offset=0 results=500 total_count=0 total_known=false db_ready=true indexing_active=false"},"uuid":"c0aa4cde-2c82-46ef-8cb5-17e7cc0aaea3","timestamp":"2026-02-22T09:39:13.884Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"c0aa4cde-2c82-46ef-8cb5-17e7cc0aaea3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01GFxMBBTAwd1XAWY9819b6d","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me analyze the logs carefully.\n\nThe error is \"unable to open database file\" happening repeatedly in the watcher. But then search queries succeed fine (`db_ready=true`, results returning 1173929+ entries). \n\nKey observations:\n1. Watcher errors happen continuously with \"unable to open database file\"\n2. Search works fine - `db_ready=true`, results returning successfully\n3. This is NOT a one-time transient error - it's persistent for the watcher\n\nLet me look at how `db_connection` is implemented and how the watcher uses it.","signature":"ErYFCkYICxgCKkDGiG5Uu53koBSHd8P7+V2ESagCC/JABQVS3wYGU7XcX49MDVNy69wX+OAwQvaj6ph4VNpyAj6Lm5p1pZFIaOybEgyJ4X6Y23fLdxwwrbAaDNlwb4ZZ276+sIhO/iIwxeSaH1ytXOpFm5m/+s6QrolqbBme8nDdBSG14Eiektqsx86dytyNTK1wJvQA3PQMKp0E/zARA+nILyimTU1VTULrVDvidBvaHAO6tlZ01zKLS/Ivp8ojinjNuAeXCRlvXWxFvCzZg8OBY6arCEWKaY+47lG5AW20MsmPXq0m+QOtNJEqdHAUh47GvhLwPGv5ywrZoYjBt1xP371OUGoatpwDMRlnAN4TEQJ0DfYS9AWYX9sopNcNWZ1YQ1ax56O2lOvj9eaNzwGciddpFVF0WfEEhf+IWyT4T22Yvuke5sSLnM6YdriVNQ9FzRrCQhlz95PrPnIWD8LA06Hf69/o7ty9hA+oKyzoRYkrLaWUnc1ACJv/3EInuNTY4biIxu6i/QRlLY3sUp4v4PP03/zbqiq0zNibjInwO8F6SVjWxiwYHyNwZhh3Og75C2EUi2RwQjETZlZ5Leibshici3i8fLzhGZ7ruJNSAz/D1ft8OxxzKzjvoIlFeDkPG5evvP6Ymh/4qd0Q3reaZIdroSELXqeIn8mGhkQhIxXJAkuT5FdHHpAIeC4j0V/t6wZPbyh727GFY8xgPaSjHBj+LwGBzW8vGP45mZkL4bLxI5S2hCVmO/VJAZ4LahQB8YBF81M+uKcaC+YhpB/EBeZtb91LDgTxAE4tGRu2nnKo1m+1M2J/0XkZ9AZ4GbfJIjwNs+IP8nAUbvdDQqABFURjZR0Vf1ESCZ3vBJEcsMsV5QRsh3u9oUhgLa5RNfJtorZcHeiRpaY0CWJV+DO++LY9gpWKNhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4761,"cache_read_input_tokens":60800,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4761},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtHtgZm2kPGFKN9BKtw","type":"assistant","uuid":"9a3b960c-5789-42a3-98f3-617fba959aa4","timestamp":"2026-02-22T09:39:22.004Z"}
{"parentUuid":"9a3b960c-5789-42a3-98f3-617fba959aa4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01GFxMBBTAwd1XAWY9819b6d","type":"message","role":"assistant","content":[{"type":"text","text":"로그에서 패턴을 분석해볼게요."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4761,"cache_read_input_tokens":60800,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4761},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtHtgZm2kPGFKN9BKtw","type":"assistant","uuid":"6b1743f6-2640-4def-9caa-858da55ab995","timestamp":"2026-02-22T09:39:22.598Z"}
{"parentUuid":"6b1743f6-2640-4def-9caa-858da55ab995","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01GFxMBBTAwd1XAWY9819b6d","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018SwXPJXYKcrETL1QPHQEez","name":"Grep","input":{"pattern":"db_connection FAILED|process_watcher_paths|unable to open","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4761,"cache_read_input_tokens":60800,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4761},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtHtgZm2kPGFKN9BKtw","type":"assistant","uuid":"8213fdff-d99e-49c1-bc7e-339fce98daf1","timestamp":"2026-02-22T09:39:24.309Z"}
{"parentUuid":"8213fdff-d99e-49c1-bc7e-339fce98daf1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_018SwXPJXYKcrETL1QPHQEez","toolUseID":"toolu_018SwXPJXYKcrETL1QPHQEez","timestamp":"2026-02-22T09:39:25.121Z","uuid":"5d50d3c9-312d-4c3f-a3e4-d7fb12fde22f"}
{"parentUuid":"8213fdff-d99e-49c1-bc7e-339fce98daf1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018SwXPJXYKcrETL1QPHQEez","type":"tool_result","content":"2616:            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n2640:fn process_watcher_paths(\n2690:                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n2837:                    process_watcher_paths(\n2864:                    process_watcher_paths("}]},"uuid":"41000304-a131-4d97-95dc-27d027483eeb","timestamp":"2026-02-22T09:39:25.120Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"2616:            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n2640:fn process_watcher_paths(\n2690:                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n2837:                    process_watcher_paths(\n2864:                    process_watcher_paths(","numLines":5},"sourceToolAssistantUUID":"8213fdff-d99e-49c1-bc7e-339fce98daf1"}
{"parentUuid":"41000304-a131-4d97-95dc-27d027483eeb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01GFxMBBTAwd1XAWY9819b6d","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012JgyfEs5nGLBXkmErQUw1G","name":"Grep","input":{"pattern":"fn db_connection\\b|fn process_watcher_paths|fn start_fsevent_watcher","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4761,"cache_read_input_tokens":60800,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4761},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtHtgZm2kPGFKN9BKtw","type":"assistant","uuid":"4ae25a65-7aa3-4fc3-b301-2f6be76802bc","timestamp":"2026-02-22T09:39:25.423Z"}
{"parentUuid":"4ae25a65-7aa3-4fc3-b301-2f6be76802bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_012JgyfEs5nGLBXkmErQUw1G","toolUseID":"toolu_012JgyfEs5nGLBXkmErQUw1G","timestamp":"2026-02-22T09:39:26.099Z","uuid":"3308aa1b-ac60-4d26-ba87-95cca3f852a1"}
{"parentUuid":"4ae25a65-7aa3-4fc3-b301-2f6be76802bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012JgyfEs5nGLBXkmErQUw1G","type":"tool_result","content":"432:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n2640:fn process_watcher_paths(\n2723:fn start_fsevent_watcher_worker("}]},"uuid":"30d164c6-0698-4ed4-816a-4c5c16cbc1e1","timestamp":"2026-02-22T09:39:26.097Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"432:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n2640:fn process_watcher_paths(\n2723:fn start_fsevent_watcher_worker(","numLines":3},"sourceToolAssistantUUID":"4ae25a65-7aa3-4fc3-b301-2f6be76802bc"}
{"parentUuid":"30d164c6-0698-4ed4-816a-4c5c16cbc1e1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01NmFusCdYQBBwXPBy5LkcEQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GFwDPMzrPY1CDcvdNVnWZ8","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":432,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":650,"cache_read_input_tokens":65561,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":650},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtJZQyKUuzZQDgoL6Qd","type":"assistant","uuid":"e9e5ae60-0647-4e07-82a3-8f1f626f04fb","timestamp":"2026-02-22T09:39:28.617Z"}
{"parentUuid":"e9e5ae60-0647-4e07-82a3-8f1f626f04fb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01GFwDPMzrPY1CDcvdNVnWZ8","toolUseID":"toolu_01GFwDPMzrPY1CDcvdNVnWZ8","timestamp":"2026-02-22T09:39:28.657Z","uuid":"c633bae5-4e62-4271-a137-b7c36fbb7c61"}
{"parentUuid":"e9e5ae60-0647-4e07-82a3-8f1f626f04fb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GFwDPMzrPY1CDcvdNVnWZ8","type":"tool_result","content":"   432→pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n   433→    db_connection_with_timeout(db_path, 3000)\n   434→}\n   435→\n   436→fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n   437→    let conn = db_connection_with_timeout(db_path, 500)?;\n   438→    conn.execute_batch(\n   439→        \"PRAGMA cache_size = -32768;\n   440→         PRAGMA mmap_size = 268435456;\",\n   441→    )\n   442→    .map_err(|e| e.to_string())?;\n   443→    Ok(conn)\n   444→}\n   445→\n   446→pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n   447→    conn.execute_batch(\n   448→        r#\"\n   449→        PRAGMA synchronous = OFF;\n   450→        PRAGMA cache_size = -131072;\n   451→        PRAGMA mmap_size = 536870912;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6607bc43-ce99-409e-939c-d441899a2a7f","timestamp":"2026-02-22T09:39:28.654Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;","numLines":20,"startLine":432,"totalLines":5889}},"sourceToolAssistantUUID":"e9e5ae60-0647-4e07-82a3-8f1f626f04fb"}
{"parentUuid":"6607bc43-ce99-409e-939c-d441899a2a7f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01NmFusCdYQBBwXPBy5LkcEQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01At2A4ykp7KNjL6Q42vTKqw","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2600,"limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":650,"cache_read_input_tokens":65561,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":650},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtJZQyKUuzZQDgoL6Qd","type":"assistant","uuid":"e0e9510a-785c-41d0-884c-5acf45b9ea51","timestamp":"2026-02-22T09:39:29.281Z"}
{"parentUuid":"e0e9510a-785c-41d0-884c-5acf45b9ea51","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01At2A4ykp7KNjL6Q42vTKqw","toolUseID":"toolu_01At2A4ykp7KNjL6Q42vTKqw","timestamp":"2026-02-22T09:39:29.294Z","uuid":"d644db62-769b-47c8-8691-3320bb851643"}
{"parentUuid":"e0e9510a-785c-41d0-884c-5acf45b9ea51","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01At2A4ykp7KNjL6Q42vTKqw","type":"tool_result","content":"  2600→            }\n  2601→            Err(_) => {\n  2602→                to_delete.push(path_str);\n  2603→            }\n  2604→        }\n  2605→    }\n  2606→\n  2607→    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n  2608→\n  2609→    if to_upsert.is_empty() && to_delete.is_empty() {\n  2610→        return Ok(0);\n  2611→    }\n  2612→\n  2613→    let op_start = std::time::Instant::now();\n  2614→    let mut conn = db_connection(&state.db_path).map_err(|e| {\n  2615→        eprintln!(\n  2616→            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n  2617→            op_start.elapsed().as_millis(),\n  2618→            e,\n  2619→            to_upsert.len(),\n  2620→            to_delete.len(),\n  2621→            state.indexing_active.load(AtomicOrdering::Acquire)\n  2622→        );\n  2623→        e\n  2624→    })?;\n  2625→    let mut changed = 0;\n  2626→\n  2627→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2628→    changed += delete_paths(&mut conn, &to_delete)?;\n  2629→\n  2630→    Ok(changed)\n  2631→}\n  2632→\n  2633→#[cfg(target_os = \"macos\")]\n  2634→const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n  2635→\n  2636→#[cfg(target_os = \"macos\")]\n  2637→const DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n  2638→\n  2639→#[cfg(target_os = \"macos\")]\n  2640→fn process_watcher_paths(\n  2641→    app: &AppHandle,\n  2642→    state: &AppState,\n  2643→    pending: &mut HashSet<PathBuf>,\n  2644→    deadline: &mut Option<Instant>,\n  2645→    last_status_emit: &mut Instant,\n  2646→    pending_status_emit: &mut bool,\n  2647→) {\n  2648→    if pending.is_empty() {\n  2649→        return;\n  2650→    }\n  2651→\n  2652→    if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2653→        return;\n  2654→    }\n  2655→\n  2656→    let mut batch: Vec<PathBuf> = pending.drain().collect();\n  2657→    batch.sort();\n  2658→\n  2659→    match apply_path_changes(state, &batch) {\n  2660→        Ok(changed) => {\n  2661→            *deadline = None;\n  2662→            if changed > 0 {\n  2663→                invalidate_search_caches(state);\n  2664→                touch_status_updated(state);\n  2665→                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2666→                    let _ = refresh_and_emit_status_counts(app, state);\n  2667→                    *last_status_emit = Instant::now();\n  2668→                    *pending_status_emit = false;\n  2669→                } else {\n  2670→                    *pending_status_emit = true;\n  2671→                }\n  2672→            }\n  2673→        }\n  2674→        Err(err) => {\n  2675→            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n  2676→            if is_busy {\n  2677→                eprintln!(\n  2678→                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n  2679→                    DB_BUSY_RETRY_DELAY.as_secs(),\n  2680→                    err,\n  2681→                    batch.len()\n  2682→                );\n  2683→                for path in batch {\n  2684→                    pending.insert(path);\n  2685→                }\n  2686→                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n  2687→                return;\n  2688→            }\n  2689→            eprintln!(\n  2690→                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n  2691→                err,\n  2692→                batch.len(),\n  2693→                state.indexing_active.load(AtomicOrdering::Acquire)\n  2694→            );\n  2695→            *deadline = None;\n  2696→            if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2697→                return;\n  2698→            }\n  2699→            let mut status = state.status.lock();\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"bb9df60d-45d7-4e52-8bd4-87d4e90e2a82","timestamp":"2026-02-22T09:39:29.292Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();","numLines":100,"startLine":2600,"totalLines":5889}},"sourceToolAssistantUUID":"e0e9510a-785c-41d0-884c-5acf45b9ea51"}
{"parentUuid":"bb9df60d-45d7-4e52-8bd4-87d4e90e2a82","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01VDoXCR6Mpgva7FctdWZRfg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016gQwQbjZBehteLSCyMcPkH","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2699,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2064,"cache_read_input_tokens":66211,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2064},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtJnBfx3znrDwTTnJ4F","type":"assistant","uuid":"dccafc34-be7e-4d3b-b27b-4517f31dfe01","timestamp":"2026-02-22T09:39:31.482Z"}
{"parentUuid":"dccafc34-be7e-4d3b-b27b-4517f31dfe01","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_016gQwQbjZBehteLSCyMcPkH","toolUseID":"toolu_016gQwQbjZBehteLSCyMcPkH","timestamp":"2026-02-22T09:39:31.494Z","uuid":"7546cccf-fa5d-4bf6-a150-f825d8ec2582"}
{"parentUuid":"dccafc34-be7e-4d3b-b27b-4517f31dfe01","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016gQwQbjZBehteLSCyMcPkH","type":"tool_result","content":"  2699→            let mut status = state.status.lock();\n  2700→            if !matches!(status.state, IndexState::Indexing) {\n  2701→                status.state = IndexState::Error;\n  2702→            }\n  2703→            status.message = Some(format!(\"Watcher update failed: {err}\"));\n  2704→            drop(status);\n  2705→            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n  2706→        }\n  2707→    }\n  2708→}\n  2709→\n  2710→#[cfg(target_os = \"macos\")]\n  2711→const EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n  2712→\n  2713→#[cfg(target_os = \"macos\")]\n  2714→fn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n  2715→    let conn = db_connection(db_path)?;\n  2716→    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n  2717→}\n  2718→\n  2719→#[cfg(target_os = \"macos\")]\n  2720→const MUST_SCAN_THRESHOLD: usize = 10;\n  2721→\n  2722→#[cfg(target_os = \"macos\")]\n  2723→fn start_fsevent_watcher_worker(\n  2724→    app: AppHandle,\n  2725→    state: AppState,\n  2726→    since_event_id: Option<u64>,\n  2727→    conditional: bool,\n  2728→) {\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"7f3230a9-d1eb-45e4-b0bf-cd0fdf8fd96d","timestamp":"2026-02-22T09:39:31.493Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {","numLines":30,"startLine":2699,"totalLines":5889}},"sourceToolAssistantUUID":"dccafc34-be7e-4d3b-b27b-4517f31dfe01"}
{"parentUuid":"7f3230a9-d1eb-45e4-b0bf-cd0fdf8fd96d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01VDoXCR6Mpgva7FctdWZRfg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PkGucUTsYvc4QPWZ72PrBR","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":400,"limit":35},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2064,"cache_read_input_tokens":66211,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2064},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtJnBfx3znrDwTTnJ4F","type":"assistant","uuid":"d5056b01-c9f8-4f16-b01e-4e632c91d26a","timestamp":"2026-02-22T09:39:32.138Z"}
{"parentUuid":"d5056b01-c9f8-4f16-b01e-4e632c91d26a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01PkGucUTsYvc4QPWZ72PrBR","toolUseID":"toolu_01PkGucUTsYvc4QPWZ72PrBR","timestamp":"2026-02-22T09:39:32.152Z","uuid":"858e5f8c-7c82-4464-ae5f-dc71103a186a"}
{"parentUuid":"d5056b01-c9f8-4f16-b01e-4e632c91d26a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PkGucUTsYvc4QPWZ72PrBR","type":"tool_result","content":"   400→        })\n   401→        .unwrap_or(false)\n   402→}\n   403→\n   404→fn bench_mode_enabled() -> bool {\n   405→    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n   406→}\n   407→\n   408→fn perf_log_enabled() -> bool {\n   409→    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n   410→}\n   411→\n   412→pub(crate) fn perf_log(message: impl AsRef<str>) {\n   413→    if perf_log_enabled() {\n   414→        eprintln!(\"[perf] {}\", message.as_ref());\n   415→    }\n   416→}\n   417→\n   418→fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n   419→    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n   420→    conn.execute_batch(&format!(\n   421→        r#\"\n   422→        PRAGMA journal_mode=WAL;\n   423→        PRAGMA synchronous=NORMAL;\n   424→        PRAGMA temp_store=MEMORY;\n   425→        PRAGMA busy_timeout={busy_timeout_ms};\n   426→        \"#,\n   427→    ))\n   428→    .map_err(|e| e.to_string())?;\n   429→    Ok(conn)\n   430→}\n   431→\n   432→pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n   433→    db_connection_with_timeout(db_path, 3000)\n   434→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"006f3da0-2220-483b-a816-de5f8f1b5f3f","timestamp":"2026-02-22T09:39:32.150Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}","numLines":35,"startLine":400,"totalLines":5889}},"sourceToolAssistantUUID":"d5056b01-c9f8-4f16-b01e-4e632c91d26a"}
{"parentUuid":"006f3da0-2220-483b-a816-de5f8f1b5f3f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01SuMSk9w6BGpGJzTagNK5De","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a clear picture. Let me analyze this carefully.\n\n**Key observations from the logs:**\n\n1. `db_connection FAILED after 0-4ms: unable to open database file` - the error is \"unable to open database file\", NOT \"database is locked\" or \"busy\". This is a fundamental file access error.\n\n2. The error duration is 0-4ms — the connection attempt fails almost immediately.\n\n3. `db_ready=true` in search logs — the DB is accessible for search queries\n\n4. `indexing_active=false` — indexer is not running\n\n5. The errors are repeated many times (not just once) - this is NOT transient. \n\nThe watcher triggers on every file change, and each time it tries to open the database, it fails with the same \"unable to open database file\" error. The distinction is important: \"database is locked\" means the file exists but is held by another connection, while \"unable to open database file\" means SQLite can't access the file at all. This suggests the watcher thread has a different execution context than the main thread where the database was successfully initialized — the file path or permissions might be inaccessible from that background thread's perspective. Looking at the timing in the logs, the watcher fails immediately with \"unable to open database file\" while search works later with `db_ready=true`. The first search shows `total_count=0 total_known=false`, suggesting the database isn't fully initialized yet, but then subsequent searches appear to work. So the watcher is hitting the database before it's ready, while the search queries succeed once initialization completes. I'm realizing the watcher might be starting before the database file is even created. Let me trace through the initialization sequence to see exactly when the watcher gets spawned relative to when the database is set up.","signature":"EoAeCkYICxgCKkABPMkqyjGVw5PCzTANh7ugjOD9WIdAwcV8uXc15vmQM1Rlwyl3YavgF+f9argEUWewGY8v1vVK4I91c2EwnbNFEgxrzfvgr0B+hauZmmAaDMt6WEu35nesQcrtPSIwdhi9GzLycaqF2eX/Uf3owFTp+gB3rNVKg6ARuQOeP/pKqZrpYmWEHXErFBh23jVhKuccd5i8IDj5DBw1MZGPT2z4lwYlki59oQE0W6Bi2kWPdp00nSEBALx6jCwJ93H+mnSaxZC9vxWw44r70f20K0FSuuHFqAFBBcqyBq0hWcOGtC4s2iEJG/vUiSV1cSdIu8Tfh9w194z1em4b7cGpVDjOUIdzG5KJAp8S0oksmfNzFFZxBgqFs84HSwYRRMoWxNaLP1sIuKzqDEaSUg2XONED0AiZUXi6ZOKEaBtpuS77XE61RAMgKpJyLZhPN9dNYGHirs7Vyhus9PquCLbN5FAJk2Yh4/78bjaT5DDARQuP2195T4dSOjFDqHL/S+dubRsj15X1tYZbXBDCHvOsV/BH6hoxKNHAwJyGSuTE4dWeziFJgdBJdoPLsg3IV9UzI13Gf+kVeDb8KVtd1fKXm5j8VFPo9xcGTUpAbOBr/XyhHWC8mwWizZpr1thyTBoPEjeulNGwF3OF51Btjd5gs3ii59KP1VR3ulGyTyOOv2JBclLajBsKp+J0WKqRQTeYogt5clpxi6S1lvLlX5IE1VaSNsZqPr9kaGzjmS88212ArqFZQRPsLt9W6S39Yfrtit1TKp8KZzZQVjjom+QY+7wD+hatCy7slPivgJcqsti6zrZTYGxjPhNp+MQKsDeRU8ZuziWmX1R5hfM9yAQi0RragYw/fPCbZNw9LmAdZdCTLVNklwnPuMfj6wcUk6STZapmREatanACJwDYjROifSm88OsuijSvFcOiKE3n75i8WsoHj9Re4aXvdZe2+UMglPx2VmokEDvhngl8b9cLdruPNULEISZyxD3LclKF8VJLNX73M6vlFTcCYq969yNq+4I8HF1v6MO6CbaPYQhvaCP6krAc0+oHsd90sbLT0d1AtAmC+IiANwFh2iG6sF8tfxX29ssQtMTlbZpH0M//BaIT+lYp5CZe7OVrhD88OakMxNNJVDbQVJJQo8jHo1w7zIi5LIGlGHHImRUt/6Fc8Jh5l8XKaInFxasDY1zas29ADxp3WwHSRhvnBN7MkRvhuhW3IXHJbp5voJhNaGKHYW00rdfDbOR3o+9diq8nlR3ut2PcrKjyfNgt4JaKRpcqT77VRnRu5KYLQ66t/sSJBRVP0LXTV2337r3PYnK1yEfJojiuF4RV52TtNcewAH2On88QbSOOFXBVy5B0gUg78AoO0aLZAufHuJ3BnUx1FdU6OtKcD5oSxFLk6RX+D5iml+w9sv6k7QkO9hYkaA+CX9szo9fKkh1jkBEOz2rqhTdrIaY0KXai3zVP/DwNnwEpY2MHAHxpOn4/dBE5tPzNy28J0CNhEfJ0JTRT9Ti165Ye1Dksg/FqHLkaq8I0B2PNYUQZhL1Ppk9/fB+WeZ8+4fXxEOb1GuRE6I/zT0LB8TYYoNCxW9afI7LBkqmRj3aWqaTYKcLEZ+bDkZENK1hkZa5zHFnsYVhGUEsO3MZ0NXDPEdiBjeZWhxbJh47FRD0ELv6IvwNEjd1/LwROfjZnirYxUYlD2L8MufUtLA4GJ7nyrBMGt6WlZ7gk37KJhPV8JiVGwr4FpDN3CkOY8FBO1TdAeKX3JBpvDJpu++0ZKPX3vNRymwopxH3d8eotetleMZh92KhsITsw8N2X6GOrBm1kqAJIWKj9s21gtpQz8LuUsN4AyfyqJPoRlVuK+68hN8SWNg0kHlGVTS1AQ+oJ7qZJm8oo0Vy4l3LZUtCzQBfT+SbxpdVi4dGKJQ7nTc9NMaSCJKI8yPbrNoNCc6Ny8fwK0AErUnMptjB2lDgBAuTaMDXlUclNQcOe5doUSv3SxeDqnDGaIxvHvRR/5039MmgiW/55dgA0YITmLhigJxC0YmCahm0+/ZPoMChGZDnLB1LjoIRU+uiZvUcTPYGMmgfLaOneeWOaE/ukdPL9b2bJOu8CV8D8qbYmdz/M0Eqipt17KnSEIBbNaRHSUb7iKWzAOrGSZB1XtwQeXlQTjX0p27Ssz4SW+waQbTtbEo2v1C6l9P7daSRclbktKqWvaqvEq2YRd0vpBTpogWawbRgXM4SpZLgLwcYBBp5lDvk1y7a9QLulcBBP+7WRmvZy0rWquuXQ6DrW6PWG6fJ3McFcBcTsovTnAgQC72wN0/Ti01MqwEU9t+RfwfOOMzCKJI35IiPAaxU21BT6uMKdrf7OHuNg3GcmrR3Fu56MMx1YL+RdIgK4TPVqImRM2W2xczXEnA/1q19DygVyB/QRxgOOhW/4yESDMQXO35xCyQCq1LTcDalf3lsjESEpQYfSVhgBmTc3CLWgJy1l4lommTDCgpFkFlFPcJTmXZd8M+kUrgi71BBpY2+y6JBm/O3IyDlv0cls5r2ZS9TpUgOpkHzcnWml4Jz4jesx903WtdRaokE8nIiFPIfMEnIymj1uytEHXgMBJH69uD5SH8hD2iW6l0TZzpnxF/xt+4xXfMFAdbXcrX2g1A/JDtAXS+jxRbCdaOpDV/Z3oR8IAw4yT5gKdqqtbXdQiY61qFhYimt12vHpMNIZXBqmIjK+HjKjzYI6a1fXf8BAlHiESERlCdju+JxRvkZ6ScvgZndMKOoWU6Uw5Kds/lzeXFALM99Y6QKehNRUcUdfKX9TX6lwjUMhRLl6Poukj671G1KL+7eHM1FWJf4fcePNR7/KsLKeju0+S2uzs+FAvcU6PPxs2y4LNnRqH696rQaQoydtwoDBzzRG0JVJmmEIaUcN7tQ0bKePTozxGkMZpbUv7QQIzL6CY5xU3QoLgPFhUQ4CAgD0QGmM3wlA2tZqu0OA1E/xX1w3gHydOG5eALqYRaSDFnurC7ZUHiUbzwGPpUpGnkRDtEi5oho/BoMaSNxvWTQBRm1uVvbVTQRZYMzwtGRsDFXJaH+3MenVequqZe5Px+wuMKkPB+3X9+Go+FIIuiEqBrHVImxQdzjtGNjHDVCHA1m9Lt7u3CXFUdUqlhSoNZ2tbmARYD7XWA2xpQGCXDdkeI3Lsld9FNhnBNcHAHivLFld6ilTbLQmZCueb7RevqkZ9I1UrutvHWqAq6vog5MDW11rf734ZWK1vP/jMyXF+Xq/e0CGOZ6gqOUtjL2amP0colwPveDoOEs/s8EPegnxLkNHi4VCYKJO09Y/PBH3kD4E6uPMi5XH5zA5tvv9BUPq3bsxLdkZ/B7LH8PKSb5exI/6ZZginHTgV0MHMXozc7rI+7WEAKs2nbNEJWCyJPuKTVoDDCiUMCjyr0+5HMuZ61HIGcGWP9xCLpEsZKLk+BCa0IGZ8jidgQE2HSfqImMtv26PNxgiK/aKZ81+A6C7tfqT8CuzQBl0NquxIt5wR1GENmFKCVq3ARM+J/D+SWJUB1H4J6Ng8n03sr5xPZ/1d5iGUdLvHpDJ76kXJUpiRaXskoQIesGR8ZIWe9Q7yBza66ZkP8+ve8Y5R4paS3P2ALBlqEL8Tb0ggLGu1ot3E0Ty7mmat42rui7ZpUe6PHiLxhfR6uK28dZHUXPEsz2fil7RY3ARO/WAe8ZsJ2i1vkFr0Xb3c8VdvXydoXPP/ACdP96Tz0hPhFqpfSrTiJzj7PI1kMEXhlGM/gx8IZXKTC3G3+NvP2kJ87aX9R1Pu1B9LNm2co2rPEE+k5V1p3bN+rTm/TZukNXC/OBkI3+mXPqbo4QhmDjSoy1YGzZK4TT8jMQHlX4hNoIC1GRgihQP7563PCh53MlQNSpxKVzNqIPY2NUbNwQXmuanQmqbKWY31CGUmxw/sBJkYEFxYPE7uhogf3B4XTapEPMYeZHlaYBoWHCnGxrXnAJDoXGRqcf2OPQEhVIdsWr16vqLEq6AoW/EX70Nja1NclOSlIj65siSsf2uVpo3br2vAxAXwh13jghNo9SmLXY31gk+W50+8H5tad25Bj0SH6MOkg9E5xSG9Yk+9xrOiRnFygMKW/92SpdaE4LFogv5x3pl+R9XrdL9JtK9B5rWEdDe12McPVcedsGBMvPssjQN9rTv1o6nR4Cm/2/Vn58ihmLMs4wKWiGqEGbHX/pOF+FMUU5LsgW/zMiHn5UfkbDQZHtiANfuFERoW17uodqExCKe0oHmg2Q704Kt1WBlick4Ll0+5iqCi2Z7S/SO746vVdmq8DFxBy0JwnwVRnEbXJ95lpvDhLgHg+jK+PDPBpW1oKk6CW1ud4kZyskVlmDdrca5+Mcgl0OimWqeVYldD9YyXN158RpdFDnkKVzjKOXqf5thlahInUU4F5Zg5h+SFp5gxvOCc/1WOr8kOoB3ciis/PB+uJ0gha9ShPMfayLqgEDkXHese/wg2++98PbmsiLJL2AbBtCKXtf2pRBuU1uIpZL3AwWqMIxX5jIG1yxPlBL/9BjpgZXy23s3963jL4OLowINo97Gnkco3A8/+0UHZMIvyXUdB6G6PKXFMoB6mEKGkRDMBx3d0uvPCavFCST7nNwHcofd+FR9rDp3dKXKrYzPLeyyKJ1uQndlp0YgCyyipt3xSrh+LiiRhhoK2hIQ7imPyCcpWwxQiDGZBcHeF5u/dU2zL8YGc2tINZOdbZHPlHNQuo3g6KT9rMcQGkR1bpU5+xYM99ziYoDwa27z/MIFXJ6tuExn3cMPPTYml05a4dqr7Kv0ZKdUDS7gnPdavT4PMjWsOdKE7CYA4+Qs7hgTi4doVDqn7j1tAJuR7sAik2G1vZv82Lqapx+uecN8lGEpmfMx5NolHUGeNOm7sgsvOdVs3sztvK8U3KlM6SzfczmFwYXKzH2/7QwJPDTmTZlbQyZVqAC4iIYhn3iM9CV3cD8Em7EcmEzPY2Y+uwcSLHjNLeVJEZnUIS3nEyoo0bVOe0MBkkpba7Wcwa2J/uWXFdtEM6iKPOWS158mGxNxtZkOdtA18IDJZJSa4c7eiOT/nT8mZNfGo7r8S3vxyFWI9WaBkGvqhPWWZsxmInm9SVkk3/o/WUHqYA7UGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1440,"cache_read_input_tokens":68275,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1440},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtJypAZ6seuTA3QZbdL","type":"assistant","uuid":"dc454c88-03e1-4955-bcf4-f67bce757d21","timestamp":"2026-02-22T09:39:53.909Z"}
{"parentUuid":"dc454c88-03e1-4955-bcf4-f67bce757d21","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01SuMSk9w6BGpGJzTagNK5De","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QXURfH67DCAc9x4soPA1nv","name":"Grep","input":{"pattern":"start_fsevent_watcher|db_ready|watcher.*start","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1440,"cache_read_input_tokens":68275,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1440},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtJypAZ6seuTA3QZbdL","type":"assistant","uuid":"2d5eaf0a-bc2f-454e-9875-86b97649f0dc","timestamp":"2026-02-22T09:39:54.358Z"}
{"parentUuid":"2d5eaf0a-bc2f-454e-9875-86b97649f0dc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01QXURfH67DCAc9x4soPA1nv","toolUseID":"toolu_01QXURfH67DCAc9x4soPA1nv","timestamp":"2026-02-22T09:39:55.047Z","uuid":"7133bf1c-1e47-4d97-8c2b-cd8e269b3332"}
{"parentUuid":"2d5eaf0a-bc2f-454e-9875-86b97649f0dc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QXURfH67DCAc9x4soPA1nv","type":"tool_result","content":"339:    pub(crate) db_ready: Arc<AtomicBool>,\n529:/// when new indexes are added; runs after db_ready so it does not block startup.\n2723:fn start_fsevent_watcher_worker(\n2752:            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n2990:    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n2996:    } else if indexing_active || !db_ready {\n3013:            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n3017:            db_ready,\n3091:        // Allow new watcher to start\n3319:    if !state.db_ready.load(AtomicOrdering::Acquire) {\n4001:            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n4004:                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n4018:                db_ready,\n4881:            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n5142:        db_ready: Arc::new(AtomicBool::new(false)),\n5203:        state.db_ready.store(true, AtomicOrdering::Release);\n5204:        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n5280:                    start_fsevent_watcher_worker(\n5291:                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n5458:            db_ready: Arc::new(AtomicBool::new(true)),"}]},"uuid":"d3a34ab9-6c90-44f2-a029-374a967bb1a1","timestamp":"2026-02-22T09:39:55.045Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"339:    pub(crate) db_ready: Arc<AtomicBool>,\n529:/// when new indexes are added; runs after db_ready so it does not block startup.\n2723:fn start_fsevent_watcher_worker(\n2752:            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n2990:    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n2996:    } else if indexing_active || !db_ready {\n3013:            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n3017:            db_ready,\n3091:        // Allow new watcher to start\n3319:    if !state.db_ready.load(AtomicOrdering::Acquire) {\n4001:            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n4004:                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n4018:                db_ready,\n4881:            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n5142:        db_ready: Arc::new(AtomicBool::new(false)),\n5203:        state.db_ready.store(true, AtomicOrdering::Release);\n5204:        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n5280:                    start_fsevent_watcher_worker(\n5291:                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n5458:            db_ready: Arc::new(AtomicBool::new(true)),","numLines":20},"sourceToolAssistantUUID":"2d5eaf0a-bc2f-454e-9875-86b97649f0dc"}
{"parentUuid":"d3a34ab9-6c90-44f2-a029-374a967bb1a1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_019xNLqWMJ9PstYRVU7Jn4e5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016FkjsPbSCK2XbycGumkjHR","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":5190,"limit":120},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1675,"cache_read_input_tokens":69715,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1675},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtLfZcMCtkaKcLe2TfN","type":"assistant","uuid":"cc6d6807-b481-4e84-a053-0cc792d4cc46","timestamp":"2026-02-22T09:39:57.551Z"}
{"parentUuid":"cc6d6807-b481-4e84-a053-0cc792d4cc46","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_016FkjsPbSCK2XbycGumkjHR","toolUseID":"toolu_016FkjsPbSCK2XbycGumkjHR","timestamp":"2026-02-22T09:39:57.568Z","uuid":"98c46bdc-50a9-46cd-99d0-979df3d00169"}
{"parentUuid":"cc6d6807-b481-4e84-a053-0cc792d4cc46","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016FkjsPbSCK2XbycGumkjHR","type":"tool_result","content":"  5190→    let app_handle = app.handle().clone();\n  5191→    std::thread::spawn(move || {\n  5192→        let thread_started = std::time::Instant::now();\n  5193→        eprintln!(\"[startup/thread] init thread started\");\n  5194→\n  5195→        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n  5196→        if let Err(err) = init_db_tables(&state.db_path) {\n  5197→            set_state(&state, IndexState::Error, Some(err.clone()));\n  5198→            emit_index_state(&app_handle, \"Error\", Some(err));\n  5199→            return;\n  5200→        }\n  5201→        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n  5202→\n  5203→        state.db_ready.store(true, AtomicOrdering::Release);\n  5204→        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n  5205→\n  5206→        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n  5207→        {\n  5208→            let idx_db_path = state.db_path.clone();\n  5209→            std::thread::spawn(move || {\n  5210→                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n  5211→                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n  5212→                }\n  5213→            });\n  5214→        }\n  5215→\n  5216→        // Deferred housekeeping -- purge + status counts run in background\n  5217→        {\n  5218→            let hk_app = app_handle.clone();\n  5219→            let hk_state = state.clone();\n  5220→            std::thread::spawn(move || {\n  5221→                // Brief pause so indexing thread can start first\n  5222→                std::thread::sleep(std::time::Duration::from_millis(500));\n  5223→                let hk_started = std::time::Instant::now();\n  5224→                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n  5225→                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n  5226→                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n  5227→                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n  5228→                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n  5229→                let wait_started = std::time::Instant::now();\n  5230→                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n  5231→                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n  5232→                {\n  5233→                    std::thread::sleep(Duration::from_millis(50));\n  5234→                }\n  5235→                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n  5236→                    eprintln!(\n  5237→                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n  5238→                        wait_started.elapsed().as_millis(),\n  5239→                        POST_READY_GRACE.as_millis()\n  5240→                    );\n  5241→                } else {\n  5242→                    eprintln!(\n  5243→                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n  5244→                        FRONTEND_READY_TIMEOUT.as_millis()\n  5245→                    );\n  5246→                }\n  5247→                std::thread::sleep(POST_READY_GRACE);\n  5248→                let purge_started = std::time::Instant::now();\n  5249→                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n  5250→                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n  5251→                } else {\n  5252→                    eprintln!(\n  5253→                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n  5254→                        purge_started.elapsed().as_millis()\n  5255→                    );\n  5256→                }\n  5257→                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n  5258→            });\n  5259→        }\n  5260→\n  5261→        #[cfg(target_os = \"macos\")]\n  5262→        {\n  5263→            if bench_mode {\n  5264→                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n  5265→            } else {\n  5266→                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n  5267→                    .ok()\n  5268→                    .map(|c| {\n  5269→                        let eid = get_meta(&c, \"last_event_id\")\n  5270→                            .and_then(|v| v.parse::<u64>().ok());\n  5271→                        let complete = get_meta(&c, \"index_complete\")\n  5272→                            .map(|v| v == \"1\")\n  5273→                            .unwrap_or(false);\n  5274→                        (eid, complete)\n  5275→                    })\n  5276→                    .unwrap_or((None, false));\n  5277→\n  5278→                if stored_event_id.is_some() && index_complete {\n  5279→                    // Conditional startup: try watcher replay first, skip full scan if OK\n  5280→                    start_fsevent_watcher_worker(\n  5281→                        app_handle.clone(),\n  5282→                        state.clone(),\n  5283→                        stored_event_id,\n  5284→                        true,\n  5285→                    );\n  5286→                } else {\n  5287→                    if !index_complete {\n  5288→                        eprintln!(\"[mac] index incomplete; starting full index\");\n  5289→                    }\n  5290→                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n  5291→                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n  5292→                }\n  5293→            }\n  5294→        }\n  5295→\n  5296→        #[cfg(target_os = \"windows\")]\n  5297→        {\n  5298→            win::start_windows_indexing(app_handle.clone(), state.clone());\n  5299→        }\n  5300→\n  5301→        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n  5302→        {\n  5303→            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n  5304→        }\n  5305→\n  5306→        if bench_mode {\n  5307→            start_bench_runner(app_handle.clone(), state.clone());\n  5308→        }\n  5309→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5eef2ac5-01a9-4950-89d4-1355264945bd","timestamp":"2026-02-22T09:39:57.566Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n","numLines":120,"startLine":5190,"totalLines":5889}},"sourceToolAssistantUUID":"cc6d6807-b481-4e84-a053-0cc792d4cc46"}
{"parentUuid":"5eef2ac5-01a9-4950-89d4-1355264945bd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01W9gGwW7PRK1cAubWJybniM","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to look at `start_fsevent_watcher_worker` more carefully to understand what happens in the watcher thread, and specifically, when the watcher starts trying to write to the DB.\n\nThe watcher is started here (line 5291):\n```rust\nstart_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n```\n\nThis is after `db_ready = true` is set. So the DB file should exist at that point.\n\nBut the error \"unable to open database file\" doesn't mean \"file doesn't exist\". Let me think more carefully.\n\n\"unable to open database file\" (SQLITE_CANTOPEN) can happen for several reasons:\n\n\n1. File doesn't exist (but we know it does since search works)\n2. Directory doesn't exist\n3. Permission denied\n4. On macOS, if the app is sandboxed, a background thread may not have access to certain paths\n5. The WAL file or SHM file may be locked by the indexer\n\nI'm noticing `PRAGMA synchronous = OFF;` being set in `set_indexing_pragmas` — when synchronous is disabled, SQLite might not properly sync the WAL, which could cause issues. More importantly, I need to trace through what the `ensure_db_indexes` background thread is doing and whether it's holding locks that prevent the watcher from accessing the database.\n\nLooking at the logs more carefully, I see the watcher fails to open the database while search succeeds, and they're using different connection methods — search uses `db_connection_for_search` which likely has different locking or access patterns than what the watcher is attempting.\n\nThe \"unable to open database file\" error happens almost immediately (0-4ms), so it's not a timeout issue. I'm wondering if the problem is related to how the indexer configures SQLite pragmas — specifically `synchronous=OFF` combined with `wal_autocheckpoint=0` might be leaving the WAL file in an inconsistent state that blocks other connections from opening the database.\n\nLet me look at the `reset_index` function to see if that could be the culprit. It sets `synchronous=OFF` and a large cache size before doing bulk deletes, but the logs show `indexing_active=false` so that's probably not running.\n\nActually, I should examine the `ensure_db_indexes` thread more carefully—it spawns in the background and creates indexes on the database. Let me trace through what it's doing...\n\nCreating database indexes...\n\nThe issue is that index creation requires an exclusive write lock, and even though WAL mode allows readers to continue, it can't handle concurrent writes. The \"unable to open database file\" error suggests something else is going wrong—maybe a permissions issue or the database file getting deleted while the index creation is in progress.\n\nThe user mentioned this happens intermittently, and looking at the logs, the watcher errors burst and then search works fine afterward. I'm noticing the logs are truncated at the beginning, which makes it hard to see the full context. The pattern shows `indexing_active=false` when the watcher errors occur, then `total_count=0` initially before search results appear—this timing suggests the index reset might be interfering with ongoing operations.\n\nSo the sequence seems to be: full index completes, the watcher starts processing FSEvents, tries to open the database and fails with \"unable to open database file,\" while search continues working. On macOS, this error can occur from file descriptor limits, path length issues, or directory permission problems rather than a simple lock contention.\n\nThe real issue might be the WAL configuration — with `synchronous=OFF` and `wal_autocheckpoint=0`, the indexer runs massive inserts without waiting for writes to complete or checkpointing the WAL file. This causes the WAL to grow unchecked, and when the watcher tries to open the database afterward, it can't properly initialize the shared-memory coordination file that WAL mode requires.\n\nDropping indexes on fresh runs...\n\nAfter indexing completes, the code recreates those indexes and then runs `ANALYZE` followed by a passive WAL checkpoint. The issue is that `ensure_db_indexes` might be trying to create indexes simultaneously, causing lock contention between the two operations.\n\nBut that would typically surface as \"database is locked\" rather than \"unable to open database file\". Let me reconsider—maybe the problem is with the database file path itself becoming unavailable, though that seems unlikely. Actually, I should trace through `db_connection_with_timeout` more carefully. It opens the connection and then sets WAL mode, but `Connection::open` itself could fail with \"unable to open database file\" if the file doesn't exist or the path is inaccessible.\n\nLooking at the actual SQLite error codes, `SQLITE_CANTOPEN` (error 14) produces exactly that message. On macOS specifically, there's a scenario where setting `synchronous=OFF` combined with a process crash or WAL corruption can leave the database in a corrupted state—though the user mentioned search works, so that's probably not it. But here's something I hadn't considered: **file descriptor exhaustion**. macOS limits open file descriptors per process (default 256), and during full indexing there could be multiple database connections running simultaneously plus hundreds of file descriptors from directory scanning with jwalk's threading. If the FD table fills up, `open()` fails with EMFILE.\n\nThough actually, Tauri apps often have higher limits (10240+) from launchd settings. Still, with 16 rayon threads, multiple SQLite connections, and pipe FDs for subprocesses, it's theoretically possible to overflow. But I'm speculating here. Looking at recent changes—the `run_incremental_index` modifications with increased `flush_batch_size` and `jwalk_num_threads_fresh` using more threads—more threads definitely means more file descriptors open at once. Let me trace through the actual `run_incremental_index_inner` implementation to see what's really happening.\n\nConfiguring the directory walker with rayon thread pools...\n\nThe issue is that for each root directory in `scan_roots`, a new rayon thread pool gets created with up to 16 threads, and if there are multiple roots being scanned, multiple pools spin up simultaneously, which could be exhausting the file descriptor limit.\n\nBut this would affect all operations, not just the watcher. The real difference is that the watcher runs as a long-lived background thread with its own event loop, while search operations are more transient. Both use the same database connection path, so the issue must be something specific to how the watcher maintains its state over time.\n\nLooking at the logs more carefully, I notice the errors cluster at specific moments when `indexing_active=false`. During fresh indexing runs, the code disables WAL checkpointing entirely, which means the WAL file can grow to hundreds of megabytes with millions of entries. When other connections try to open the database in WAL mode afterward, they need to handle these massive WAL and SHM files, which could be causing the file descriptor exhaustion specifically in the watcher's context. Looking at the CREATE INDEX operation more carefully—it needs an exclusive lock on the database, which in WAL mode means blocking new readers from starting while the index is being built on those 1.1M rows. That could be preventing the watcher from opening a connection when it tries to check the database state. Let me step back and reconsider what \"unable to open database file\" actually means in rusqlite, since I might be overcomplicating the locking mechanics here. error string comes from SQLite error code SQLITE_CANTOPEN (14). The exact submessage might contain more info, but the rusqlite string representation is just \"Unable to open the database file\".\n\nOne specific case for SQLITE_CANTOPEN on macOS: **SHM file access permissions**. SQLite WAL mode requires a shared memory file (`.db-shm`). On macOS with App Sandbox, the app might not have write access to the directory containing the DB if it's in a sandboxed location. But... the search works, so the app CAN open the DB.\n\nAnother case: **SQLITE_CANTOPEN_BKPT** - This can happen if the WAL file or SHM file can't be opened for writing. If another process has the WAL file locked exclusively...\n\nActually, looking at the error pattern differently: the watcher errors burst and then stop while search keeps working. This suggests the database is briefly locked during an indexing operation. When `reset_index` or `start_full_index` runs, it's likely dropping and recreating indexes or clearing entries, which would temporarily block the watcher thread from accessing the database. When other connections try to open the database, they might encounter inconsistency issues. WAL mode shouldn't directly cause \"unable to open database file\" errors though, so I'm not entirely certain of the exact mechanism here. But looking at what actually matters—the user-visible impact—the watcher errors occur during that burst window but the app continues functioning normally afterward, which suggests the real problem is that file system changes happening in that window aren't being tracked, potentially leaving gaps in the index until the next full scan. The practical fix would be to make the watcher handle these connection failures more gracefully, perhaps with exponential backoff retries.\n\nBut \"unable to open database file\" is fundamentally different from \"database is locked\"—the latter suggests a temporary contention issue that retrying helps with, while the former implies the database is genuinely inaccessible. That said, if this is a temporary state tied to WAL file handling during bulk operations, then a delayed retry could work. Looking at the current error handling, it only retries on \"locked\" or \"busy\" errors and emits an error state otherwise, so I need to consider whether \"unable to open database file\" should be treated as a retriable condition. I'm wondering if the issue happens during index recreation—when `is_fresh_run` drops and recreates indexes, the database can still be opened since that's just a write transaction, and WAL mode allows concurrent readers. But I'm also noticing that `run_incremental_index` uses a massive batch size of 50,000 rows for fresh runs, which might be causing the problem.\n\nWith `synchronous=OFF` and transactions that large, the WAL file could balloon to hundreds of megabytes, and if the SHM coordination file gets corrupted during a write, subsequent connection attempts would fail. Though the user didn't mention a crash, and search is working fine, so that doesn't quite fit either.\n\nLet me look at the actual error pattern more carefully—all the watcher errors show `indexing_active=false`, while search logs show successful results with the same flag, which suggests this might not be a persistent issue but something timing-related that happens before the search completes.\n\nLooking at the startup sequence, `db_ready` gets set to true first, then the ensure_db_indexes thread starts, followed by the housekeeping thread, then the watcher, and finally the full index begins. When that full index kicks off, it applies special pragmas that might be interfering with the watcher's ability to write during that window.\n\nThe key insight is that these pragma settings like `synchronous=OFF` and `wal_autocheckpoint=0` are per-connection, not global. So the indexer connection operates with those relaxed settings while the watcher opens its own connection with default settings. The WAL file grows during indexing, and when indexing finishes, it restores normal pragmas.\n\nNow I'm wondering if this could be a macOS sandbox or TCC permissions issue rather than a code problem. The search functionality works fine and can open the database, so the app clearly has access. But the watcher fails specifically. Both use the same connection function though, and threads share the process sandbox anyway. Maybe this isn't actually a bug in the code itself, but something environmental.\n\nI'm thinking about transient OS-level issues on macOS—disk spinup, iCloud syncing, or the app data directory being temporarily locked by Time Machine or Spotlight. Though with 1.1M entries, this would likely be on an SSD without iCloud sync. Let me look at the `reset_index` function to see if the user triggered a reset, which might be opening a new database connection...\n\nExamining the reset function...\n\nDisabling synchronous writes and setting a large cache size, then clearing the entries and metadata tables. When that connection drops after the deletes, SQLite closes without flushing the WAL to the main database file since synchronous is off. Then `start_full_index_worker` immediately opens a fresh connection with the same settings and begins writing, while the file watcher is still active and trying to access the database.\n\nWait, I need to look at the actual `reset_index` function more carefully to understand what's really happening here.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2214,"cache_read_input_tokens":71390,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2214},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtLrGJBYaAa2qfkeG66","type":"assistant","uuid":"e7ff97d7-e54f-4fbb-a5d2-d859363c1e75","timestamp":"2026-02-22T09:41:55.102Z"}
{"parentUuid":"e7ff97d7-e54f-4fbb-a5d2-d859363c1e75","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01W9gGwW7PRK1cAubWJybniM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013nNtaAQZUn1KagxbFKJAkd","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":3055,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2214,"cache_read_input_tokens":71390,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2214},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtLrGJBYaAa2qfkeG66","type":"assistant","uuid":"19dcd05a-bfa4-4095-a402-d1f236d2cc14","timestamp":"2026-02-22T09:41:55.200Z"}
{"parentUuid":"19dcd05a-bfa4-4095-a402-d1f236d2cc14","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013nNtaAQZUn1KagxbFKJAkd","toolUseID":"toolu_013nNtaAQZUn1KagxbFKJAkd","timestamp":"2026-02-22T09:41:55.236Z","uuid":"f968c4d1-fff5-406d-87f3-1e5f3bb9ceeb"}
{"parentUuid":"19dcd05a-bfa4-4095-a402-d1f236d2cc14","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013nNtaAQZUn1KagxbFKJAkd","type":"tool_result","content":"  3055→        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n  3056→        while state.watcher_active.load(AtomicOrdering::Acquire) {\n  3057→            if std::time::Instant::now() >= deadline {\n  3058→                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n  3059→                break;\n  3060→            }\n  3061→            std::thread::sleep(std::time::Duration::from_millis(50));\n  3062→        }\n  3063→\n  3064→        let conn = db_connection(&state.db_path)?;\n  3065→        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n  3066→        let _ = conn.execute_batch(\n  3067→            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n  3068→        );\n  3069→        conn.execute(\"DELETE FROM entries\", [])\n  3070→            .map_err(|e| e.to_string())?;\n  3071→        conn.execute(\"DELETE FROM meta\", [])\n  3072→            .map_err(|e| e.to_string())?;\n  3073→\n  3074→        {\n  3075→            let mut status = state.status.lock();\n  3076→            status.state = IndexState::Indexing;\n  3077→            status.entries_count = 0;\n  3078→            status.last_updated = None;\n  3079→            status.permission_errors = 0;\n  3080→            status.message = None;\n  3081→            status.scanned = 0;\n  3082→            status.indexed = 0;\n  3083→            status.current_path.clear();\n  3084→        }\n  3085→\n  3086→        invalidate_search_caches(&state);\n  3087→\n  3088→        emit_index_state(&app, \"Indexing\", None);\n  3089→        emit_index_updated(&app, 0, now_epoch(), 0);\n  3090→\n  3091→        // Allow new watcher to start\n  3092→        state.watcher_stop.store(false, AtomicOrdering::Release);\n  3093→\n  3094→        #[cfg(target_os = \"windows\")]\n  3095→        {\n  3096→            win::start_windows_indexing(app, state);\n  3097→            Ok(())\n  3098→        }\n  3099→        #[cfg(not(target_os = \"windows\"))]\n  3100→        {\n  3101→            start_full_index_worker(app, state)\n  3102→        }\n  3103→    })\n  3104→    .await\n  3105→    .map_err(|e| e.to_string())?\n  3106→}\n  3107→\n  3108→fn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n  3109→    if !search_log_enabled() {\n  3110→        return;\n  3111→    }\n  3112→\n  3113→    let log_path = db_path.with_file_name(\"search.log\");\n  3114→    let Ok(mut f) = fs::OpenOptions::new()\n  3115→        .create(true)\n  3116→        .append(true)\n  3117→        .open(&log_path)\n  3118→    else {\n  3119→        return;\n  3120→    };\n  3121→    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n  3122→    let _ = writeln!(\n  3123→        f,\n  3124→        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n  3125→        now_epoch(),\n  3126→        query,\n  3127→        mode,\n  3128→        results.len(),\n  3129→        top,\n  3130→    );\n  3131→}\n  3132→\n  3133→fn search_log_enabled() -> bool {\n  3134→    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d45c9dd4-ff46-4f00-90cb-a3e5a6e3d44a","timestamp":"2026-02-22T09:41:55.234Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))","numLines":80,"startLine":3055,"totalLines":5889}},"sourceToolAssistantUUID":"19dcd05a-bfa4-4095-a402-d1f236d2cc14"}
{"parentUuid":"d45c9dd4-ff46-4f00-90cb-a3e5a6e3d44a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01588m7mKEt2SmfXZkgToRfJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BWE4zRxU6URLttwrgSw62G","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":3020,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7857,"cache_read_input_tokens":73604,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7857},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtVXp2nM2ugFNe2gbXc","type":"assistant","uuid":"61b3dc64-393e-4ce8-ac8d-38d7d141d647","timestamp":"2026-02-22T09:41:57.702Z"}
{"parentUuid":"61b3dc64-393e-4ce8-ac8d-38d7d141d647","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01BWE4zRxU6URLttwrgSw62G","toolUseID":"toolu_01BWE4zRxU6URLttwrgSw62G","timestamp":"2026-02-22T09:41:57.714Z","uuid":"8086035c-539d-452d-ab02-313f891deef8"}
{"parentUuid":"61b3dc64-393e-4ce8-ac8d-38d7d141d647","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BWE4zRxU6URLttwrgSw62G","type":"tool_result","content":"  3020→            dto.scanned,\n  3021→            dto.indexed,\n  3022→        );\n  3023→    }\n  3024→    dto\n  3025→}\n  3026→\n  3027→#[tauri::command]\n  3028→fn get_home_dir(state: State<'_, AppState>) -> String {\n  3029→    state.home_dir.to_string_lossy().to_string()\n  3030→}\n  3031→\n  3032→#[tauri::command]\n  3033→fn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n  3034→    #[cfg(target_os = \"windows\")]\n  3035→    {\n  3036→        win::start_windows_indexing(app, state.inner().clone());\n  3037→        Ok(())\n  3038→    }\n  3039→    #[cfg(not(target_os = \"windows\"))]\n  3040→    {\n  3041→        start_full_index_worker(app, state.inner().clone())\n  3042→    }\n  3043→}\n  3044→\n  3045→#[tauri::command]\n  3046→async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n  3047→    let state = state.inner().clone();\n  3048→    tauri::async_runtime::spawn_blocking(move || {\n  3049→        if state.indexing_active.load(AtomicOrdering::Acquire) {\n  3050→            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n  3051→        }\n  3052→\n  3053→        // Stop existing file watcher and wait for it to fully exit\n  3054→        state.watcher_stop.store(true, AtomicOrdering::Release);\n  3055→        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n  3056→        while state.watcher_active.load(AtomicOrdering::Acquire) {\n  3057→            if std::time::Instant::now() >= deadline {\n  3058→                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n  3059→                break;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"51d34812-d49b-4442-ac0a-1cff9bd629e8","timestamp":"2026-02-22T09:41:57.713Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;","numLines":40,"startLine":3020,"totalLines":5889}},"sourceToolAssistantUUID":"61b3dc64-393e-4ce8-ac8d-38d7d141d647"}
{"parentUuid":"51d34812-d49b-4442-ac0a-1cff9bd629e8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01HUPQH4dJxtMcxpuWm6ajoB","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I see the issue! Let me trace the flow for `reset_index` when the watcher doesn't stop within 5 seconds:\n\n1. `state.watcher_stop.store(true)` - signal watcher to stop\n2. Wait up to 5 seconds for `watcher_active` to become false\n3. If watcher doesn't stop: \"proceeding anyway\"\n4. Open DB connection with `synchronous=OFF`\n5. DELETE all entries\n6. DELETE all meta  \n7. Set `watcher_stop = false` (allow new watcher to start)\n8. Start full index\n\nBut wait - the issue in the logs shows `indexing_active=false`. \n\nSo this might not be the reset path. Looking more carefully at the logs, that `indexing_active=false` at the start is probably the tail end of a longer line. Let me check if it's coming from `reset_index` or `start_full_index`. Actually, the watcher errors all show `indexing_active=false`, and the search logs afterward show `db_ready=true indexing_active=false` with results coming back correctly. This means the index already exists with 1.1M+ entries and indexing has completed. Maybe I'm looking at a completely different scenario here.\n\nWhat if the watcher errors are happening right when the full index finishes? At the end of indexing, `run_incremental_index` completes, then `restore_normal_pragmas` runs with a `PASSIVE CHECKPOINT`, and `indexing_active` gets set to false. That checkpoint might cause a brief window where new connections fail to open. Though actually, in SQLite WAL mode, a PASSIVE checkpoint doesn't block new connections at all—readers and writers can proceed normally. `RESTART` or `FULL` checkpoints might block, but we're using PASSIVE. I'm trying to understand what `wal_autocheckpoint=0` actually does in this context.\n\nWith autocheckpointing disabled, the WAL file can grow indefinitely—with 1.1M entries at roughly 100 bytes each, that's around 110MB of WAL data. When the indexer finally calls `PRAGMA wal_checkpoint(PASSIVE)`, it needs to move all those WAL pages back to the main database file, which could take several seconds. During this checkpoint, the database file is being written extensively, and while other readers can still read from the WAL, I'm wondering if creating new connections might fail when the WAL and SHM files are being heavily modified. Rather than keep digging into this, I think the real issue is that this is a temporary condition—possibly a macOS-specific quirk with WAL files during checkpoint—and the solution should be to implement retry logic.\n\nLooking back at the user's log, that truncated `ing_active=false` at the start is interesting. It's likely the tail end of a log line like `[run_incremental_index] done: scanned=... indexed=... indexing_active=false`. The most plausible explanation is that the user starts the app fresh, the full index runs with `synchronous=OFF` and `wal_autocheckpoint=0`, indexing completes, and then during or right after the `PASSIVE CHECKPOINT`, the connection fails.\n\nThe watcher starts receiving FSEvents and tries to open the database, but for a brief window the database is in a state where new connections fail with \"unable to open database file\". Once the checkpoint finishes, the database becomes accessible again and search starts working. This fits all the pieces: `indexing_active=false` shows indexing just wrapped up, the watcher errors come in a burst then stop, and search works afterward once the database is accessible again.\n\nThe reason a `PASSIVE CHECKPOINT` would cause `CANTOPEN` is that during the checkpoint, SQLite acquires a `SHARED` lock on each database page as it copies from the WAL to the main database file. With `wal_autocheckpoint=0` and a massive WAL file (110MB+), the checkpoint operation can cause connection failures.\n\nLooking at the actual code flow, after running `ANALYZE` and restoring normal pragmas—which includes setting the journal mode back to WAL, adjusting synchronous settings, and then executing a `PASSIVE CHECKPOINT`—the connection remains open. The checkpoint itself might be triggering the SHM file recreation or modification, which causes other threads attempting to open the database during that window to hit the `CANTOPEN` error. I see the `restore_normal_pragmas` function sets `synchronous=NORMAL` and runs a passive WAL checkpoint, then I need to trace where the indexer connection gets dropped—it's created in `run_incremental_index` and passed through the call stack, so I need to follow that flow to understand when the connection is actually closed.\n\nLooking at this from another angle, I should check if the `ensure_db_indexes` thread could be causing the issue instead. Setting up database indexes...\n\nThe `CREATE INDEX` operation runs as a write transaction, and while SQLite's WAL mode allows reads during writes, the index creation needs exclusive access during its final commit phase. But actually, the CANTOPEN error happens at the connection level before any transactions even start, so this shouldn't be the culprit either.\n\nCANTOPEN really only means the file or directory doesn't exist, permissions are denied, or the system has hit file descriptor limits. Since the search thread can access the database fine, the issue might be EMFILE—with up to 16 concurrent threads in the thread pool each holding file descriptors for metadata pre-fetching, plus multiple SQLite connections, we could be exhausting the system's open file limit.\n\nThough macOS typically allows 10,240 files per process, which should be plenty even with peak usage around 100 open descriptors. So that's probably not it either. Let me reconsider whether the recent change to `jwalk::WalkDirGeneric` might be the culprit here.\n\nThe new implementation stores pre-fetched metadata in `entry.client_state`, but there's a conditional that skips the metadata fetch during the first shallow pass when depth is within limits. This means entries from that initial shallow scan might have `None` for their metadata state, causing the code to skip them as permission errors when it actually just hasn't fetched their metadata yet.\n\nFor fresh runs with only a single pass, all entries get pre-fetched properly. I'm now checking whether the database pragmas are correctly restored after the fresh index completes—specifically whether `restore_normal_pragmas` properly undoes the performance optimizations that were applied during indexing. I'm realizing `wal_autocheckpoint` isn't being reset in `restore_normal_pragmas`, but more importantly, it's a process-wide setting that affects all connections, not just the indexer connection—so disabling it during indexing impacts the entire database's checkpoint behavior across the application. on! Setting `wal_autocheckpoint=0` on the indexer connection disables automatic checkpointing for the ENTIRE PROCESS for that database!\n\nHmm, but `restore_normal_pragmas` doesn't reset `wal_autocheckpoint`. So after indexing, `wal_autocheckpoint` is still 0 for the entire process. This means the WAL file will keep growing indefinitely until... it could potentially get very large.\n\nBUT - `restore_normal_pragmas` does `PRAGMA wal_checkpoint(PASSIVE)` which forces a manual checkpoint. After that, new connections start from a clean (or smaller) WAL.\n\nWait, but `wal_autocheckpoint=0` means auto-checkpoint is DISABLED. And we never re-enable it. So after the manual PASSIVE checkpoint, the WAL gets checkpointed but then grows again indefinitely as future writes accumulate without auto-checkpoint kicking in. The watcher's small incremental writes would cause slow WAL growth over time, but that wouldn't explain the immediate error we're seeing.\n\nLet me focus on the actual error message itself - the \"unable to open database file\" error from SQLite. I need to check if the watcher's error message format matches what rusqlite would produce. The SHM file in WAL mode is the likely culprit—if it's locked or in an inconsistent state when another connection tries to open the database, SQLite returns CANTOPEN. The `ensure_db_indexes` thread holding an exclusive lock during `CREATE INDEX` could leave the SHM file in a state that prevents subsequent connections from opening it. ensure_db_indexes` runs concurrently with the incremental indexer, and both are trying to acquire write locks for `CREATE INDEX` operations at the same time. When the WAL is in exclusive writer mode during these DDL operations, new connections from the watcher fail with CANTOPEN instead of the expected BUSY error.\n\nLooking at the observable facts though—the error is specifically CANTOPEN rather than BUSY, it happens in bursts then stops, search still works, and indexing_active is false during the errors—this points to something happening with the WAL or SHM file state during the post-indexing checkpoint phase.\n\nThe real issue seems to be that `ensure_db_indexes` is running concurrently with the indexer when it should wait until indexing fully completes. For now though, the quickest fix is treating CANTOPEN as retryable in the watcher like we do with locked errors, which would prevent the UI from showing an error state. The longer-term solution would be restructuring when that index thread starts.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":793,"cache_read_input_tokens":81461,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":793},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtVivmQHcFp4rqWnGS7","type":"assistant","uuid":"f8c31aa4-7715-4cba-908f-7b75346c627f","timestamp":"2026-02-22T09:43:28.612Z"}
{"parentUuid":"f8c31aa4-7715-4cba-908f-7b75346c627f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01HUPQH4dJxtMcxpuWm6ajoB","type":"message","role":"assistant","content":[{"type":"text","text":"로그를 상세 분석했습니다.\n\n---\n\n## 원인 분석\n\n**일시적인 현상이 맞습니다.** 하지만 구조적인 Race Condition이 원인입니다.\n\n### 에러 특성\n\n- `SQLITE_CANTOPEN` (에러 14) — DB가 잠긴 게 아니라 **아예 열리지 않는** 상태\n- 0~4ms 만에 실패 → timeout 문제가 아님\n- 수십 개의 watcher 이벤트가 연속 실패 후 정상 복귀\n- 검색(`db_ready=true`)은 정상 동작\n\n### 핵심 Race Condition\n\n앱 시작 시 아래 세 작업이 **동시**에 실행됩니다:\n\n```\ndb_ready = true\n ├── [Thread A] ensure_db_indexes()   → CREATE INDEX on entries (write lock)\n ├── [Thread B] run_incremental_index → DROP INDEX + 대량 INSERT + CREATE INDEX\n │                                      (synchronous=OFF, wal_autocheckpoint=0)\n └── [Thread C] FSEvent watcher       → db_connection() 시도 → CANTOPEN\n```\n\n**`wal_autocheckpoint=0`은 per-connection이 아닌 process-wide 설정**입니다. 즉, 인덱서가 설정한 후 `restore_normal_pragmas`에서 복구하지 않아서 WAL 자동 checkpoint가 비활성 상태로 남습니다.\n\nThread A와 Thread B가 동시에 DDL (CREATE INDEX, DROP INDEX)을 실행하면 WAL 모드의 SHM 파일이 exclusive write lock 상태가 됩니다. 이 순간 새 connection을 열려고 하면 `SQLITE_BUSY`가 아닌 `SQLITE_CANTOPEN`으로 실패합니다.\n\n### 문제 위치\n\n**1. `restore_normal_pragmas`에서 `wal_autocheckpoint` 복구 누락:**\n```rust\n// 현재: wal_autocheckpoint=0 복구 안 됨\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        \"PRAGMA journal_mode=WAL; PRAGMA synchronous=NORMAL; ...\"\n    )\n```\n\n**2. `ensure_db_indexes`가 indexing 완료 전에 시작됨:**\n- `db_ready=true` 즉시 → `ensure_db_indexes` 실행 (Thread A)\n- 동시에 → `run_incremental_index` 실행 (Thread B) → DROP INDEX 후 CREATE INDEX\n\n**3. watcher의 error handling이 CANTOPEN을 재시도 안 함:**\n```rust\nlet is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n// \"unable to open database file\"는 재시도 없이 Error 상태로 전환 → UI에 \"Index: Error\" 표시\n```\n\n---\n\n## 수정 방향 (3가지)\n\n1. `restore_normal_pragmas`에 `wal_autocheckpoint=1000` 복구 추가  \n2. `ensure_db_indexes`를 인덱싱 완료 후에 실행 (race 제거)  \n3. watcher에서 CANTOPEN도 재시도 대상으로 처리\n\n수정할까요?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":793,"cache_read_input_tokens":81461,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":793},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNtVivmQHcFp4rqWnGS7","type":"assistant","uuid":"b6129052-af1a-49da-b75f-e8b880233806","timestamp":"2026-02-22T09:43:44.133Z"}
{"parentUuid":"b6129052-af1a-49da-b75f-e8b880233806","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"78656fa3-104d-450c-a8b4-b5a099ff870c","toolUseID":"78656fa3-104d-450c-a8b4-b5a099ff870c","timestamp":"2026-02-22T09:43:44.205Z","uuid":"253372cf-e809-4055-a8ea-900b91a557af"}
{"parentUuid":"253372cf-e809-4055-a8ea-900b91a557af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2387}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-22T09:43:46.594Z","uuid":"ca4c9cc0-66a9-47d2-b968-5e27c6cc341f","toolUseID":"78656fa3-104d-450c-a8b4-b5a099ff870c"}
{"parentUuid":"ca4c9cc0-66a9-47d2-b968-5e27c6cc341f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"turn_duration","durationMs":269183,"timestamp":"2026-02-22T09:43:46.596Z","uuid":"c531d901-54ff-455a-b037-74a2d2dd8f9c","isMeta":false}
{"type":"file-history-snapshot","messageId":"e8589c66-8edd-43ed-bdca-1b505b53cf2a","snapshot":{"messageId":"e8589c66-8edd-43ed-bdca-1b505b53cf2a","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-22T09:36:47.635Z"}},"timestamp":"2026-02-22T09:48:56.127Z"},"isSnapshotUpdate":false}
{"parentUuid":"c531d901-54ff-455a-b037-74a2d2dd8f9c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":"1, 2, 3의 수정에 따라 cpu 사용량, indexing 속도, 메모리 어떤 것에 영향을 미치는지 영향 범위를 알려줘"},"uuid":"e8589c66-8edd-43ed-bdca-1b505b53cf2a","timestamp":"2026-02-22T09:48:52.229Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"e8589c66-8edd-43ed-bdca-1b505b53cf2a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_019sah6K64fuuYRHmchcKHSd","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants to understand the impact of each of the 3 proposed fixes on CPU usage, indexing speed, and memory. Let me analyze each fix carefully.\n\n**Fix 1: Add `wal_autocheckpoint=1000` restoration in `restore_normal_pragmas`**\n\n`wal_autocheckpoint=0` means WAL auto-checkpoint is disabled. Setting it to 0 during indexing is intentional to prevent auto-checkpoints from interrupting the bulk insert. After indexing, failing to restore this means:\n- WAL file keeps growing indefinitely as watcher writes accumulate\n- No auto-checkpoint = WAL pages accumulate in the WAL file\n\n\n- Readers still work (WAL mode allows concurrent reads), but they need to scan more WAL pages on each query, and the WAL file grows unbounded\n\nRestoring `wal_autocheckpoint=1000` after indexing means SQLite automatically checkpoints every 1000 WAL pages, keeping the WAL file bounded in size but introducing more frequent I/O operations. This fix slightly increases CPU from periodic checkpoint work while reducing memory usage and having no impact on indexing speed itself.\n\nFor Fix 2, moving `ensure_db_indexes` to run after indexing completes would be redundant during fresh indexing (since indexes are already recreated after the bulk insert), but would affect timing during incremental indexing. The total CPU work stays the same, just shifted to after the indexing phase completes. FASTER because:\n  - No contention with `ensure_db_indexes` during fresh index\n  - For fresh index: indexes are already dropped/recreated by the indexer itself\n  - For incremental index: the existing indexes help with upsert lookups\n- Memory: no significant change\n- The race condition is eliminated\n\nFor a fresh run, the indexer already drops all indexes, bulk inserts, then recreates them, so `ensure_db_indexes` running after would just be a no-op with IF NOT EXISTS. For incremental runs where the indexer doesn't touch indexes, moving `ensure_db_indexes` after eliminates the contention window.\n\nNow looking at treating CANTOPEN as retryable in the watcher—currently it immediately errors, but if I treat it like BUSY with a retry delay, it could significantly improve user experience by avoiding false error states. The downside is that if CANTOPEN is actually persistent, the retry loop would run indefinitely, but the performance impact is negligible.\n\nThinking through how these fixes interact: Fix 1 restores the WAL checkpoint every 1000 pages post-indexing, which is about 4MB of WAL data. is eliminating the race condition, not performance. Fix 3 just adds retry logic for CANTOPEN errors, which improves reliability without affecting performance.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":64,"cache_read_input_tokens":88065,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":64},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNu2ZLBYNbwZTyC1sLgi","type":"assistant","uuid":"4e3d10c7-7223-4edc-b3b6-9a364e127c58","timestamp":"2026-02-22T09:49:25.998Z"}
{"parentUuid":"4e3d10c7-7223-4edc-b3b6-9a364e127c58","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_019sah6K64fuuYRHmchcKHSd","type":"message","role":"assistant","content":[{"type":"text","text":"각 수정이 실제로 어떤 경로에서 영향을 미치는지 코드 기준으로 분석합니다.\n\n---\n\n## Fix 1 — `restore_normal_pragmas`에 `wal_autocheckpoint=1000` 복구\n\n**현재 상태:**\n```rust\n// set_indexing_pragmas에서 설정\nPRAGMA wal_autocheckpoint = 0;  // auto-checkpoint 비활성\n\n// restore_normal_pragmas에서 복구 안 됨\n// → 앱 실행 내내 0으로 유지\n```\n\n`wal_autocheckpoint`는 **process-wide** 설정입니다. 0으로 방치되면 이후 watcher가 파일 변경을 기록할 때마다 WAL 파일이 계속 증가합니다.\n\n| 항목 | 영향 | 설명 |\n|------|------|------|\n| **CPU** | 소폭 증가 | 1000 WAL pages(≈4MB)마다 PASSIVE checkpoint 자동 실행. 단, PASSIVE는 reader/writer를 차단하지 않아 실질 부하는 미미 |\n| **메모리** | 감소 | WAL 파일이 무한 증가하지 않음. mmap된 WAL 영역 축소. 장시간 실행 시 수십~수백MB 차이 가능 |\n| **인덱싱 속도** | 영향 없음 | 인덱싱 중에는 여전히 `wal_autocheckpoint=0` 유지. 복구는 인덱싱 완료 후에만 적용 |\n| **검색 속도** | 소폭 개선 | WAL이 작을수록 쿼리 시 WAL 스캔 페이지 수 감소 |\n\n---\n\n## Fix 2 — `ensure_db_indexes`를 인덱싱 완료 후 실행\n\n**현재 흐름:**\n```\ndb_ready=true\n ├── [Thread A] ensure_db_indexes() → CREATE INDEX (write lock 경쟁)\n └── [Thread B] run_incremental_index\n      ├── fresh: DROP INDEX → bulk insert → CREATE INDEX  ← A와 DDL 동시 경쟁\n      └── incremental: upsert (기존 index 유지)\n```\n\n**수정 후 흐름:**\n```\ndb_ready=true\n └── [Thread B] run_incremental_index\n      ├── fresh: DROP INDEX → bulk insert → CREATE INDEX\n      └── incremental: upsert\n           └── (완료 후) ensure_db_indexes()\n```\n\n| 항목 | fresh index | incremental index |\n|------|-------------|-------------------|\n| **CPU** | 변화 없음. `ensure_db_indexes`는 `CREATE INDEX IF NOT EXISTS` → 이미 존재하므로 no-op | 변화 없음. 인덱싱 후 실행이므로 순차적으로 동일 작업 |\n| **인덱싱 속도** | **향상 가능**. Thread A/B의 DDL 경쟁 제거로 lock contention 해소 | 미미. incremental은 원래 index를 유지하며 upsert |\n| **메모리** | 영향 없음 | 영향 없음 |\n| **Race Condition** | **제거** | **제거** |\n\n**주의:** incremental 실행 시, `ensure_db_indexes`가 인덱싱 후로 밀리므로 새 인덱스가 추가된 경우 인덱스 생성이 약간 늦어집니다. 하지만 이는 기능적 문제가 아닙니다.\n\n---\n\n## Fix 3 — watcher에서 CANTOPEN도 재시도 처리\n\n**현재 코드:**\n```rust\nlet is_busy = err.contains(\"locked\") || err.contains(\"busy\");\nif is_busy { /* retry */ }\n// CANTOPEN → 즉시 Error 상태로 전환, 이벤트 유실\n```\n\n**수정 후:**\n```rust\nlet is_retryable = err.contains(\"locked\") || err.contains(\"busy\")\n    || err.contains(\"unable to open\");\nif is_retryable { /* retry with delay */ }\n```\n\n| 항목 | 영향 | 설명 |\n|------|------|------|\n| **CPU** | 무시 가능 | retry 대기 중 sleep 상태. 실제 CPU 0에 수렴 |\n| **메모리** | 미미한 증가 | retry 동안 pending paths를 HashSet에 보관. watcher 이벤트 수십 개 × PathBuf 크기 |\n| **인덱싱 속도** | 영향 없음 | watcher와 indexer는 별개 경로 |\n| **정확성** | **개선** | CANTOPEN 중 받은 이벤트가 재시도로 반영됨. 현재는 해당 이벤트 유실 |\n| **부작용** | CANTOPEN이 영구적 오류일 경우 retry loop가 반복 | `DB_BUSY_RETRY_DELAY(3s)` 간격으로 무한 재시도 가능. 최대 재시도 횟수 제한 필요 |\n\n---\n\n## 종합 영향 요약\n\n| | CPU | 메모리 | 인덱싱 속도 | 안정성 |\n|--|-----|--------|------------|--------|\n| **Fix 1** | 미미 증가 | **감소** (WAL 크기 제한) | 변화 없음 | 개선 |\n| **Fix 2** | 변화 없음 | 변화 없음 | **개선** (race 제거) | **개선** |\n| **Fix 3** | 무시 가능 | 미미 증가 | 변화 없음 | **개선** |\n\n세 수정 모두 **성능에 부정적인 영향이 없으며**, Fix 2는 인덱싱 안정성, Fix 1은 장기 메모리 사용량에 실질적인 개선 효과가 있습니다. 진행할까요?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":64,"cache_read_input_tokens":88065,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":64},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNu2ZLBYNbwZTyC1sLgi","type":"assistant","uuid":"3d2d97d0-e614-4eb8-a1c7-73cc3bc27081","timestamp":"2026-02-22T09:49:51.655Z"}
{"parentUuid":"3d2d97d0-e614-4eb8-a1c7-73cc3bc27081","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"655f874d-7f93-4f2e-84c2-3c9718d6f0de","toolUseID":"655f874d-7f93-4f2e-84c2-3c9718d6f0de","timestamp":"2026-02-22T09:49:51.731Z","uuid":"e1052b66-9ec2-435b-9ae8-741be95146ed"}
{"parentUuid":"e1052b66-9ec2-435b-9ae8-741be95146ed","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2108}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-22T09:49:53.840Z","uuid":"2178dc72-6eff-45b4-b204-4e92bdd596d1","toolUseID":"655f874d-7f93-4f2e-84c2-3c9718d6f0de"}
{"parentUuid":"2178dc72-6eff-45b4-b204-4e92bdd596d1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"turn_duration","durationMs":57714,"timestamp":"2026-02-22T09:49:53.842Z","uuid":"2baf94dc-de9f-430f-abee-bb866608d161","isMeta":false}
{"type":"file-history-snapshot","messageId":"f8e70f67-c92e-4b8c-b732-ffa8da85b20d","snapshot":{"messageId":"f8e70f67-c92e-4b8c-b732-ffa8da85b20d","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-22T09:36:47.635Z"}},"timestamp":"2026-02-22T09:51:33.228Z"},"isSnapshotUpdate":false}
{"parentUuid":"2baf94dc-de9f-430f-abee-bb866608d161","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":"수정 진행해줘"},"uuid":"f8e70f67-c92e-4b8c-b732-ffa8da85b20d","timestamp":"2026-02-22T09:51:29.501Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"f8e70f67-c92e-4b8c-b732-ffa8da85b20d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01DVupLNFD2U48Ng1RuMQAYC","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me look at the relevant code sections before making changes.","signature":"EugBCkYICxgCKkBbmmj2rqa970seHC7cz2g03tKWYEA11UrHObnLhIO6LnOykHhp0sa1X8lsi+vyYU7VBnE+gbdjZfoBOmDjAQSQEgyibCgrGq2o4MFvJrkaDIdHQ2s4yd55vuh7FiIwFK+V3qJv/PzeALbWITCOP2oPjbBuYozFDSUw/ekbireKsLFAm7mCVB20yCBN7rrIKlCyWOQSOAUm77/Y4N9/L22OmNGlW6NhNa4rb4BtTlswGymjC39tbdnaW2v96a2u0VdspmsXfijCzF7bOKQgY5cKXMz2AUewfovMypv5uAyzlBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12,"cache_read_input_tokens":91026,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuE9dzL7TwbGc62hC1F","type":"assistant","uuid":"0be8fe6c-9094-4352-acab-29760d51ed87","timestamp":"2026-02-22T09:51:35.506Z"}
{"parentUuid":"0be8fe6c-9094-4352-acab-29760d51ed87","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01DVupLNFD2U48Ng1RuMQAYC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QW7SK8PbvRonL6NQCcPeCy","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":460,"limit":25},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12,"cache_read_input_tokens":91026,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuE9dzL7TwbGc62hC1F","type":"assistant","uuid":"5d3bfa58-aa4b-45f4-bd50-cc81087d39a4","timestamp":"2026-02-22T09:51:36.629Z"}
{"parentUuid":"5d3bfa58-aa4b-45f4-bd50-cc81087d39a4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01QW7SK8PbvRonL6NQCcPeCy","toolUseID":"toolu_01QW7SK8PbvRonL6NQCcPeCy","timestamp":"2026-02-22T09:51:36.640Z","uuid":"1375d1aa-7a54-4907-8a06-ecc41e74859e"}
{"parentUuid":"5d3bfa58-aa4b-45f4-bd50-cc81087d39a4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QW7SK8PbvRonL6NQCcPeCy","type":"tool_result","content":"   460→        r#\"\n   461→        PRAGMA synchronous = NORMAL;\n   462→        PRAGMA cache_size = -16384;\n   463→        PRAGMA mmap_size = 268435456;\n   464→        PRAGMA wal_autocheckpoint = 1000;\n   465→        \"#,\n   466→    )\n   467→    .map_err(|e| e.to_string())?;\n   468→    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n   469→    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n   470→    // when the next auto-checkpoint threshold is hit.\n   471→    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n   472→        .map_err(|e| e.to_string())?;\n   473→    Ok(())\n   474→}\n   475→\n   476→/// Phase 1: creates tables only. Fast even on large DBs.\n   477→fn init_db_tables(db_path: &Path) -> AppResult<()> {\n   478→    let t = Instant::now();\n   479→    let conn = db_connection(db_path)?;\n   480→    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n   481→\n   482→    let current_version: i32 = conn\n   483→        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n   484→        .unwrap_or(0);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"7e1dce3e-c476-4a76-bac6-fed357ab6ff0","timestamp":"2026-02-22T09:51:36.639Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\n/// Phase 1: creates tables only. Fast even on large DBs.\nfn init_db_tables(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);","numLines":25,"startLine":460,"totalLines":5889}},"sourceToolAssistantUUID":"5d3bfa58-aa4b-45f4-bd50-cc81087d39a4"}
{"parentUuid":"7e1dce3e-c476-4a76-bac6-fed357ab6ff0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01DVupLNFD2U48Ng1RuMQAYC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NhqzASu1DX7MaSQrt76bqd","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":5195,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12,"cache_read_input_tokens":91026,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuE9dzL7TwbGc62hC1F","type":"assistant","uuid":"bf96e97a-2e1f-4a35-b64e-92cfceca9fe5","timestamp":"2026-02-22T09:51:37.277Z"}
{"parentUuid":"bf96e97a-2e1f-4a35-b64e-92cfceca9fe5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01NhqzASu1DX7MaSQrt76bqd","toolUseID":"toolu_01NhqzASu1DX7MaSQrt76bqd","timestamp":"2026-02-22T09:51:37.289Z","uuid":"aa88817a-a4be-46aa-836a-18b87e20dd43"}
{"parentUuid":"bf96e97a-2e1f-4a35-b64e-92cfceca9fe5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NhqzASu1DX7MaSQrt76bqd","type":"tool_result","content":"  5195→        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n  5196→        if let Err(err) = init_db_tables(&state.db_path) {\n  5197→            set_state(&state, IndexState::Error, Some(err.clone()));\n  5198→            emit_index_state(&app_handle, \"Error\", Some(err));\n  5199→            return;\n  5200→        }\n  5201→        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n  5202→\n  5203→        state.db_ready.store(true, AtomicOrdering::Release);\n  5204→        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n  5205→\n  5206→        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n  5207→        {\n  5208→            let idx_db_path = state.db_path.clone();\n  5209→            std::thread::spawn(move || {\n  5210→                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n  5211→                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n  5212→                }\n  5213→            });\n  5214→        }\n  5215→\n  5216→        // Deferred housekeeping -- purge + status counts run in background\n  5217→        {\n  5218→            let hk_app = app_handle.clone();\n  5219→            let hk_state = state.clone();\n  5220→            std::thread::spawn(move || {\n  5221→                // Brief pause so indexing thread can start first\n  5222→                std::thread::sleep(std::time::Duration::from_millis(500));\n  5223→                let hk_started = std::time::Instant::now();\n  5224→                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6b147359-5288-446a-a971-99a0bb4575b5","timestamp":"2026-02-22T09:51:37.288Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);","numLines":30,"startLine":5195,"totalLines":5889}},"sourceToolAssistantUUID":"bf96e97a-2e1f-4a35-b64e-92cfceca9fe5"}
{"parentUuid":"6b147359-5288-446a-a971-99a0bb4575b5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Fya8rNQGbiPAgtA851GpF6","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Good. Now I have the context. Let me look at `restore_normal_pragmas` to see if `wal_autocheckpoint` is already there or not.\n\nFrom what I see at line 460-464:\n```rust\nr#\"\nPRAGMA synchronous = NORMAL;\nPRAGMA cache_size = -16384;\nPRAGMA mmap_size = 268435456;\nPRAGMA wal_autocheckpoint = 1000;\n\"#,\n```\n\nOh wait, `wal_autocheckpoint = 1000` is already in `restore_normal_pragmas`! Let me re-read the full function.","signature":"EsEECkYICxgCKkCvDFLxtevY9ui7wK628dNbcHfm6lNppoddpmeQ9KYjTazIlOww0uUAOYttYLlHzENQlTbF/EnxK9JAgUQ/BBLFEgy0zQJuAkfLLutLHboaDH7fHTtPvoBVl6y7tSIwi0XF18eM3jkvTi3mAqRRGNlP15wSqEvzH4uDhZc2MaJZ0hu71X1bUovdXAH7crUAKqgD2HmCEmJCLAL3rCGv6ddAaxiNU7c6+B+CZlPPwRu5aEtBquxrM9I14qiuQkeR1yzkjUejsucxsNdBV/oov6phiRt4dUDDOK81x8ZHvPl4IDJ0+5zLcycbJFS1l9CHC3fEYCPkaQKF+aGGOOfOk4VccCkHbi5IaJA2J+eDXGwCValMB3IBS3pQsZeAQUVo1ELMhgu2vi7T6ughugwPuH5K3ZBJrLXgg/szFUelL653ylAyNk5Lbw4zzEXr+fNka9f4tdaAkOPdEKani6VgvnI14ODJ5CDQrTPzLpLeHkby1lsya0V1+L6A+JH72gQmHSMKmKho5Yj/h+9/+1L/oGnlNe5/73XAyuRUGFDA34Due/asof4p4uCC3sVw3yPT2vdCquA+9PwOcScS+BPNUYl4MtVYxVnRubBH8xVskyK3UHnx/mS4ZSuyJi2LRvI/H7rtZZ2mHuAwx610r4jPvnmGIdq9EiORahaBbid43IMh5gFN4kCfhNKrIME6j8vdRKfpOdIGFc+Glpeu2wmED5vX8+EQtzx76/unCH2nJ65lTns91ByT3LJK0hgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1386,"cache_read_input_tokens":91038,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1386},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuESYjFtPwrNcdEANYg","type":"assistant","uuid":"79771ee6-5e25-4a66-a22e-b7c5f1a9dc28","timestamp":"2026-02-22T09:51:41.296Z"}
{"parentUuid":"79771ee6-5e25-4a66-a22e-b7c5f1a9dc28","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Fya8rNQGbiPAgtA851GpF6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Q2sDaLZcGhD8wX39LYjpvG","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":446,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1386,"cache_read_input_tokens":91038,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1386},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuESYjFtPwrNcdEANYg","type":"assistant","uuid":"41c93e18-a02d-404d-b7fd-89101e24ad8b","timestamp":"2026-02-22T09:51:42.471Z"}
{"parentUuid":"41c93e18-a02d-404d-b7fd-89101e24ad8b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Q2sDaLZcGhD8wX39LYjpvG","toolUseID":"toolu_01Q2sDaLZcGhD8wX39LYjpvG","timestamp":"2026-02-22T09:51:42.519Z","uuid":"373104a8-3df3-4684-bff9-d97a3cff5242"}
{"parentUuid":"41c93e18-a02d-404d-b7fd-89101e24ad8b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q2sDaLZcGhD8wX39LYjpvG","type":"tool_result","content":"   446→pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n   447→    conn.execute_batch(\n   448→        r#\"\n   449→        PRAGMA synchronous = OFF;\n   450→        PRAGMA cache_size = -131072;\n   451→        PRAGMA mmap_size = 536870912;\n   452→        PRAGMA wal_autocheckpoint = 0;\n   453→        \"#,\n   454→    )\n   455→    .map_err(|e| e.to_string())\n   456→}\n   457→\n   458→pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n   459→    conn.execute_batch(\n   460→        r#\"\n   461→        PRAGMA synchronous = NORMAL;\n   462→        PRAGMA cache_size = -16384;\n   463→        PRAGMA mmap_size = 268435456;\n   464→        PRAGMA wal_autocheckpoint = 1000;\n   465→        \"#,\n   466→    )\n   467→    .map_err(|e| e.to_string())?;\n   468→    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n   469→    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n   470→    // when the next auto-checkpoint threshold is hit.\n   471→    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n   472→        .map_err(|e| e.to_string())?;\n   473→    Ok(())\n   474→}\n   475→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"870e5157-153f-4719-9106-d752d769a053","timestamp":"2026-02-22T09:51:42.517Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n","numLines":30,"startLine":446,"totalLines":5889}},"sourceToolAssistantUUID":"41c93e18-a02d-404d-b7fd-89101e24ad8b"}
{"parentUuid":"870e5157-153f-4719-9106-d752d769a053","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Fya8rNQGbiPAgtA851GpF6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NJAFZArj6t6uCHcJB6HPj7","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2055,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1386,"cache_read_input_tokens":91038,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1386},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuESYjFtPwrNcdEANYg","type":"assistant","uuid":"da7e718e-fb6f-45a7-a465-9e9021506754","timestamp":"2026-02-22T09:51:43.117Z"}
{"parentUuid":"da7e718e-fb6f-45a7-a465-9e9021506754","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01NJAFZArj6t6uCHcJB6HPj7","toolUseID":"toolu_01NJAFZArj6t6uCHcJB6HPj7","timestamp":"2026-02-22T09:51:43.162Z","uuid":"62160374-7ce7-423f-9e4a-40c37058c1aa"}
{"parentUuid":"da7e718e-fb6f-45a7-a465-9e9021506754","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NJAFZArj6t6uCHcJB6HPj7","type":"tool_result","content":"  2055→\n  2056→    let mut conn = db_connection(&state.db_path)?;\n  2057→    set_indexing_pragmas(&conn)?;\n  2058→\n  2059→    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n  2060→    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n  2061→    // which can be 3-5x faster when loading hundreds of thousands of rows.\n  2062→    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n  2063→        .and_then(|v| v.parse::<i64>().ok())\n  2064→        .unwrap_or(0)\n  2065→        == 0;\n  2066→    if is_fresh_run {\n  2067→        let _ = conn.execute_batch(\n  2068→            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n  2069→             DROP INDEX IF EXISTS idx_entries_mtime;\n  2070→             DROP INDEX IF EXISTS idx_entries_name_nocase;\n  2071→             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n  2072→        );\n  2073→    }\n  2074→\n  2075→    let result = run_incremental_index_inner(app, state, &mut conn);\n  2076→\n  2077→    if is_fresh_run {\n  2078→        let t_idx = Instant::now();\n  2079→        let _ = conn.execute_batch(\n  2080→            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n  2081→             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n  2082→             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n  2083→             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n  2084→        );\n  2085→        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n  2086→    }\n  2087→\n  2088→    let t_analyze = Instant::now();\n  2089→    let _ = conn.execute_batch(\"ANALYZE\");\n  2090→    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n  2091→    let t_checkpoint = Instant::now();\n  2092→    let _ = restore_normal_pragmas(&conn);\n  2093→    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n  2094→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3fa0d5ae-21e0-49b5-b352-f4673891b7e6","timestamp":"2026-02-22T09:51:43.160Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n","numLines":40,"startLine":2055,"totalLines":5889}},"sourceToolAssistantUUID":"da7e718e-fb6f-45a7-a465-9e9021506754"}
{"parentUuid":"3fa0d5ae-21e0-49b5-b352-f4673891b7e6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Wb4Vt8bD1V3j1da7E6bqEF","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Fix 1 is already done - `restore_normal_pragmas` already has `PRAGMA wal_autocheckpoint = 1000`. This was a recent change.\n\nNow let me focus on:\n- Fix 2: Move `ensure_db_indexes` to after indexing completes (not at `db_ready=true`)\n- Fix 3: Treat CANTOPEN as retryable in watcher\n\nLet me look at the watcher error handling code more carefully.","signature":"Ev0DCkYICxgCKkAVLcrWMxnh/RDu/vXL0jycTSgfVK6kmAYhhedbw2KF2mKs3Mb68WYYJQCpnQykM3JjXDYGrcSIqcT6HdIbNwEPEgx3aowOg1/t35r/9cUaDKJEueo/sz9DftFs0iIwtM1ekAmWbXUI1jbiScJPS0gGpdxSbftzAuvPq3MgAXd+nx0RMg94RvWV0m0C3uYIKuQCqlvbiMb3sK8hZ+Y5/Yc5ze4a3WUHvJRA3QaYt73vI3tQhUXucdf4SSjaOih3mqkE14XxmSsT8cnulSTNMC0L0MjM0LXIMe7eNcYK8j2w31lNdAi2CUbtyB/LYcN0guizT29OAaNdgdVKxfjX5Hz3J/K4Ep+6RMK1n/uPLvyaQm+X5LzGz9/zWmE1Za7CHm7uRAP+p1p0GR4MdDjmbLEFFxjVErxuqCubVyaNRL6qFd1MXzXbPSzmG/N4sn7UBoPpmFluP5GTmAouE+sSdSB3S2LZSOzR7D8rQ5RoMfRW56lrQhsiS+cnv0CcbShrLqlwJLpp4A1bT+kdMqlrNuthW8Yp6WN4w9jFKTLoa6JPz9Pun0Giw5xkdT+HA2UiO1kubNGMTntf+txg4t7YMmYadlJpiVdo1JD/+U9204/a2CRM0psv8CCw1y/xx4T6EtNp+RZ0NFUe0DHuyV4pGVBOOszlqPIYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1799,"cache_read_input_tokens":92424,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1799},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuEs3sRrGPQiZa8R6Vy","type":"assistant","uuid":"de0c67d5-4e08-470c-a337-e3dc3889614d","timestamp":"2026-02-22T09:51:47.557Z"}
{"parentUuid":"de0c67d5-4e08-470c-a337-e3dc3889614d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Wb4Vt8bD1V3j1da7E6bqEF","type":"message","role":"assistant","content":[{"type":"text","text":"Fix 1은 이미 `restore_normal_pragmas`에 `wal_autocheckpoint = 1000`이 있어서 **완료 상태**입니다.\n\nFix 2, 3을 진행합니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1799,"cache_read_input_tokens":92424,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1799},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuEs3sRrGPQiZa8R6Vy","type":"assistant","uuid":"b0cff83a-d654-4c94-8418-71774e20908a","timestamp":"2026-02-22T09:51:48.737Z"}
{"parentUuid":"b0cff83a-d654-4c94-8418-71774e20908a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Wb4Vt8bD1V3j1da7E6bqEF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Puoq1EqdZA5hcARGrNU1fr","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2094,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1799,"cache_read_input_tokens":92424,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1799},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuEs3sRrGPQiZa8R6Vy","type":"assistant","uuid":"0a84d39b-5fb0-4c09-8a54-3a1ae22b6192","timestamp":"2026-02-22T09:51:50.203Z"}
{"parentUuid":"0a84d39b-5fb0-4c09-8a54-3a1ae22b6192","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Puoq1EqdZA5hcARGrNU1fr","toolUseID":"toolu_01Puoq1EqdZA5hcARGrNU1fr","timestamp":"2026-02-22T09:51:50.250Z","uuid":"c78fc5af-e436-4455-89ef-26a1de5ab53f"}
{"parentUuid":"0a84d39b-5fb0-4c09-8a54-3a1ae22b6192","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Puoq1EqdZA5hcARGrNU1fr","type":"tool_result","content":"  2094→\n  2095→    match &result {\n  2096→        Ok(_) => {\n  2097→            let _ = set_meta(&conn, \"index_complete\", \"1\");\n  2098→            let snapshot = state.status.lock().clone();\n  2099→            perf_log(format!(\n  2100→                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n  2101→                started.elapsed().as_millis(),\n  2102→                snapshot.scanned,\n  2103→                snapshot.indexed,\n  2104→                snapshot.entries_count,\n  2105→                snapshot.permission_errors,\n  2106→                snapshot.message,\n  2107→            ));\n  2108→        }\n  2109→        Err(err) => {\n  2110→            perf_log(format!(\n  2111→                \"index_run_error elapsed_ms={} err={}\",\n  2112→                started.elapsed().as_millis(),\n  2113→                err,\n  2114→            ));\n  2115→        }\n  2116→    }\n  2117→\n  2118→    result\n  2119→}\n  2120→\n  2121→fn run_incremental_index_inner(\n  2122→    app: &AppHandle,\n  2123→    state: &AppState,\n  2124→    conn: &mut Connection,\n  2125→) -> AppResult<()> {\n  2126→\n  2127→    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n  2128→        &state.home_dir,\n  2129→        &state.cwd,\n  2130→        state.path_ignores.as_ref(),\n  2131→        state.path_ignore_patterns.as_ref(),\n  2132→    );\n  2133→    let gi_filter = state.gitignore.get();\n  2134→\n  2135→    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n  2136→        .and_then(|v| v.parse().ok())\n  2137→        .unwrap_or(0);\n  2138→    let current_run_id = last_run_id + 1;\n  2139→    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n  2140→    let is_fresh = last_run_id == 0;\n  2141→\n  2142→    // Fresh index has no secondary indexes to maintain, so we can use larger\n  2143→    // batches to reduce transaction overhead (fewer commits = faster).\n  2144→    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n  2145→\n  2146→    let mut scanned: u64 = 0;\n  2147→    let mut indexed: u64 = 0;\n  2148→    let mut permission_errors: u64 = 0;\n  2149→    let mut current_path = String::new();\n  2150→    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n  2151→    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n  2152→    let mut last_emit = Instant::now();\n  2153→    let mut last_perf_emit = Instant::now();\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"fa9d5128-0bb2-447a-b302-efce878b6222","timestamp":"2026-02-22T09:51:50.242Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();","numLines":60,"startLine":2094,"totalLines":5889}},"sourceToolAssistantUUID":"0a84d39b-5fb0-4c09-8a54-3a1ae22b6192"}
{"parentUuid":"fa9d5128-0bb2-447a-b302-efce878b6222","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Wb4Vt8bD1V3j1da7E6bqEF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LVYC5UX7Qkwfx7HiCBQ1hj","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2670,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1799,"cache_read_input_tokens":92424,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1799},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuEs3sRrGPQiZa8R6Vy","type":"assistant","uuid":"6aa45ba9-56bc-48bf-84c1-cc628aaa737d","timestamp":"2026-02-22T09:51:50.452Z"}
{"parentUuid":"6aa45ba9-56bc-48bf-84c1-cc628aaa737d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01LVYC5UX7Qkwfx7HiCBQ1hj","toolUseID":"toolu_01LVYC5UX7Qkwfx7HiCBQ1hj","timestamp":"2026-02-22T09:51:50.492Z","uuid":"72ec4b1d-312b-413c-9ae3-4bd70c638763"}
{"parentUuid":"6aa45ba9-56bc-48bf-84c1-cc628aaa737d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LVYC5UX7Qkwfx7HiCBQ1hj","type":"tool_result","content":"  2670→                    *pending_status_emit = true;\n  2671→                }\n  2672→            }\n  2673→        }\n  2674→        Err(err) => {\n  2675→            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n  2676→            if is_busy {\n  2677→                eprintln!(\n  2678→                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n  2679→                    DB_BUSY_RETRY_DELAY.as_secs(),\n  2680→                    err,\n  2681→                    batch.len()\n  2682→                );\n  2683→                for path in batch {\n  2684→                    pending.insert(path);\n  2685→                }\n  2686→                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n  2687→                return;\n  2688→            }\n  2689→            eprintln!(\n  2690→                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n  2691→                err,\n  2692→                batch.len(),\n  2693→                state.indexing_active.load(AtomicOrdering::Acquire)\n  2694→            );\n  2695→            *deadline = None;\n  2696→            if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2697→                return;\n  2698→            }\n  2699→            let mut status = state.status.lock();\n  2700→            if !matches!(status.state, IndexState::Indexing) {\n  2701→                status.state = IndexState::Error;\n  2702→            }\n  2703→            status.message = Some(format!(\"Watcher update failed: {err}\"));\n  2704→            drop(status);\n  2705→            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n  2706→        }\n  2707→    }\n  2708→}\n  2709→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"35c81126-887d-4d80-9542-4a81a86c834e","timestamp":"2026-02-22T09:51:50.490Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n","numLines":40,"startLine":2670,"totalLines":5889}},"sourceToolAssistantUUID":"6aa45ba9-56bc-48bf-84c1-cc628aaa737d"}
{"parentUuid":"35c81126-887d-4d80-9542-4a81a86c834e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01VZoMR2GacaEYXPHDYEHJwT","type":"message","role":"assistant","content":[{"type":"text","text":"이제 두 수정을 적용합니다.\n\n**Fix 2: `ensure_db_indexes`를 인덱싱 완료 후 실행**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2025,"cache_read_input_tokens":94223,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2025},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuFQnqfWMKXY5AvHF8M","type":"assistant","uuid":"886e289f-2c84-477e-9d79-9c0deb69ce58","timestamp":"2026-02-22T09:51:53.142Z"}
{"parentUuid":"886e289f-2c84-477e-9d79-9c0deb69ce58","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01VZoMR2GacaEYXPHDYEHJwT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01A436nhyVw7QsJ9pW85EExt","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background","new_string":"        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2025,"cache_read_input_tokens":94223,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2025},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuFQnqfWMKXY5AvHF8M","type":"assistant","uuid":"b731ccac-8781-41f8-aa5d-2ae796f32190","timestamp":"2026-02-22T09:51:58.017Z"}
{"parentUuid":"b731ccac-8781-41f8-aa5d-2ae796f32190","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01A436nhyVw7QsJ9pW85EExt","toolUseID":"toolu_01A436nhyVw7QsJ9pW85EExt","timestamp":"2026-02-22T09:51:58.031Z","uuid":"489799ff-4c1e-4dcb-8b18-19f797f35dfb"}
{"parentUuid":"b731ccac-8781-41f8-aa5d-2ae796f32190","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01A436nhyVw7QsJ9pW85EExt","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"30b16733-1f0e-4d14-91e8-8e44fbf8a945","timestamp":"2026-02-22T09:51:58.029Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background","newString":"        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\n/// Phase 1: creates tables only. Fast even on large DBs.\nfn init_db_tables(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\n/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n/// when new indexes are added; runs after db_ready so it does not block startup.\nfn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n\n    conn.execute_batch(\n        r#\"\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n\n    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n        // range-scan optimization when an ESCAPE clause is present, causing a full\n        // table scan even though `path` has a UNIQUE (implicit) index.\n        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n        let lo = format!(\"{prefix}/\");\n        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n            params![prefix, lo, hi],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let conn = db_connection(&state.db_path)?;\n    let (entries_count, last_updated) = update_counts(&conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts so next startup can read them instantly\n    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_counts(conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(10),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":5203,"oldLines":16,"newStart":5203,"newLines":6,"lines":["         state.db_ready.store(true, AtomicOrdering::Release);","         eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());"," ","-        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.","-        {","-            let idx_db_path = state.db_path.clone();","-            std::thread::spawn(move || {","-                if let Err(e) = ensure_db_indexes(&idx_db_path) {","-                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");","-                }","-            });","-        }","-","         // Deferred housekeeping -- purge + status counts run in background","         {","             let hk_app = app_handle.clone();"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"b731ccac-8781-41f8-aa5d-2ae796f32190"}
{"parentUuid":"30b16733-1f0e-4d14-91e8-8e44fbf8a945","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01DRKLdQY6aBBkEeMjFV5jNy","type":"message","role":"assistant","content":[{"type":"text","text":"이제 `run_incremental_index`가 완료된 직후에 `ensure_db_indexes`를 호출합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":464,"cache_read_input_tokens":96248,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":464},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuFxkhUui94wuCJ3S73","type":"assistant","uuid":"9ae8ee47-10b2-4415-88f8-3cd136a1386e","timestamp":"2026-02-22T09:52:00.153Z"}
{"parentUuid":"cbd9efe1-965b-43ed-9619-5aa276a4a45d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01PXTahRCdMqusUgvqHy14rk","type":"message","role":"assistant","content":[{"type":"text","text":"**Fix 3: watcher에서 CANTOPEN도 재시도 처리**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":537,"cache_read_input_tokens":96712,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":537},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNuGUwtj3Za4EwbDMCtg","type":"assistant","uuid":"55ae369d-567e-4d08-84f0-07ce230c3a4e","timestamp":"2026-02-22T09:52:06.857Z"}
