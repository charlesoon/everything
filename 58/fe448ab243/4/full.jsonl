{"type":"file-history-snapshot","messageId":"2f6edd34-5622-4a4d-82d2-1e4df241b2ce","snapshot":{"messageId":"2f6edd34-5622-4a4d-82d2-1e4df241b2ce","trackedFileBackups":{},"timestamp":"2026-02-20T09:42:47.807Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:clear","command":"entire hooks claude-code session-start"},"parentToolUseID":"a3424200-ad41-44b4-930c-00a754f9ca6a","toolUseID":"a3424200-ad41-44b4-930c-00a754f9ca6a","timestamp":"2026-02-20T09:42:46.974Z","uuid":"13cab965-6982-44bf-904b-585cf0bcae0c"}
{"parentUuid":"13cab965-6982-44bf-904b-585cf0bcae0c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-caveat>Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.</local-command-caveat>"},"isMeta":true,"uuid":"462631af-0231-4691-8c0a-077522a8b1ad","timestamp":"2026-02-20T09:42:47.807Z"}
{"parentUuid":"462631af-0231-4691-8c0a-077522a8b1ad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<command-name>/clear</command-name>\n            <command-message>clear</command-message>\n            <command-args></command-args>"},"uuid":"2f6edd34-5622-4a4d-82d2-1e4df241b2ce","timestamp":"2026-02-20T09:42:46.130Z"}
{"parentUuid":"2f6edd34-5622-4a4d-82d2-1e4df241b2ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-stdout></local-command-stdout>"},"uuid":"b7d9797c-75ac-4644-bf96-9885c336cd83","timestamp":"2026-02-20T09:42:47.807Z"}
{"type":"file-history-snapshot","messageId":"8e63129d-2cb0-4c95-9b61-c37c6aa6fa77","snapshot":{"messageId":"8e63129d-2cb0-4c95-9b61-c37c6aa6fa77","trackedFileBackups":{},"timestamp":"2026-02-20T09:42:52.984Z"},"isSnapshotUpdate":false}
{"parentUuid":"b7d9797c-75ac-4644-bf96-9885c336cd83","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"재실행시 Ready인 상태에서 갑자기 Index: Error\nEntries: 1,171,663\nReset Index\nWatcher update failed: database is locked 로 바뀐다. 이 이슈를 추적하게 로그 넣어줘"},"uuid":"8e63129d-2cb0-4c95-9b61-c37c6aa6fa77","timestamp":"2026-02-20T09:42:51.544Z","permissionMode":"bypassPermissions"}
{"parentUuid":"8e63129d-2cb0-4c95-9b61-c37c6aa6fa77","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_015Bx9xkLasj28vs2Hkg8txY","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is reporting that when restarting the app, it starts in \"Ready\" state but then suddenly changes to \"Index: Error\" with the message \"Watcher update failed: database is locked\". They want me to add logging to track this issue.\n\nLet me first read the main Rust backend file to understand the current code structure.","signature":"EuoDCkYICxgCKkBIcWrZxfTiP7/9k9q82QIsnQfCDH81IbAzV/L41XfR6ildotkfrMK9rFmSDoqtW/4LETbIg5D4boyKwlHjkmbKEgxZYZXuUULLlFWUWkMaDANclnT//GsdDtzC6SIwtRifg9Gp1xavrsRK+1fm7UtumaEsPSOd0qSXJm5QOn9R5jfKgX+5HvuDVc4clCiKKtECkrJqYQpJYcRQse73kq26OygM3Gs85PuEl7uwGa7nq4WLUHduD4VmcZ3VnLHk5mC1ff/lCcnCuoYIfnvhPNgMUOzl5D9IYe7+FJdCsX+1b7gJYvs+K0dQ//qwhLPVzMEuX2ajeaag5QkvBhlaqp489+Ud+AV65lANU5aBaJAI8tDBcxVpMZWoH9nBBpljij0Bc3hllzKF9tZYzU9q8vh9l8pe7qOBPGus7RqEHHdCsM5wvJNxqGWJ6ZDE0D8PHZOyFJYG0lrbRWw5kbyEEZdH5hc1Wlm7RokbSWg1Arm4ZauaEA097aek7hpnT1L3/kYwACrxxpjJ7OOa91uG7a5PWEnE+XiFaD06yGcRK3LnuvDUS/EU3+YEURWjcOw4heUDW8UbNIkNu/CWCEWygM/VJlorJ7DdWBqtjdMdkc1TwzbynI4WWgNEwrblPbZNLO56WxgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7966,"cache_read_input_tokens":25541,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7966},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6wxt1svUCEqT1UMame","type":"assistant","uuid":"601d8c32-43c2-4f31-af29-dd60d3562da4","timestamp":"2026-02-20T09:42:56.636Z"}
{"parentUuid":"601d8c32-43c2-4f31-af29-dd60d3562da4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_015Bx9xkLasj28vs2Hkg8txY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014pUyz6R8qHUsc3MSwX1tK6","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7966,"cache_read_input_tokens":25541,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7966},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6wxt1svUCEqT1UMame","type":"assistant","uuid":"3a0dc0ed-11fb-4e4d-b7f3-437ea7494afe","timestamp":"2026-02-20T09:42:56.905Z"}
{"parentUuid":"3a0dc0ed-11fb-4e4d-b7f3-437ea7494afe","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"File content (52218 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","is_error":true,"tool_use_id":"toolu_014pUyz6R8qHUsc3MSwX1tK6"}]},"uuid":"c198f874-be02-45ff-906a-dcf75d2dbd83","timestamp":"2026-02-20T09:42:57.550Z","toolUseResult":"Error: File content (52218 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","sourceToolAssistantUUID":"3a0dc0ed-11fb-4e4d-b7f3-437ea7494afe"}
{"parentUuid":"c198f874-be02-45ff-906a-dcf75d2dbd83","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_011i83zVB8PwHt1yLAhjuf8N","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VE1tBgrmBXZZqizHELUwMc","name":"Grep","input":{"pattern":"database is locked|Watcher update failed|watcher|locked","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":5},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":224,"cache_read_input_tokens":33507,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":224},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6xJFqXzVzaQVRT3K4z","type":"assistant","uuid":"61aec051-36d2-41ba-b268-a287a70191bc","timestamp":"2026-02-20T09:43:00.926Z"}
{"parentUuid":"61aec051-36d2-41ba-b268-a287a70191bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01VE1tBgrmBXZZqizHELUwMc","toolUseID":"toolu_01VE1tBgrmBXZZqizHELUwMc","timestamp":"2026-02-20T09:43:01.772Z","uuid":"224b37be-1a5f-483f-b59d-350bc6553fba"}
{"parentUuid":"61aec051-36d2-41ba-b268-a287a70191bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VE1tBgrmBXZZqizHELUwMc","type":"tool_result","content":"288-    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n289-    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n290-    /// In-memory index for instant search while DB upsert runs in background.\n291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293:    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295:    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n300-pub(crate) struct NegativeNameEntry {\n301-    query_lower: String,\n--\n2427-\n2428-#[cfg(target_os = \"macos\")]\n2429-const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n2430-\n2431-#[cfg(target_os = \"macos\")]\n2432:fn process_watcher_paths(\n2433-    app: &AppHandle,\n2434-    state: &AppState,\n2435-    pending: &mut HashSet<PathBuf>,\n2436-    last_status_emit: &mut Instant,\n2437-    pending_status_emit: &mut bool,\n--\n2467-            }\n2468-            let mut status = state.status.lock();\n2469-            if !matches!(status.state, IndexState::Indexing) {\n2470-                status.state = IndexState::Error;\n2471-            }\n2472:            status.message = Some(format!(\"Watcher update failed: {err}\"));\n2473-            drop(status);\n2474:            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n2475-        }\n2476-    }\n2477-}\n2478-\n2479-#[cfg(target_os = \"macos\")]\n--\n2487-\n2488-#[cfg(target_os = \"macos\")]\n2489-const MUST_SCAN_THRESHOLD: usize = 10;\n2490-\n2491-#[cfg(target_os = \"macos\")]\n2492:fn start_fsevent_watcher_worker(\n2493-    app: AppHandle,\n2494-    state: AppState,\n2495-    since_event_id: Option<u64>,\n2496-    conditional: bool,\n2497-) {\n2498-    use std::sync::mpsc::{self, RecvTimeoutError};\n2499-    std::thread::spawn(move || {\n2500-        let (tx, rx) = mpsc::channel();\n2501-\n2502:        let mut watcher =\n2503:            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n2504-                Ok(w) => w,\n2505-                Err(err) => {\n2506-                    set_state(\n2507-                        &state,\n2508-                        IndexState::Error,\n2509:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2510-                    );\n2511-                    emit_index_state(\n2512-                        &app,\n2513-                        \"Error\",\n2514:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2515-                    );\n2516-                    return;\n2517-                }\n2518-            };\n2519-\n2520-        if conditional {\n2521:            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n2522-            set_state(&state, IndexState::Ready, None);\n2523-            emit_index_state(&app, \"Ready\", None);\n2524-        }\n2525-\n2526-        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n--\n2544-                    }\n2545-                }\n2546-                None => Duration::from_secs(1),\n2547-            };\n2548-            match rx.recv_timeout(wait) {\n2549:                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n2550-                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n2551-                    let prev_len = pending_paths.len();\n2552-                    for path in paths {\n2553-                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n2554-                            pending_paths.insert(path);\n--\n2556-                    }\n2557-                    if pending_paths.len() > prev_len {\n2558-                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n2559-                    }\n2560-                }\n2561:                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n2562-                    must_scan_count += 1;\n2563-                    if replay_phase\n2564-                        && must_scan_count >= MUST_SCAN_THRESHOLD\n2565-                        && !full_scan_triggered\n2566-                    {\n--\n2590-                                }\n2591-                            }\n2592-                        }\n2593-                    }\n2594-                }\n2595:                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n2596:                    process_watcher_paths(\n2597-                        &app,\n2598-                        &state,\n2599-                        &mut pending_paths,\n2600-                        &mut last_status_emit,\n2601-                        &mut pending_status_emit,\n--\n2618-                Err(RecvTimeoutError::Disconnected) => break,\n2619-            }\n2620-\n2621-            if let Some(due) = deadline {\n2622-                if Instant::now() >= due {\n2623:                    process_watcher_paths(\n2624-                        &app,\n2625-                        &state,\n2626-                        &mut pending_paths,\n2627-                        &mut last_status_emit,\n2628-                        &mut pending_status_emit,\n--\n2637-                pending_status_emit = false;\n2638-            }\n2639-\n2640-            // Periodic event_id flush\n2641-            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n2642:                let eid = watcher.last_event_id();\n2643-                let _ = persist_event_id(&state.db_path, eid);\n2644-                last_flush = Instant::now();\n2645-            }\n2646-\n2647-            // Periodic count refresh to keep in-memory counts accurate\n--\n2650-                last_count_refresh = Instant::now();\n2651-            }\n2652-        }\n2653-\n2654-        // Final flush on shutdown\n2655:        let eid = watcher.last_event_id();\n2656-        let _ = persist_event_id(&state.db_path, eid);\n2657:        watcher.stop();\n2658-    });\n2659-}\n2660-\n2661-fn validate_new_name(new_name: &str) -> AppResult<String> {\n2662-    let trimmed = new_name.trim();\n--\n2796-    tauri::async_runtime::spawn_blocking(move || {\n2797-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n2798-            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n2799-        }\n2800-\n2801:        // Stop existing file watcher and wait for it to fully exit\n2802:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2803-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2804:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2805-            if std::time::Instant::now() >= deadline {\n2806:                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2807-                break;\n2808-            }\n2809-            std::thread::sleep(std::time::Duration::from_millis(50));\n2810-        }\n2811-\n--\n2828-\n2829-        invalidate_search_caches(&state);\n2830-\n2831-        emit_index_updated(&app, 0, now_epoch(), 0);\n2832-\n2833:        // Allow new watcher to start\n2834:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2835-\n2836-        #[cfg(target_os = \"windows\")]\n2837-        {\n2838-            win::start_windows_indexing(app, state);\n2839-            Ok(())\n--\n4493-        fd_search_cache: Arc::new(Mutex::new(None)),\n4494-        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4495-        ignore_cache: Arc::new(Mutex::new(None)),\n4496-        gitignore,\n4497-        mem_index: Arc::new(RwLock::new(None)),\n4498:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4499:        watcher_active: Arc::new(AtomicBool::new(false)),\n4500-    };\n4501-\n4502-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n4503-    app.manage(state.clone());\n4504-    if !bench_mode {\n--\n4562-                        (eid, complete)\n4563-                    })\n4564-                    .unwrap_or((None, false));\n4565-\n4566-                if stored_event_id.is_some() && index_complete {\n4567:                    // Conditional startup: try watcher replay first, skip full scan if OK\n4568:                    start_fsevent_watcher_worker(\n4569-                        app_handle.clone(),\n4570-                        state.clone(),\n4571-                        stored_event_id,\n4572-                        true,\n4573-                    );\n4574-                } else {\n4575-                    if !index_complete {\n4576-                        eprintln!(\"[mac] index incomplete — starting full index\");\n4577-                    }\n4578-                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n4579:                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n4580-                }\n4581-            }\n4582-        }\n4583-\n4584-        #[cfg(target_os = \"windows\")]\n--\n4706-            fd_search_cache: Arc::new(Mutex::new(None)),\n4707-            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4708-            ignore_cache: Arc::new(Mutex::new(None)),\n4709-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4710-            mem_index: Arc::new(RwLock::new(None)),\n4711:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4712:            watcher_active: Arc::new(AtomicBool::new(false)),\n4713-        }\n4714-    }\n4715-\n4716-    #[test]\n4717-    fn should_skip_path_for_ignored_descendant() {"}]},"uuid":"e64854fc-11e3-4b10-89ae-7a3b9b6782e3","timestamp":"2026-02-20T09:43:01.771Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"288-    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n289-    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n290-    /// In-memory index for instant search while DB upsert runs in background.\n291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293:    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295:    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n300-pub(crate) struct NegativeNameEntry {\n301-    query_lower: String,\n--\n2427-\n2428-#[cfg(target_os = \"macos\")]\n2429-const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n2430-\n2431-#[cfg(target_os = \"macos\")]\n2432:fn process_watcher_paths(\n2433-    app: &AppHandle,\n2434-    state: &AppState,\n2435-    pending: &mut HashSet<PathBuf>,\n2436-    last_status_emit: &mut Instant,\n2437-    pending_status_emit: &mut bool,\n--\n2467-            }\n2468-            let mut status = state.status.lock();\n2469-            if !matches!(status.state, IndexState::Indexing) {\n2470-                status.state = IndexState::Error;\n2471-            }\n2472:            status.message = Some(format!(\"Watcher update failed: {err}\"));\n2473-            drop(status);\n2474:            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n2475-        }\n2476-    }\n2477-}\n2478-\n2479-#[cfg(target_os = \"macos\")]\n--\n2487-\n2488-#[cfg(target_os = \"macos\")]\n2489-const MUST_SCAN_THRESHOLD: usize = 10;\n2490-\n2491-#[cfg(target_os = \"macos\")]\n2492:fn start_fsevent_watcher_worker(\n2493-    app: AppHandle,\n2494-    state: AppState,\n2495-    since_event_id: Option<u64>,\n2496-    conditional: bool,\n2497-) {\n2498-    use std::sync::mpsc::{self, RecvTimeoutError};\n2499-    std::thread::spawn(move || {\n2500-        let (tx, rx) = mpsc::channel();\n2501-\n2502:        let mut watcher =\n2503:            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n2504-                Ok(w) => w,\n2505-                Err(err) => {\n2506-                    set_state(\n2507-                        &state,\n2508-                        IndexState::Error,\n2509:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2510-                    );\n2511-                    emit_index_state(\n2512-                        &app,\n2513-                        \"Error\",\n2514:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2515-                    );\n2516-                    return;\n2517-                }\n2518-            };\n2519-\n2520-        if conditional {\n2521:            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n2522-            set_state(&state, IndexState::Ready, None);\n2523-            emit_index_state(&app, \"Ready\", None);\n2524-        }\n2525-\n2526-        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n--\n2544-                    }\n2545-                }\n2546-                None => Duration::from_secs(1),\n2547-            };\n2548-            match rx.recv_timeout(wait) {\n2549:                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n2550-                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n2551-                    let prev_len = pending_paths.len();\n2552-                    for path in paths {\n2553-                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n2554-                            pending_paths.insert(path);\n--\n2556-                    }\n2557-                    if pending_paths.len() > prev_len {\n2558-                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n2559-                    }\n2560-                }\n2561:                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n2562-                    must_scan_count += 1;\n2563-                    if replay_phase\n2564-                        && must_scan_count >= MUST_SCAN_THRESHOLD\n2565-                        && !full_scan_triggered\n2566-                    {\n--\n2590-                                }\n2591-                            }\n2592-                        }\n2593-                    }\n2594-                }\n2595:                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n2596:                    process_watcher_paths(\n2597-                        &app,\n2598-                        &state,\n2599-                        &mut pending_paths,\n2600-                        &mut last_status_emit,\n2601-                        &mut pending_status_emit,\n--\n2618-                Err(RecvTimeoutError::Disconnected) => break,\n2619-            }\n2620-\n2621-            if let Some(due) = deadline {\n2622-                if Instant::now() >= due {\n2623:                    process_watcher_paths(\n2624-                        &app,\n2625-                        &state,\n2626-                        &mut pending_paths,\n2627-                        &mut last_status_emit,\n2628-                        &mut pending_status_emit,\n--\n2637-                pending_status_emit = false;\n2638-            }\n2639-\n2640-            // Periodic event_id flush\n2641-            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n2642:                let eid = watcher.last_event_id();\n2643-                let _ = persist_event_id(&state.db_path, eid);\n2644-                last_flush = Instant::now();\n2645-            }\n2646-\n2647-            // Periodic count refresh to keep in-memory counts accurate\n--\n2650-                last_count_refresh = Instant::now();\n2651-            }\n2652-        }\n2653-\n2654-        // Final flush on shutdown\n2655:        let eid = watcher.last_event_id();\n2656-        let _ = persist_event_id(&state.db_path, eid);\n2657:        watcher.stop();\n2658-    });\n2659-}\n2660-\n2661-fn validate_new_name(new_name: &str) -> AppResult<String> {\n2662-    let trimmed = new_name.trim();\n--\n2796-    tauri::async_runtime::spawn_blocking(move || {\n2797-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n2798-            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n2799-        }\n2800-\n2801:        // Stop existing file watcher and wait for it to fully exit\n2802:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2803-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2804:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2805-            if std::time::Instant::now() >= deadline {\n2806:                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2807-                break;\n2808-            }\n2809-            std::thread::sleep(std::time::Duration::from_millis(50));\n2810-        }\n2811-\n--\n2828-\n2829-        invalidate_search_caches(&state);\n2830-\n2831-        emit_index_updated(&app, 0, now_epoch(), 0);\n2832-\n2833:        // Allow new watcher to start\n2834:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2835-\n2836-        #[cfg(target_os = \"windows\")]\n2837-        {\n2838-            win::start_windows_indexing(app, state);\n2839-            Ok(())\n--\n4493-        fd_search_cache: Arc::new(Mutex::new(None)),\n4494-        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4495-        ignore_cache: Arc::new(Mutex::new(None)),\n4496-        gitignore,\n4497-        mem_index: Arc::new(RwLock::new(None)),\n4498:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4499:        watcher_active: Arc::new(AtomicBool::new(false)),\n4500-    };\n4501-\n4502-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n4503-    app.manage(state.clone());\n4504-    if !bench_mode {\n--\n4562-                        (eid, complete)\n4563-                    })\n4564-                    .unwrap_or((None, false));\n4565-\n4566-                if stored_event_id.is_some() && index_complete {\n4567:                    // Conditional startup: try watcher replay first, skip full scan if OK\n4568:                    start_fsevent_watcher_worker(\n4569-                        app_handle.clone(),\n4570-                        state.clone(),\n4571-                        stored_event_id,\n4572-                        true,\n4573-                    );\n4574-                } else {\n4575-                    if !index_complete {\n4576-                        eprintln!(\"[mac] index incomplete — starting full index\");\n4577-                    }\n4578-                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n4579:                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n4580-                }\n4581-            }\n4582-        }\n4583-\n4584-        #[cfg(target_os = \"windows\")]\n--\n4706-            fd_search_cache: Arc::new(Mutex::new(None)),\n4707-            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4708-            ignore_cache: Arc::new(Mutex::new(None)),\n4709-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4710-            mem_index: Arc::new(RwLock::new(None)),\n4711:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4712:            watcher_active: Arc::new(AtomicBool::new(false)),\n4713-        }\n4714-    }\n4715-\n4716-    #[test]\n4717-    fn should_skip_path_for_ignored_descendant() {","numLines":236},"sourceToolAssistantUUID":"61aec051-36d2-41ba-b268-a287a70191bc"}
{"parentUuid":"e64854fc-11e3-4b10-89ae-7a3b9b6782e3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01D1zWnBfBjtNGkjLN3Z2Gdx","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me look at the `process_watcher_paths` function more closely to understand what's happening when the database is locked, and also look at the upsert/DB functions that are called from the watcher.","signature":"EvQCCkYICxgCKkA+cHysZBEgDlZ4fucHnYFxF4i9x6u5ffhANlPGKF+HxD2qfmSxViekgw2DPNgcRHDWp07ATCGyaOMGf4oqlQVrEgxfb45d+mZY3P+3oJgaDPCc2ElMBHhGjat4giIwazFfRTtpvMUSUodH/6xfKqkdzzFuUbLYcEr63x5C8wDs6VhpqkyYKgjckSZy4kV4KtsBMGXH3C97kXx5ah38vVW9c5mCkX0khzNYIwpNbr0D+qTH2QjAYANaf+3PdLQvjTfqa7ejB2mQd9RT7GlMayY77QFjv/X3RaNdTCa4SYdAB/ogu39XhX+WslojWyQjXPhsIviKIOO445jFZ57n2aca2ULzWBd99dihqifyNmwaXaVvS9zjul+SQs+joHpwOQCs1Fv7l3ekPifxgIm1gQVzid3JH2XCxgGCqTipxZcmS/YEabWbaVFDC7nE6SQjpLvf/yLziMP7x/gIZXdz5hA6khpGyu4bpZvzECJgGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3260,"cache_read_input_tokens":33731,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3260},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6xbxTDphSuRhdZTPZV","type":"assistant","uuid":"1aa796d6-a9e3-43f9-b607-788e98f9b75d","timestamp":"2026-02-20T09:43:05.541Z"}
{"parentUuid":"1aa796d6-a9e3-43f9-b607-788e98f9b75d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01D1zWnBfBjtNGkjLN3Z2Gdx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TkmuQ3VnWGJMuoMgtMfSC4","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2420,"limit":120},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3260,"cache_read_input_tokens":33731,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3260},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6xbxTDphSuRhdZTPZV","type":"assistant","uuid":"71652dfd-99b1-462d-9716-024c53add065","timestamp":"2026-02-20T09:43:06.601Z"}
{"parentUuid":"71652dfd-99b1-462d-9716-024c53add065","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01TkmuQ3VnWGJMuoMgtMfSC4","toolUseID":"toolu_01TkmuQ3VnWGJMuoMgtMfSC4","timestamp":"2026-02-20T09:43:06.616Z","uuid":"b7cda2b8-5caa-4ebc-8ccd-c6b8f004fd25"}
{"parentUuid":"71652dfd-99b1-462d-9716-024c53add065","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TkmuQ3VnWGJMuoMgtMfSC4","type":"tool_result","content":"  2420→    let mut changed = 0;\n  2421→\n  2422→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2423→    changed += delete_paths(&mut conn, &to_delete)?;\n  2424→\n  2425→    Ok(changed)\n  2426→}\n  2427→\n  2428→#[cfg(target_os = \"macos\")]\n  2429→const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n  2430→\n  2431→#[cfg(target_os = \"macos\")]\n  2432→fn process_watcher_paths(\n  2433→    app: &AppHandle,\n  2434→    state: &AppState,\n  2435→    pending: &mut HashSet<PathBuf>,\n  2436→    last_status_emit: &mut Instant,\n  2437→    pending_status_emit: &mut bool,\n  2438→) {\n  2439→    if pending.is_empty() {\n  2440→        return;\n  2441→    }\n  2442→\n  2443→    if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2444→        return;\n  2445→    }\n  2446→\n  2447→    let mut batch: Vec<PathBuf> = pending.drain().collect();\n  2448→    batch.sort();\n  2449→\n  2450→    match apply_path_changes(state, &batch) {\n  2451→        Ok(changed) => {\n  2452→            if changed > 0 {\n  2453→                invalidate_search_caches(state);\n  2454→                touch_status_updated(state);\n  2455→                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2456→                    let _ = refresh_and_emit_status_counts(app, state);\n  2457→                    *last_status_emit = Instant::now();\n  2458→                    *pending_status_emit = false;\n  2459→                } else {\n  2460→                    *pending_status_emit = true;\n  2461→                }\n  2462→            }\n  2463→        }\n  2464→        Err(err) => {\n  2465→            if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2466→                return;\n  2467→            }\n  2468→            let mut status = state.status.lock();\n  2469→            if !matches!(status.state, IndexState::Indexing) {\n  2470→                status.state = IndexState::Error;\n  2471→            }\n  2472→            status.message = Some(format!(\"Watcher update failed: {err}\"));\n  2473→            drop(status);\n  2474→            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n  2475→        }\n  2476→    }\n  2477→}\n  2478→\n  2479→#[cfg(target_os = \"macos\")]\n  2480→const EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n  2481→\n  2482→#[cfg(target_os = \"macos\")]\n  2483→fn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n  2484→    let conn = db_connection(db_path)?;\n  2485→    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n  2486→}\n  2487→\n  2488→#[cfg(target_os = \"macos\")]\n  2489→const MUST_SCAN_THRESHOLD: usize = 10;\n  2490→\n  2491→#[cfg(target_os = \"macos\")]\n  2492→fn start_fsevent_watcher_worker(\n  2493→    app: AppHandle,\n  2494→    state: AppState,\n  2495→    since_event_id: Option<u64>,\n  2496→    conditional: bool,\n  2497→) {\n  2498→    use std::sync::mpsc::{self, RecvTimeoutError};\n  2499→    std::thread::spawn(move || {\n  2500→        let (tx, rx) = mpsc::channel();\n  2501→\n  2502→        let mut watcher =\n  2503→            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n  2504→                Ok(w) => w,\n  2505→                Err(err) => {\n  2506→                    set_state(\n  2507→                        &state,\n  2508→                        IndexState::Error,\n  2509→                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n  2510→                    );\n  2511→                    emit_index_state(\n  2512→                        &app,\n  2513→                        \"Error\",\n  2514→                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n  2515→                    );\n  2516→                    return;\n  2517→                }\n  2518→            };\n  2519→\n  2520→        if conditional {\n  2521→            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n  2522→            set_state(&state, IndexState::Ready, None);\n  2523→            emit_index_state(&app, \"Ready\", None);\n  2524→        }\n  2525→\n  2526→        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n  2527→        let mut deadline: Option<Instant> = None;\n  2528→        let mut last_flush = Instant::now();\n  2529→        let mut last_status_emit = Instant::now();\n  2530→        let mut pending_status_emit = false;\n  2531→        let mut last_count_refresh = Instant::now();\n  2532→        let mut must_scan_count: usize = 0;\n  2533→        let mut replay_phase = conditional;\n  2534→        let mut full_scan_triggered = false;\n  2535→\n  2536→        loop {\n  2537→            let wait = match deadline {\n  2538→                Some(due) => {\n  2539→                    let now = Instant::now();\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"517edec7-621c-4adf-ab65-0e403854b28b","timestamp":"2026-02-20T09:43:06.614Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();","numLines":120,"startLine":2420,"totalLines":5127}},"sourceToolAssistantUUID":"71652dfd-99b1-462d-9716-024c53add065"}
{"parentUuid":"517edec7-621c-4adf-ab65-0e403854b28b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_011MkzFFJFCNGdqASRwwBPvi","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LhJgmKP9xXHbrBL5FG6z5e","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2340,"limit":85},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1920,"cache_read_input_tokens":36991,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1920},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6xxgPZ7p5s3s1oHccT","type":"assistant","uuid":"324d59a2-5522-4947-9df7-ac6250699d2b","timestamp":"2026-02-20T09:43:09.076Z"}
{"parentUuid":"324d59a2-5522-4947-9df7-ac6250699d2b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01LhJgmKP9xXHbrBL5FG6z5e","toolUseID":"toolu_01LhJgmKP9xXHbrBL5FG6z5e","timestamp":"2026-02-20T09:43:09.085Z","uuid":"20615079-751d-4048-8f7a-fd227fa9c64c"}
{"parentUuid":"324d59a2-5522-4947-9df7-ac6250699d2b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LhJgmKP9xXHbrBL5FG6z5e","type":"tool_result","content":"  2340→    let now = Instant::now();\n  2341→    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n  2342→}\n  2343→\n  2344→fn remember_op(\n  2345→    state: &AppState,\n  2346→    op_type: &'static str,\n  2347→    old_path: Option<String>,\n  2348→    new_path: Option<String>,\n  2349→) {\n  2350→    let mut ops = state.recent_ops.lock();\n  2351→    trim_recent_ops(&mut ops);\n  2352→    ops.push(RecentOp {\n  2353→        old_path,\n  2354→        new_path,\n  2355→        op_type,\n  2356→        at: Instant::now(),\n  2357→    });\n  2358→}\n  2359→\n  2360→#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\n  2361→pub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n  2362→    let mut ops = state.recent_ops.lock();\n  2363→    trim_recent_ops(&mut ops);\n  2364→\n  2365→    ops.iter().any(|op| match op.op_type {\n  2366→        \"rename\" | \"trash\" => {\n  2367→            op.old_path\n  2368→                .as_deref()\n  2369→                .map(|old| old == path)\n  2370→                .unwrap_or(false)\n  2371→                || op\n  2372→                    .new_path\n  2373→                    .as_deref()\n  2374→                    .map(|new| new == path)\n  2375→                    .unwrap_or(false)\n  2376→        }\n  2377→        _ => false,\n  2378→    })\n  2379→}\n  2380→\n  2381→#[cfg(target_os = \"macos\")]\n  2382→fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n  2383→    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n  2384→    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n  2385→    let mut to_delete = Vec::new();\n  2386→\n  2387→    for path in paths {\n  2388→        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n  2389→            continue;\n  2390→        }\n  2391→\n  2392→        let path_str = path.to_string_lossy().to_string();\n  2393→        if path_str.is_empty() {\n  2394→            continue;\n  2395→        }\n  2396→\n  2397→        if is_recently_touched(state, &path_str) {\n  2398→            continue;\n  2399→        }\n  2400→\n  2401→        match fs::symlink_metadata(path) {\n  2402→            Ok(metadata) => {\n  2403→                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n  2404→                    to_upsert_map.insert(row.path.clone(), row);\n  2405→                }\n  2406→            }\n  2407→            Err(_) => {\n  2408→                to_delete.push(path_str);\n  2409→            }\n  2410→        }\n  2411→    }\n  2412→\n  2413→    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n  2414→\n  2415→    if to_upsert.is_empty() && to_delete.is_empty() {\n  2416→        return Ok(0);\n  2417→    }\n  2418→\n  2419→    let mut conn = db_connection(&state.db_path)?;\n  2420→    let mut changed = 0;\n  2421→\n  2422→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2423→    changed += delete_paths(&mut conn, &to_delete)?;\n  2424→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"52ed4849-55b1-4b5a-9424-954bea852a1a","timestamp":"2026-02-20T09:43:09.084Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n","numLines":85,"startLine":2340,"totalLines":5127}},"sourceToolAssistantUUID":"324d59a2-5522-4947-9df7-ac6250699d2b"}
{"parentUuid":"52ed4849-55b1-4b5a-9424-954bea852a1a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_019fMp8imgVw3d2quUMchi4s","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the flow. The issue is:\n1. App restarts and is in \"Ready\" state (via conditional startup)\n2. The watcher runs `process_watcher_paths` → `apply_path_changes` → `db_connection` + `upsert_rows` / `delete_paths`\n3. The DB connection fails because the database is locked\n\nThis likely happens because:\n- The full scan from a previous run is still persisting (background DB upsert)\n- Or more likely: two threads are trying to write to the SQLite DB simultaneously\n\nThe `database is locked` error in SQLite typically means:\n1. \n\nAnother connection has an exclusive lock (WAL mode shouldn't cause this normally), or there's a SQLITE_BUSY error when trying to acquire a write lock. I need to check the `db_connection` function and its timeout settings, but the real issue is probably that the user needs better logging to track exactly which path or operation is failing, what pending paths exist, how much time has elapsed since startup, and the full error details.","signature":"EocKCkYICxgCKkDsyWXWOgwredpaq+YuHKo6ePQ5CQ4cEpDoxZPsWBRBNXanowrnAxmJ4q3D+cHnMBcuvXbJd6w8qU37cn/blTNREgx8osjBjpCpNdn4s1caDFNvGScXnVQyp2IP8iIw/sLHI1LOvrMuzLUzFC3f0iO0wz3J1uxiLh/Oa3WAbnc4D8KN/AKdj1hpX28v5WnmKu4IMe5GNDgiwBFvpk100LpW2qUUTQUym5qrdRKcDK3qUDqlKwBzT9HJpUIbAukoP6gOEZSaXc9/hYGlfUlNyJLmd04pR4RTxA47lCaO1UXa279oXcrIvZCxDnLOmSDl3TRst4WgK5AFcSwq89JMPXz3t2NuDtWDhBxc1xGwOmZ+CsO13ZNq6KlkJsYBDPiX0sclEQeirh/rEkU7LnceaItxau9xVoXnTwPVqQVJGavp3dLU35mn7Gfdgb1PmqPAJO+ltXCa/wAiHQXpxIt/ybfVJAIJm5+pQEdcDccWwOgkg4CZfJCvZOwlVXzf7rmxqpTaFI9dC7kGvx9f8Zv2qX2FLgHlbdvDGJBHixH77Jf9FLFN1Dn35AMaaJmOxCUwWspQcsbqgsyAl8HQ8MVYgLE6vkOEzZhrqk+0jQuJjgDgjyvOGsJbbbOWGD07WsX9CC8jYs5eUjp771zt4v59GIE7/bQ0o3f3JIoqFXF4+h+5l/sHg3WEpA9cUNxJMtfh0TdpK17QpU+43oLtLeog7OxAlfI4ftmOlLjRTCtM+kAT1+Ws9x2yOH/pA/3hEe/5Mngx0SefIfrVw+9Qwqegtea/618qVchMOiWh4Eh77mwbCnynkRgjMTUZTmPwf6715t3cUPm8kJAar6XyrhfVHnv3bVuZ4bOeX7WPnEEF1wkUHiHF1ny8mfhc5r1C4dSXM3bDJ+/2Qitk4BQckZqQ0WFDKs5K9nwZqNS5Gs7oZ8t/pYaBC4PiEJj10gQ1qLzbDJGToygw5wDMenH5g6dkj21wP+zOxfypqiSOaAm2xYxSL/j5R3ShVq3iyjBoGN5W53f2SfmjViHiaeLqCxIqPzThZuGs9n7ripzXvUFDXCZKHygE1DSpEh0S3f/b763H3XfQSTvgiSUbqlKfe7lTqKEc7hmN2zG1B6uDzBMzEMwP/CRf566K/irV2Ap4+D6Qs7+b4qt8P+obqOK86YIhrBv+uluDp8uMvJNS4VhQdaS5QEqobRctGJtedtuGRzQpFDm9EuDdeXJKS4K3VMruXpsQuXiCq3Ehu5JL8oamp1zZjGqi6IBhJcF3tQNlUsWflI6ivLjadbXApjxyp8AUvl3GHcIIaxDRBDanUKQpVReTjiBbaYEBUQtgr1sDnS8ooLEg8BrKVKIobm3CPIuL9ttEFbKJwUEBh0la7GjGkYHAmOuFW+PrQGbssN16Qn8fGdBcb7t1x/2laBvtUA8+3e95/qk7qZFcXp7bq0gDL+kjwsHQXD+1w6MzMAZcDd/BHpEksE5vL+RqUCs1dBcrzJ2hom6lluU8WSVfwvBW6v8qF+SEFLuEibS+DU8W9ZIJOoK77yJ/yyQLJCp4wHuwlgFmsZtIgOnVXL6O8/0+UWwpBUMhujUHG21PeyHINAdxzfN6Fg8oNDF6BDNhGhY7H1qdbcAGnHXeAOM7itwHk9yyRQFvujVn+pOIkFJcOnsbbQSHFDSzaOg7J+C4py5+9GmCEISqD9VCEZx91rsKlNEUGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1338,"cache_read_input_tokens":38911,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1338},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6y9HsBobmxsZvQkEur","type":"assistant","uuid":"a93aee14-8a38-48cd-b606-65f3360fd537","timestamp":"2026-02-20T09:43:17.322Z"}
{"parentUuid":"a93aee14-8a38-48cd-b606-65f3360fd537","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_019fMp8imgVw3d2quUMchi4s","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014b968hbfKoEC7gdWTbRakn","name":"Grep","input":{"pattern":"fn db_connection|busy_timeout|SQLITE_BUSY|wal|journal_mode","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":4},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1338,"cache_read_input_tokens":38911,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1338},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6y9HsBobmxsZvQkEur","type":"assistant","uuid":"af7547c0-76c9-4bcd-a759-04e6e9bf28e8","timestamp":"2026-02-20T09:43:17.516Z"}
{"parentUuid":"af7547c0-76c9-4bcd-a759-04e6e9bf28e8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_014b968hbfKoEC7gdWTbRakn","toolUseID":"toolu_014b968hbfKoEC7gdWTbRakn","timestamp":"2026-02-20T09:43:18.377Z","uuid":"5ad735b9-3e7e-4ba5-a1df-03c0ac8e35ba"}
{"parentUuid":"af7547c0-76c9-4bcd-a759-04e6e9bf28e8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014b968hbfKoEC7gdWTbRakn","type":"tool_result","content":"22-#[cfg(target_os = \"macos\")]\n23-use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n24-#[cfg(target_os = \"windows\")]\n25-use std::os::windows::process::CommandExt;\n26:use walkdir::WalkDir;\n27-\n28-mod fd_search;\n29-mod gitignore_filter;\n30-#[cfg(target_os = \"macos\")]\n--\n355-        eprintln!(\"[perf] {}\", message.as_ref());\n356-    }\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n363:        PRAGMA journal_mode=WAL;\n364-        PRAGMA synchronous=NORMAL;\n365-        PRAGMA temp_store=MEMORY;\n366:        PRAGMA busy_timeout={busy_timeout_ms};\n367-        \"#,\n368-    ))\n369-    .map_err(|e| e.to_string())?;\n370-    Ok(conn)\n371-}\n372-\n373:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n374-    db_connection_with_timeout(db_path, 3000)\n375-}\n376-\n377:fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n378-    let conn = db_connection_with_timeout(db_path, 200)?;\n379-    conn.execute_batch(\n380-        \"PRAGMA cache_size = -32768;\n381-         PRAGMA mmap_size = 268435456;\",\n--\n389-        r#\"\n390-        PRAGMA synchronous = NORMAL;\n391-        PRAGMA cache_size = -65536;\n392-        PRAGMA mmap_size = 268435456;\n393:        PRAGMA wal_autocheckpoint = 0;\n394-        \"#,\n395-    )\n396-    .map_err(|e| e.to_string())\n397-}\n--\n401-        r#\"\n402-        PRAGMA synchronous = NORMAL;\n403-        PRAGMA cache_size = -16384;\n404-        PRAGMA mmap_size = 0;\n405:        PRAGMA wal_autocheckpoint = 1000;\n406-        \"#,\n407-    )\n408-    .map_err(|e| e.to_string())?;\n409:    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n410-        .map_err(|e| e.to_string())?;\n411-    Ok(())\n412-}\n413-\n--\n1303-    let metadata = fs::symlink_metadata(path).ok()?;\n1304-    index_row_from_path_and_metadata(path, &metadata)\n1305-}\n1306-\n1307:fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n1308-    let metadata = entry.metadata().ok()?;\n1309-    index_row_from_path_and_metadata(entry.path(), &metadata)\n1310-}\n1311-\n1312:fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n1313-    let metadata = entry.metadata().ok()?;\n1314-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n1315-}\n1316-\n--\n1326-        .into_iter()\n1327-        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n1328-\n1329-    for entry in iter.flatten() {\n1330:        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n1331-            rows.push(row);\n1332-        }\n1333-    }\n1334-\n--\n2096-        roots.len()\n2097-    ));\n2098-\n2099-    / 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n2100:    // Both passes use jwalk for parallel scanning\n2101-    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n2102-    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n2103-\n2104-    for pass in 0..2u8 {\n--\n2118-            let gi_ref = gi_filter.clone();\n2119-            let skip_roots = arc_ignored_roots.clone();\n2120-            let skip_patterns = arc_ignored_patterns.clone();\n2121-\n2122:            let mut builder = jwalk::WalkDir::new(root)\n2123-                .follow_links(false)\n2124-                .skip_hidden(false)\n2125:                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n2126-            if pass == 0 {\n2127-                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n2128-            }\n2129:            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n2130-                children.retain(|entry_result| {\n2131-                    entry_result\n2132-                        .as_ref()\n2133-                        .map(|entry| {\n--\n2144-                        .unwrap_or(false)\n2145-                });\n2146-            });\n2147-\n2148:            for result in walker {\n2149-                match result {\n2150-                    Ok(entry) => {\n2151-                        let path = entry.path();\n2152-                        if path == root.as_path() {\n--\n2161-                        scanned += 1;\n2162-                        root_scanned += 1;\n2163-                        current_path = path.to_string_lossy().to_string();\n2164-\n2165:                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n2166-                            row.run_id = current_run_id;\n2167-                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n2168-                                if *old_mtime == row.mtime && *old_size == row.size {\n2169-                                    stamp_batch.push(row.path);"}]},"uuid":"756c6bf6-e45a-469f-ae4e-259867a6ab29","timestamp":"2026-02-20T09:43:18.375Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"22-#[cfg(target_os = \"macos\")]\n23-use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n24-#[cfg(target_os = \"windows\")]\n25-use std::os::windows::process::CommandExt;\n26:use walkdir::WalkDir;\n27-\n28-mod fd_search;\n29-mod gitignore_filter;\n30-#[cfg(target_os = \"macos\")]\n--\n355-        eprintln!(\"[perf] {}\", message.as_ref());\n356-    }\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n363:        PRAGMA journal_mode=WAL;\n364-        PRAGMA synchronous=NORMAL;\n365-        PRAGMA temp_store=MEMORY;\n366:        PRAGMA busy_timeout={busy_timeout_ms};\n367-        \"#,\n368-    ))\n369-    .map_err(|e| e.to_string())?;\n370-    Ok(conn)\n371-}\n372-\n373:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n374-    db_connection_with_timeout(db_path, 3000)\n375-}\n376-\n377:fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n378-    let conn = db_connection_with_timeout(db_path, 200)?;\n379-    conn.execute_batch(\n380-        \"PRAGMA cache_size = -32768;\n381-         PRAGMA mmap_size = 268435456;\",\n--\n389-        r#\"\n390-        PRAGMA synchronous = NORMAL;\n391-        PRAGMA cache_size = -65536;\n392-        PRAGMA mmap_size = 268435456;\n393:        PRAGMA wal_autocheckpoint = 0;\n394-        \"#,\n395-    )\n396-    .map_err(|e| e.to_string())\n397-}\n--\n401-        r#\"\n402-        PRAGMA synchronous = NORMAL;\n403-        PRAGMA cache_size = -16384;\n404-        PRAGMA mmap_size = 0;\n405:        PRAGMA wal_autocheckpoint = 1000;\n406-        \"#,\n407-    )\n408-    .map_err(|e| e.to_string())?;\n409:    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n410-        .map_err(|e| e.to_string())?;\n411-    Ok(())\n412-}\n413-\n--\n1303-    let metadata = fs::symlink_metadata(path).ok()?;\n1304-    index_row_from_path_and_metadata(path, &metadata)\n1305-}\n1306-\n1307:fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n1308-    let metadata = entry.metadata().ok()?;\n1309-    index_row_from_path_and_metadata(entry.path(), &metadata)\n1310-}\n1311-\n1312:fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n1313-    let metadata = entry.metadata().ok()?;\n1314-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n1315-}\n1316-\n--\n1326-        .into_iter()\n1327-        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n1328-\n1329-    for entry in iter.flatten() {\n1330:        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n1331-            rows.push(row);\n1332-        }\n1333-    }\n1334-\n--\n2096-        roots.len()\n2097-    ));\n2098-\n2099-    / 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n2100:    // Both passes use jwalk for parallel scanning\n2101-    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n2102-    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n2103-\n2104-    for pass in 0..2u8 {\n--\n2118-            let gi_ref = gi_filter.clone();\n2119-            let skip_roots = arc_ignored_roots.clone();\n2120-            let skip_patterns = arc_ignored_patterns.clone();\n2121-\n2122:            let mut builder = jwalk::WalkDir::new(root)\n2123-                .follow_links(false)\n2124-                .skip_hidden(false)\n2125:                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n2126-            if pass == 0 {\n2127-                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n2128-            }\n2129:            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n2130-                children.retain(|entry_result| {\n2131-                    entry_result\n2132-                        .as_ref()\n2133-                        .map(|entry| {\n--\n2144-                        .unwrap_or(false)\n2145-                });\n2146-            });\n2147-\n2148:            for result in walker {\n2149-                match result {\n2150-                    Ok(entry) => {\n2151-                        let path = entry.path();\n2152-                        if path == root.as_path() {\n--\n2161-                        scanned += 1;\n2162-                        root_scanned += 1;\n2163-                        current_path = path.to_string_lossy().to_string();\n2164-\n2165:                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n2166-                            row.run_id = current_run_id;\n2167-                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n2168-                                if *old_mtime == row.mtime && *old_size == row.size {\n2169-                                    stamp_batch.push(row.path);","numLines":133},"sourceToolAssistantUUID":"af7547c0-76c9-4bcd-a759-04e6e9bf28e8"}
{"parentUuid":"756c6bf6-e45a-469f-ae4e-259867a6ab29","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Rnt3GpGhgEMv1E8g8D7YFw","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a good understanding of the issue. The `db_connection` function uses a `busy_timeout` of 3000ms (3 seconds). When the error \"database is locked\" occurs, it means SQLite couldn't acquire a write lock within 3 seconds.\n\nThe likely race condition:\n1. App starts up in \"conditional\" mode (Ready state)\n2. The FSEvents watcher replays history events from the stored event ID\n3. Meanwhile, if there's still a background indexing operation or something else holds the DB...\n\nWait, let me reconsider. The error happens \"갑자기\" (suddenly) - so it goes from Ready to Error. \n\nSo the real problem is that multiple concurrent operations are trying to write to SQLite at the same time—the FSEvents history replay triggers path processing which needs a write lock, but something else like `persist_event_id` or a count refresh is already holding the connection. Even with WAL mode enabled, SQLite only allows one writer at a time, and if the 3-second timeout expires before the lock is released, the operation fails with SQLITE_BUSY.\n\nBut there's a subtlety here: `SQLITE_LOCKED` (error code 6) is different from `SQLITE_BUSY` (error code 5). `SQLITE_LOCKED` happens within the same process when there's a table-level lock, and the busy_timeout doesn't always help with that. Looking at the startup sequence, the FSEvents watcher thread runs concurrently with other initialization like `perf_log` calls, and that's where the contention is happening.\n\nThe real issue is that multiple workers are trying to access the database at the same time during startup. I need to add detailed logging to trace exactly when and where the lock occurs — logging the error code, batch size, and paths being processed in `process_watcher_paths`, plus timestamps in `apply_path_changes` to see the sequence of operations.\n\nAdding diagnostic output with timestamps...","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2177,"cache_read_input_tokens":40249,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2177},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6ypw684MPd6RbJsDwg","type":"assistant","uuid":"4b05a170-653f-4788-b3ae-c760adbf9247","timestamp":"2026-02-20T09:43:36.385Z"}
{"parentUuid":"4b05a170-653f-4788-b3ae-c760adbf9247","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Rnt3GpGhgEMv1E8g8D7YFw","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me look at the watcher loop around HistoryDone and the startup sequence more carefully:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2177,"cache_read_input_tokens":40249,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2177},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6ypw684MPd6RbJsDwg","type":"assistant","uuid":"403841de-5660-4113-b32a-5fb791203ca2","timestamp":"2026-02-20T09:43:36.506Z"}
{"parentUuid":"403841de-5660-4113-b32a-5fb791203ca2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Rnt3GpGhgEMv1E8g8D7YFw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018B1r5D5hUcpKrC4TnEHXiz","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2536,"limit":130},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2177,"cache_read_input_tokens":40249,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2177},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK6ypw684MPd6RbJsDwg","type":"assistant","uuid":"71a2c9a3-33c5-4f12-9cb2-fe855151fa5e","timestamp":"2026-02-20T09:43:37.248Z"}
{"parentUuid":"71a2c9a3-33c5-4f12-9cb2-fe855151fa5e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_018B1r5D5hUcpKrC4TnEHXiz","toolUseID":"toolu_018B1r5D5hUcpKrC4TnEHXiz","timestamp":"2026-02-20T09:43:37.263Z","uuid":"a2fbf77f-c56a-4caf-ab30-dbfe7480726b"}
{"parentUuid":"71a2c9a3-33c5-4f12-9cb2-fe855151fa5e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018B1r5D5hUcpKrC4TnEHXiz","type":"tool_result","content":"  2536→        loop {\n  2537→            let wait = match deadline {\n  2538→                Some(due) => {\n  2539→                    let now = Instant::now();\n  2540→                    if now >= due {\n  2541→                        Duration::from_millis(0)\n  2542→                    } else {\n  2543→                        due - now\n  2544→                    }\n  2545→                }\n  2546→                None => Duration::from_secs(1),\n  2547→            };\n  2548→            match rx.recv_timeout(wait) {\n  2549→                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n  2550→                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n  2551→                    let prev_len = pending_paths.len();\n  2552→                    for path in paths {\n  2553→                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n  2554→                            pending_paths.insert(path);\n  2555→                        }\n  2556→                    }\n  2557→                    if pending_paths.len() > prev_len {\n  2558→                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n  2559→                    }\n  2560→                }\n  2561→                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n  2562→                    must_scan_count += 1;\n  2563→                    if replay_phase\n  2564→                        && must_scan_count >= MUST_SCAN_THRESHOLD\n  2565→                        && !full_scan_triggered\n  2566→                    {\n  2567→                        perf_log(format!(\n  2568→                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n  2569→                            must_scan_count\n  2570→                        ));\n  2571→                        full_scan_triggered = true;\n  2572→                        let _ = start_full_index_worker(app.clone(), state.clone());\n  2573→                    }\n  2574→                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n  2575→                        let (ignored_roots, ignored_patterns) =\n  2576→                            cached_effective_ignore_rules(&state);\n  2577→                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n  2578→                        if !rows.is_empty() {\n  2579→                            if let Ok(mut conn) = db_connection(&state.db_path) {\n  2580→                                if upsert_rows(&mut conn, &rows).is_ok() {\n  2581→                                    invalidate_search_caches(&state);\n  2582→                                    touch_status_updated(&state);\n  2583→                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2584→                                        let _ = refresh_and_emit_status_counts(&app, &state);\n  2585→                                        last_status_emit = Instant::now();\n  2586→                                        pending_status_emit = false;\n  2587→                                    } else {\n  2588→                                        pending_status_emit = true;\n  2589→                                    }\n  2590→                                }\n  2591→                            }\n  2592→                        }\n  2593→                    }\n  2594→                }\n  2595→                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n  2596→                    process_watcher_paths(\n  2597→                        &app,\n  2598→                        &state,\n  2599→                        &mut pending_paths,\n  2600→                        &mut last_status_emit,\n  2601→                        &mut pending_status_emit,\n  2602→                    );\n  2603→                    deadline = None;\n  2604→                    if replay_phase {\n  2605→                        replay_phase = false;\n  2606→                        if !full_scan_triggered {\n  2607→                            perf_log(format!(\n  2608→                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n  2609→                                must_scan_count\n  2610→                            ));\n  2611→                            let _ = refresh_and_emit_status_counts(&app, &state);\n  2612→                            last_status_emit = Instant::now();\n  2613→                            pending_status_emit = false;\n  2614→                        }\n  2615→                    }\n  2616→                }\n  2617→                Err(RecvTimeoutError::Timeout) => {}\n  2618→                Err(RecvTimeoutError::Disconnected) => break,\n  2619→            }\n  2620→\n  2621→            if let Some(due) = deadline {\n  2622→                if Instant::now() >= due {\n  2623→                    process_watcher_paths(\n  2624→                        &app,\n  2625→                        &state,\n  2626→                        &mut pending_paths,\n  2627→                        &mut last_status_emit,\n  2628→                        &mut pending_status_emit,\n  2629→                    );\n  2630→                    deadline = None;\n  2631→                }\n  2632→            }\n  2633→\n  2634→            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2635→                let _ = refresh_and_emit_status_counts(&app, &state);\n  2636→                last_status_emit = Instant::now();\n  2637→                pending_status_emit = false;\n  2638→            }\n  2639→\n  2640→            // Periodic event_id flush\n  2641→            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n  2642→                let eid = watcher.last_event_id();\n  2643→                let _ = persist_event_id(&state.db_path, eid);\n  2644→                last_flush = Instant::now();\n  2645→            }\n  2646→\n  2647→            // Periodic count refresh to keep in-memory counts accurate\n  2648→            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n  2649→                let _ = update_status_counts(&state);\n  2650→                last_count_refresh = Instant::now();\n  2651→            }\n  2652→        }\n  2653→\n  2654→        // Final flush on shutdown\n  2655→        let eid = watcher.last_event_id();\n  2656→        let _ = persist_event_id(&state.db_path, eid);\n  2657→        watcher.stop();\n  2658→    });\n  2659→}\n  2660→\n  2661→fn validate_new_name(new_name: &str) -> AppResult<String> {\n  2662→    let trimmed = new_name.trim();\n  2663→\n  2664→    if trimmed.is_empty() {\n  2665→        return Err(\"New name cannot be empty.\".to_string());\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"47073dcb-321e-4c7a-87f2-1c0c85a6472a","timestamp":"2026-02-20T09:43:37.261Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());","numLines":130,"startLine":2536,"totalLines":5127}},"sourceToolAssistantUUID":"71a2c9a3-33c5-4f12-9cb2-fe855151fa5e"}
{"parentUuid":"47073dcb-321e-4c7a-87f2-1c0c85a6472a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01HT6vqPYA5rp6a9X2VmhBzu","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a clear picture. The \"database is locked\" error occurs when:\n\n1. App restarts with conditional startup\n2. Watcher starts, goes to Ready state, then replays FSEvents history\n3. When `HistoryDone` fires, `process_watcher_paths` → `apply_path_changes` → `db_connection` → tries to write to DB\n4. But something is holding the DB lock - likely the `MustScanSubDirs` handler which also calls `db_connection` directly inline (line 2579)\n\nActually wait - there's also the possibility that the HistoryDone fires right after startup, and there's another background task still writing to the DB.\n\n\nI need to add strategic logging to trace where the lock contention is happening. I'll instrument `apply_path_changes` to log when it starts and finishes along with the operation counts, add error logging to `process_watcher_paths` with timestamps and batch details, and track when `HistoryDone` events arrive and what database operations are pending at that moment.\n\nBut wait—I'm realizing the real issue might be a race condition between multiple database writers. The `persist_event_id` function opens a connection every 30 seconds on the watcher thread, and `start_full_index_worker` can trigger a heavy write operation from a separate thread. If the watcher then tries to write via `HistoryDone` while the full index is actively writing, that's where the lock contention happens.\n\nThe `indexing_active` check in `process_watcher_paths` should prevent this, but there's a window where `full_scan_triggered` is set and the full scan hasn't yet marked `indexing_active` as true—that's the race condition I need to catch.\n\nFor debugging, I'll add detailed logging with timestamps to track the sequence of events, capture the state of `indexing_active` when the lock error occurs, show what paths are pending, and try to extract the specific SQLite error code. I'm planning to instrument `process_watcher_paths` with an error handler that logs the timestamp and batch details, then add similar logging at the start of `apply_path_changes` to trace the execution flow.\n\nActually, I should be more surgical about this—the user wants to understand *when* the lock happens during startup, *what* code path triggers it, and *what else* might be holding the database. I'll add focused `eprintln!` statements at the critical points rather than logging everything.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2938,"cache_read_input_tokens":42426,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2938},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK71DujH6wEYbnJihgno","type":"assistant","uuid":"307cda3f-8894-4f7a-a21f-39f091f4be5a","timestamp":"2026-02-20T09:43:56.368Z"}
{"parentUuid":"307cda3f-8894-4f7a-a21f-39f091f4be5a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01HT6vqPYA5rp6a9X2VmhBzu","type":"message","role":"assistant","content":[{"type":"text","text":"이제 이슈를 파악했습니다. `apply_path_changes`에서 DB 쓰기 시도 시 lock 충돌이 발생하고 있는데, 정확히 어느 시점에 무엇과 충돌하는지 추적하는 로그를 추가하겠습니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2938,"cache_read_input_tokens":42426,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2938},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK71DujH6wEYbnJihgno","type":"assistant","uuid":"8bcf4bd6-f7df-4711-9131-66a1e8176361","timestamp":"2026-02-20T09:43:57.248Z"}
{"parentUuid":"8bcf4bd6-f7df-4711-9131-66a1e8176361","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01HT6vqPYA5rp6a9X2VmhBzu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013czkvqEmhoL83XP8Grao1A","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2380,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2938,"cache_read_input_tokens":42426,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2938},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK71DujH6wEYbnJihgno","type":"assistant","uuid":"a3698fef-2788-4905-a71e-c4fa291cf954","timestamp":"2026-02-20T09:43:58.433Z"}
{"parentUuid":"a3698fef-2788-4905-a71e-c4fa291cf954","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013czkvqEmhoL83XP8Grao1A","toolUseID":"toolu_013czkvqEmhoL83XP8Grao1A","timestamp":"2026-02-20T09:43:58.454Z","uuid":"ff5a742e-a795-4814-9edf-4e9147b9e0ec"}
{"parentUuid":"a3698fef-2788-4905-a71e-c4fa291cf954","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013czkvqEmhoL83XP8Grao1A","type":"tool_result","content":"  2380→\n  2381→#[cfg(target_os = \"macos\")]\n  2382→fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n  2383→    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n  2384→    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n  2385→    let mut to_delete = Vec::new();\n  2386→\n  2387→    for path in paths {\n  2388→        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n  2389→            continue;\n  2390→        }\n  2391→\n  2392→        let path_str = path.to_string_lossy().to_string();\n  2393→        if path_str.is_empty() {\n  2394→            continue;\n  2395→        }\n  2396→\n  2397→        if is_recently_touched(state, &path_str) {\n  2398→            continue;\n  2399→        }\n  2400→\n  2401→        match fs::symlink_metadata(path) {\n  2402→            Ok(metadata) => {\n  2403→                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n  2404→                    to_upsert_map.insert(row.path.clone(), row);\n  2405→                }\n  2406→            }\n  2407→            Err(_) => {\n  2408→                to_delete.push(path_str);\n  2409→            }\n  2410→        }\n  2411→    }\n  2412→\n  2413→    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n  2414→\n  2415→    if to_upsert.is_empty() && to_delete.is_empty() {\n  2416→        return Ok(0);\n  2417→    }\n  2418→\n  2419→    let mut conn = db_connection(&state.db_path)?;\n  2420→    let mut changed = 0;\n  2421→\n  2422→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2423→    changed += delete_paths(&mut conn, &to_delete)?;\n  2424→\n  2425→    Ok(changed)\n  2426→}\n  2427→\n  2428→#[cfg(target_os = \"macos\")]\n  2429→const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"deda1e5e-0182-4f0f-b99e-443fe6f3180d","timestamp":"2026-02-20T09:43:58.452Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);","numLines":50,"startLine":2380,"totalLines":5127}},"sourceToolAssistantUUID":"a3698fef-2788-4905-a71e-c4fa291cf954"}
{"parentUuid":"deda1e5e-0182-4f0f-b99e-443fe6f3180d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01MAs3CuesfDJCxoZwjX9QdX","type":"message","role":"assistant","content":[{"type":"text","text":"이제 로그를 추가합니다. 세 군데 수정합니다:\n\n1. `apply_path_changes` — DB 연결 시도 전 로그\n2. `process_watcher_paths` — 에러 핸들러 상세 로그  \n3. `MustScanSubDirs` 인라인 DB 호출 — 동시 쓰기 추적"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1817,"cache_read_input_tokens":45364,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1817},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK72oJCWLze8AmZ41Sp5","type":"assistant","uuid":"0f6bcf40-80d7-4763-8b12-4cc8926fe31b","timestamp":"2026-02-20T09:44:02.480Z"}
{"type":"file-history-snapshot","messageId":"01d3ff97-7f47-4468-b371-270dbaef3230","snapshot":{"messageId":"8e63129d-2cb0-4c95-9b61-c37c6aa6fa77","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v1","version":1,"backupTime":"2026-02-20T09:44:07.710Z"}},"timestamp":"2026-02-20T09:42:52.984Z"},"isSnapshotUpdate":true}
{"parentUuid":"0f6bcf40-80d7-4763-8b12-4cc8926fe31b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01MAs3CuesfDJCxoZwjX9QdX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Wgk11zgWEJ66uTpjXkefa5","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}","new_string":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1817,"cache_read_input_tokens":45364,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1817},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK72oJCWLze8AmZ41Sp5","type":"assistant","uuid":"01d3ff97-7f47-4468-b371-270dbaef3230","timestamp":"2026-02-20T09:44:07.706Z"}
{"parentUuid":"01d3ff97-7f47-4468-b371-270dbaef3230","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01Wgk11zgWEJ66uTpjXkefa5","toolUseID":"toolu_01Wgk11zgWEJ66uTpjXkefa5","timestamp":"2026-02-20T09:44:07.716Z","uuid":"b3a4c431-5af1-4837-a616-c225e89a678f"}
{"parentUuid":"01d3ff97-7f47-4468-b371-270dbaef3230","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Wgk11zgWEJ66uTpjXkefa5","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"2cdc1366-8640-4443-9f75-b06be90f23db","timestamp":"2026-02-20T09:44:07.715Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}","newString":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2416,"oldLines":12,"newStart":2416,"newLines":36,"lines":["         return Ok(0);","     }"," ","-    let mut conn = db_connection(&state.db_path)?;","+    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);","+    eprintln!(","+        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",","+        to_upsert.len(),","+        to_delete.len(),","+        indexing","+    );","+","+    let conn_start = std::time::Instant::now();","+    let mut conn = db_connection(&state.db_path).map_err(|e| {","+        eprintln!(","+            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",","+            conn_start.elapsed().as_millis(),","+            e,","+            to_upsert.len(),","+            to_delete.len(),","+            state.indexing_active.load(AtomicOrdering::Acquire)","+        );","+        e","+    })?;","     let mut changed = 0;"," ","     changed += upsert_rows(&mut conn, &to_upsert)?;","     changed += delete_paths(&mut conn, &to_delete)?;"," ","+    eprintln!(","+        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",","+        changed,","+        conn_start.elapsed().as_millis()","+    );","     Ok(changed)"," }"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"01d3ff97-7f47-4468-b371-270dbaef3230"}
{"parentUuid":"2cdc1366-8640-4443-9f75-b06be90f23db","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01HiXSEZZeR52NDa3eR3hKhf","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014tw9vg2V6XA2DhCsSsGBUh","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }","new_string":"        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":906,"cache_read_input_tokens":47181,"output_tokens":565,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":906,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK73Tzs5Gfsu16YzLi7s","type":"assistant","uuid":"8cff813f-55c0-4670-a571-5054dbf44f38","timestamp":"2026-02-20T09:44:15.943Z"}
{"parentUuid":"8cff813f-55c0-4670-a571-5054dbf44f38","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_014tw9vg2V6XA2DhCsSsGBUh","toolUseID":"toolu_014tw9vg2V6XA2DhCsSsGBUh","timestamp":"2026-02-20T09:44:15.953Z","uuid":"bfff68d0-12d8-47e1-b4bb-2c4fc67644f1"}
{"parentUuid":"8cff813f-55c0-4670-a571-5054dbf44f38","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014tw9vg2V6XA2DhCsSsGBUh","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"e191c170-0ee6-4987-8680-2ed8d914d7be","timestamp":"2026-02-20T09:44:15.952Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }","newString":"        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2486,"oldLines":6,"newStart":2486,"newLines":22,"lines":["             }","         }","         Err(err) => {","+            eprintln!(","+                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",","+                err,","+                batch.len(),","+                state.indexing_active.load(AtomicOrdering::Acquire)","+            );","+            if batch.len() <= 20 {","+                for p in &batch {","+                    eprintln!(\"[watcher]   path: {}\", p.display());","+                }","+            } else {","+                for p in batch.iter().take(5) {","+                    eprintln!(\"[watcher]   path: {}\", p.display());","+                }","+                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);","+            }","             if state.indexing_active.load(AtomicOrdering::Acquire) {","                 return;","             }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"8cff813f-55c0-4670-a571-5054dbf44f38"}
{"parentUuid":"e191c170-0ee6-4987-8680-2ed8d914d7be","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Vr9qjYK2WY9VP8KEAZVb18","type":"message","role":"assistant","content":[{"type":"text","text":"이제 `MustScanSubDirs` 인라인 DB 호출에도 로그를 추가합니다 (동시 쓰기 추적):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":622,"cache_read_input_tokens":48087,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":622},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7458UgJahTQwL6ym7f","type":"assistant","uuid":"8ab65c0d-d835-4c98-b8f7-10f919189f9e","timestamp":"2026-02-20T09:44:19.079Z"}
{"parentUuid":"8ab65c0d-d835-4c98-b8f7-10f919189f9e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Vr9qjYK2WY9VP8KEAZVb18","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MqATSBB7J3BphCDVMcVfK5","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"                    if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {","new_string":"                    if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":622,"cache_read_input_tokens":48087,"output_tokens":331,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":622,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK7458UgJahTQwL6ym7f","type":"assistant","uuid":"02c4a2a7-b247-44e4-aaac-df3e59ced031","timestamp":"2026-02-20T09:44:21.626Z"}
{"parentUuid":"02c4a2a7-b247-44e4-aaac-df3e59ced031","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01MqATSBB7J3BphCDVMcVfK5","toolUseID":"toolu_01MqATSBB7J3BphCDVMcVfK5","timestamp":"2026-02-20T09:44:21.639Z","uuid":"bc7c2043-0760-4f23-96b6-7ef9e6d8e79f"}
{"parentUuid":"02c4a2a7-b247-44e4-aaac-df3e59ced031","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MqATSBB7J3BphCDVMcVfK5","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"4d9333b9-9dd9-462a-8715-eb540670fc5e","timestamp":"2026-02-20T09:44:21.637Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"                    if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {","newString":"                    if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2616,"oldLines":6,"newStart":2616,"newLines":11,"lines":["                             cached_effective_ignore_rules(&state);","                         let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);","                         if !rows.is_empty() {","+                            eprintln!(","+                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",","+                                rows.len(),","+                                path.display()","+                            );","                             if let Ok(mut conn) = db_connection(&state.db_path) {","                                 if upsert_rows(&mut conn, &rows).is_ok() {","                                     invalidate_search_caches(&state);"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"02c4a2a7-b247-44e4-aaac-df3e59ced031"}
{"parentUuid":"4d9333b9-9dd9-462a-8715-eb540670fc5e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01QuQxBPaPyVQQExvz1jG4T9","type":"message","role":"assistant","content":[{"type":"text","text":"마지막으로 `HistoryDone` 수신 시점 로그를 추가합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":369,"cache_read_input_tokens":48709,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":369},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK74VQECkYTYaurc5VYK","type":"assistant","uuid":"f73e4fdc-7e0d-4aaa-93fc-e3273579f7b1","timestamp":"2026-02-20T09:44:24.292Z"}
{"parentUuid":"f73e4fdc-7e0d-4aaa-93fc-e3273579f7b1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01QuQxBPaPyVQQExvz1jG4T9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SmAHqM28uJoZRniKLjLSkU","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(","new_string":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths("},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":369,"cache_read_input_tokens":48709,"output_tokens":292,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":369,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK74VQECkYTYaurc5VYK","type":"assistant","uuid":"c7cbd78e-783a-4303-ab80-e29cce4becb4","timestamp":"2026-02-20T09:44:26.486Z"}
{"parentUuid":"c7cbd78e-783a-4303-ab80-e29cce4becb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01SmAHqM28uJoZRniKLjLSkU","toolUseID":"toolu_01SmAHqM28uJoZRniKLjLSkU","timestamp":"2026-02-20T09:44:26.498Z","uuid":"6cf8446e-927a-457d-9902-b7b94c518e34"}
{"parentUuid":"c7cbd78e-783a-4303-ab80-e29cce4becb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SmAHqM28uJoZRniKLjLSkU","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"7851ac7f-2a37-4112-b7c3-b108aea87b42","timestamp":"2026-02-20T09:44:26.497Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(","newString":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2638,"oldLines":6,"newStart":2638,"newLines":11,"lines":["                     }","                 }","                 Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {","+                    eprintln!(","+                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",","+                        pending_paths.len(),","+                        state.indexing_active.load(AtomicOrdering::Acquire)","+                    );","                     process_watcher_paths(","                         &app,","                         &state,"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"c7cbd78e-783a-4303-ab80-e29cce4becb4"}
{"parentUuid":"7851ac7f-2a37-4112-b7c3-b108aea87b42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01SayJmk9ZjGSCqmQQgNeQjY","type":"message","role":"assistant","content":[{"type":"text","text":"빌드해서 컴파일 오류 없는지 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":330,"cache_read_input_tokens":49078,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":330},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK74rJ5oRYhzaDn9ycaY","type":"assistant","uuid":"e8d6485c-0a58-4230-a25b-b68789f82162","timestamp":"2026-02-20T09:44:28.889Z"}
{"parentUuid":"e8d6485c-0a58-4230-a25b-b68789f82162","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01SayJmk9ZjGSCqmQQgNeQjY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0114E3CkmzV8NHM47RDRHtiD","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | tail -20","description":"Cargo check for compile errors","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":330,"cache_read_input_tokens":49078,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":330},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK74rJ5oRYhzaDn9ycaY","type":"assistant","uuid":"02d3653f-7a91-467c-895c-0db7452a5393","timestamp":"2026-02-20T09:44:30.006Z"}
{"parentUuid":"02d3653f-7a91-467c-895c-0db7452a5393","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0114E3CkmzV8NHM47RDRHtiD","type":"tool_result","content":"warning: function `start_full_index_worker_silent` is never used\n    --> src/main.rs:1843:15\n     |\n1843 | pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nwarning: associated items `build` and `entries` are never used\n   --> src/mem_search.rs:61:12\n    |\n 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 2.04s","is_error":false}]},"uuid":"23b9e91a-2424-4964-97fd-bf2cb9e68819","timestamp":"2026-02-20T09:44:33.399Z","toolUseResult":{"stdout":"warning: function `start_full_index_worker_silent` is never used\n    --> src/main.rs:1843:15\n     |\n1843 | pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nwarning: associated items `build` and `entries` are never used\n   --> src/mem_search.rs:61:12\n    |\n 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 2.04s","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"02d3653f-7a91-467c-895c-0db7452a5393"}
{"parentUuid":"23b9e91a-2424-4964-97fd-bf2cb9e68819","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01LEyBvaGzCNG6k7mYZWLFh5","type":"message","role":"assistant","content":[{"type":"text","text":"컴파일 성공. 추가된 로그 내용 요약:\n\n**추가된 로그 4곳:**\n\n1. **`apply_path_changes` 진입 시** — upsert/delete 건수 + `indexing_active` 상태 출력\n2. **`db_connection` 실패 시** — 대기 시간(ms), 에러 메시지, 건수, `indexing_active` 상태\n3. **`process_watcher_paths` 에러 핸들러** — 에러 메시지, 배치 크기, 경로 목록 (20개 이하면 전부, 그 이상이면 앞 5개)\n4. **`HistoryDone` 수신 시** — pending 경로 수 + `indexing_active` 상태\n5. **`MustScanSubDirs` DB 쓰기 시** — 동시에 DB 접근하고 있는지 추적\n\n**예상 원인 가설:** `HistoryDone`이 도착해 `apply_path_changes`가 DB 쓰기를 시도하는 동시에, `MustScanSubDirs`가 이미 같은 DB에 쓰고 있거나, 이전 실행의 WAL 체크포인트 작업이 남아있는 경우. 로그를 보면 `indexing_active=false`인데 lock이 발생하는지, 혹은 `MustScanSubDirs DB write` 직후에 에러가 뜨는지 패턴이 보일 것입니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":382,"cache_read_input_tokens":49408,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":382},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK75NWmW6NsVzakXLo85","type":"assistant","uuid":"b1d3807c-5d16-4eda-a10c-8f21cfde6430","timestamp":"2026-02-20T09:44:43.586Z"}
{"parentUuid":"b1d3807c-5d16-4eda-a10c-8f21cfde6430","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"ea52d7e1-500f-4a39-a835-5c4b5e6cc824","toolUseID":"ea52d7e1-500f-4a39-a835-5c4b5e6cc824","timestamp":"2026-02-20T09:44:43.616Z","uuid":"5d43f6d3-2cb9-428e-bfa5-d2f04986f365"}
{"parentUuid":"5d43f6d3-2cb9-428e-bfa5-d2f04986f365","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":958}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-20T09:44:44.575Z","uuid":"e22d429d-b436-4733-8c42-2c6898e180d5","toolUseID":"ea52d7e1-500f-4a39-a835-5c4b5e6cc824"}
{"parentUuid":"e22d429d-b436-4733-8c42-2c6898e180d5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"turn_duration","durationMs":111591,"timestamp":"2026-02-20T09:44:44.576Z","uuid":"69fe8474-d08c-424e-abd6-8526ee2eca3f","isMeta":false}
{"type":"file-history-snapshot","messageId":"4f430021-1dfe-4d35-8d4f-f636d7b95195","snapshot":{"messageId":"4f430021-1dfe-4d35-8d4f-f636d7b95195","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-20T09:45:53.463Z"}},"timestamp":"2026-02-20T09:45:53.463Z"},"isSnapshotUpdate":false}
{"parentUuid":"69fe8474-d08c-424e-abd6-8526ee2eca3f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":"[startup] setup_app() entered\n[startup] +0ms loading pathignore rules...\n[startup] +1ms pathignore done\n[startup] +1ms AppState created\n[startup] +4ms global shortcut registered\n[startup] +4ms setup_app() done, spawning init thread\n[startup/thread] init thread started\n[startup/thread] +0ms calling init_db...\n[init_db] +4ms db_connection opened\n[init_db] +4ms version check done (v=4)\n[init_db] +4ms schema ensured\n[init_db] +4ms total\n[startup/thread] +4ms init_db done\n[startup/thread] +4ms db_ready=true — launching indexing immediately\n[watcher] apply_path_changes: upsert=16 delete=4 indexing_active=false\n[watcher] apply_path_changes done: changed=16 elapsed=16ms\n[startup/housekeeping] refresh_and_emit_status_counts done in 7915ms\n[watcher] apply_path_changes: upsert=13 delete=4 indexing_active=false\n[watcher] process_watcher_paths ERROR: database is locked | batch_size=17 indexing_active=false\n[watcher]   path: /Users/al02402336/.cisco/vpn/log/UIHistory_2026.02.20.18.38.54.537.txt\n[watcher]   path: /Users/al02402336/.codex/sessions/2026/02/20/rollout-2026-02-20T18-45-24-019c7a70-9450-7c53-997b-1ae293ced4e6.jsonl\n[watcher]   path: /Users/al02402336/.codex/sessions/2026/02/20/rollout-2026-02-20T18-45-29-019c7a70-a7c6-76c2-a69d-ee3d9fe0d3ec.jsonl\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0Wh9RBd\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0Wh9RBd/.lock\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0Wh9RBd/apply_patch\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0Wh9RBd/applypatch\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0fz4PKD\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0fz4PKD/.lock\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0fz4PKD/apply_patch\n[watcher]   path: /Users/al02402336/.codex/tmp/arg0/codex-arg0fz4PKD/applypatch\n[watcher]   path: /Users/al02402336/Library/Application Support/Pencil/sentry/scope_v3.json\n[watcher]   path: /Users/al02402336/Library/Application Support/com.openai.REDACTED\n[watcher]   path: REDACTED.db\n[watcher]   path: REDACTED.db-shm\n[watcher]   path: REDACTED.db-wal\n[watcher] apply_path_changes: upsert=11 delete=7 indexing_active=false\n[startup/housekeeping] all done in 13943ms\n[watcher] apply_path_changes done: changed=15 elapsed=2139ms\n[watcher] apply_path_changes: upsert=1 delete=0 indexing_active=false\n[watcher] apply_path_changes done: changed=1 elapsed=6ms\n[watcher] apply_path_changes: upsert=11 delete=4 indexing_active=false\n[watcher] apply_path_changes done: changed=11 elapsed=8ms"},"uuid":"4f430021-1dfe-4d35-8d4f-f636d7b95195","timestamp":"2026-02-20T09:45:52.265Z","permissionMode":"bypassPermissions"}
{"parentUuid":"4f430021-1dfe-4d35-8d4f-f636d7b95195","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_016qywEG4W5vPNSzB5PKobhq","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I can see the issue clearly from the logs:\n\n1. `[startup/housekeeping] refresh_and_emit_status_counts done in 7915ms` - This housekeeping task is taking 7.9 seconds and it's holding a DB connection during that time\n2. The watcher tries to write to DB during that time → `database is locked`\n\nThe key observation:\n- `refresh_and_emit_status_counts` took **7915ms** to complete\n- During that time, the watcher tried to do another `apply_path_changes` and got `database is locked`\n- Then `[startup/housekeeping] all done in 13943ms` - the full housekeeping took ~14 seconds!\n\n\n- The root cause is that `refresh_and_emit_status_counts` is holding a long-lived DB connection, blocking the watcher from writing. I need to examine what this function actually does to see where the bottleneck is.","signature":"EpMICkYICxgCKkC0gk4y1Mt+csavQEgwHIHRf5WD6g5FrDP0fzXBOVFbVaxR+5WHnmOLSUrohwq09u6NwA3wyYFLxgeVRmgNN/wjEgyvYu62i1NXrB9ghjYaDGvMzzFUeTgdLaeLQSIwZBP8wY/rOT6OFp9aD9IXjzIIy8sTrrF8TdMhYUGwfRXi6cf72V4hJ3Ht7N8u8gKCKvoGk7AbCU1LFELfLPB7SKTmim9vCGwdY7pK8PduKK94WLi3AlXtHdHwav+vrnpNOqBJcY3cvvCeKPrLOeZGTvp86FWM5BEoDrpjhg3PQ1EXjgVi6DsamHEErVwYIdw5t4tpkHanFm+7mP9+RXCnkxpp5GrHfvW3XXhQjhMT/YCFRp1ikjqAeadxB0RX6ksmSYR9FB036R23vLJ4rZKAJFkRuGyj+U71oyMbFJaYZLCOxCGr/l8ohRxLLgy21bdOTpW4tiD9f9lU68SsVSVyvujIdMHNevCO58h1QO9wC2JtYQ/m3uKuJhzYnVs0HD0FQlJxbvyJ6ArDa0ar5CbF+//axRRcLheR3VOTbKEE8zGWDLoOLOBLy0bbXHTJGxWhJNqGFd+qHhQNNRSIip7kqHCt8YsAFPTS4+j8NOAcqkZapPZHqg0kyBOhnCdSyuOtMl2iYLW9YnhYFxzTga9jpWq/sTI89thiWbmMQn8EGgABoa40q9OnVCpaFEfOdGihhwQMTiLakq0MgfzJGxIENooMLTNuwz3QhWypuxWo7H+0kaDzvYd6tcOiSxbwy/0ne7L3BWVq966wFpzdsW3WU8GAh3yK6DdthdzvKp9GD1/UdcDzhvn8/3Z5eylYhCbOO/rP1t9NZ7dVy7n84fk9zXfwXpsKIyxqXulY80B/qhg/lO4Wn9hOcBquiYNgceT1xJoUf5NQQZnmlkFEZ9BrRy23zsPCEJXHEcCF4Vueok7Ncl4hntQdDfnQHzapG/017UyyYBfewNKu6Bx9u9vdT3BoQ/D6xLqQLcG5idERLFt9t3J6/tUrHoxNdxKVpAv6ipbq1HgLow+OlIwqpgTrYqq6DHrd+Km4kKnlcju1eposWJj2hCXeULkfs5csaejxnm9ZD2YBEh83qxLG3bEGvPJPisfv57/WBhd7NWz8xxNdiwJhUzt5trrcDm3du9dpKKKV0SjHRw0MKW5HtNpb05DOTl5+m4xBMyfDeP6bRNtx/OGwN81LzSCO3y6Bv+zlU0+HMyJv8ho9ymsy7yA+7XeI+BPz2/DeFxILHIT4zOyQA8fLhAL8i7Uq9cumsahkRBox0avDqYAG6fOL9Y58juDiK/O9d5pqfUMf4gCaRgaJ3YLm2sim1b+rlUSL8L407vjZan/C8AimpRXDx2Uu1KefdybqGUCwzkHF1NgYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1211,"cache_read_input_tokens":50237,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1211},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7BGW2ka9N5aoygtbQJ","type":"assistant","uuid":"1b4fc897-ad34-45b5-8bf2-04d4c0de9c3c","timestamp":"2026-02-20T09:46:02.181Z"}
{"parentUuid":"1b4fc897-ad34-45b5-8bf2-04d4c0de9c3c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_016qywEG4W5vPNSzB5PKobhq","type":"message","role":"assistant","content":[{"type":"text","text":"원인이 명확합니다. `refresh_and_emit_status_counts`가 **7915ms** 동안 DB를 점유하고 있는 동안, watcher가 두 번째 쓰기를 시도해서 `database is locked`가 발생한 것입니다.\n\n`refresh_and_emit_status_counts`와 housekeeping 함수를 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1211,"cache_read_input_tokens":50237,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1211},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7BGW2ka9N5aoygtbQJ","type":"assistant","uuid":"4fc48e74-5b8f-41ae-abf8-6aba00d588c0","timestamp":"2026-02-20T09:46:03.038Z"}
{"parentUuid":"4fc48e74-5b8f-41ae-abf8-6aba00d588c0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_016qywEG4W5vPNSzB5PKobhq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EYLokK7SbPG4XUesmiNWmL","name":"Grep","input":{"pattern":"fn refresh_and_emit_status_counts|fn update_status_counts|housekeeping|startup/housekeeping","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":4},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1211,"cache_read_input_tokens":50237,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1211},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7BGW2ka9N5aoygtbQJ","type":"assistant","uuid":"aa6501e9-454f-470a-a28e-48dad13b743f","timestamp":"2026-02-20T09:46:04.635Z"}
{"parentUuid":"aa6501e9-454f-470a-a28e-48dad13b743f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01EYLokK7SbPG4XUesmiNWmL","toolUseID":"toolu_01EYLokK7SbPG4XUesmiNWmL","timestamp":"2026-02-20T09:46:05.427Z","uuid":"727329b4-d58a-4968-9317-770b02352be6"}
{"parentUuid":"aa6501e9-454f-470a-a28e-48dad13b743f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EYLokK7SbPG4XUesmiNWmL","type":"tool_result","content":"514-\n515-    Ok((entries_count, last_updated))\n516-}\n517-\n518:pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n519-    let (entries_count, last_updated) = update_counts(state)?;\n520-    let mut status = state.status.lock();\n521-    status.entries_count = entries_count;\n522-    status.last_updated = last_updated;\n--\n1791-        status.permission_errors,\n1792-    );\n1793-}\n1794-\n1795:pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n1796-    let (entries_count, last_updated) = update_status_counts(state)?;\n1797-    // Persist cached counts so next startup can read them instantly\n1798-    if let Ok(conn) = db_connection(&state.db_path) {\n1799-        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n--\n4578-\n4579-        state.db_ready.store(true, AtomicOrdering::Release);\n4580-        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n4581-\n4582:        // Deferred housekeeping — purge + status counts run in background\n4583-        {\n4584-            let hk_app = app_handle.clone();\n4585-            let hk_state = state.clone();\n4586-            std::thread::spawn(move || {\n4587-                // Brief pause so indexing thread can start first\n4588-                std::thread::sleep(std::time::Duration::from_millis(500));\n4589-                let hk_started = std::time::Instant::now();\n4590-                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n4591:                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n4592-                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n4593:                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n4594-                }\n4595:                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n4596-            });\n4597-        }\n4598-\n4599-        #[cfg(target_os = \"macos\")]"}]},"uuid":"dece21ab-26a2-43fc-a3f3-a5e4786109ac","timestamp":"2026-02-20T09:46:05.426Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"514-\n515-    Ok((entries_count, last_updated))\n516-}\n517-\n518:pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n519-    let (entries_count, last_updated) = update_counts(state)?;\n520-    let mut status = state.status.lock();\n521-    status.entries_count = entries_count;\n522-    status.last_updated = last_updated;\n--\n1791-        status.permission_errors,\n1792-    );\n1793-}\n1794-\n1795:pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n1796-    let (entries_count, last_updated) = update_status_counts(state)?;\n1797-    // Persist cached counts so next startup can read them instantly\n1798-    if let Ok(conn) = db_connection(&state.db_path) {\n1799-        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n--\n4578-\n4579-        state.db_ready.store(true, AtomicOrdering::Release);\n4580-        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n4581-\n4582:        // Deferred housekeeping — purge + status counts run in background\n4583-        {\n4584-            let hk_app = app_handle.clone();\n4585-            let hk_state = state.clone();\n4586-            std::thread::spawn(move || {\n4587-                // Brief pause so indexing thread can start first\n4588-                std::thread::sleep(std::time::Duration::from_millis(500));\n4589-                let hk_started = std::time::Instant::now();\n4590-                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n4591:                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n4592-                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n4593:                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n4594-                }\n4595:                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n4596-            });\n4597-        }\n4598-\n4599-        #[cfg(target_os = \"macos\")]","numLines":42},"sourceToolAssistantUUID":"aa6501e9-454f-470a-a28e-48dad13b743f"}
{"parentUuid":"dece21ab-26a2-43fc-a3f3-a5e4786109ac","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_0127u5T15auXYRzB4R6wW1Sh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015pZ1DG9aS45zdzEV3Vy69A","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":490,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1345,"cache_read_input_tokens":51448,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1345},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7C99nyjNSwfa6DsDKh","type":"assistant","uuid":"575a93b6-50bc-4362-803f-0709d756e26c","timestamp":"2026-02-20T09:46:07.807Z"}
{"parentUuid":"575a93b6-50bc-4362-803f-0709d756e26c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_015pZ1DG9aS45zdzEV3Vy69A","toolUseID":"toolu_015pZ1DG9aS45zdzEV3Vy69A","timestamp":"2026-02-20T09:46:07.818Z","uuid":"7f213b5a-e572-47e6-bb93-0348f009af0c"}
{"parentUuid":"575a93b6-50bc-4362-803f-0709d756e26c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015pZ1DG9aS45zdzEV3Vy69A","type":"tool_result","content":"   490→pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n   491→    conn.execute(\n   492→        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n   493→        params![key, value],\n   494→    )\n   495→    .map_err(|e| e.to_string())?;\n   496→    Ok(())\n   497→}\n   498→\n   499→fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n   500→    let conn = db_connection(&state.db_path)?;\n   501→\n   502→    let entries_count = conn\n   503→        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n   504→            row.get::<_, i64>(0)\n   505→        })\n   506→        .map_err(|e| e.to_string())?\n   507→        .max(0) as u64;\n   508→\n   509→    let last_updated = conn\n   510→        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n   511→            row.get::<_, Option<i64>>(0)\n   512→        })\n   513→        .map_err(|e| e.to_string())?;\n   514→\n   515→    Ok((entries_count, last_updated))\n   516→}\n   517→\n   518→pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n   519→    let (entries_count, last_updated) = update_counts(state)?;\n   520→    let mut status = state.status.lock();\n   521→    status.entries_count = entries_count;\n   522→    status.last_updated = last_updated;\n   523→    Ok((entries_count, last_updated))\n   524→}\n   525→\n   526→pub(crate) fn invalidate_search_caches(state: &AppState) {\n   527→    state.fd_search_cache.lock().take();\n   528→    state.negative_name_cache.lock().clear();\n   529→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"4916b977-7b1c-4147-9731-d5e1d0013320","timestamp":"2026-02-20T09:46:07.817Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}","numLines":40,"startLine":490,"totalLines":5177}},"sourceToolAssistantUUID":"575a93b6-50bc-4362-803f-0709d756e26c"}
{"parentUuid":"4916b977-7b1c-4147-9731-d5e1d0013320","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01WuZhbeU9eu1bJYqAVbp4BX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MySCfWJF5Hh6M3dJRJyn3c","name":"Grep","input":{"pattern":"fn purge_ignored_entries","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":772,"cache_read_input_tokens":52793,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":772},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7CKkmjwF66rZtGGSRh","type":"assistant","uuid":"94b8f379-d0bb-4bdd-b362-89ac52eb06f1","timestamp":"2026-02-20T09:46:11.043Z"}
{"parentUuid":"94b8f379-d0bb-4bdd-b362-89ac52eb06f1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01MySCfWJF5Hh6M3dJRJyn3c","toolUseID":"toolu_01MySCfWJF5Hh6M3dJRJyn3c","timestamp":"2026-02-20T09:46:11.803Z","uuid":"0fced77b-3468-4c8f-bb98-37651946ceaf"}
{"parentUuid":"94b8f379-d0bb-4bdd-b362-89ac52eb06f1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MySCfWJF5Hh6M3dJRJyn3c","type":"tool_result","content":"1066-        roots: roots.clone(),\n1067-        patterns: patterns.clone(),\n1068-        pathignore_mtime,\n1069-        gitignore_mtime,\n1070-    });\n1071-\n1072-    (roots, patterns)\n1073-}\n1074-\n1075-fn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n1076-    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n1077-    for root in roots {\n1078-        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n1079-    }\n1080-    for pattern in patterns {\n1081-        ignore_pattern_key(pattern).hash(&mut hasher);\n1082-    }\n1083-    hasher.finish()\n1084-}\n1085-\n1086:fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n1087-    if ignored_roots.is_empty() {\n1088-        return Ok(());\n1089-    }\n1090-\n1091-    let conn = db_connection(db_path)?;\n1092-    for root in ignored_roots {\n1093-        let root_str = root.to_string_lossy().to_string();\n1094-        if root_str.is_empty() {\n1095-            continue;\n1096-        }\n1097-\n1098-        if root_str == \"/\" {\n1099-            conn.execute(\"DELETE FROM entries\", [])\n1100-                .map_err(|e| e.to_string())?;\n1101-            break;\n1102-        }\n1103-\n1104-        let prefix = root_str.trim_end_matches('/');\n1105-        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n1106-        conn.execute("}]},"uuid":"2d0d2da7-1d38-42ec-ae28-eebe1056e201","timestamp":"2026-02-20T09:46:11.801Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"1066-        roots: roots.clone(),\n1067-        patterns: patterns.clone(),\n1068-        pathignore_mtime,\n1069-        gitignore_mtime,\n1070-    });\n1071-\n1072-    (roots, patterns)\n1073-}\n1074-\n1075-fn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n1076-    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n1077-    for root in roots {\n1078-        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n1079-    }\n1080-    for pattern in patterns {\n1081-        ignore_pattern_key(pattern).hash(&mut hasher);\n1082-    }\n1083-    hasher.finish()\n1084-}\n1085-\n1086:fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n1087-    if ignored_roots.is_empty() {\n1088-        return Ok(());\n1089-    }\n1090-\n1091-    let conn = db_connection(db_path)?;\n1092-    for root in ignored_roots {\n1093-        let root_str = root.to_string_lossy().to_string();\n1094-        if root_str.is_empty() {\n1095-            continue;\n1096-        }\n1097-\n1098-        if root_str == \"/\" {\n1099-            conn.execute(\"DELETE FROM entries\", [])\n1100-                .map_err(|e| e.to_string())?;\n1101-            break;\n1102-        }\n1103-\n1104-        let prefix = root_str.trim_end_matches('/');\n1105-        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n1106-        conn.execute(","numLines":41},"sourceToolAssistantUUID":"94b8f379-d0bb-4bdd-b362-89ac52eb06f1"}
{"parentUuid":"2d0d2da7-1d38-42ec-ae28-eebe1056e201","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01JA7Pf9Jqk6rtcUyYByVtDR","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have the full picture:\n\n1. Startup: `refresh_and_emit_status_counts` is called from the housekeeping thread after 500ms delay\n2. `refresh_and_emit_status_counts` → `update_counts` → opens `db_connection` with a `SELECT COUNT(*) FROM entries` (1.1M entries!) → this takes 7915ms\n3. During this time, the watcher fires and tries to do `apply_path_changes` → `db_connection` → tries to open another connection and write\n\nThe `SELECT COUNT(*) FROM entries` on 1.1M rows takes 7.9 seconds. \n\nThat's the root cause. But `SELECT COUNT(*)` should be fast in SQLite normally—unless there's something blocking it. WAL mode shouldn't cause readers to block writers, so that's not it. Let me think about what `refresh_and_emit_status_counts` is actually doing: it opens a connection, runs the count query, then runs another query to get the max indexed_at timestamp, and then opens a second connection for something else.\n\nLooking at the logs more carefully, I see `refresh_and_emit_status_counts` took 7.9 seconds, and it's opening a write connection with `set_meta`. The watcher is also trying to write at the same time, so the write operation is getting blocked—probably by the status counts refresh holding a lock longer than expected. Looking at the sequence of operations, the first `apply_path_changes` completes successfully in 16ms, then housekeeping finishes its status refresh after 7915ms. The second attempt to apply changes starts but immediately hits a database lock error, though a third attempt succeeds afterward before housekeeping reports completion at 13943ms total.\n\nThe third operation's 2139ms elapsed time is the key issue—that's how long it waited to acquire the database lock. The culprit is `purge_ignored_entries`, which runs during housekeeping and holds a write lock for roughly 6 seconds (the gap between the first housekeeping phase finishing and the overall completion). While that deletion is happening, the second `apply_path_changes` can't proceed because the database is locked, and the third attempt has to wait out most of that lock duration before it can finally execute.\n\nThe real fix is either batching the deletions in `purge_ignored_entries` to release the lock between chunks, or increasing the `busy_timeout` value so write operations have more time to wait for the lock to become available. db_connection` (from 3000ms to something larger), OR make `purge_ignored_entries` commit in smaller chunks.\n\nLooking at `purge_ignored_entries`, it runs multiple DELETE queries sequentially on a single connection in auto-commit mode, which could hold WAL write locks for an extended period. In WAL mode, if this DELETE operation takes longer than the watcher's 3000ms timeout, the watcher gets blocked with a \"database is locked\" error.\n\nThe immediate options are increasing the watcher's `busy_timeout`, batching the DELETEs in smaller chunks, or using a write mutex to serialize database writes. But just raising the timeout doesn't solve the underlying problem—if `purge_ignored_entries` takes 6 seconds and the watcher only waits 3 seconds, I'd need to increase the timeout to at least 6 seconds, which is just masking the real issue.\n\nThe better approach is batching the DELETE operations in `purge_ignored_entries` to reduce lock contention. I'm also noticing that `update_counts` running `SELECT COUNT(*)` on 1.1M rows in 7.9 seconds seems slow for what should be a relatively fast operation in SQLite. each root, the function runs `DELETE FROM entries` statements that trigger FTS5 updates for every single row in the 1.1M entry table - that's what's causing the 6-second delay. The fix would be either batching these deletes into smaller transactions or increasing the busy timeout so the watcher can handle this startup scenario, but since the user asked me to add logging to track the issue, I've already accomplished that by identifying the root cause through the logs.","signature":"Euk9CkYICxgCKkDhc5T3uakEHY7CWf1ZV67APQZwsJwPen5bNoJ90PrIAMyvLwPf6jjaOMQ4IDfrsKs9xHCsFRuwGQXc+kUCR1tYEgxZQMIf4UswhsBSslYaDGk8Opf6z72KLe698SIwvIvUc5rL0woyLdZClIIZmWmvAi4YpY8bC3rxof2pCjGdvc0CsBDRmVpwJIaR8WfhKtA8awM4TTH3eGsCyT23MMYCqG/pONaQx3Jpo34NhZ0Y/DB4PbGRICRSSa20PAYiXWZb7eTsYhlf19vD1EB9WVOCTzLXldZdwcT15f/Sse6cEoTNB4G/reoH7AWlitSRtuddMuB+sjONZtm3kaBt5KdrTnox3lz6/zG51+zLaDmOuwzoEtxz87dj5NWXB7ONaqU3Fb9uVmxEAXTohBHlIznaaMFjjRRm3u7BzsFQS/zvjY7BODoBnDULTr/AmH4rLJ8kIIjNOj14znQed99Qa7W2e27ADOhj1o09DA3S0kykNmT+zFltTJuLjTq+NNF/A8kXI/pLTJouR7CAtDzUzaeFByovi70fv3F49TcaZ0SlwgViL33rOFYkhsNGqrMX2qcZCduRcF5zmrPRcTPp1xcpPSH/wk1jhks/NoOydxAKgr59KfFJ/GuEPgiDjhvrcOBDk9oWsTOMnQja56ZPi/Qy93vy/4UFB2asBDiVu/Ew5uLue7bP/IiiEpNDFsc/OLaPYtt/7+0K96LnfOMsT1/FHEsXT5nzsmeAmDCn7T9dgUOecRcVUlXHZIy6q40xXPiutt9aocKISzXgCx2JcTdykOvwLPO8FuC6B/iJ+rDb4c8dTZX5RXHOgjklhFCKDTjH3u9veBDMjgJHC25tne1X+uoOj4uzLBbJbYu+PE4U3/gGLXNYUt4eLGt1DG5m0tc52XQLxPnuDjpZ4UdNwjMsu4rVUUKmuI7RF8WM7jIUJ35GQNzem9WC+Q6eAqCreMoi+zZDemB5C8y6CVdfCpe/lwFqCQ9GNlUBrAWNZO0h/G66w6Ln6opvpqfEgrVNH8FPUHdFMWoxQvOng2glsRE14XgIyanic28oOaHNICt6TroHmN60X2FaWQlSXN/cQXpIqUQlU5KK5qmLQaZK4tnLySkRObdeDsDEZ0FW7Tl8+EQDZ0F/JTC/RwMGrWRvTtuZAPO7F2YrqjAKzv+rm/EsgxdMDAgCcu0s58xluEJGwPXmRs8bhExhWTPuDvaA6bWdq3K6EK+qNtvbUn10+YEn3j9PQzA/APCeW+6F0s78XYEAyyjlHRV8mdhVAdVAvWc12YzgspcEDJPqUQWoUxmiudVvkbb7/2yvGApMnsWXn0AGVbHmjxNez1r3VgnFegmefTMHi5FzNl+xzrvahw7Zz0y1f8WYvTNI4kHRHMB75Pf8Ca1TWC1gViEnUYrNZCi+An3Uc2LwO3k5451LODC5DMunrOHG8j0xZTSWkLYDHTC9oxGJiHfEPO9MIhtfHThGYulRcXKiY58uYiPYNnvFrOJYUyM8NskP41DB0Mfy7Du91GOxONxN0EQhVeWpAHioSUouuPADLpZL7GkqIjHeefevkXV9zwrnGtVjrPjHOKXD2OSpji2xwVTPRqu5q0aj8jFY9zPzZFeo/hLw59IF4tiHZ0li420rdp6zV/Saewg/lasUznvpz1wj0+jd55zBNdZkFhyLD4YG/FdTIcqp99CYhuJpt9y95d/WSGP94yJ7wJXCe0QYO7UC3rIlMYwV0nFvav4lBiZh2p8yN3FeV4te+Y7Fy+j5WmCNLQO9ok6bDVlNQCfhptkj42FPmNzxgHSh+ikYAm7uTT/Q5R7LHP4dzXGItGm3hpkBdvy/iwlAbxOJ9hp8OiL4ONdOT+M1yj0dDGt1BtP2099wpKiA2Lvhp6MSolLo0qwlW9leqIE6Fmx97AYm2FcVC7tGoxVaMymId30u3v2ePIAAuHeSzFCJgUDiXDBKckh2am9QfJITOKRQEA0h9q+lfUg3tgiDib82oNFIZ9CHRw4Wxgkwlw+EZYvJwaMbqAl/reaU9GTBagOUZofRISE1IsbV6/rgzrSYtiUKP/bwKHv7J7TZ0UVuqQPJD2GtoRWjDKLymVy1nlH34N49q5tfDUngOPA1VTDGO623rQORwn06/V4C8vKDDptt50Es153SDDkyrua4kKfI10hUFgq6U/gu7lOK+BvPpu/oRATdeVLa96F2ru+5qrbCcho2kFG48ZsIxuvb7O42KsY8MKvQJb7UpmADBckdCBq9HlYJWtVeC5BBx3oJZPM0tTa0YBqCqWiwnxvGeS8LxMj1CPyTo5rpEXgCv5K+z2//+ayIXlo0rQ0k7RLYjdHLdj9YhRddH22ngIAqtWwUnisX9pjvIj03ANijBq/t21aPSKYb8LDR+CntW/wgIKHvOEnUn8z95vss8NwQybUVTvQ+XYHNahKwBXabERSY2JTWixbJNYqZ5798ihL7JPe2gmt2w8Y4Xu+86paDxExq+DgMfYKYx6njQbAux7WRMpAsV4MneGwFnzMI57DvJa3Ujx1fy07QIwlUywN+rSfk4J586af2f8qYozzeip3+tdZnLH9S92rlN5qBwZsM2oRCC52gPM45Zje7t7kC/4E7ciWMWstCz5+5wyZdb6/Qz4zlTAKzo1DlaWjJTjIqvm6IlA5WTRl/Sx728sdgxvCCE4QlviQmVjc6sYyJsf3/gvBLuwJOzmxdYg46mmWLqRY+1RVd4eZ2lkHuUullsPNCsbVv8mCG2uMWLUMkIO8HhSS1NSoOxFQNiKHtCh/ymN1XdCYZ1e2pTsXFyyOi5VaEFoH2CZHnsLKtV21aNX1RnGcarQW2T5ZffkNNT9OcMMhTK1NKnf8GBXOiYe3AVS5sm1b78LaES0SCrGVMWDzeQTXqknMgWYtZIX5RmuSB1mTxe4aMcMWjRdmzG9Ka9yQ7UhfoG+ml054L1rso2Mv2u7Ovq7T9Xeo4yLl4CdX3UcvcSHKvQsXHsyjSStbqM7/vcULBHKQxFoLLne9uGZIMOrRsvmnyOFu+kW8DoJUtgxaJr5nU0ZjtNIsUmcsbMPGOVmzxdgPZ1Qsb0rvt20X+nlI3fldIsUKOvbflGlG4ibDuUcpwdPTOv8U+FQZJXyI+5vqvcu60LU7VhycFKOPYqj2ZeeaVjOG1l+WK9mDcbmWz+SAwjTDCCdNHs1Kxi23897JNl7FLKzf84plGR4yvQyYQFKUXQzh57vdOEIMDf6jfCoOYyPTQZzApiVs7/Ugnoc/QSsevnXIxU+lRj4ngTRS8lFj8Xmm0KS38RTLAp3vrq0VjPi0Vc6j63zv8P/XVZQYiVmWPY1/uewpDItQeoWwz9f5yoMoCwEAI3CS1M96uGO/+ZGixRGSoa8eHK/ZKmGKjf8ufb6bytBpQpSD6jbqFcil3C459xu7Yt1aa0wS/v+j7eM6K6rbtWkj9ceEQlZ9Xd5vLMl++gLNWLzNrZahY1vNUvR/FG2WMnHoSkZvoExzX6y7cGnL19A+g408uROUDeIo4TmY3xjd0X9TlbOGooxZFWWpoJpXIEIG4fi+28E0+wat6X/+HJLwSFbQ+2pTGC/M1ZxY9+Xv3sKpwB7rW+naOv+qimzzdb1uWvzVu5T+kH4XtDCJF1XMTOVkwKQcLr4QzqdluyLdnvF6uG4wn+tPv4YLIYkn4ENAxi/wMq7bg31aPVWSfWeu5r6t3uqbvq9JkUYEb2ZMsNNtLPG09lKbWyW1zp4BGKcoJrkiLB/X9YKwuRI6AD/mHCySGD/fz+xpl7Tcxoe0hLpll+S0hdnlNwkZg3haGxWeX8WVJ9DGzTRjQExhnFILfni2W1QPpq2XBhPXjUT203nUlyktFu5n0YJCupIQAUJgTJUB3XSdWtHWvAzKeAPxHemDtsAS9O1Mwf8wvqKrJqOJeqtK4KSuSRxmDrYlPP03n30cqy/EJuWM1bHBj3l8TwYMyI21FMxSf1BVPuzeTp5pDeQaGrIvYsLmVvtjvbNVp2/h7LfQPwBzOKBA/o7RyZAN9Is5/Va6B7oa7bXPtd6GAWQ5L0iE7TzfulR0b+iy0jCGktx7A3RRLNzHoeU3/hFLHISG9Yo2br+PplU/IotVX/ZZfuve9Ob8aqLIISKfoePON4XvX4SRpz8ccolVZ8XFj2e0OOb0lMAq3hjh7JTXvyWNqDBeOAXzq1/2YDoOX2R44nt5OFOdNgB6JZ2wWUxgtVdrDonLX9F0bXbXBzGQovH8T4z2ODA11sENphyE6YHjWMwRBfk/R6L6/gmi/viclD3rxNthTBPGUNkVekNX8Q+0LWyi2uC8Pisq4UwV8119GoBac+8T6TTO+/9H2bAoIqmD+NlX6oVwvSy+5qPJq7YfL4ZaKb2Exi/KWN9s0zbSd9UnYItIrBeX0MS3ffvyhw10f7E3EaZFxpy3RxiyWDoGwnYZafxpMuM+BfwH0d0IOTT301Tr2EQ60MV/XVbsLDaqdgeVMu8+0q6fC80oaAJF1SDUn1aQuemenskU7OsXLX2xyw+ShlM/FpwjncbiPMlJJplhMlgY+HWM2U8Pj+MCYZDR4xz5MfT72uY9lhz9OS3fqTL75bwxAJOF+StaFj+CZ2bW0YrKZECjn2RpE8FV9uhKUJzzXCEAtFyovv63MPo+I/KdJhtwy/p1znX0ekCw+5ODC5oAKB1wqlwAR1eufFHXAVyJdyKTmdlzQ4ZXncG+qAPBJPCTc2DvpFlROfJ79gDZdswP7qAKXpSdurpdbM6HaQaw8WEQuK9S58pmScfyHqEjMkJRMREpaS0hWUajHDAsCZPZfSPAIFg59aUege0YET/1ldtmmfWZbTn0va283s6lZ8zWDDyFy3z3CwwQ09usr+fqAhKHQRsSZTC5bsFGdWN5LzKT9JGG5UG90IkviBHIfhvxOoENoBfrO6yLoaAOyfKRP87vNM01wMlLSwF5XCg9Y1D1FvPEvFrmiICS1y3wZRna4Ed9NN0C3TsOAh4wxQ3RsXdykNG3PmhD0l08C1UNixUMTfyubBShUx/zHYtihjbjgm3mjSWC4vyteWd3rn0bUUIgqi7AYqWWDdTnvJVMLOO2QHWBI/5d2AjgfnaDlt0JVGTp+ejp7XY72Cs/bbWtcJfksX3FHb/qVoHpoepz6WCFGyAsXrsjn7yyrlr/Lono76m2D4bqK2rmxhUB51ZzO4PyE3M+D1MSwGWpZWS2mvnGpgKje/xYNLRwrR6poO2ApMfo40Gc2UkQlmtxPuaEdrTnq4KEGh7Q6Ka9tZAXoqtig3drgsUIq2dFTFueJ9wou+VzKrs90ogFxXfYpLtLELWRmRtlP6a2cX7RYu6ySTk/mhmDJlwjp0PaM6q25SRnAAEGJHKUM/T2I/6XRxHxRuejmKOTguXWDsa1/S9vo2qarYzY/UO1niyJyC1I7NrcPypBJ1aOQfI1ZungvD/tTkQ5JJFmiFufcWwtVGV78r33rEJtYN9Xnf97JelRpN0zqySYAUKD5qV3Az2/03iNo7Cw4fEdMQAwvIFYrVWIMM3pAy0dSByCtYR/4da6oy46Q7CXznSgeV9T7bDmei3YANj86MyX7swD+koGkFzsy+wglMB3T2Zoh0GUMoTiIFgLHV2puOzXWpS5CtQor5TTLcyjEA0Is1dTT9UoSNwBmy8xQBJLIMrhA0qHrVhVFChu3A15FynRhKs2NNZI7pI0SaZhKnhe7TpwXEP8jees3i3+dHZXgSmXgSs7NkO9sBeaO0KUExKvjfKLBtihCcFx/AVjdh3aMgJ0lDxJvi/cjBx9W2yQ+Gyh27qYG8FV/+Mr9f2nZTakjZmmDiX0n3uPt/GBXvvi5anbrXn+d5ak9MBLBV9oiG5loD90QHcYg8XrxMVkJc7wRuZEwjplVQQJ024QFA0A80qA3A8hcoBPM9dA4WqkwjhXsxRpis21jaZuszGXV5jEqKxXPqn/Kvc6sknV9+lEpb4b3f98j7Hxr6NZiYYPr/gfczfUcg5BfpTJgyvObj1k+x5l6BtvpfTGnGXQOfvFyn0KsjZIMN+aJvmVVJbyRQQ4c8kkN2MmQHCNk/ayX2N8HngPBgHVe2C1FPZi+tDLGcaguwEPo/OKj77FwWyt2vGBSEVBztMlSEAwL2gkmj2mV+LtAchNtdewyVo4Z7OjITguNf5efcZ34B8jTQ1mZX4buLkc1ZAvGeWREHj55w+6fFh9R8nonWe3i0eIopjmRndlmcqd3BWNGRdcLad02orOXM2eXMy0C3rg28IYKBmLbGIXGFm/d14GBwcmVMRtPk7UqR9oTRn4mMLEm2jOoWuEBy4YHq66ZHk0/UkwI2d4DcguJmyxN1G80tytppQF7VI5jQPEEam2arq7iQ+grHBYHc+0pbCcow/AKc1S88FJRmIoosojD0kiK3Y9LTrTJf8BsJTwZdr4YquGgfV8DIdR5XjcPl3uPGvgtzKKu3cCJD1AW/KJuNEhue8kfBF6I7cHAL8nODWC00G7nZn3Q1G0PTLGYHkZPdjumGjC9TxEASgk2VToBhMalsy2fVbW8XBcxVn6cQybm5+Ng/ocQ/kE8rbIxwfaRUvRQtLCO8cbp/AU1yEVoCjBXcUnxWB/9/9UETopcP/XAIbD9yG9UPJHwXgmTCMgJr5A0EwaClkYTK2S+OZ2RrJyWsyeyeFSPmmVcxAkzs4hJlqyRB7cj24owwsE4E6jX2qx7EiQI1srPHoqfNagp8bKzZwEaD2tca8LAsuGvjgQ4Li/PXaI258eNxUSfrnuCUdlkGCg+zT52ZQsvFYbVqLvTT+0jBpslFGU2KNKd/z9QXu40gRIprFMN1zFn1r0IJd5sPFLLoN65lr+JR5ShfRxJEinCwNQrEGaWXlBNcylRXji7AU2415aMUwYog4QL6cnc/HaAqtl/YrY77ydPKCgqEsVL6gjSz3SZswnW+whFehP8IXMzYJJmDbDqEW0YQ2AjczOndqoacW/VGtLq8+1woGwJuCwbZ4jbOWt/mC3ntiCBwsNlDwQA9x0pvc0D9KtmvM/Kj7JoU5VKO/gAwm3KRwfXyRTyFdpc4uO833+Eo6AxdfzeSK+cNGCEoaBPPKRpnu/q4IvmoOSMlYl3uHS4NZA2EBMmvR4k2FhWYkObT+92EZQ/JKInD3D5qgCgh67JYM4NzkYdnhvJkCmz/GGOHZjwPymSVF33CWSdpq0jYZqePy1khzL8kn8Av6Dk0baZbWqSYx253yXJL9v+Xpzr08BaCuj/U4Sp3tyAqinW1b3ZHPLKIUitw8/dfiO9ZtZYBbdIY67ig7ukSpzakt3YBm7ruWwN4+tEMNPM0YMdoOMJe1smQUG7NoUQ7zGbv4HFj22ognxRJDs234AdQUjg2tIMcr/Htzjsx0WbbClmM5GrLtLx+u0ZtI14eeqWrrk2B3ywSp4ZMW3yNE1KDLR9fEAel9xZBOz4a60SZcJUNK5eE+3/vD9KC5dFvjYXVMrfWwt6ivqxHZfX/mV3f2ohIb2oHnCUieXTaZXAFilZlqWCIFCD9KWXohuoZTM3pnmkVk3ac8Mj5j29tuCWH1IuRAMrvpOgoJQ8DlqpI/zptR1hK2x+NWv+e1+JCnkU4N3vK+oyeUXQ+fRPwB373Uw4dDvyn/69bKzZW1xtIApsnA/NtiTItpK6dgoxWFKEHhi/Oi3IxVbbn05B1UQY+zbqRHDbeYR2S0TCQeyQ17WQpm82ctHGkRs0SgJxkVaiihB4lgsNm6tBNgulaHOst2y/Cz2mQUQtwHEbtJjGCWZ+Ny9LXvxI3GmxWEV4cBEyJAUf/81wA+z+6I6IR9CpAlf4qv0PMRVCkseASlLuhk+RsxlPxyxGmhuurFiOIN14Ho3bErLUomklty0Ya9WnUDFu2I3yTn95wY5tzIYx8OaYDtQtY6dxMXdVHFDTU+c42aOFhn9XxDHYSoDDEVTDY+UGA76PMhNBcwKEqdIqxfTat0eZAO9fw7VbM5P7ON4xc5Ipm+pxKoRK+7dwLrfjY7tzVAqrla/6aMVnkdMd1nxhauNdAU/PXQpRC9BuiARsO0TxlYdUGVWqhPlgJ7xT+G6/sgElWQ7d8A1xlfDM/ZFJ0LErepW9SR/NdIkDVY7pegry5x0orlBm3nSUQzbu/GuisZkzp3nIaPxdKJRsP86Cuwueu1exRsuGiye5FQu7zQIUH+pZil6v464skZBJfgh0pSIF98Wggtcgj/IFbFNu4Lu8d7HNttwtWSymok+1AlRTDyxcC8YmE0fgwwZHTBybLIRrOzxCB0GZFDOLO1RWsAjmNFmovixlAqqzToCgHylr/aen4Ff+OYRV4n4d+NS7BbzlEww4BlXLDDTp93EjVgZhS4UhhNtnIz9AsE0T5xK/nPyN3IQLaxfD52hqDEv63uRLKN+0S2IYcrzENCTG4ajF4exYR+Uo+oLXA+jr1EbQCqP622fbpWRQqBQSzv9KVZuFu0q25xOfZ6Wp9qVSIKwyaZjIFgRgGI4dzy7SgopzSc7Jy/wE/zPTly7Xg5XJ2zUA0uedAHN18zWVgohlsr8Lf6cRLxv1nfbEju7gYmbBJWiHWjzTwag0PrJP7seJBaKojT6zLy9kYUPn/4SrsTXELdTkWru5vvlnriqbhPykL8mMXJY/1nwR+ybZXXnCYDJCKmYlQYOfiRqZ7O4Oo51WvMaXyusukrmj5lF3r2Pla//11h+NjllDEQq+qVpeLmNGPJGiUOMDy1d2xmOubNEkj+Hw76RrTMkujS1rkN21RlYdyoKKMH5PaIVRB3axzzXeX526ET2cG02Yq5nu1wMkjjZc+PB/isbvq0MAexo4ndsSA0HoISX1CmAgMl3n610YL17Vg3pdlMwd2c09hYvZ3zSE/dHetPewiB/lt6ZoObqTVdUPHVKd/m+oupx8TONrzt9LbZZZM6Q5Hcl/4qSHq7FkeowDv82CDWV5HtUCkpygYOsXTsKkq8agUMt28QOzNvn00dPs8e+dH9NMCjokEBcL3XSks+pAtBjoA50iN/oBlwtJh+M5YlD0J5tAZrq/uRgAX6ff/0g3i/D9XbRapPGyVA3/Wtz+EhGf2Sp79z3ml6uA/JTiL+ihR6Q2R83Br14XBYXJkYQ0cxA5joxjNaemHG/wT/xmX3RVX1buM8CmdhQmTlUjofDfmqrgy83xXQyJuBZkR4qSjnt0dJYwoIvoHrbPiWASCDpqq2j5eUhi2NRjFcjJqQ0WrsWeilF8tr8GMsRTYcYU8rUhTJ1TuGfYX7nLGenh+yA03VS0rGH5rhKM2v2ZcO6kJKs2ZMqzySS9L9RZfRSXJN6cuDdnazhetOd8ADZTHeupkQVBE8TcQ6DGuchlpXaAQ/cm3Su1zLGOoFmhNPNtKCfM4yD5whK/J6uW3ZUFgWgt/cW3o9Pm+hRhv1PAducukim7aIgTyLUqYJvbMvOY/ht7tN2xOT3ksZ4/T158N0ljqilW9EJM2FcDqOYp78lGv7CGZJBJUjqBmOusc/YuRtyvlQT69R0mvi2IFRLICp1iRtATZ0a1Af9/H/vSWTyjAIM6l8Tc0DsAQgmaewXNFvOQL84QA9KOvbcMOIZ1omZ7aWKOQq+pbJca1GCG8ACTLNsDtvFv/7B1+ok0NlW+ZkC+p1BVE8G550h1HhfHGyzfuR/pnPAPSj0p3f2SJT2tSC1RMscjz+GRErB05SoUBXtpGtj74GlTzOInMa4hiAAKat3fqokQvwoemhPlisa2XMdBQtDq8w3qZhFWubmvqFhk0U1h+PYG/6llQZcN0hLtmAEwhpl8CC9M0UEo1Y2ttMdhQaJ/T5VZsnUqTB4hLbI9PmCEMYDWrfc0dgC1Q3qg13+a7mYFvxB+V7996iuiTxg85acvqq6dFQ2JuGEy5KVDqojJaY0RaHW8GXZby3GKVWWAqI61aAnTvEUmV997ACMe9Cyr8k5Eql3VNFaD3lL4jcIYTsB+jAxQMtWm97Oo9UxNHZzn140tNn4PBECaNbX9xS0kz+ZHT1whkiwTQztQIJ3u2JYj93hLdN7DKOPZkcuRBQsKPLLx5+oul0h5Er3WLQnOQ3WeuNBxP24ORe+8B02PS0qhWEWrSuk09nmxf3q/EvWz2DJ12zdhVhZI8ZIzbWOyAQLN1qfyBQDiy6Fk3zrIz29Tm0rq/Iyv8l+q5Q3HdyMvWsiUd8V/o7hHKz2ISEtS71xMUfTPW0SuUZt7QNwgsinxx9+Rf9OXPOsLVjtomQeapAe+UKzh5GGDSgie29LJzGnlTzE62CuNJANE182aaqRBJ8ZAyq6idNPRcL6WRIipnhHXIzolT6hX8Bpg/XWsIrWDHsYsGIoo2a/UDIMfnX0rOFqEyaQ+84eKPdb9uxanfegazkv4w3ELVifGgr0SZU1Vdm7krGcGFWyk5aeFDjvzxvM6cGnHxlAHV29jbj7C87qxqj4onnlouMtjHABwTVJYA8sNLVLSUaErOXa0PRkWCvj58ynT8E1r4vlu0kRnc099ZwQ6s8LigDzuXs/6CosBrHRp3pbR0msNrlaspEIZyz1YCRnmBMIplFB6vukYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":648,"cache_read_input_tokens":53565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":648},"output_tokens":11,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7CcTcFfFeRRnGeGDCa","type":"assistant","uuid":"bf2cf882-e766-43ba-82ab-fdccb4b635c9","timestamp":"2026-02-20T09:46:52.365Z"}
{"parentUuid":"bf2cf882-e766-43ba-82ab-fdccb4b635c9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01JA7Pf9Jqk6rtcUyYByVtDR","type":"message","role":"assistant","content":[{"type":"text","text":"로그로 정확한 원인이 보입니다. 분석 결과:\n\n**원인 흐름:**\n\n```\n[housekeeping] refresh_and_emit_status_counts done in 7915ms   ← SELECT COUNT(*) on 1.1M rows\n                                                                  + set_meta write\n[watcher] apply_path_changes: upsert=13 delete=4               ← 쓰기 시도\n[watcher] ERROR: database is locked                            ← 3초 대기 후 실패\n...\n[housekeeping] all done in 13943ms                             ← purge_ignored_entries가 ~6초 소요\n[watcher] apply_path_changes done: elapsed=2139ms              ← 3번째는 2139ms 기다린 뒤 성공\n```\n\n**실제 범인: `purge_ignored_entries`**\n\n- housekeeping phase 1 (`refresh_and_emit_status_counts`) 끝나고 phase 2인 `purge_ignored_entries`가 실행\n- `DELETE FROM entries WHERE path LIKE ...` — 1.1M rows에 FTS5 trigger가 붙어 있어서 행당 FTS5 업데이트 발생 → **~6초 동안 write lock 점유**\n- watcher의 `busy_timeout = 3000ms`이지만 DELETE가 6초 걸리므로 → `database is locked`\n- 3번째 시도는 lock이 풀릴 때까지 2139ms 기다린 뒤 성공\n\n**수정 방향 두 가지:**\n1. `purge_ignored_entries`를 batched DELETE로 나눠서 중간에 lock 해제\n2. watcher의 `db_connection` `busy_timeout`을 10~15초로 늘리기 (임시방편)\n\n어떤 방향으로 수정할까요?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":648,"cache_read_input_tokens":53565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":648},"output_tokens":11,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7CcTcFfFeRRnGeGDCa","type":"assistant","uuid":"d935e18e-04fe-42eb-b1ae-385aa10e7a03","timestamp":"2026-02-20T09:47:00.118Z"}
{"parentUuid":"d935e18e-04fe-42eb-b1ae-385aa10e7a03","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"c7d8185f-80c6-4641-9f28-43cad6718869","toolUseID":"c7d8185f-80c6-4641-9f28-43cad6718869","timestamp":"2026-02-20T09:47:00.159Z","uuid":"02f33865-71cc-441b-a53e-ae4cac604a10"}
{"parentUuid":"02f33865-71cc-441b-a53e-ae4cac604a10","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":792}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-20T09:47:00.952Z","uuid":"ce1d6ea0-8e91-4898-bfb6-05bac70c2b4c","toolUseID":"c7d8185f-80c6-4641-9f28-43cad6718869"}
{"parentUuid":"ce1d6ea0-8e91-4898-bfb6-05bac70c2b4c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"turn_duration","durationMs":67489,"timestamp":"2026-02-20T09:47:00.954Z","uuid":"c4a3d82e-fe62-41ec-bc9b-7b2ab88f28ef","isMeta":false}
{"type":"file-history-snapshot","messageId":"35ad442a-a70a-42c0-8827-d1440344bc3a","snapshot":{"messageId":"35ad442a-a70a-42c0-8827-d1440344bc3a","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-20T09:45:53.463Z"}},"timestamp":"2026-02-20T09:48:27.778Z"},"isSnapshotUpdate":false}
{"parentUuid":"c4a3d82e-fe62-41ec-bc9b-7b2ab88f28ef","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":"db가 busy한거니까 pending 해두고 consume하면 되지 않을까?"},"uuid":"35ad442a-a70a-42c0-8827-d1440344bc3a","timestamp":"2026-02-20T09:48:26.457Z","permissionMode":"bypassPermissions"}
{"parentUuid":"35ad442a-a70a-42c0-8827-d1440344bc3a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Meh9uaTQs4bwRyGnbS8ao7","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user suggests that instead of failing immediately when the DB is locked, we should queue (pending) the watcher changes and consume them later when the DB becomes available. This is a good approach - instead of increasing timeout or batching deletes, we hold onto the pending paths and retry them.\n\nThe watcher already has a `pending_paths: HashSet<PathBuf>` that accumulates paths. The issue is that when `process_watcher_paths` fails (drains `pending` and fails), those paths are lost.\n\nLooking at the current code:\n```rust\nfn process_watcher_paths(..., pending: &mut HashSet<PathBuf>, ...) {\n\n\n```\n\nThe problem is that we drain the pending set into a batch before attempting the DB operation, so if that operation fails, we've already lost those paths and can't retry them.\n\nThe solution is to restore the paths back into `pending` when the operation fails, letting the existing debounce and periodic tick mechanisms handle the retry naturally without needing explicit backoff logic. , looking at the loop:\n```rust\nErr(RecvTimeoutError::Timeout) => {}\n```\nOn timeout, it checks `deadline` and `pending_status_emit`. If there's no deadline set (no pending paths) and no new FSEvents come in, we might not retry for a while.\n\nThe approach:\n1. On failure in `process_watcher_paths`, put the paths back into `pending`\n2. Set a `retry_deadline` so we retry after a short delay (e.g., 1-2 seconds)\n\nActually the simplest thing: don't drain `pending` before the DB call - check if it can succeed first. Or: on error, put paths back into `pending` and set `deadline` to `Instant::now() + some_duration`.\n\nFor the function signature, the cleanest solution is to have it return an `Option<Instant>` for when a retry deadline should be set, or modify the signature to accept a mutable reference to `deadline`. Since `deadline` lives in the outer loop, returning the new deadline value is probably cleaner than passing it through. On error, I'd re-insert the batch back into `pending` and signal that a retry deadline should be established. be 2-5 seconds. For error handling, I should avoid setting an Error state for transient failures like database locks—just log and retry silently instead. Only set Error state for persistent, non-recoverable errors. Let me check how many places call `process_watcher_paths` to understand the scope of this change.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":29,"cache_read_input_tokens":56963,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":29},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7Ndqyyiovyk28GRP18","type":"assistant","uuid":"f1d9537a-f41b-4a6d-af7c-d1a89369eb6d","timestamp":"2026-02-20T09:48:54.814Z"}
{"parentUuid":"f1d9537a-f41b-4a6d-af7c-d1a89369eb6d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Meh9uaTQs4bwRyGnbS8ao7","type":"message","role":"assistant","content":[{"type":"text","text":"좋은 접근입니다. 현재 문제는 `process_watcher_paths`가 `pending.drain()`으로 경로를 꺼낸 뒤 DB 실패 시 그 경로들을 버리는 것입니다. 실패 시 `pending`에 돌려놓고 retry deadline을 설정하면 자연스럽게 재시도됩니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":29,"cache_read_input_tokens":56963,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":29},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7Ndqyyiovyk28GRP18","type":"assistant","uuid":"edcb71a2-4301-4b53-9d5c-d51aecdbeeb4","timestamp":"2026-02-20T09:48:55.582Z"}
{"parentUuid":"edcb71a2-4301-4b53-9d5c-d51aecdbeeb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Meh9uaTQs4bwRyGnbS8ao7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DreBBRVs3GPuds6Yvp4fbW","name":"Grep","input":{"pattern":"process_watcher_paths","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":2},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":29,"cache_read_input_tokens":56963,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":29},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7Ndqyyiovyk28GRP18","type":"assistant","uuid":"3e966280-d214-4cc7-90f8-fb9ac8eca445","timestamp":"2026-02-20T09:48:56.888Z"}
{"parentUuid":"3e966280-d214-4cc7-90f8-fb9ac8eca445","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01DreBBRVs3GPuds6Yvp4fbW","toolUseID":"toolu_01DreBBRVs3GPuds6Yvp4fbW","timestamp":"2026-02-20T09:48:57.727Z","uuid":"e35ad4a1-8568-4a5f-b853-7843f4e1d81f"}
{"parentUuid":"3e966280-d214-4cc7-90f8-fb9ac8eca445","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DreBBRVs3GPuds6Yvp4fbW","type":"tool_result","content":"2454-\n2455-#[cfg(target_os = \"macos\")]\n2456:fn process_watcher_paths(\n2457-    app: &AppHandle,\n2458-    state: &AppState,\n--\n2488-        Err(err) => {\n2489-            eprintln!(\n2490:                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n2491-                err,\n2492-                batch.len(),\n--\n2644-                        state.indexing_active.load(AtomicOrdering::Acquire)\n2645-                    );\n2646:                    process_watcher_paths(\n2647-                        &app,\n2648-                        &state,\n--\n2671-            if let Some(due) = deadline {\n2672-                if Instant::now() >= due {\n2673:                    process_watcher_paths(\n2674-                        &app,\n2675-                        &state,"}]},"uuid":"03acefb8-c192-4b09-b85a-28089d95115a","timestamp":"2026-02-20T09:48:57.725Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"2454-\n2455-#[cfg(target_os = \"macos\")]\n2456:fn process_watcher_paths(\n2457-    app: &AppHandle,\n2458-    state: &AppState,\n--\n2488-        Err(err) => {\n2489-            eprintln!(\n2490:                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n2491-                err,\n2492-                batch.len(),\n--\n2644-                        state.indexing_active.load(AtomicOrdering::Acquire)\n2645-                    );\n2646:                    process_watcher_paths(\n2647-                        &app,\n2648-                        &state,\n--\n2671-            if let Some(due) = deadline {\n2672-                if Instant::now() >= due {\n2673:                    process_watcher_paths(\n2674-                        &app,\n2675-                        &state,","numLines":23},"sourceToolAssistantUUID":"3e966280-d214-4cc7-90f8-fb9ac8eca445"}
{"parentUuid":"03acefb8-c192-4b09-b85a-28089d95115a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01VJB6nX8JPR6tr2LkUVoBnB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Moh5BGgnipU9wHe4f3C5SK","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2454,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1771,"cache_read_input_tokens":56992,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1771},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7Qqp7bg7KrcHgNxXuw","type":"assistant","uuid":"51617a61-9901-4f92-b8bd-ac49be8883a1","timestamp":"2026-02-20T09:49:00.208Z"}
{"parentUuid":"51617a61-9901-4f92-b8bd-ac49be8883a1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Moh5BGgnipU9wHe4f3C5SK","toolUseID":"toolu_01Moh5BGgnipU9wHe4f3C5SK","timestamp":"2026-02-20T09:49:00.247Z","uuid":"e999b634-5703-47ee-80ca-7e930f0a6182"}
{"parentUuid":"51617a61-9901-4f92-b8bd-ac49be8883a1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Moh5BGgnipU9wHe4f3C5SK","type":"tool_result","content":"  2454→\n  2455→#[cfg(target_os = \"macos\")]\n  2456→fn process_watcher_paths(\n  2457→    app: &AppHandle,\n  2458→    state: &AppState,\n  2459→    pending: &mut HashSet<PathBuf>,\n  2460→    last_status_emit: &mut Instant,\n  2461→    pending_status_emit: &mut bool,\n  2462→) {\n  2463→    if pending.is_empty() {\n  2464→        return;\n  2465→    }\n  2466→\n  2467→    if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2468→        return;\n  2469→    }\n  2470→\n  2471→    let mut batch: Vec<PathBuf> = pending.drain().collect();\n  2472→    batch.sort();\n  2473→\n  2474→    match apply_path_changes(state, &batch) {\n  2475→        Ok(changed) => {\n  2476→            if changed > 0 {\n  2477→                invalidate_search_caches(state);\n  2478→                touch_status_updated(state);\n  2479→                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2480→                    let _ = refresh_and_emit_status_counts(app, state);\n  2481→                    *last_status_emit = Instant::now();\n  2482→                    *pending_status_emit = false;\n  2483→                } else {\n  2484→                    *pending_status_emit = true;\n  2485→                }\n  2486→            }\n  2487→        }\n  2488→        Err(err) => {\n  2489→            eprintln!(\n  2490→                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n  2491→                err,\n  2492→                batch.len(),\n  2493→                state.indexing_active.load(AtomicOrdering::Acquire)\n  2494→            );\n  2495→            if batch.len() <= 20 {\n  2496→                for p in &batch {\n  2497→                    eprintln!(\"[watcher]   path: {}\", p.display());\n  2498→                }\n  2499→            } else {\n  2500→                for p in batch.iter().take(5) {\n  2501→                    eprintln!(\"[watcher]   path: {}\", p.display());\n  2502→                }\n  2503→                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n  2504→            }\n  2505→            if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2506→                return;\n  2507→            }\n  2508→            let mut status = state.status.lock();\n  2509→            if !matches!(status.state, IndexState::Indexing) {\n  2510→                status.state = IndexState::Error;\n  2511→            }\n  2512→            status.message = Some(format!(\"Watcher update failed: {err}\"));\n  2513→            drop(status);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"644d8fd4-e0d3-4d6d-9790-f245f169e0d8","timestamp":"2026-02-20T09:49:00.245Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);","numLines":60,"startLine":2454,"totalLines":5177}},"sourceToolAssistantUUID":"51617a61-9901-4f92-b8bd-ac49be8883a1"}
{"parentUuid":"644d8fd4-e0d3-4d6d-9790-f245f169e0d8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_012rbRBYk5JX6eYAT5fpYebH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CV4xnmjDqoJVtSizpZyWy2","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2514,"limit":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1029,"cache_read_input_tokens":58763,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1029},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7R2czgW5ctMsFd9X1H","type":"assistant","uuid":"5bc76dc1-33c8-4f1a-ad9b-ba8f2b448175","timestamp":"2026-02-20T09:49:02.652Z"}
{"parentUuid":"5bc76dc1-33c8-4f1a-ad9b-ba8f2b448175","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01CV4xnmjDqoJVtSizpZyWy2","toolUseID":"toolu_01CV4xnmjDqoJVtSizpZyWy2","timestamp":"2026-02-20T09:49:02.696Z","uuid":"69fae81f-a6a0-4d52-abf6-97bd5dde4b7f"}
{"parentUuid":"5bc76dc1-33c8-4f1a-ad9b-ba8f2b448175","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CV4xnmjDqoJVtSizpZyWy2","type":"tool_result","content":"  2514→            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n  2515→        }\n  2516→    }\n  2517→}\n  2518→\n  2519→#[cfg(target_os = \"macos\")]\n  2520→const EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n  2521→\n  2522→#[cfg(target_os = \"macos\")]\n  2523→fn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d20ac036-a5f3-4e3f-b602-a4d039b4b0fe","timestamp":"2026-02-20T09:49:02.687Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {","numLines":10,"startLine":2514,"totalLines":5177}},"sourceToolAssistantUUID":"5bc76dc1-33c8-4f1a-ad9b-ba8f2b448175"}
{"parentUuid":"d20ac036-a5f3-4e3f-b602-a4d039b4b0fe","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Jr8TYqF65bw8WiLWAELNB9","type":"message","role":"assistant","content":[{"type":"text","text":"이제 호출부도 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":354,"cache_read_input_tokens":59792,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":354},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7RD7H8fr7nFq87WfCX","type":"assistant","uuid":"725088a5-ca4d-45dd-beee-7fdc48338a23","timestamp":"2026-02-20T09:49:04.967Z"}
{"parentUuid":"725088a5-ca4d-45dd-beee-7fdc48338a23","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Jr8TYqF65bw8WiLWAELNB9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Wh6cY6b7fJ7g48RLmSUTLN","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2635,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":354,"cache_read_input_tokens":59792,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":354},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7RD7H8fr7nFq87WfCX","type":"assistant","uuid":"72251888-71ff-43ee-9c18-9dde1481e9b1","timestamp":"2026-02-20T09:49:05.586Z"}
{"parentUuid":"72251888-71ff-43ee-9c18-9dde1481e9b1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Wh6cY6b7fJ7g48RLmSUTLN","toolUseID":"toolu_01Wh6cY6b7fJ7g48RLmSUTLN","timestamp":"2026-02-20T09:49:05.595Z","uuid":"786b288e-1ee5-4fb5-b251-0a1132419bab"}
{"parentUuid":"72251888-71ff-43ee-9c18-9dde1481e9b1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Wh6cY6b7fJ7g48RLmSUTLN","type":"tool_result","content":"  2635→                                }\n  2636→                            }\n  2637→                        }\n  2638→                    }\n  2639→                }\n  2640→                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n  2641→                    eprintln!(\n  2642→                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n  2643→                        pending_paths.len(),\n  2644→                        state.indexing_active.load(AtomicOrdering::Acquire)\n  2645→                    );\n  2646→                    process_watcher_paths(\n  2647→                        &app,\n  2648→                        &state,\n  2649→                        &mut pending_paths,\n  2650→                        &mut last_status_emit,\n  2651→                        &mut pending_status_emit,\n  2652→                    );\n  2653→                    deadline = None;\n  2654→                    if replay_phase {\n  2655→                        replay_phase = false;\n  2656→                        if !full_scan_triggered {\n  2657→                            perf_log(format!(\n  2658→                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n  2659→                                must_scan_count\n  2660→                            ));\n  2661→                            let _ = refresh_and_emit_status_counts(&app, &state);\n  2662→                            last_status_emit = Instant::now();\n  2663→                            pending_status_emit = false;\n  2664→                        }\n  2665→                    }\n  2666→                }\n  2667→                Err(RecvTimeoutError::Timeout) => {}\n  2668→                Err(RecvTimeoutError::Disconnected) => break,\n  2669→            }\n  2670→\n  2671→            if let Some(due) = deadline {\n  2672→                if Instant::now() >= due {\n  2673→                    process_watcher_paths(\n  2674→                        &app,\n  2675→                        &state,\n  2676→                        &mut pending_paths,\n  2677→                        &mut last_status_emit,\n  2678→                        &mut pending_status_emit,\n  2679→                    );\n  2680→                    deadline = None;\n  2681→                }\n  2682→            }\n  2683→\n  2684→            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2685→                let _ = refresh_and_emit_status_counts(&app, &state);\n  2686→                last_status_emit = Instant::now();\n  2687→                pending_status_emit = false;\n  2688→            }\n  2689→\n  2690→            // Periodic event_id flush\n  2691→            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n  2692→                let eid = watcher.last_event_id();\n  2693→                let _ = persist_event_id(&state.db_path, eid);\n  2694→                last_flush = Instant::now();\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"fe94e3bc-789a-466d-86c2-5e6fc7008526","timestamp":"2026-02-20T09:49:05.594Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();","numLines":60,"startLine":2635,"totalLines":5177}},"sourceToolAssistantUUID":"72251888-71ff-43ee-9c18-9dde1481e9b1"}
{"parentUuid":"fe94e3bc-789a-466d-86c2-5e6fc7008526","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_018fZhRtA9R5PMppcs3rb6eu","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a clear picture. Here's my plan:\n\n1. Change `process_watcher_paths` to take `deadline: &mut Option<Instant>` as a parameter\n2. On DB failure: \n   - Check if the error is a \"database is locked\"/\"busy\" type error\n   - If yes: restore paths back to `pending`, set `deadline = Some(Instant::now() + RETRY_DELAY)`, log a warning (not an error)\n   - If no: original error behavior\n3. Remove the path logging since it's only needed for tracking which we've now done\n\nActually, let me think about this more carefully. \n\nThe `RETRY_DELAY` needs to account for how long `purge_ignored_entries` takes—around 6 seconds—so I should set it to something like 3-5 seconds to give that operation breathing room. But if I retry after 3 seconds and it's still running, we'll just fail again. I could use exponential backoff, but since we're putting paths back into `pending` and letting the deadline control when we retry, a fixed 3-second delay should work fine.\n\nFor error handling, I should only retry on SQLite \"database is locked\" errors rather than all database errors, since permanent failures like disk full shouldn't keep retrying indefinitely. I need to check if the error message contains \"locked\" or \"busy\" to distinguish these cases.\n\nMy approach: add a constant for the 3-second retry delay, modify the function signature to accept a mutable deadline parameter, and when `apply_path_changes` fails with a lock error, restore the batch to pending and set a new deadline instead of immediately failing. For other errors, I'll keep the original error behavior. Then I need to update all three call sites to pass the deadline reference.\n\nNow I'm thinking through how to handle the `HistoryDone` case...\n\nthe issue is that resetting `deadline = None` after calling `process_watcher_paths` would wipe out any retry deadline the function just set. The cleanest solution is to let the function itself manage the deadline—it resets to `None` on success and sets it to the retry delay on lock errors, so I shouldn't reset it afterward. I could pass `deadline` as a mutable reference to the function and let it manage the state directly—on success it clears the deadline, and on retriable failure it sets a retry delay. Then in the `HistoryDone` handler, I'd remove the explicit `deadline = None` line since the function already handles it, or only clear it if there are no pending paths left. the function, I need to handle the `HistoryDone` case carefully—when replay finishes, I should clear the deadline since we're done with that phase, but I also need to make sure the function itself manages deadline updates for retriable errors. Let me trace through the logic: if `process_watcher_paths` sets a retry deadline on failure, then the callers shouldn't override it with `deadline = None` afterward. I'll remove those explicit resets and let the function control the deadline state entirely.\n\nI should also define a retry delay constant and check for database lock errors by converting the error string to lowercase before matching against \"locked\" or \"busy\".","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1044,"cache_read_input_tokens":60146,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1044},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7RRZszB7CN1CUksrV7","type":"assistant","uuid":"04681a28-597f-4c2d-bba8-eda795a11f77","timestamp":"2026-02-20T09:49:41.480Z"}
{"parentUuid":"04681a28-597f-4c2d-bba8-eda795a11f77","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_018fZhRtA9R5PMppcs3rb6eu","type":"message","role":"assistant","content":[{"type":"text","text":"변경 범위가 명확합니다. `process_watcher_paths`에 `deadline: &mut Option<Instant>`를 추가하고, DB busy 실패 시 경로를 `pending`에 복원 + retry deadline 설정, 성공 시 deadline 클리어로 처리합니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1044,"cache_read_input_tokens":60146,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1044},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7RRZszB7CN1CUksrV7","type":"assistant","uuid":"1d12673e-e83e-4a23-878f-84488749a516","timestamp":"2026-02-20T09:49:42.647Z"}
{"parentUuid":"1d12673e-e83e-4a23-878f-84488749a516","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_018fZhRtA9R5PMppcs3rb6eu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Q374KzTWKoPjdFCjC9spWu","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}","new_string":"#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1044,"cache_read_input_tokens":60146,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1044},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7RRZszB7CN1CUksrV7","type":"assistant","uuid":"8fb638ea-7e25-4912-ba6d-e645640cd58d","timestamp":"2026-02-20T09:49:55.039Z"}
{"parentUuid":"8fb638ea-7e25-4912-ba6d-e645640cd58d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01Q374KzTWKoPjdFCjC9spWu","toolUseID":"toolu_01Q374KzTWKoPjdFCjC9spWu","timestamp":"2026-02-20T09:49:55.052Z","uuid":"edd49b6c-eba9-44b5-b04c-806425b1baef"}
{"parentUuid":"8fb638ea-7e25-4912-ba6d-e645640cd58d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q374KzTWKoPjdFCjC9spWu","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"5e642930-616e-47f6-be1c-371db82016cf","timestamp":"2026-02-20T09:49:55.050Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}","newString":"#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if batch.len() <= 20 {\n                for p in &batch {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n            } else {\n                for p in batch.iter().take(5) {\n                    eprintln!(\"[watcher]   path: {}\", p.display());\n                }\n                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);\n            }\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2453,"oldLines":10,"newStart":2453,"newLines":14,"lines":[" const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);"," "," #[cfg(target_os = \"macos\")]","+const DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);","+","+#[cfg(target_os = \"macos\")]"," fn process_watcher_paths(","     app: &AppHandle,","     state: &AppState,","     pending: &mut HashSet<PathBuf>,","+    deadline: &mut Option<Instant>,","     last_status_emit: &mut Instant,","     pending_status_emit: &mut bool,"," ) {"]},{"oldStart":2473,"oldLines":6,"newStart":2477,"newLines":7,"lines":[" ","     match apply_path_changes(state, &batch) {","         Ok(changed) => {","+            *deadline = None;","             if changed > 0 {","                 invalidate_search_caches(state);","                 touch_status_updated(state);"]},{"oldStart":2486,"oldLines":22,"newStart":2491,"newLines":27,"lines":["             }","         }","         Err(err) => {","+            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");","+            if is_busy {","+                eprintln!(","+                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",","+                    DB_BUSY_RETRY_DELAY.as_secs(),","+                    err,","+                    batch.len()","+                );","+                for path in batch {","+                    pending.insert(path);","+                }","+                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);","+                return;","+            }","             eprintln!(","                 \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",","                 err,","                 batch.len(),","                 state.indexing_active.load(AtomicOrdering::Acquire)","             );","-            if batch.len() <= 20 {","-                for p in &batch {","-                    eprintln!(\"[watcher]   path: {}\", p.display());","-                }","-            } else {","-                for p in batch.iter().take(5) {","-                    eprintln!(\"[watcher]   path: {}\", p.display());","-                }","-                eprintln!(\"[watcher]   ... ({} more)\", batch.len() - 5);","-            }","+            *deadline = None;","             if state.indexing_active.load(AtomicOrdering::Acquire) {","                 return;","             }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"8fb638ea-7e25-4912-ba6d-e645640cd58d"}
{"parentUuid":"5e642930-616e-47f6-be1c-371db82016cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01HGtfi8WQtFELYp9jS1pf7V","type":"message","role":"assistant","content":[{"type":"text","text":"이제 3곳의 호출부를 수정합니다. `deadline = None` 라인은 제거하고 함수가 직접 관리하게 합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3734,"cache_read_input_tokens":61190,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3734},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7V52Dz8dnjtqyudy5L","type":"assistant","uuid":"0ddbd369-f1c4-47f7-aa59-29987e147245","timestamp":"2026-02-20T09:49:58.158Z"}
{"parentUuid":"0ddbd369-f1c4-47f7-aa59-29987e147245","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01HGtfi8WQtFELYp9jS1pf7V","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RNAd8pM8iRH2d5gEADt9Ma","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;","new_string":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3734,"cache_read_input_tokens":61190,"output_tokens":485,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":3734,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK7V52Dz8dnjtqyudy5L","type":"assistant","uuid":"dd31ec25-a41e-4ef6-95b6-41849cbc108c","timestamp":"2026-02-20T09:50:01.890Z"}
{"parentUuid":"dd31ec25-a41e-4ef6-95b6-41849cbc108c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01RNAd8pM8iRH2d5gEADt9Ma","toolUseID":"toolu_01RNAd8pM8iRH2d5gEADt9Ma","timestamp":"2026-02-20T09:50:01.905Z","uuid":"ad9d6805-f42d-462b-8df5-7038c738f7ef"}
{"parentUuid":"dd31ec25-a41e-4ef6-95b6-41849cbc108c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RNAd8pM8iRH2d5gEADt9Ma","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"53f9f3b5-5fd0-4880-bef3-69d96a19dae1","timestamp":"2026-02-20T09:50:01.903Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;","newString":"                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2657,"oldLines":10,"newStart":2657,"newLines":10,"lines":["                         &app,","                         &state,","                         &mut pending_paths,","+                        &mut deadline,","                         &mut last_status_emit,","                         &mut pending_status_emit,","                     );","-                    deadline = None;","                     if replay_phase {","                         replay_phase = false;","                         if !full_scan_triggered {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"dd31ec25-a41e-4ef6-95b6-41849cbc108c"}
{"parentUuid":"53f9f3b5-5fd0-4880-bef3-69d96a19dae1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01KzPgGVvYXDRppNYGbMiDk4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Y4aEfqdQHMfWJ6XoAytsKi","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }","new_string":"            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":523,"cache_read_input_tokens":64924,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":523},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7VaV1uj78ekShqWKQQ","type":"assistant","uuid":"55d7c261-8d92-4d36-bfa3-a87a68057499","timestamp":"2026-02-20T09:50:07.141Z"}
{"parentUuid":"55d7c261-8d92-4d36-bfa3-a87a68057499","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01Y4aEfqdQHMfWJ6XoAytsKi","toolUseID":"toolu_01Y4aEfqdQHMfWJ6XoAytsKi","timestamp":"2026-02-20T09:50:07.151Z","uuid":"fd5c2425-bb0f-4f53-b64b-f43b1e14e822"}
{"parentUuid":"55d7c261-8d92-4d36-bfa3-a87a68057499","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Y4aEfqdQHMfWJ6XoAytsKi","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"13f1430d-0f42-489c-8679-448cf7e6ded1","timestamp":"2026-02-20T09:50:07.150Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }","newString":"            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2684,"oldLines":10,"newStart":2684,"newLines":10,"lines":["                         &app,","                         &state,","                         &mut pending_paths,","+                        &mut deadline,","                         &mut last_status_emit,","                         &mut pending_status_emit,","                     );","-                    deadline = None;","                 }","             }"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"55d7c261-8d92-4d36-bfa3-a87a68057499"}
{"parentUuid":"13f1430d-0f42-489c-8679-448cf7e6ded1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Ka6aPJYyZMwgQfmy7F27Bx","type":"message","role":"assistant","content":[{"type":"text","text":"`HistoryDone` 이후에 있는 `deadline = None` 없이 `replay_phase` 처리가 맞는지 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":65794,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":65794},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7Vxy7rNp3ExTEXLazE","type":"assistant","uuid":"6ed11151-9c49-4ba8-9ed5-f35a2cbc5136","timestamp":"2026-02-20T09:50:09.840Z"}
{"parentUuid":"6ed11151-9c49-4ba8-9ed5-f35a2cbc5136","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Ka6aPJYyZMwgQfmy7F27Bx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VLUGoNSNG12vzFmXcoV96D","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2640,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":65794,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":65794},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7Vxy7rNp3ExTEXLazE","type":"assistant","uuid":"367fff22-c822-4b4c-a3c4-d1f3a2b687f2","timestamp":"2026-02-20T09:50:10.598Z"}
{"parentUuid":"367fff22-c822-4b4c-a3c4-d1f3a2b687f2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01VLUGoNSNG12vzFmXcoV96D","toolUseID":"toolu_01VLUGoNSNG12vzFmXcoV96D","timestamp":"2026-02-20T09:50:10.606Z","uuid":"9495e4d2-c69e-4cd7-8b93-e8f0d3fc5c42"}
{"parentUuid":"367fff22-c822-4b4c-a3c4-d1f3a2b687f2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VLUGoNSNG12vzFmXcoV96D","type":"tool_result","content":"  2640→                                        last_status_emit = Instant::now();\n  2641→                                        pending_status_emit = false;\n  2642→                                    } else {\n  2643→                                        pending_status_emit = true;\n  2644→                                    }\n  2645→                                }\n  2646→                            }\n  2647→                        }\n  2648→                    }\n  2649→                }\n  2650→                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n  2651→                    eprintln!(\n  2652→                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n  2653→                        pending_paths.len(),\n  2654→                        state.indexing_active.load(AtomicOrdering::Acquire)\n  2655→                    );\n  2656→                    process_watcher_paths(\n  2657→                        &app,\n  2658→                        &state,\n  2659→                        &mut pending_paths,\n  2660→                        &mut deadline,\n  2661→                        &mut last_status_emit,\n  2662→                        &mut pending_status_emit,\n  2663→                    );\n  2664→                    if replay_phase {\n  2665→                        replay_phase = false;\n  2666→                        if !full_scan_triggered {\n  2667→                            perf_log(format!(\n  2668→                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n  2669→                                must_scan_count\n  2670→                            ));\n  2671→                            let _ = refresh_and_emit_status_counts(&app, &state);\n  2672→                            last_status_emit = Instant::now();\n  2673→                            pending_status_emit = false;\n  2674→                        }\n  2675→                    }\n  2676→                }\n  2677→                Err(RecvTimeoutError::Timeout) => {}\n  2678→                Err(RecvTimeoutError::Disconnected) => break,\n  2679→            }\n  2680→\n  2681→            if let Some(due) = deadline {\n  2682→                if Instant::now() >= due {\n  2683→                    process_watcher_paths(\n  2684→                        &app,\n  2685→                        &state,\n  2686→                        &mut pending_paths,\n  2687→                        &mut deadline,\n  2688→                        &mut last_status_emit,\n  2689→                        &mut pending_status_emit,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"60ca7d5c-ec83-4e24-895e-cff80d961e79","timestamp":"2026-02-20T09:50:10.605Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,","numLines":50,"startLine":2640,"totalLines":5187}},"sourceToolAssistantUUID":"367fff22-c822-4b4c-a3c4-d1f3a2b687f2"}
{"parentUuid":"60ca7d5c-ec83-4e24-895e-cff80d961e79","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_019DSaN3cdt1WZgyPu85pD2o","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The code looks correct. Now let me check: in `HistoryDone`, the old code had `deadline = None` after `process_watcher_paths`. Now the function manages `deadline`:\n- Success: `*deadline = None` ✓\n- DB busy: `*deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY)` ✓ (retry will happen)\n- Fatal error: `*deadline = None` ✓Then `replay_phase` processing happens after. If we set a retry deadline, the `replay_phase` block still runs (which calls `refresh_and_emit_status_counts`). That's fine.\n\n\nI'm realizing there's a potential issue here: if `process_watcher_paths` sets a retry deadline due to DB being busy, the `replay_phase` block will still execute and call `refresh_and_emit_status_counts`, which itself tries to write to the DB via `set_meta`. If the DB is still locked, that write could fail too, though it's silently ignored. The real question is whether the retry mechanism for `process_watcher_paths` is working as intended.\n\nLooking at the flow more carefully: when `process_watcher_paths` returns with a deadline set to retry, the loop checks `if let Some(due) = deadline { if Instant::now() >= due {...}}`. Since the deadline is 3 seconds in the future, that condition will be false initially, so it won't retry immediately—it'll wait until the deadline passes. I should also verify that the `watcher_stop` check is properly integrated into this logic.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":925,"cache_read_input_tokens":65794,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":925},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7WDYi9f8rfeK5ydsiV","type":"assistant","uuid":"28fd7180-2473-4060-bebc-1d7be4dfcd0e","timestamp":"2026-02-20T09:50:21.685Z"}
{"parentUuid":"28fd7180-2473-4060-bebc-1d7be4dfcd0e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_019DSaN3cdt1WZgyPu85pD2o","type":"message","role":"assistant","content":[{"type":"text","text":"`watcher_stop` 체크도 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":925,"cache_read_input_tokens":65794,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":925},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7WDYi9f8rfeK5ydsiV","type":"assistant","uuid":"95ed65f7-05f2-4872-995b-6eb6465a4ba4","timestamp":"2026-02-20T09:50:21.700Z"}
{"parentUuid":"95ed65f7-05f2-4872-995b-6eb6465a4ba4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_019DSaN3cdt1WZgyPu85pD2o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YK2SWpp4cvUE4dCs7YB9tt","name":"Grep","input":{"pattern":"watcher_stop|watcher_active","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":2},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":925,"cache_read_input_tokens":65794,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":925},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7WDYi9f8rfeK5ydsiV","type":"assistant","uuid":"28af2ad3-bdb3-47e0-a1ec-4bc8337f97c5","timestamp":"2026-02-20T09:50:21.727Z"}
{"parentUuid":"28af2ad3-bdb3-47e0-a1ec-4bc8337f97c5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01YK2SWpp4cvUE4dCs7YB9tt","toolUseID":"toolu_01YK2SWpp4cvUE4dCs7YB9tt","timestamp":"2026-02-20T09:50:23.089Z","uuid":"18d3040a-9edb-4269-9aff-ec614fc40d24"}
{"parentUuid":"28af2ad3-bdb3-47e0-a1ec-4bc8337f97c5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YK2SWpp4cvUE4dCs7YB9tt","type":"tool_result","content":"292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295-    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n--\n2860-\n2861-        // Stop existing file watcher and wait for it to fully exit\n2862:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2863-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2864:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2865-            if std::time::Instant::now() >= deadline {\n2866-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n--\n2892-\n2893-        // Allow new watcher to start\n2894:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2895-\n2896-        #[cfg(target_os = \"windows\")]\n--\n4556-        gitignore,\n4557-        mem_index: Arc::new(RwLock::new(None)),\n4558:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4559:        watcher_active: Arc::new(AtomicBool::new(false)),\n4560-    };\n4561-\n--\n4769-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4770-            mem_index: Arc::new(RwLock::new(None)),\n4771:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4772:            watcher_active: Arc::new(AtomicBool::new(false)),\n4773-        }\n4774-    }"}]},"uuid":"78961f6e-01b2-4a37-a651-e54a1d479ce6","timestamp":"2026-02-20T09:50:23.088Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295-    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n--\n2860-\n2861-        // Stop existing file watcher and wait for it to fully exit\n2862:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2863-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2864:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2865-            if std::time::Instant::now() >= deadline {\n2866-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n--\n2892-\n2893-        // Allow new watcher to start\n2894:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2895-\n2896-        #[cfg(target_os = \"windows\")]\n--\n4556-        gitignore,\n4557-        mem_index: Arc::new(RwLock::new(None)),\n4558:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4559:        watcher_active: Arc::new(AtomicBool::new(false)),\n4560-    };\n4561-\n--\n4769-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4770-            mem_index: Arc::new(RwLock::new(None)),\n4771:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4772:            watcher_active: Arc::new(AtomicBool::new(false)),\n4773-        }\n4774-    }","numLines":35},"sourceToolAssistantUUID":"28af2ad3-bdb3-47e0-a1ec-4bc8337f97c5"}
{"parentUuid":"78961f6e-01b2-4a37-a651-e54a1d479ce6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Ka5spiXmUYArpcfRt7r98b","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The `watcher_stop` and `watcher_active` flags seem to be used in the watcher loop to stop the watcher. The watcher loop checks `watcher_stop` somewhere to break... Let me check where in the watcher loop it checks `watcher_stop`. Actually, looking at the fsevent watcher, I don't see a `watcher_stop` check in the loop. Let me look for it.\n\nActually, the `watcher_stop` check is probably in the Windows version of the watcher, not the macOS one. The macOS watcher uses FSEvents which has its own stop mechanism. So the retry logic should work fine.\n\n\nLet me run a compile check to make sure everything builds correctly.","signature":"EuEFCkYICxgCKkDA1+yZ2P17LwpAuFiFBhwMqxyavS+tDdg71Yo9CwO5Ewa2VNt0+xQ+evCabP7U3cIz+9xI6ftz6g6Kzcgg4xPAEgwrRRpmBBs4iURrmqUaDAnd0k5fI+2/1kOSFCIwwZymjq6ODF34QItgSyTW2xmobJ1Yl+2PcupZLBXFsGjmUSEMlSo5Ox1N07F8JZelKsgEuraE5pge1U28v+G3jYU9JQ/i3cZkYarlNFCibI1Iv4/iqjZyCkVcAHmqLimTGeioK7yKasUSsEpK6QlF8AGidhBf0HSvhAuuHvXjuJPvbpA8dceOApGcsOq71uX3jCP+QpPe26kA1hvdtHLB1lHKd60uujk2Di7Qr1sAJkH5stAm8m+dUgEejCs0z74rrfjFywGXrwE1HwHn7T1LD0+XZDCVPRBSlxDfXRbSc6yy3QsbxFDeLe5rpwUaYKN5w0wZEjy2kmpbp0ODJOpdnv0XPkyVST8/i16C+uNwTgJjcKSOrzQ2DbtfBKd5nljz5Vk+nyFIG73UHbxOJ1NKZ2t2jHv29SZntzV1I/pL8DTGU+iC7ct/VyAjI07CH0bnRsa90WbIa9dWIxPmGbFY/l0b9QLhk4sjZrKHhIPuQWG1bPUwi52fP4AYi0aZIOjdoKbR7YVBxlZYwukAaNWPi2AVXYdJ4hRwWr7KRKh0gcFfL9DT3imtmmiKYD74v4XuWhZ6LMyE6YZ1qJ9BdgAtMh0hm+aeteI6hADMv/bOM4gLakmZ7P1nq0eabIcDZQ4GpXBRYRftg7KE56FRWfXsdG8h9sKRmmQyO64H9xxyoIzAmQ6BmBxP8pimBXIx5jjqqjje6uVsqC/bZFGHn/xdnA22brzlrZlgK5UhxdwIXuAxy2mRbcNA/4jVbWXtkpcfgbg6YE0pqCTj3RNfqnNhyfbSxHe9rEY63EiT/ky049jfGEMt7q3lEE3UbOhudpsmE6JTSIAdFY9SlfUYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1146,"cache_read_input_tokens":66719,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1146},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7X8pUrmoyDfDTgJRWk","type":"assistant","uuid":"37d332c0-1613-460f-9181-85c1c155b46e","timestamp":"2026-02-20T09:50:28.150Z"}
{"parentUuid":"37d332c0-1613-460f-9181-85c1c155b46e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Ka5spiXmUYArpcfRt7r98b","type":"message","role":"assistant","content":[{"type":"text","text":"컴파일 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1146,"cache_read_input_tokens":66719,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1146},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7X8pUrmoyDfDTgJRWk","type":"assistant","uuid":"dfaf1fbe-5723-4cb1-8d4b-21d7abb0510e","timestamp":"2026-02-20T09:50:28.167Z"}
{"parentUuid":"dfaf1fbe-5723-4cb1-8d4b-21d7abb0510e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01Ka5spiXmUYArpcfRt7r98b","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UeKvwNUN7oKwcwSRVvkE8h","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | grep -E \"error|warning: unused|Finished\"","description":"Cargo check for compile errors","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1146,"cache_read_input_tokens":66719,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1146},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7X8pUrmoyDfDTgJRWk","type":"assistant","uuid":"9cb7b7d2-747b-4288-842d-e545dae9d6af","timestamp":"2026-02-20T09:50:29.187Z"}
{"parentUuid":"9cb7b7d2-747b-4288-842d-e545dae9d6af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UeKvwNUN7oKwcwSRVvkE8h","type":"tool_result","content":"    Finished `dev` profile [unoptimized + debuginfo] target(s) in 1.91s","is_error":false}]},"uuid":"bf716d5f-7317-4ab1-82d2-602b2a5ac494","timestamp":"2026-02-20T09:50:31.360Z","toolUseResult":{"stdout":"    Finished `dev` profile [unoptimized + debuginfo] target(s) in 1.91s","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"9cb7b7d2-747b-4288-842d-e545dae9d6af"}
{"parentUuid":"bf716d5f-7317-4ab1-82d2-602b2a5ac494","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01FoyBJcNHfKu83CAqUdpDcG","type":"message","role":"assistant","content":[{"type":"text","text":"컴파일 성공. 변경 내용 요약:\n\n**핵심 변경:**\n- `process_watcher_paths`에 `deadline: &mut Option<Instant>` 파라미터 추가\n- 성공 시 → `*deadline = None`\n- DB busy (`locked`/`busy`) 실패 시 → 경로를 `pending`에 복원 + `*deadline = Some(Instant::now() + 3s)` (에러 상태 emit 없음)\n- 기타 진짜 에러 시 → 기존대로 Error 상태 emit\n\n**동작 흐름:**\n```\nHistoryDone → process_watcher_paths → DB busy\n  → batch 경로들 pending에 돌려넣기\n  → deadline = now + 3s 설정\n  (3초 후) → deadline 만료 → process_watcher_paths 재시도\n  → purge_ignored_entries 완료됐으면 → 성공, deadline = None\n```\n\n`purge_ignored_entries`가 6초 걸리므로 3초 후 한 번 더 실패할 수도 있지만, 그때도 동일하게 pending에 보존되고 3초 후 재시도합니다. 결국 DB가 풀리면 자동으로 consume됩니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":342,"cache_read_input_tokens":67865,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":342},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK7XmKSZgwhJdrTDDw4t","type":"assistant","uuid":"761ceb2e-1eb0-431a-aa8c-38f0b2a85063","timestamp":"2026-02-20T09:50:41.580Z"}
{"parentUuid":"761ceb2e-1eb0-431a-aa8c-38f0b2a85063","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"13f51e83-f28a-49c4-85aa-9710f58163c2","toolUseID":"13f51e83-f28a-49c4-85aa-9710f58163c2","timestamp":"2026-02-20T09:50:41.625Z","uuid":"144acdb2-130e-4986-9880-d70187991565"}
{"parentUuid":"144acdb2-130e-4986-9880-d70187991565","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":971}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-20T09:50:42.597Z","uuid":"90ba3f16-b8e6-445c-b00c-fffe2653dc3c","toolUseID":"13f51e83-f28a-49c4-85aa-9710f58163c2"}
{"parentUuid":"90ba3f16-b8e6-445c-b00c-fffe2653dc3c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"turn_duration","durationMs":134819,"timestamp":"2026-02-20T09:50:42.598Z","uuid":"3577d463-5865-4904-9639-27b3b60fd803","isMeta":false}
{"type":"file-history-snapshot","messageId":"e7f40bfc-8e72-40bc-afd8-9323c61e89be","snapshot":{"messageId":"e7f40bfc-8e72-40bc-afd8-9323c61e89be","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v3","version":3,"backupTime":"2026-02-20T09:57:30.255Z"}},"timestamp":"2026-02-20T09:57:30.254Z"},"isSnapshotUpdate":false}
{"parentUuid":"3577d463-5865-4904-9639-27b3b60fd803","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":"<command-message>ln:codereview</command-message>\n<command-name>/ln:codereview</command-name>"},"uuid":"e7f40bfc-8e72-40bc-afd8-9323c61e89be","timestamp":"2026-02-20T09:57:28.670Z"}
{"parentUuid":"e7f40bfc-8e72-40bc-afd8-9323c61e89be","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"type":"text","text":"Conduct a thorough, line-by-line code review with a critical perspective.\n\n**Usage:**\n```bash\n/ln:codereview           # Review all uncommitted changes (default)\n/ln:codereview all       # Review all uncommitted changes (staged + unstaged)\n/ln:codereview unstaged  # Review only unstaged changes\n```\n\n## Review Scope\n\n**Mode 1: All uncommitted changes (default)**\n- Command: `git diff HEAD` (staged + unstaged)\n- Reviews everything not yet committed\n\n**Mode 2: Unstaged only**\n- Command: `git diff` (working directory changes only)\n- Reviews only files not yet staged\n\nAll modes include:\n1. **Critical examination**: Line-by-line inspection with skeptical mindset\n2. **Pattern validation**: Verify adherence to project conventions and guides\n\n## Review Categories\n\n### Code Quality\n- **Clean code**: No TODO comments, no unused code\n- **Naming conventions**: Consistent with project standards\n- **File organization**: Proper separation of concerns\n- **Documentation**: Adequate comments where necessary\n\n### Technical Validation\n- **Build verification**: Zero warnings, all tests pass\n- **Type safety**: No type errors or unsafe operations\n- **Performance**: No memory leaks, efficient algorithms\n- **Security**: No hardcoded secrets or vulnerabilities\n\n### Architecture Review\n- **Design patterns**: Appropriate use of patterns\n- **Dependency management**: Minimal coupling\n- **Error handling**: Comprehensive error coverage\n- **Concurrency**: Thread safety and race conditions\n\n### Design Principles (OCP/SRP)\n\n**OCP (Open-Closed Principle) violations to catch:**\n- Adding `else if` / `switch case` to extend existing behavior\n- Modifying stable code instead of creating new modules\n- Missing extension points (strategy, registry, plugin patterns)\n\n**SRP (Single Responsibility Principle) violations to catch:**\n- One file handling multiple unrelated concerns\n- Functions/classes that change for multiple reasons\n- God objects or utility dumps\n\n**When found, suggest:**\n- Extract new behavior into separate file/class\n- Use strategy/registry pattern for extensibility\n- Split multi-responsibility files into focused modules\n\n## Review Process\n\n### Step 0: Understand Project Context (MANDATORY)\n\nBefore reviewing any code, you MUST understand the project environment:\n\n1. **Read CLAUDE.md** - Check project root and user's `~/.claude/CLAUDE.md` for project-specific conventions\n2. **Identify app type** - Read entry points, config files, or main modules to determine:\n   - **Platform**: Desktop (Electron) / Mobile (React Native, Flutter, iOS, Android) / Web server / CLI / Library\n   - **User model**: Single-user vs Multi-user\n   - **Network exposure**: Local-only vs Network-exposed API\n3. **Understand architecture** - Scan key files to grasp the overall structure\n\n**Why this matters:**\n- Security concerns differ drastically between local desktop app and public API server\n- \"Memory leak\" in a short-lived CLI is irrelevant; in a long-running server it's critical\n- Path traversal in local-only app with file dialog is low-risk; in server accepting arbitrary input it's critical\n\n**DO NOT skip this step.** Reviewing without context leads to false positives and wastes everyone's time.\n\n### Step 1: Analyze Changes\n\nDetermine review mode from command argument (default: `all`):\n\n**Mode: all (default)**\n```bash\ngit diff HEAD  # All uncommitted changes (staged + unstaged)\n```\n\n**Mode: unstaged**\n```bash\ngit diff  # Only unstaged changes\n```\n\n### Step 2: Validate Build\n- TypeScript: `npx tsc --noEmit`\n- Linting: `npm run lint`\n- Testing: `npm run test`\n- Language-specific checks per development guides\n\n### Step 3: Generate Report\n\nI will provide a structured report with:\n\n#### Critical Issues 🚨\n- **ONLY** issues that will cause runtime crashes, data loss, or security breaches\n- Must be reproducible with concrete steps\n- Example: SQL injection, unhandled null causing crash, infinite loop\n\n#### Major Issues ⚠️\n- Issues that cause incorrect behavior users will notice\n- Must demonstrate actual failure scenario\n- Example: Wrong calculation result, UI not updating, API returning wrong data\n\n#### Minor Issues 💡\n- Style violations or optimization opportunities\n- Suggestions for improvement\n- Example: Inconsistent naming, missing error message\n\n**DO NOT mark as Critical/Major:**\n- Theoretical concerns without concrete failure scenario\n- \"Could potentially cause...\" without proof\n- Design preferences or \"I would do it differently\"\n\n#### Positive Highlights ✅\n- Well-implemented patterns\n- Good practices observed\n\n## Review Principles\n\n- **No temporary solutions**: Reject workarounds or hacks\n- **Complete implementation**: No partial features with TODOs\n- **Performance first**: Consider memory, CPU, and I/O impact\n- **Build cleanliness**: Zero warnings tolerance\n- **Guide compliance**: Follow all development guides in docs/\n\n## ⛔ Anti-Hallucination Rules\n\nBefore reporting ANY issue, you MUST:\n\n1. **READ the actual code** - Don't guess based on patterns. Read the exact lines.\n2. **TRACE the execution flow** - Follow the code path. If you claim race condition, prove it step by step.\n3. **VERIFY the issue exists** - Can you reproduce it? Show concrete scenario.\n4. **CHECK context** - What's the runtime environment? Desktop vs server, single-user vs multi-user?\n5. **CONFIRM it's not intentional** - fire-and-forget, placeholder values updated later, etc. may be by design.\n\n### Issue Validation Checklist\n\nFor each issue you want to report, answer:\n1. Did I read the ACTUAL code, not just the diff snippet?\n2. Can I show the EXACT line numbers where this fails?\n3. Is this a REAL bug or theoretical concern that can't happen in practice?\n4. Does the surrounding code already handle this case?\n\n### What NOT to report as issues:\n- Singleton with placeholder that gets updated in init/start method\n- \"Memory leak\" in single-user desktop app with bounded data\n- \"Race condition\" when there's already a guard (e.g., `if (this.running) return`)\n- Intentional fire-and-forget patterns with error logging\n- \"Missing cleanup\" when cleanup exists in useEffect return or stop() method\n\n## Exclusions (Do NOT Review)\n\n- **Git submodule reference changes only**: Skip dirty submodule states, submodule commit hash changes in the main repo. Source code inside submodules CAN and SHOULD be reviewed when requested.\n\n## Output Format\n\nThe review will be delivered as a comprehensive report with:\n- Severity-based issue categorization\n- Specific line references for each issue\n- Concrete suggestions for fixes\n- Overall code health assessment"}]},"isMeta":true,"uuid":"ac64743d-c066-4d10-a54d-e60e854023e0","timestamp":"2026-02-20T09:57:28.670Z"}
{"parentUuid":"ac64743d-c066-4d10-a54d-e60e854023e0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_012GCZJHshQpU6b34wg2HQsr","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants me to run a code review on the uncommitted changes. Let me use the Skill tool to execute the ln:codereview skill.\n\nWait, I see the command has already been expanded in the message with the full prompt content. I should follow the instructions directly instead of calling the Skill tool again.\n\nLet me proceed with the code review as instructed by the skill.\n\nStep 0: Understand Project Context - I already know this from the CLAUDE.md in my context:\n- macOS \"Everything\"-style file search app\n- Tauri v2 + Rust (backend) + Svelte 4 (frontend) + SQLite (FTS5)\n\n\n- Desktop app, single-user, local-only with minimal security concerns since it's a local desktop application","signature":"Es0GCkYICxgCKkALqXTogm8pPQP/7xvscO5EP17r6stAEcOA19YD1luO+ncEmRf9+hFarkNFNSRLiJljNOvw8wi0sY7mG9iJ+TUzEgwAejoVcpnvMg7CxeIaDLIVOPIkGWYcpKpuziIwNxweSydL99dHZfvatvJJIVnVtcxKr5oJpCAW7ivkF5nDsIKQVPt2xPqDMqoZHJWPKrQFLGyPVk6/9Ewa1E+D2Bae1BtAEqZxYn7MGGpRRUtRX2AhxAP5eTP/kACoCNPwuuBAbFP+Q+ePHJWnLUiuFH5suUu7bV4JOaJsmUdSbevMlzYIuZZzbYl87eQGow739zz1Iu+LG6U4lIwaGehurCmCe3E4Ke07Wg7hXM9PrOI42Og2IPLR2oiy03pLJP8jd3Ipj3letEmGXaihhdOi0+KRr28g5Bnlbnuoj5DM03t6BlDc1PhLJr64aVYnE9tQfvHmWAb+UtOhLm+N9MYP2aMx6bOeObXsPhjada7gmcfmFYLQ+Px+WOColv+0KewbITydYykPMByJBbQPB5Kp/eXCww4kkSX8mIhNQDVi3Uzbjl4XRPuxwxoF9H8BZlRNLfPLx77C/eKexx/83piSDsaqL0nojcS4eU0Fcu7oUCcM2m++Y+URi55wczYlB/cyN0j7lH6h2nFdbl250NBoAfDluqk6i78oa4HGCNjKGyjfcy6E3b+exRoY5L2w3CPblDJmPFR7iqs6+cU2klhLBUGGhkpwh14B5SxpqeQyHneTefiQjC3AAroyv9OTBDYt0qCFDHXFuc+TpmhyTBXNk0LAhr7jcF0Y1cHlCnoPqqsJYooOhChSd0bOG0AmAwbGiEcPzO/dmuYslbYsr1KEuQPmRW0RRdCKCOSk2dC9uTsAjsC8sn6o5hR8pF3FFRAIOiMSmJKq61wVVv8VbyWNa8SkoPK2ARirBAlXJLs1H8MHh1UJvl/2GGI+jBnq4jE1XVzCNn8XUw8lG7MWCTQUjC3k/ak3vQKONSLzF4hL5dFi4+mJDDp8YrQcj60FT9edEM+87Brf0hhd5u3FWDgS6+zHlFv5VQmTJjD70en5BPAMX8QVxj3reMk8zf7rrQwgKbuj4JwkjvjNMAs6yjGMe6ygkDnH5OoYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1735,"cache_read_input_tokens":68575,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1735},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK84ep93472Xp7WDULQm","type":"assistant","uuid":"1ee1921b-5257-44a0-b02d-aff6134bb835","timestamp":"2026-02-20T09:57:37.541Z"}
{"parentUuid":"1ee1921b-5257-44a0-b02d-aff6134bb835","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_012GCZJHshQpU6b34wg2HQsr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019KeNv7gKzHHhu7oyoqNfkM","name":"Bash","input":{"command":"git diff HEAD","description":"Get all uncommitted changes"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1735,"cache_read_input_tokens":68575,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1735},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK84ep93472Xp7WDULQm","type":"assistant","uuid":"f21a3d6a-7953-4d2c-b5eb-b31a8ef3d0cd","timestamp":"2026-02-20T09:57:37.913Z"}
{"parentUuid":"f21a3d6a-7953-4d2c-b5eb-b31a8ef3d0cd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019KeNv7gKzHHhu7oyoqNfkM","type":"tool_result","content":"diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs\nindex 782d89a..f9dc01d 100644\n--- a/src-tauri/src/main.rs\n+++ b/src-tauri/src/main.rs\n@@ -2416,23 +2416,51 @@ fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n         return Ok(0);\n     }\n \n-    let mut conn = db_connection(&state.db_path)?;\n+    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n+    eprintln!(\n+        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n+        to_upsert.len(),\n+        to_delete.len(),\n+        indexing\n+    );\n+\n+    let conn_start = std::time::Instant::now();\n+    let mut conn = db_connection(&state.db_path).map_err(|e| {\n+        eprintln!(\n+            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n+            conn_start.elapsed().as_millis(),\n+            e,\n+            to_upsert.len(),\n+            to_delete.len(),\n+            state.indexing_active.load(AtomicOrdering::Acquire)\n+        );\n+        e\n+    })?;\n     let mut changed = 0;\n \n     changed += upsert_rows(&mut conn, &to_upsert)?;\n     changed += delete_paths(&mut conn, &to_delete)?;\n \n+    eprintln!(\n+        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n+        changed,\n+        conn_start.elapsed().as_millis()\n+    );\n     Ok(changed)\n }\n \n #[cfg(target_os = \"macos\")]\n const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n \n+#[cfg(target_os = \"macos\")]\n+const DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n+\n #[cfg(target_os = \"macos\")]\n fn process_watcher_paths(\n     app: &AppHandle,\n     state: &AppState,\n     pending: &mut HashSet<PathBuf>,\n+    deadline: &mut Option<Instant>,\n     last_status_emit: &mut Instant,\n     pending_status_emit: &mut bool,\n ) {\n@@ -2449,6 +2477,7 @@ fn process_watcher_paths(\n \n     match apply_path_changes(state, &batch) {\n         Ok(changed) => {\n+            *deadline = None;\n             if changed > 0 {\n                 invalidate_search_caches(state);\n                 touch_status_updated(state);\n@@ -2462,6 +2491,27 @@ fn process_watcher_paths(\n             }\n         }\n         Err(err) => {\n+            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n+            if is_busy {\n+                eprintln!(\n+                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n+                    DB_BUSY_RETRY_DELAY.as_secs(),\n+                    err,\n+                    batch.len()\n+                );\n+                for path in batch {\n+                    pending.insert(path);\n+                }\n+                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n+                return;\n+            }\n+            eprintln!(\n+                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n+                err,\n+                batch.len(),\n+                state.indexing_active.load(AtomicOrdering::Acquire)\n+            );\n+            *deadline = None;\n             if state.indexing_active.load(AtomicOrdering::Acquire) {\n                 return;\n             }\n@@ -2576,6 +2626,11 @@ fn start_fsevent_watcher_worker(\n                             cached_effective_ignore_rules(&state);\n                         let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                         if !rows.is_empty() {\n+                            eprintln!(\n+                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n+                                rows.len(),\n+                                path.display()\n+                            );\n                             if let Ok(mut conn) = db_connection(&state.db_path) {\n                                 if upsert_rows(&mut conn, &rows).is_ok() {\n                                     invalidate_search_caches(&state);\n@@ -2593,14 +2648,19 @@ fn start_fsevent_watcher_worker(\n                     }\n                 }\n                 Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n+                    eprintln!(\n+                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n+                        pending_paths.len(),\n+                        state.indexing_active.load(AtomicOrdering::Acquire)\n+                    );\n                     process_watcher_paths(\n                         &app,\n                         &state,\n                         &mut pending_paths,\n+                        &mut deadline,\n                         &mut last_status_emit,\n                         &mut pending_status_emit,\n                     );\n-                    deadline = None;\n                     if replay_phase {\n                         replay_phase = false;\n                         if !full_scan_triggered {\n@@ -2624,10 +2684,10 @@ fn start_fsevent_watcher_worker(\n                         &app,\n                         &state,\n                         &mut pending_paths,\n+                        &mut deadline,\n                         &mut last_status_emit,\n                         &mut pending_status_emit,\n                     );\n-                    deadline = None;\n                 }\n             }","is_error":false}]},"uuid":"eb505449-bd3b-4643-a01c-9f9c7dfc9a38","timestamp":"2026-02-20T09:57:38.059Z","toolUseResult":{"stdout":"diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs\nindex 782d89a..f9dc01d 100644\n--- a/src-tauri/src/main.rs\n+++ b/src-tauri/src/main.rs\n@@ -2416,23 +2416,51 @@ fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n         return Ok(0);\n     }\n \n-    let mut conn = db_connection(&state.db_path)?;\n+    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n+    eprintln!(\n+        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n+        to_upsert.len(),\n+        to_delete.len(),\n+        indexing\n+    );\n+\n+    let conn_start = std::time::Instant::now();\n+    let mut conn = db_connection(&state.db_path).map_err(|e| {\n+        eprintln!(\n+            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n+            conn_start.elapsed().as_millis(),\n+            e,\n+            to_upsert.len(),\n+            to_delete.len(),\n+            state.indexing_active.load(AtomicOrdering::Acquire)\n+        );\n+        e\n+    })?;\n     let mut changed = 0;\n \n     changed += upsert_rows(&mut conn, &to_upsert)?;\n     changed += delete_paths(&mut conn, &to_delete)?;\n \n+    eprintln!(\n+        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n+        changed,\n+        conn_start.elapsed().as_millis()\n+    );\n     Ok(changed)\n }\n \n #[cfg(target_os = \"macos\")]\n const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n \n+#[cfg(target_os = \"macos\")]\n+const DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n+\n #[cfg(target_os = \"macos\")]\n fn process_watcher_paths(\n     app: &AppHandle,\n     state: &AppState,\n     pending: &mut HashSet<PathBuf>,\n+    deadline: &mut Option<Instant>,\n     last_status_emit: &mut Instant,\n     pending_status_emit: &mut bool,\n ) {\n@@ -2449,6 +2477,7 @@ fn process_watcher_paths(\n \n     match apply_path_changes(state, &batch) {\n         Ok(changed) => {\n+            *deadline = None;\n             if changed > 0 {\n                 invalidate_search_caches(state);\n                 touch_status_updated(state);\n@@ -2462,6 +2491,27 @@ fn process_watcher_paths(\n             }\n         }\n         Err(err) => {\n+            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n+            if is_busy {\n+                eprintln!(\n+                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n+                    DB_BUSY_RETRY_DELAY.as_secs(),\n+                    err,\n+                    batch.len()\n+                );\n+                for path in batch {\n+                    pending.insert(path);\n+                }\n+                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n+                return;\n+            }\n+            eprintln!(\n+                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n+                err,\n+                batch.len(),\n+                state.indexing_active.load(AtomicOrdering::Acquire)\n+            );\n+            *deadline = None;\n             if state.indexing_active.load(AtomicOrdering::Acquire) {\n                 return;\n             }\n@@ -2576,6 +2626,11 @@ fn start_fsevent_watcher_worker(\n                             cached_effective_ignore_rules(&state);\n                         let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                         if !rows.is_empty() {\n+                            eprintln!(\n+                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n+                                rows.len(),\n+                                path.display()\n+                            );\n                             if let Ok(mut conn) = db_connection(&state.db_path) {\n                                 if upsert_rows(&mut conn, &rows).is_ok() {\n                                     invalidate_search_caches(&state);\n@@ -2593,14 +2648,19 @@ fn start_fsevent_watcher_worker(\n                     }\n                 }\n                 Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n+                    eprintln!(\n+                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n+                        pending_paths.len(),\n+                        state.indexing_active.load(AtomicOrdering::Acquire)\n+                    );\n                     process_watcher_paths(\n                         &app,\n                         &state,\n                         &mut pending_paths,\n+                        &mut deadline,\n                         &mut last_status_emit,\n                         &mut pending_status_emit,\n                     );\n-                    deadline = None;\n                     if replay_phase {\n                         replay_phase = false;\n                         if !full_scan_triggered {\n@@ -2624,10 +2684,10 @@ fn start_fsevent_watcher_worker(\n                         &app,\n                         &state,\n                         &mut pending_paths,\n+                        &mut deadline,\n                         &mut last_status_emit,\n                         &mut pending_status_emit,\n                     );\n-                    deadline = None;\n                 }\n             }","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"f21a3d6a-7953-4d2c-b5eb-b31a8ef3d0cd"}
{"parentUuid":"eb505449-bd3b-4643-a01c-9f9c7dfc9a38","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01BTcTx6V9ahMBw1jULbxJG3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DEg9GGb5VEsDXdgW9ULeF4","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1","description":"Build validation","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1885,"cache_read_input_tokens":70310,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1885},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK85CvRtvJns6sRxLLmX","type":"assistant","uuid":"1b7e3c5b-6962-4e45-9a5d-71ec2ccbe2fd","timestamp":"2026-02-20T09:57:40.792Z"}
{"parentUuid":"1b7e3c5b-6962-4e45-9a5d-71ec2ccbe2fd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DEg9GGb5VEsDXdgW9ULeF4","type":"tool_result","content":"warning: function `set_ready_with_cached_counts` is never used\n    --> src/main.rs:1810:15\n     |\n1810 | pub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `#[warn(dead_code)]` on by default\n\nwarning: function `start_full_index_worker_silent` is never used\n    --> src/main.rs:1843:15\n     |\n1843 | pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nwarning: associated items `build` and `entries` are never used\n   --> src/mem_search.rs:61:12\n    |\n 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.57s","is_error":false}]},"uuid":"8d64e65c-9216-4d15-859d-1db1f57b0031","timestamp":"2026-02-20T09:57:41.632Z","toolUseResult":{"stdout":"warning: function `set_ready_with_cached_counts` is never used\n    --> src/main.rs:1810:15\n     |\n1810 | pub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `#[warn(dead_code)]` on by default\n\nwarning: function `start_full_index_worker_silent` is never used\n    --> src/main.rs:1843:15\n     |\n1843 | pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nwarning: associated items `build` and `entries` are never used\n   --> src/mem_search.rs:61:12\n    |\n 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.57s","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"1b7e3c5b-6962-4e45-9a5d-71ec2ccbe2fd"}
{"parentUuid":"8d64e65c-9216-4d15-859d-1db1f57b0031","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01UY362iUD6QMf3Kxmsa8kyC","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Warnings exist, but they're pre-existing (not introduced by this diff). Let me verify this by checking if these warnings existed before.\n\nActually, the warnings about `set_ready_with_cached_counts`, `start_full_index_worker_silent`, and `MemIndex::build/entries` are pre-existing and not introduced by our changes. Let me focus on the diff.\n\nNow let me do the actual code review.\n\n**Review of the diff:**\n\n1. **`apply_path_changes` logging** (lines +2416-2451):\n   - `let indexing = state.indexing_active.load(...)` - this variable is captured but then a second load happens in the error closure. The first load result could be stale by the time the error handler runs. \n\nThe logging pattern looks sound overall—`conn_start` is captured before the connection attempt to measure total latency, the error handler correctly re-throws after logging, and the success log at the end tracks elapsed time from connection open through all DB writes, which seems intentional for performance monitoring.\n\n2. **`DB_BUSY_RETRY_DELAY` constant** - 3 seconds seems reasonable, though there's more context in the logs about this choice.\n\n3. **`process_watcher_paths` changes** - The new `deadline` parameter is being passed mutably so the function can clear it on success. This works correctly whether called after `HistoryDone` or on deadline expiry, since the deadline clearing now happens inside the function instead of after it returns. I'm checking whether there's an edge case where a new FSEvent could set the deadline while this function is running and inadvertently clear it.\n\nActually, that's not possible - the watcher thread drains the channel first, then calls `process_watcher_paths` synchronously, so no new events can arrive and modify the deadline while the function is executing. On the error path, the function restores any unprocessed paths back to the pending queue and sets the deadline to retry after a delay.\n\nFor hard errors, I'm clearing the deadline upfront so we don't attempt a retry, and the `indexing_active` check happens after that, so the deadline is definitely cleared before returning. The `HistoryDone` handler was removed entirely.\n\nLooking at the deadline expiry handler, I've removed the manual deadline clearing after the call since the function now manages it internally—setting it to `None` on success or hard error, and to a future time on busy errors. There's a potential issue where `refresh_and_emit_status_counts` runs even when the DB is busy and might fail silently, but that's not critical. I'm also noticing that `apply_path_changes` is logging on every invocation, which could be noisy.\n\nThe `conn_start` label is doing double duty—measuring both connection time and total DB write duration—so the name is a bit misleading, though the metric itself is useful. There's also a minor inefficiency where the `indexing` variable is captured and then re-read from the atomic state.\n\nload() in the error handler, which could give different values between logs, but that's acceptable for diagnostics. No correctness issues overall, though I'm wondering about the `replay_phase` block behavior when `process_watcher_paths` returns early due to DB contention and sets a retry deadline.\n\nThe `replay_phase` flag gets cleared regardless of whether the DB operation succeeds, and `refresh_and_emit_status_counts` runs even when the database is busy, potentially writing stale cached entry counts to metadata that might fail silently.\n\nLooking at the bigger picture, there aren't any major issues here—the retry mechanism handles transient database busy states cleanly without corrupting error state. The main problems are minor: that `apply_path_changes` debug output fires constantly on every watcher event rather than just during startup or actual errors, and `conn_start` is a misleading name since it measures total write time rather than just connection overhead. On the positive side, the deadline management is properly contained within the function and paths are correctly restored to a HashSet for retries.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":446,"cache_read_input_tokens":72195,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":446},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK85UBheVy5dgmizYLZo","type":"assistant","uuid":"144205b8-d89f-4974-ac82-579f443131c5","timestamp":"2026-02-20T09:58:26.792Z"}
{"parentUuid":"144205b8-d89f-4974-ac82-579f443131c5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01UY362iUD6QMf3Kxmsa8kyC","type":"message","role":"assistant","content":[{"type":"text","text":"---\n\n## Code Review Report\n\n**Context:** macOS desktop app, single-user, local-only. Security concerns are minimal.\n\n---\n\n### Critical Issues 🚨\n\nNone.\n\n---\n\n### Major Issues ⚠️\n\nNone.\n\n---\n\n### Minor Issues 💡\n\n**1. `apply_path_changes` eprintln fires on every watcher event permanently**\n\n```rust\n// +2419 in diff\neprintln!(\n    \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n    ...\n);\n// +2437\neprintln!(\n    \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n    ...\n);\n```\n\n이 로그는 startup 문제 추적 목적으로 추가됐지만 조건 없이 항상 실행됩니다. 이후에도 watcher가 파일 변경을 처리할 때마다 stderr에 출력됩니다. `db_connection FAILED` 에러 로그만 남기고 나머지 두 줄은 제거해도 됩니다.\n\n**2. `conn_start` 이름이 측정 범위와 불일치**\n\n```rust\nlet conn_start = std::time::Instant::now();  // connection 전에 시작\nlet mut conn = db_connection(...)?;\n// ...\nupsert_rows(&mut conn, &to_upsert)?;\ndelete_paths(&mut conn, &to_delete)?;\n\neprintln!(\"... elapsed={}ms\", conn_start.elapsed().as_millis());  // 전체 쓰기 시간\n```\n\n`conn_start`라는 이름은 \"connection open 시간\"을 암시하지만 실제로는 연결 + upsert + delete 전체를 측정합니다. `write_start` 또는 `op_start`가 더 명확합니다.\n\n---\n\n### Positive Highlights ✅\n\n**1. 재시도 로직이 깔끔합니다.**\n`batch`를 `pending`에 되돌리고 `deadline`을 설정하는 방식이 기존 루프 메커니즘을 재활용하여 별도 재시도 스레드나 복잡한 상태 없이 자연스럽게 동작합니다.\n\n**2. `deadline` 관리가 함수 내부로 올바르게 이동됐습니다.**\n성공/busy/hard error 세 경우 모두 `deadline`을 적절히 처리하며, 호출부의 중복 `deadline = None`도 제거했습니다.\n\n**3. busy vs. 진짜 에러 구분이 명확합니다.**\nDB busy는 Error 상태를 emit하지 않고 조용히 재시도, 실제 에러만 Error 상태로 전환하는 것이 UX적으로 올바릅니다.\n\n---\n\n**Overall:** 로직상 문제 없음. `apply_path_changes`의 항상-실행 eprintln 2개를 제거하면 완성도가 높아집니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":446,"cache_read_input_tokens":72195,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":446},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK85UBheVy5dgmizYLZo","type":"assistant","uuid":"0722b60b-9332-4b18-925a-e395e4dcfbe2","timestamp":"2026-02-20T09:58:38.162Z"}
{"parentUuid":"0722b60b-9332-4b18-925a-e395e4dcfbe2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6e608ca8-6912-45bd-b8cd-123fd6636f79","toolUseID":"6e608ca8-6912-45bd-b8cd-123fd6636f79","timestamp":"2026-02-20T09:58:38.220Z","uuid":"c9fb8dc8-b33b-4d4c-923f-9360c0ae01f0"}
{"parentUuid":"c9fb8dc8-b33b-4d4c-923f-9360c0ae01f0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1520}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-20T09:58:39.741Z","uuid":"c448846b-f04a-48f9-b877-3c101eb2aa1a","toolUseID":"6e608ca8-6912-45bd-b8cd-123fd6636f79"}
{"parentUuid":"c448846b-f04a-48f9-b877-3c101eb2aa1a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"turn_duration","durationMs":69486,"timestamp":"2026-02-20T09:58:39.743Z","uuid":"734db575-a1cd-4e53-8841-977579d2bc55","isMeta":false}
{"type":"file-history-snapshot","messageId":"488f6426-c49b-4604-a65f-4b726ea95667","snapshot":{"messageId":"488f6426-c49b-4604-a65f-4b726ea95667","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v3","version":3,"backupTime":"2026-02-20T09:57:30.255Z"}},"timestamp":"2026-02-20T10:00:56.262Z"},"isSnapshotUpdate":false}
{"parentUuid":"734db575-a1cd-4e53-8841-977579d2bc55","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":"수정해줘"},"uuid":"488f6426-c49b-4604-a65f-4b726ea95667","timestamp":"2026-02-20T10:00:54.415Z","permissionMode":"bypassPermissions"}
{"parentUuid":"488f6426-c49b-4604-a65f-4b726ea95667","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01MZD8Wt6rUP9cDyPiXrDtLs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019Lybnv4mKEPqR4EFeLWUzk","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2413,"limit":55},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":9,"cache_read_input_tokens":75557,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK8KqVk9pQ9YbDpRNWQJ","type":"assistant","uuid":"8693225d-b76a-40ba-9c3d-84bf63753b50","timestamp":"2026-02-20T10:01:00.006Z"}
{"parentUuid":"8693225d-b76a-40ba-9c3d-84bf63753b50","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_019Lybnv4mKEPqR4EFeLWUzk","toolUseID":"toolu_019Lybnv4mKEPqR4EFeLWUzk","timestamp":"2026-02-20T10:01:00.045Z","uuid":"e673ba40-2929-43c1-9386-50242ded56b8"}
{"parentUuid":"8693225d-b76a-40ba-9c3d-84bf63753b50","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019Lybnv4mKEPqR4EFeLWUzk","type":"tool_result","content":"  2413→    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n  2414→\n  2415→    if to_upsert.is_empty() && to_delete.is_empty() {\n  2416→        return Ok(0);\n  2417→    }\n  2418→\n  2419→    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n  2420→    eprintln!(\n  2421→        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n  2422→        to_upsert.len(),\n  2423→        to_delete.len(),\n  2424→        indexing\n  2425→    );\n  2426→\n  2427→    let conn_start = std::time::Instant::now();\n  2428→    let mut conn = db_connection(&state.db_path).map_err(|e| {\n  2429→        eprintln!(\n  2430→            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n  2431→            conn_start.elapsed().as_millis(),\n  2432→            e,\n  2433→            to_upsert.len(),\n  2434→            to_delete.len(),\n  2435→            state.indexing_active.load(AtomicOrdering::Acquire)\n  2436→        );\n  2437→        e\n  2438→    })?;\n  2439→    let mut changed = 0;\n  2440→\n  2441→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2442→    changed += delete_paths(&mut conn, &to_delete)?;\n  2443→\n  2444→    eprintln!(\n  2445→        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n  2446→        changed,\n  2447→        conn_start.elapsed().as_millis()\n  2448→    );\n  2449→    Ok(changed)\n  2450→}\n  2451→\n  2452→#[cfg(target_os = \"macos\")]\n  2453→const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n  2454→\n  2455→#[cfg(target_os = \"macos\")]\n  2456→const DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n  2457→\n  2458→#[cfg(target_os = \"macos\")]\n  2459→fn process_watcher_paths(\n  2460→    app: &AppHandle,\n  2461→    state: &AppState,\n  2462→    pending: &mut HashSet<PathBuf>,\n  2463→    deadline: &mut Option<Instant>,\n  2464→    last_status_emit: &mut Instant,\n  2465→    pending_status_emit: &mut bool,\n  2466→) {\n  2467→    if pending.is_empty() {\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c0c68943-8126-4751-867b-071e4041bf7f","timestamp":"2026-02-20T10:01:00.043Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {","numLines":55,"startLine":2413,"totalLines":5187}},"sourceToolAssistantUUID":"8693225d-b76a-40ba-9c3d-84bf63753b50"}
{"parentUuid":"c0c68943-8126-4751-867b-071e4041bf7f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01DBk3UQe9hcrQ7bTT6A8PR9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TWrGrUVeoLCLpD35FmjmZo","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)","new_string":"    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":992,"cache_read_input_tokens":75566,"output_tokens":627,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":992,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK8L6yR73ynLLddUZVKY","type":"assistant","uuid":"9ba238a6-9bf6-4dad-98b4-a7783184c1cf","timestamp":"2026-02-20T10:01:07.096Z"}
{"parentUuid":"9ba238a6-9bf6-4dad-98b4-a7783184c1cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01TWrGrUVeoLCLpD35FmjmZo","toolUseID":"toolu_01TWrGrUVeoLCLpD35FmjmZo","timestamp":"2026-02-20T10:01:07.106Z","uuid":"8508217f-8d58-4670-8499-c299f67ef4a7"}
{"parentUuid":"9ba238a6-9bf6-4dad-98b4-a7783184c1cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TWrGrUVeoLCLpD35FmjmZo","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"d5d03ecf-8462-4bf3-90a9-0e3c7c4af6af","timestamp":"2026-02-20T10:01:07.105Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)","newString":"    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        indexing\n    );\n\n    let conn_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            conn_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    eprintln!(\n        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",\n        changed,\n        conn_start.elapsed().as_millis()\n    );\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2416,"oldLines":19,"newStart":2416,"newLines":11,"lines":["         return Ok(0);","     }"," ","-    let indexing = state.indexing_active.load(AtomicOrdering::Acquire);","-    eprintln!(","-        \"[watcher] apply_path_changes: upsert={} delete={} indexing_active={}\",","-        to_upsert.len(),","-        to_delete.len(),","-        indexing","-    );","-","-    let conn_start = std::time::Instant::now();","+    let op_start = std::time::Instant::now();","     let mut conn = db_connection(&state.db_path).map_err(|e| {","         eprintln!(","             \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",","-            conn_start.elapsed().as_millis(),","+            op_start.elapsed().as_millis(),","             e,","             to_upsert.len(),","             to_delete.len(),"]},{"oldStart":2441,"oldLines":11,"newStart":2433,"newLines":6,"lines":["     changed += upsert_rows(&mut conn, &to_upsert)?;","     changed += delete_paths(&mut conn, &to_delete)?;"," ","-    eprintln!(","-        \"[watcher] apply_path_changes done: changed={} elapsed={}ms\",","-        changed,","-        conn_start.elapsed().as_millis()","-    );","     Ok(changed)"," }"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"9ba238a6-9bf6-4dad-98b4-a7783184c1cf"}
{"parentUuid":"d5d03ecf-8462-4bf3-90a9-0e3c7c4af6af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01SLRgo5nYsWFYywGZd7E34P","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Cpse4uPWnjYrJaiDPefwZr","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | grep -E \"^error\"","description":"Check for compile errors","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":684,"cache_read_input_tokens":76558,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":684},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK8LcbP9UXmHr88ctZ9j","type":"assistant","uuid":"8691eb9b-4a24-4abe-89e9-5911593d4e42","timestamp":"2026-02-20T10:01:10.381Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-20T10:01:13.428Z","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","content":"{\"task_id\":\"bd7c628\",\"tool_use_id\":\"REDACTED\",\"description\":\"Check for compile errors\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"8691eb9b-4a24-4abe-89e9-5911593d4e42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"bd7c628","timeoutMs":60000},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_01Cpse4uPWnjYrJaiDPefwZr","uuid":"c9bac331-682c-4e52-b95e-f1acd0d06154","timestamp":"2026-02-20T10:01:13.429Z"}
{"parentUuid":"c9bac331-682c-4e52-b95e-f1acd0d06154","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":4,"totalLines":0,"totalBytes":0,"taskId":"bd7c628","timeoutMs":60000},"toolUseID":"bash-progress-1","parentToolUseID":"toolu_01Cpse4uPWnjYrJaiDPefwZr","uuid":"bc3098dd-dc7e-4102-95b5-d694542d6dca","timestamp":"2026-02-20T10:01:14.430Z"}
{"parentUuid":"bc3098dd-dc7e-4102-95b5-d694542d6dca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":5,"totalLines":0,"totalBytes":0,"taskId":"bd7c628","timeoutMs":60000},"toolUseID":"bash-progress-2","parentToolUseID":"toolu_01Cpse4uPWnjYrJaiDPefwZr","uuid":"30a21d04-6fb1-4fd4-ad8c-c11d584a45d4","timestamp":"2026-02-20T10:01:15.430Z"}
{"parentUuid":"8691eb9b-4a24-4abe-89e9-5911593d4e42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Cpse4uPWnjYrJaiDPefwZr","type":"tool_result","content":"","is_error":false}]},"uuid":"eeca23c9-1d7e-407c-83f5-e34c989275b1","timestamp":"2026-02-20T10:01:16.092Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false,"returnCodeInterpretation":"No matches found","noOutputExpected":false},"sourceToolAssistantUUID":"8691eb9b-4a24-4abe-89e9-5911593d4e42"}
{"parentUuid":"eeca23c9-1d7e-407c-83f5-e34c989275b1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","message":{"model":"claude-sonnet-4-6","id":"msg_01DV3HePaY9UxTZuU1gHfn9m","type":"message","role":"assistant","content":[{"type":"text","text":"완료. 두 가지 수정:\n- 항상 실행되던 eprintln 2개 (`apply_path_changes` 진입/완료 로그) 제거\n- `conn_start` → `op_start` 으로 rename (전체 write 시간 측정임을 명확히)\n\n에러 시에만 로그가 남는 구조로 정리됐습니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":144,"cache_read_input_tokens":77242,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":144},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK8MGdcpmiT7YBvkGCjW","type":"assistant","uuid":"b32bccc0-d7bd-4460-aec3-e5012c33d9af","timestamp":"2026-02-20T10:01:20.266Z"}
{"parentUuid":"b32bccc0-d7bd-4460-aec3-e5012c33d9af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"9f6de1e4-2422-4fc5-a3a0-c390064e8a4a","toolUseID":"9f6de1e4-2422-4fc5-a3a0-c390064e8a4a","timestamp":"2026-02-20T10:01:20.321Z","uuid":"297f1670-1e9b-4e24-bbdf-df1b25d95460"}
{"type":"queue-operation","operation":"remove","timestamp":"2026-02-20T10:01:21.547Z","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951"}
{"parentUuid":"297f1670-1e9b-4e24-bbdf-df1b25d95460","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1189}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-20T10:01:21.511Z","uuid":"c7112ff3-c5c0-49dd-99c6-d365eaccbabf","toolUseID":"9f6de1e4-2422-4fc5-a3a0-c390064e8a4a"}
{"type":"file-history-snapshot","messageId":"1affb77e-5c3b-4392-b77a-6185f06c1647","snapshot":{"messageId":"1affb77e-5c3b-4392-b77a-6185f06c1647","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v4","version":4,"backupTime":"2026-02-20T10:21:57.829Z"}},"timestamp":"2026-02-20T10:21:57.828Z"},"isSnapshotUpdate":false}
{"parentUuid":"c7112ff3-c5c0-49dd-99c6-d365eaccbabf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":"warning 수정해줘\n\nwarning: function `set_ready_with_cached_counts` is never used\n    --> src/main.rs:1810:15\n     |\n1810 | pub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `#[warn(dead_code)]` on by default\n\nwarning: function `start_full_index_worker_silent` is never used\n    --> src/main.rs:1843:15\n     |\n1843 | pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nwarning: associated items `build` and `entries` are never used\n   --> src/mem_search.rs:61:12\n    |\n 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.69s\n     Running `target/debug/everything`"},"uuid":"1affb77e-5c3b-4392-b77a-6185f06c1647","timestamp":"2026-02-20T10:21:56.217Z","permissionMode":"bypassPermissions"}
{"parentUuid":"1affb77e-5c3b-4392-b77a-6185f06c1647","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"e79c89dc-4efc-4e2e-a741-e4dfaa03f951","version":"2.1.49","gitBranch":"main","slug":"joyful-cuddling-wreath","type":"user","message":{"role":"user","content":[{"type":"text","text":"[Request interrupted by user]"}]},"uuid":"41f1fc4d-451d-42b4-8d08-69a344724577","timestamp":"2026-02-20T10:21:58.781Z"}
