{"type":"file-history-snapshot","messageId":"b53171aa-c670-474c-822b-9c82ab3dfab0","snapshot":{"messageId":"b53171aa-c670-474c-822b-9c82ab3dfab0","trackedFileBackups":{},"timestamp":"2026-02-20T09:12:44.090Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:clear","command":"entire hooks claude-code session-start"},"parentToolUseID":"06a23af0-ac64-4bb8-b4f2-bf00f8f952ac","toolUseID":"06a23af0-ac64-4bb8-b4f2-bf00f8f952ac","timestamp":"2026-02-20T09:12:43.762Z","uuid":"619a4ed3-e9f9-48c8-b2d9-387d6d2c1d8a"}
{"parentUuid":"619a4ed3-e9f9-48c8-b2d9-387d6d2c1d8a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-caveat>Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.</local-command-caveat>"},"isMeta":true,"uuid":"63bcbf72-d793-4064-8272-e0fee52e056a","timestamp":"2026-02-20T09:12:44.090Z"}
{"parentUuid":"63bcbf72-d793-4064-8272-e0fee52e056a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<command-name>/clear</command-name>\n            <command-message>clear</command-message>\n            <command-args></command-args>"},"uuid":"b53171aa-c670-474c-822b-9c82ab3dfab0","timestamp":"2026-02-20T09:12:43.500Z"}
{"parentUuid":"b53171aa-c670-474c-822b-9c82ab3dfab0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-stdout></local-command-stdout>"},"uuid":"42711318-8383-49f3-8997-8d4117370230","timestamp":"2026-02-20T09:12:44.090Z"}
{"type":"file-history-snapshot","messageId":"6c135ae7-deb9-45d0-bdfd-39ed1fcc89e0","snapshot":{"messageId":"6c135ae7-deb9-45d0-bdfd-39ed1fcc89e0","trackedFileBackups":{},"timestamp":"2026-02-20T09:13:19.001Z"},"isSnapshotUpdate":false}
{"parentUuid":"42711318-8383-49f3-8997-8d4117370230","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"Index: Error\nEntries: 1,171,663\nReset Index\nWatcher update failed: database is locked \n\n로그 추가해서 원인을 확인해줄래? 재실행하면 바로 재현돼"},"uuid":"6c135ae7-deb9-45d0-bdfd-39ed1fcc89e0","timestamp":"2026-02-20T09:13:17.652Z","permissionMode":"bypassPermissions"}
{"parentUuid":"6c135ae7-deb9-45d0-bdfd-39ed1fcc89e0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_019Ej96Q6QiDapdg5VwvBASZ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is reporting an issue where:\n1. Index shows \"Error\"\n2. There are 1,171,663 entries\n3. \"Watcher update failed: database is locked\" error message\n\nThey want me to add logging to identify the root cause, and say it can be reproduced by restarting the app.\n\nLet me look at the relevant code to understand where the watcher update happens and where the database locking issue might occur.","signature":"Eq0ECkYICxgCKkAU7CUIiNPTcrQb3QmR0Ymn+YLsgz9QTJw/EOYKEcauFiWAwBrJ/km3kWxTsalz7V+hnXadjuO++YwmkWtPNVp8EgxV7taVizRWLp4tI8AaDFOO5Ya+8JaSzt3d9SIwMGN6Yd8ZuQXwgTtNHdvuMAVPvsTq5Zvs1NECW2/ddDwmTeVly60O6fWEj4bcnl6GKpQD9G9DIJ973z4px7YwFewXUJKvWM9HgTOEXkHFERxj92rxsmZq04VjbAC8zvA0dP1373RLV45Gy+shvp1O4LezF9hEx0D/NOvoeGvYA95vJRkyBIx1GlSig0CPRlWoOrI6NOFjR23b6o8K/ry6iLirIxzpZxUTfwddyqsWy3IqOHPwztTXENFPUVAA8LV0lQgPPjeVexenztzv5kni/Lv40v0MiE6zHnz+u9xcXr3pHmfXOu8pCmglxNRhdAKY+yvjkZi7C9lU1kzSz+f0W/VVFkzX71+okjwHyDo4ta05R8xWzWYaZGNBPG3D8SlmiMdzQrAiKIkHMqkufIwNOHdZWth9HviDmMKENc6MF5YFYrtzX0CX/OLFXp/RL8okYxT4RvAoLoe3etCLyNLphI3BBnC338tC7LsPzzujyPFJ82Jqb6CZiCse+YuVq4XdxsvnpGasBqnT1yYG2YZfMllTav487u0nrxYGoHq7xUVbOvWxkue8nQq/JdlUbCr800T9YhAAxrHmwivaYyK7ms77B9H747AYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7977,"cache_read_input_tokens":25541,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7977},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4hDsX6LsL9zHRXjYB5","type":"assistant","uuid":"866c1ca8-167a-498e-a7d7-a1a057636303","timestamp":"2026-02-20T09:13:23.247Z"}
{"parentUuid":"866c1ca8-167a-498e-a7d7-a1a057636303","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_019Ej96Q6QiDapdg5VwvBASZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011KtphqZcDoC2hSSyVWaxNz","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7977,"cache_read_input_tokens":25541,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7977},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4hDsX6LsL9zHRXjYB5","type":"assistant","uuid":"3211342b-f352-4787-baf0-ed2decd3e9a0","timestamp":"2026-02-20T09:13:24.045Z"}
{"parentUuid":"3211342b-f352-4787-baf0-ed2decd3e9a0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_011KtphqZcDoC2hSSyVWaxNz","toolUseID":"toolu_011KtphqZcDoC2hSSyVWaxNz","timestamp":"2026-02-20T09:13:24.064Z","uuid":"2978004d-e03f-4bc2-aa3b-e42e43ad8b05"}
{"parentUuid":"3211342b-f352-4787-baf0-ed2decd3e9a0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011KtphqZcDoC2hSSyVWaxNz","type":"tool_result","content":"     1→#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n     2→\n     3→use std::{\n     4→    cmp::Ordering,\n     5→    collections::{HashMap, HashSet},\n     6→    fs,\n     7→    hash::{Hash, Hasher},\n     8→    io::{self, BufRead, BufReader, Write},\n     9→    path::{Path, PathBuf},\n    10→    process::{Command, Stdio},\n    11→    sync::{\n    12→        atomic::{AtomicBool, Ordering as AtomicOrdering},\n    13→        Arc, OnceLock,\n    14→    },\n    15→    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n    16→};\n    17→\n    18→use parking_lot::{Mutex, RwLock};\n    19→use rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\n    20→use serde::Serialize;\n    21→use tauri::{AppHandle, Emitter, Manager, State};\n    22→#[cfg(target_os = \"macos\")]\n    23→use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n    24→#[cfg(target_os = \"windows\")]\n    25→use std::os::windows::process::CommandExt;\n    26→use walkdir::WalkDir;\n    27→\n    28→mod fd_search;\n    29→mod gitignore_filter;\n    30→#[cfg(target_os = \"macos\")]\n    31→mod mac;\n    32→mod mem_search;\n    33→mod query;\n    34→#[cfg(target_os = \"windows\")]\n    35→mod win;\n    36→use fd_search::{FdSearchCache, FdSearchResultDto};\n    37→use query::{escape_like, parse_query, SearchMode};\n    38→\n    39→const DEFAULT_LIMIT: u32 = 300;\n    40→const SHORT_QUERY_LIMIT: u32 = 100;\n    41→const MAX_LIMIT: u32 = 1000;\n    42→pub(crate) const BATCH_SIZE: usize = 10_000;\n    43→const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n    44→pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n    45→const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n    46→const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n    47→const DB_VERSION: i32 = 4;\n    48→const DEFERRED_DIR_NAMES: &[&str] = &[\n    49→    \"Library\", \".Trash\", \".Trashes\",\n    50→    // Windows system directories (deferred when scan_root is C:\\)\n    51→    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    52→    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n    53→];\n    54→const SHALLOW_SCAN_DEPTH: usize = 6;\n    55→const JWALK_NUM_THREADS: usize = 4;\n    56→\n    57→pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    58→    \".git\",\n    59→    \"node_modules\",\n    60→    \".Trash\",\n    61→    \".Trashes\",\n    62→    \".npm\",\n    63→    \".cache\",\n    64→    \"CMakeFiles\",\n    65→    \".qtc_clangd\",\n    66→    \"__pycache__\",\n    67→    \".gradle\",\n    68→];\n    69→\n    70→pub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    71→    // macOS\n    72→    \"Library/Caches\",\n    73→    \"Library/Developer/CoreSimulator\",\n    74→    \"Library/Logs\",\n    75→    // Cross-platform\n    76→    \".vscode/extensions\",\n    77→    // Windows: noisy system directories under AppData\n    78→    \"AppData/Local/Temp\",\n    79→    \"AppData/Local/Microsoft\",\n    80→    \"AppData/Local/Google\",\n    81→    \"AppData/Local/Packages\",\n    82→];\n    83→\n    84→type AppResult<T> = Result<T, String>;\n    85→static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n    86→static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n    87→static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n    88→\n    89→#[derive(Debug, Clone, Serialize)]\n    90→#[serde(rename_all = \"camelCase\")]\n    91→pub struct EntryDto {\n    92→    pub path: String,\n    93→    pub name: String,\n    94→    pub dir: String,\n    95→    pub is_dir: bool,\n    96→    pub ext: Option<String>,\n    97→    pub size: Option<i64>,\n    98→    pub mtime: Option<i64>,\n    99→}\n   100→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"cebcbc64-9d5b-479a-a65f-b89a01a62c50","timestamp":"2026-02-20T09:13:24.063Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n","numLines":100,"startLine":1,"totalLines":5087}},"sourceToolAssistantUUID":"3211342b-f352-4787-baf0-ed2decd3e9a0"}
{"parentUuid":"cebcbc64-9d5b-479a-a65f-b89a01a62c50","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01LfTs6qiU6aGqGXr3msCPMt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01W1AxbpMumCrxGqSt1m2RYG","name":"Grep","input":{"pattern":"database is locked|Watcher update failed|watcher","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":5},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1698,"cache_read_input_tokens":33518,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1698},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4hZqJqKqaubcPfnTGb","type":"assistant","uuid":"fdd95f8a-b36b-4f6f-8590-cc92a7d70679","timestamp":"2026-02-20T09:13:27.244Z"}
{"parentUuid":"fdd95f8a-b36b-4f6f-8590-cc92a7d70679","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01W1AxbpMumCrxGqSt1m2RYG","toolUseID":"toolu_01W1AxbpMumCrxGqSt1m2RYG","timestamp":"2026-02-20T09:13:27.992Z","uuid":"4c92f7fb-f59b-4430-9aca-bc42a0e8097b"}
{"parentUuid":"fdd95f8a-b36b-4f6f-8590-cc92a7d70679","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01W1AxbpMumCrxGqSt1m2RYG","type":"tool_result","content":"288-    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n289-    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n290-    /// In-memory index for instant search while DB upsert runs in background.\n291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293:    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295:    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n300-pub(crate) struct NegativeNameEntry {\n301-    query_lower: String,\n--\n2427-\n2428-#[cfg(target_os = \"macos\")]\n2429-const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n2430-\n2431-#[cfg(target_os = \"macos\")]\n2432:fn process_watcher_paths(\n2433-    app: &AppHandle,\n2434-    state: &AppState,\n2435-    pending: &mut HashSet<PathBuf>,\n2436-    last_status_emit: &mut Instant,\n2437-    pending_status_emit: &mut bool,\n--\n2467-            }\n2468-            let mut status = state.status.lock();\n2469-            if !matches!(status.state, IndexState::Indexing) {\n2470-                status.state = IndexState::Error;\n2471-            }\n2472:            status.message = Some(format!(\"Watcher update failed: {err}\"));\n2473-            drop(status);\n2474:            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n2475-        }\n2476-    }\n2477-}\n2478-\n2479-#[cfg(target_os = \"macos\")]\n--\n2487-\n2488-#[cfg(target_os = \"macos\")]\n2489-const MUST_SCAN_THRESHOLD: usize = 10;\n2490-\n2491-#[cfg(target_os = \"macos\")]\n2492:fn start_fsevent_watcher_worker(\n2493-    app: AppHandle,\n2494-    state: AppState,\n2495-    since_event_id: Option<u64>,\n2496-    conditional: bool,\n2497-) {\n2498-    use std::sync::mpsc::{self, RecvTimeoutError};\n2499-    std::thread::spawn(move || {\n2500-        let (tx, rx) = mpsc::channel();\n2501-\n2502:        let mut watcher =\n2503:            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n2504-                Ok(w) => w,\n2505-                Err(err) => {\n2506-                    set_state(\n2507-                        &state,\n2508-                        IndexState::Error,\n2509:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2510-                    );\n2511-                    emit_index_state(\n2512-                        &app,\n2513-                        \"Error\",\n2514:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2515-                    );\n2516-                    return;\n2517-                }\n2518-            };\n2519-\n2520-        if conditional {\n2521:            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n2522-            set_state(&state, IndexState::Ready, None);\n2523-            emit_index_state(&app, \"Ready\", None);\n2524-        }\n2525-\n2526-        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n--\n2544-                    }\n2545-                }\n2546-                None => Duration::from_secs(1),\n2547-            };\n2548-            match rx.recv_timeout(wait) {\n2549:                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n2550-                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n2551-                    let prev_len = pending_paths.len();\n2552-                    for path in paths {\n2553-                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n2554-                            pending_paths.insert(path);\n--\n2556-                    }\n2557-                    if pending_paths.len() > prev_len {\n2558-                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n2559-                    }\n2560-                }\n2561:                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n2562-                    must_scan_count += 1;\n2563-                    if replay_phase\n2564-                        && must_scan_count >= MUST_SCAN_THRESHOLD\n2565-                        && !full_scan_triggered\n2566-                    {\n--\n2590-                                }\n2591-                            }\n2592-                        }\n2593-                    }\n2594-                }\n2595:                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n2596:                    process_watcher_paths(\n2597-                        &app,\n2598-                        &state,\n2599-                        &mut pending_paths,\n2600-                        &mut last_status_emit,\n2601-                        &mut pending_status_emit,\n--\n2618-                Err(RecvTimeoutError::Disconnected) => break,\n2619-            }\n2620-\n2621-            if let Some(due) = deadline {\n2622-                if Instant::now() >= due {\n2623:                    process_watcher_paths(\n2624-                        &app,\n2625-                        &state,\n2626-                        &mut pending_paths,\n2627-                        &mut last_status_emit,\n2628-                        &mut pending_status_emit,\n--\n2637-                pending_status_emit = false;\n2638-            }\n2639-\n2640-            // Periodic event_id flush\n2641-            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n2642:                let eid = watcher.last_event_id();\n2643-                let _ = persist_event_id(&state.db_path, eid);\n2644-                last_flush = Instant::now();\n2645-            }\n2646-\n2647-            // Periodic count refresh to keep in-memory counts accurate\n--\n2650-                last_count_refresh = Instant::now();\n2651-            }\n2652-        }\n2653-\n2654-        // Final flush on shutdown\n2655:        let eid = watcher.last_event_id();\n2656-        let _ = persist_event_id(&state.db_path, eid);\n2657:        watcher.stop();\n2658-    });\n2659-}\n2660-\n2661-fn validate_new_name(new_name: &str) -> AppResult<String> {\n2662-    let trimmed = new_name.trim();\n--\n2786-    tauri::async_runtime::spawn_blocking(move || {\n2787-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n2788-            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n2789-        }\n2790-\n2791:        // Stop existing file watcher and wait for it to fully exit\n2792:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2794:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2795-            if std::time::Instant::now() >= deadline {\n2796:                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2797-                break;\n2798-            }\n2799-            std::thread::sleep(std::time::Duration::from_millis(50));\n2800-        }\n2801-\n--\n2818-\n2819-        invalidate_search_caches(&state);\n2820-\n2821-        emit_index_updated(&app, 0, now_epoch(), 0);\n2822-\n2823:        // Allow new watcher to start\n2824:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2825-\n2826-        #[cfg(target_os = \"windows\")]\n2827-        {\n2828-            win::start_windows_indexing(app, state);\n2829-            Ok(())\n--\n4454-        fd_search_cache: Arc::new(Mutex::new(None)),\n4455-        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4456-        ignore_cache: Arc::new(Mutex::new(None)),\n4457-        gitignore,\n4458-        mem_index: Arc::new(RwLock::new(None)),\n4459:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4460:        watcher_active: Arc::new(AtomicBool::new(false)),\n4461-    };\n4462-\n4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n4464-    app.manage(state.clone());\n4465-    if !bench_mode {\n--\n4523-                        (eid, complete)\n4524-                    })\n4525-                    .unwrap_or((None, false));\n4526-\n4527-                if stored_event_id.is_some() && index_complete {\n4528:                    // Conditional startup: try watcher replay first, skip full scan if OK\n4529:                    start_fsevent_watcher_worker(\n4530-                        app_handle.clone(),\n4531-                        state.clone(),\n4532-                        stored_event_id,\n4533-                        true,\n4534-                    );\n4535-                } else {\n4536-                    if !index_complete {\n4537-                        eprintln!(\"[mac] index incomplete — starting full index\");\n4538-                    }\n4539-                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n4540:                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n4541-                }\n4542-            }\n4543-        }\n4544-\n4545-        #[cfg(target_os = \"windows\")]\n--\n4666-            fd_search_cache: Arc::new(Mutex::new(None)),\n4667-            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4668-            ignore_cache: Arc::new(Mutex::new(None)),\n4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4670-            mem_index: Arc::new(RwLock::new(None)),\n4671:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4672:            watcher_active: Arc::new(AtomicBool::new(false)),\n4673-        }\n4674-    }\n4675-\n4676-    #[test]\n4677-    fn should_skip_path_for_ignored_descendant() {"}]},"uuid":"cfc442aa-ad50-47fe-89b3-c9512f8af5d8","timestamp":"2026-02-20T09:13:27.991Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"288-    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n289-    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n290-    /// In-memory index for instant search while DB upsert runs in background.\n291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293:    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295:    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n300-pub(crate) struct NegativeNameEntry {\n301-    query_lower: String,\n--\n2427-\n2428-#[cfg(target_os = \"macos\")]\n2429-const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n2430-\n2431-#[cfg(target_os = \"macos\")]\n2432:fn process_watcher_paths(\n2433-    app: &AppHandle,\n2434-    state: &AppState,\n2435-    pending: &mut HashSet<PathBuf>,\n2436-    last_status_emit: &mut Instant,\n2437-    pending_status_emit: &mut bool,\n--\n2467-            }\n2468-            let mut status = state.status.lock();\n2469-            if !matches!(status.state, IndexState::Indexing) {\n2470-                status.state = IndexState::Error;\n2471-            }\n2472:            status.message = Some(format!(\"Watcher update failed: {err}\"));\n2473-            drop(status);\n2474:            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n2475-        }\n2476-    }\n2477-}\n2478-\n2479-#[cfg(target_os = \"macos\")]\n--\n2487-\n2488-#[cfg(target_os = \"macos\")]\n2489-const MUST_SCAN_THRESHOLD: usize = 10;\n2490-\n2491-#[cfg(target_os = \"macos\")]\n2492:fn start_fsevent_watcher_worker(\n2493-    app: AppHandle,\n2494-    state: AppState,\n2495-    since_event_id: Option<u64>,\n2496-    conditional: bool,\n2497-) {\n2498-    use std::sync::mpsc::{self, RecvTimeoutError};\n2499-    std::thread::spawn(move || {\n2500-        let (tx, rx) = mpsc::channel();\n2501-\n2502:        let mut watcher =\n2503:            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n2504-                Ok(w) => w,\n2505-                Err(err) => {\n2506-                    set_state(\n2507-                        &state,\n2508-                        IndexState::Error,\n2509:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2510-                    );\n2511-                    emit_index_state(\n2512-                        &app,\n2513-                        \"Error\",\n2514:                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n2515-                    );\n2516-                    return;\n2517-                }\n2518-            };\n2519-\n2520-        if conditional {\n2521:            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n2522-            set_state(&state, IndexState::Ready, None);\n2523-            emit_index_state(&app, \"Ready\", None);\n2524-        }\n2525-\n2526-        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n--\n2544-                    }\n2545-                }\n2546-                None => Duration::from_secs(1),\n2547-            };\n2548-            match rx.recv_timeout(wait) {\n2549:                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n2550-                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n2551-                    let prev_len = pending_paths.len();\n2552-                    for path in paths {\n2553-                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n2554-                            pending_paths.insert(path);\n--\n2556-                    }\n2557-                    if pending_paths.len() > prev_len {\n2558-                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n2559-                    }\n2560-                }\n2561:                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n2562-                    must_scan_count += 1;\n2563-                    if replay_phase\n2564-                        && must_scan_count >= MUST_SCAN_THRESHOLD\n2565-                        && !full_scan_triggered\n2566-                    {\n--\n2590-                                }\n2591-                            }\n2592-                        }\n2593-                    }\n2594-                }\n2595:                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n2596:                    process_watcher_paths(\n2597-                        &app,\n2598-                        &state,\n2599-                        &mut pending_paths,\n2600-                        &mut last_status_emit,\n2601-                        &mut pending_status_emit,\n--\n2618-                Err(RecvTimeoutError::Disconnected) => break,\n2619-            }\n2620-\n2621-            if let Some(due) = deadline {\n2622-                if Instant::now() >= due {\n2623:                    process_watcher_paths(\n2624-                        &app,\n2625-                        &state,\n2626-                        &mut pending_paths,\n2627-                        &mut last_status_emit,\n2628-                        &mut pending_status_emit,\n--\n2637-                pending_status_emit = false;\n2638-            }\n2639-\n2640-            // Periodic event_id flush\n2641-            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n2642:                let eid = watcher.last_event_id();\n2643-                let _ = persist_event_id(&state.db_path, eid);\n2644-                last_flush = Instant::now();\n2645-            }\n2646-\n2647-            // Periodic count refresh to keep in-memory counts accurate\n--\n2650-                last_count_refresh = Instant::now();\n2651-            }\n2652-        }\n2653-\n2654-        // Final flush on shutdown\n2655:        let eid = watcher.last_event_id();\n2656-        let _ = persist_event_id(&state.db_path, eid);\n2657:        watcher.stop();\n2658-    });\n2659-}\n2660-\n2661-fn validate_new_name(new_name: &str) -> AppResult<String> {\n2662-    let trimmed = new_name.trim();\n--\n2786-    tauri::async_runtime::spawn_blocking(move || {\n2787-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n2788-            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n2789-        }\n2790-\n2791:        // Stop existing file watcher and wait for it to fully exit\n2792:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2794:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2795-            if std::time::Instant::now() >= deadline {\n2796:                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2797-                break;\n2798-            }\n2799-            std::thread::sleep(std::time::Duration::from_millis(50));\n2800-        }\n2801-\n--\n2818-\n2819-        invalidate_search_caches(&state);\n2820-\n2821-        emit_index_updated(&app, 0, now_epoch(), 0);\n2822-\n2823:        // Allow new watcher to start\n2824:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2825-\n2826-        #[cfg(target_os = \"windows\")]\n2827-        {\n2828-            win::start_windows_indexing(app, state);\n2829-            Ok(())\n--\n4454-        fd_search_cache: Arc::new(Mutex::new(None)),\n4455-        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4456-        ignore_cache: Arc::new(Mutex::new(None)),\n4457-        gitignore,\n4458-        mem_index: Arc::new(RwLock::new(None)),\n4459:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4460:        watcher_active: Arc::new(AtomicBool::new(false)),\n4461-    };\n4462-\n4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n4464-    app.manage(state.clone());\n4465-    if !bench_mode {\n--\n4523-                        (eid, complete)\n4524-                    })\n4525-                    .unwrap_or((None, false));\n4526-\n4527-                if stored_event_id.is_some() && index_complete {\n4528:                    // Conditional startup: try watcher replay first, skip full scan if OK\n4529:                    start_fsevent_watcher_worker(\n4530-                        app_handle.clone(),\n4531-                        state.clone(),\n4532-                        stored_event_id,\n4533-                        true,\n4534-                    );\n4535-                } else {\n4536-                    if !index_complete {\n4537-                        eprintln!(\"[mac] index incomplete — starting full index\");\n4538-                    }\n4539-                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n4540:                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n4541-                }\n4542-            }\n4543-        }\n4544-\n4545-        #[cfg(target_os = \"windows\")]\n--\n4666-            fd_search_cache: Arc::new(Mutex::new(None)),\n4667-            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4668-            ignore_cache: Arc::new(Mutex::new(None)),\n4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4670-            mem_index: Arc::new(RwLock::new(None)),\n4671:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4672:            watcher_active: Arc::new(AtomicBool::new(false)),\n4673-        }\n4674-    }\n4675-\n4676-    #[test]\n4677-    fn should_skip_path_for_ignored_descendant() {","numLines":236},"sourceToolAssistantUUID":"fdd95f8a-b36b-4f6f-8590-cc92a7d70679"}
{"parentUuid":"cfc442aa-ad50-47fe-89b3-c9512f8af5d8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Kzcj2TaW1eMUhNmpuoRua8","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me look at the `process_watcher_paths` function to understand where \"Watcher update failed: database is locked\" comes from. Let me read that section more carefully.","signature":"EtUCCkYICxgCKkDOdsUKegohOzOVlZJMI7mv1MdBP2jTrFq7WM0k+QerEpbwi4LHSPQ5Cqy1uuJVHPCUtyYwEzljqUNLT3CcAlYfEgxbca1sIolIEMajrR0aDCCPvMI7O26bchhjZSIwWIHwZXsj7J0uIQ2sRNW/Qqv3es29CStS/u9/z5reb4QsPRiMtAq+u1Sb1eAChoRBKrwBM1zJQ4CDL877lY30eooB40Fe63szpZsqbsnZVWjKHNqIyOWAve1Q2ZIgc726I99urzLNmsuub1p0R2GDBggwjZYFVBBufH977meRhMG0aBigZmUga9wIBazVESRFdHbroF+w8U7o62F92kctaukJhLDJnbkbA8jcZ46QJtgFyScpmi+W2ow5Aob9nIszzzSVEU98Df6S/gnLGvbmO7yT+MNKVr+Mj4T7K99MRj6HiSBNoJZmBvBk5LVmIfcYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3258,"cache_read_input_tokens":35216,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3258},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4hrEJGRm3zaBoRxCW7","type":"assistant","uuid":"2bfb69b1-e185-44c2-bedd-1dff68d144bd","timestamp":"2026-02-20T09:13:30.341Z"}
{"parentUuid":"2bfb69b1-e185-44c2-bedd-1dff68d144bd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Kzcj2TaW1eMUhNmpuoRua8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013pkxbNfwfZmwqnPo43QUbN","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2432,"limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3258,"cache_read_input_tokens":35216,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3258},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4hrEJGRm3zaBoRxCW7","type":"assistant","uuid":"c595648a-0336-46db-8a6b-d22f62527697","timestamp":"2026-02-20T09:13:31.424Z"}
{"parentUuid":"c595648a-0336-46db-8a6b-d22f62527697","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013pkxbNfwfZmwqnPo43QUbN","toolUseID":"toolu_013pkxbNfwfZmwqnPo43QUbN","timestamp":"2026-02-20T09:13:31.434Z","uuid":"e27ff10d-3aac-401c-9482-41468e807228"}
{"parentUuid":"c595648a-0336-46db-8a6b-d22f62527697","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013pkxbNfwfZmwqnPo43QUbN","type":"tool_result","content":"  2432→fn process_watcher_paths(\n  2433→    app: &AppHandle,\n  2434→    state: &AppState,\n  2435→    pending: &mut HashSet<PathBuf>,\n  2436→    last_status_emit: &mut Instant,\n  2437→    pending_status_emit: &mut bool,\n  2438→) {\n  2439→    if pending.is_empty() {\n  2440→        return;\n  2441→    }\n  2442→\n  2443→    if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2444→        return;\n  2445→    }\n  2446→\n  2447→    let mut batch: Vec<PathBuf> = pending.drain().collect();\n  2448→    batch.sort();\n  2449→\n  2450→    match apply_path_changes(state, &batch) {\n  2451→        Ok(changed) => {\n  2452→            if changed > 0 {\n  2453→                invalidate_search_caches(state);\n  2454→                touch_status_updated(state);\n  2455→                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2456→                    let _ = refresh_and_emit_status_counts(app, state);\n  2457→                    *last_status_emit = Instant::now();\n  2458→                    *pending_status_emit = false;\n  2459→                } else {\n  2460→                    *pending_status_emit = true;\n  2461→                }\n  2462→            }\n  2463→        }\n  2464→        Err(err) => {\n  2465→            if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2466→                return;\n  2467→            }\n  2468→            let mut status = state.status.lock();\n  2469→            if !matches!(status.state, IndexState::Indexing) {\n  2470→                status.state = IndexState::Error;\n  2471→            }\n  2472→            status.message = Some(format!(\"Watcher update failed: {err}\"));\n  2473→            drop(status);\n  2474→            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n  2475→        }\n  2476→    }\n  2477→}\n  2478→\n  2479→#[cfg(target_os = \"macos\")]\n  2480→const EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n  2481→\n  2482→#[cfg(target_os = \"macos\")]\n  2483→fn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n  2484→    let conn = db_connection(db_path)?;\n  2485→    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n  2486→}\n  2487→\n  2488→#[cfg(target_os = \"macos\")]\n  2489→const MUST_SCAN_THRESHOLD: usize = 10;\n  2490→\n  2491→#[cfg(target_os = \"macos\")]\n  2492→fn start_fsevent_watcher_worker(\n  2493→    app: AppHandle,\n  2494→    state: AppState,\n  2495→    since_event_id: Option<u64>,\n  2496→    conditional: bool,\n  2497→) {\n  2498→    use std::sync::mpsc::{self, RecvTimeoutError};\n  2499→    std::thread::spawn(move || {\n  2500→        let (tx, rx) = mpsc::channel();\n  2501→\n  2502→        let mut watcher =\n  2503→            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n  2504→                Ok(w) => w,\n  2505→                Err(err) => {\n  2506→                    set_state(\n  2507→                        &state,\n  2508→                        IndexState::Error,\n  2509→                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n  2510→                    );\n  2511→                    emit_index_state(\n  2512→                        &app,\n  2513→                        \"Error\",\n  2514→                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n  2515→                    );\n  2516→                    return;\n  2517→                }\n  2518→            };\n  2519→\n  2520→        if conditional {\n  2521→            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n  2522→            set_state(&state, IndexState::Ready, None);\n  2523→            emit_index_state(&app, \"Ready\", None);\n  2524→        }\n  2525→\n  2526→        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n  2527→        let mut deadline: Option<Instant> = None;\n  2528→        let mut last_flush = Instant::now();\n  2529→        let mut last_status_emit = Instant::now();\n  2530→        let mut pending_status_emit = false;\n  2531→        let mut last_count_refresh = Instant::now();\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"7ffd2440-49b2-47ea-810a-a9631a9830c5","timestamp":"2026-02-20T09:13:31.432Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();","numLines":100,"startLine":2432,"totalLines":5087}},"sourceToolAssistantUUID":"c595648a-0336-46db-8a6b-d22f62527697"}
{"parentUuid":"7ffd2440-49b2-47ea-810a-a9631a9830c5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_014DvREdst8uDbuSCNXLGuWx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017npGuJ7DfkwDSjeNemtevU","name":"Grep","input":{"pattern":"fn apply_path_changes|fn db_connection","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1655,"cache_read_input_tokens":38474,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1655},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4i7puV6xLiZ92XX9Yp","type":"assistant","uuid":"274743d7-70cd-4b11-8eeb-cddb0f21d55a","timestamp":"2026-02-20T09:13:36.363Z"}
{"parentUuid":"274743d7-70cd-4b11-8eeb-cddb0f21d55a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_017npGuJ7DfkwDSjeNemtevU","toolUseID":"toolu_017npGuJ7DfkwDSjeNemtevU","timestamp":"2026-02-20T09:13:37.166Z","uuid":"314107c5-7e7c-44ba-abd6-e50b095f44e1"}
{"parentUuid":"274743d7-70cd-4b11-8eeb-cddb0f21d55a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017npGuJ7DfkwDSjeNemtevU","type":"tool_result","content":"356-    }\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n--\n370-    Ok(conn)\n371-}\n372-\n373:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n374-    db_connection_with_timeout(db_path, 3000)\n375-}\n376-\n377:fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n378-    let conn = db_connection_with_timeout(db_path, 200)?;\n379-    conn.execute_batch(\n380-        \"PRAGMA cache_size = -32768;\n--\n2379-}\n2380-\n2381-#[cfg(target_os = \"macos\")]\n2382:fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n2383-    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n2384-    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n2385-    let mut to_delete = Vec::new();"}]},"uuid":"9d9a774e-fba5-4e01-b9b3-a3c17a1793b7","timestamp":"2026-02-20T09:13:37.164Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"356-    }\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n--\n370-    Ok(conn)\n371-}\n372-\n373:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n374-    db_connection_with_timeout(db_path, 3000)\n375-}\n376-\n377:fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n378-    let conn = db_connection_with_timeout(db_path, 200)?;\n379-    conn.execute_batch(\n380-        \"PRAGMA cache_size = -32768;\n--\n2379-}\n2380-\n2381-#[cfg(target_os = \"macos\")]\n2382:fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n2383-    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n2384-    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n2385-    let mut to_delete = Vec::new();","numLines":27},"sourceToolAssistantUUID":"274743d7-70cd-4b11-8eeb-cddb0f21d55a"}
{"parentUuid":"9d9a774e-fba5-4e01-b9b3-a3c17a1793b7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01HZmtGpGwXeWKRKmquicM1z","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QhSKwrDqkUaANRd1Xm7TFt","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2382,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":514,"cache_read_input_tokens":40129,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":514},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4iXVT3nT1UgZ2Mh65g","type":"assistant","uuid":"e38361f2-9a6b-4f5d-b1fd-676ae3dc5c1e","timestamp":"2026-02-20T09:13:39.116Z"}
{"parentUuid":"e38361f2-9a6b-4f5d-b1fd-676ae3dc5c1e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01QhSKwrDqkUaANRd1Xm7TFt","toolUseID":"toolu_01QhSKwrDqkUaANRd1Xm7TFt","timestamp":"2026-02-20T09:13:39.127Z","uuid":"be4aceff-9d3a-47ba-9889-233de3db61b2"}
{"parentUuid":"e38361f2-9a6b-4f5d-b1fd-676ae3dc5c1e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QhSKwrDqkUaANRd1Xm7TFt","type":"tool_result","content":"  2382→fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n  2383→    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n  2384→    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n  2385→    let mut to_delete = Vec::new();\n  2386→\n  2387→    for path in paths {\n  2388→        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n  2389→            continue;\n  2390→        }\n  2391→\n  2392→        let path_str = path.to_string_lossy().to_string();\n  2393→        if path_str.is_empty() {\n  2394→            continue;\n  2395→        }\n  2396→\n  2397→        if is_recently_touched(state, &path_str) {\n  2398→            continue;\n  2399→        }\n  2400→\n  2401→        match fs::symlink_metadata(path) {\n  2402→            Ok(metadata) => {\n  2403→                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n  2404→                    to_upsert_map.insert(row.path.clone(), row);\n  2405→                }\n  2406→            }\n  2407→            Err(_) => {\n  2408→                to_delete.push(path_str);\n  2409→            }\n  2410→        }\n  2411→    }\n  2412→\n  2413→    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n  2414→\n  2415→    if to_upsert.is_empty() && to_delete.is_empty() {\n  2416→        return Ok(0);\n  2417→    }\n  2418→\n  2419→    let mut conn = db_connection(&state.db_path)?;\n  2420→    let mut changed = 0;\n  2421→\n  2422→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2423→    changed += delete_paths(&mut conn, &to_delete)?;\n  2424→\n  2425→    Ok(changed)\n  2426→}\n  2427→\n  2428→#[cfg(target_os = \"macos\")]\n  2429→const STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n  2430→\n  2431→#[cfg(target_os = \"macos\")]\n  2432→fn process_watcher_paths(\n  2433→    app: &AppHandle,\n  2434→    state: &AppState,\n  2435→    pending: &mut HashSet<PathBuf>,\n  2436→    last_status_emit: &mut Instant,\n  2437→    pending_status_emit: &mut bool,\n  2438→) {\n  2439→    if pending.is_empty() {\n  2440→        return;\n  2441→    }\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9dc845e5-f0af-49f5-aa28-751feb73afb5","timestamp":"2026-02-20T09:13:39.126Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }","numLines":60,"startLine":2382,"totalLines":5087}},"sourceToolAssistantUUID":"e38361f2-9a6b-4f5d-b1fd-676ae3dc5c1e"}
{"parentUuid":"9dc845e5-f0af-49f5-aa28-751feb73afb5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01UXeKefWXh2yVPZKS1B2Xwo","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the flow. The issue is:\n\n1. `apply_path_changes` calls `db_connection(&state.db_path)` - this creates a new connection with a 3000ms busy timeout\n2. But the \"database is locked\" error comes from somewhere\n\nThe key question is: what is happening that causes the database to be locked? Let me look at:\n1. How the full indexer acquires the DB connection\n2. Whether there's WAL mode set up properly\n3. Whether multiple connections try to write at the same time\n\nLet me look at `db_connection_with_timeout` more carefully:","signature":"ErgFCkYICxgCKkCpKADro6WWST3IArtqoK/MkI9vzoi6gYdxyhDnrVmU2aPZkyTglqqqaTPLQEVldgL+/k3ROp9dSn+fYA2wka5pEgz17HYlfclklfGBWesaDGmlGEL9dKjemvnBVCIw2ltQL9ZxnGK+A22/V9HcEy5oz3odVzkpCLxBdioSKwF5YKw/zFGAkV+mCOQUbo5RKp8E70vTuobZu7ri8ydSOyE6x64JdDig3uctIJA2nJwGouTeXBt+SbbdeuvFq+Lk4jLzO8R73kbo0qT/G39UErXH3e3x0a/aWKQaQnMzxw2JKq9+yDU7/6qdzWZ+f7v/BU1EJ2fUpT2SPOYFdsivKGQQx4fSEVwZUFW0+BP++A98HJ/40KqWbn2/4pqP8pEEhcmJkbB27WjlGZnRrTMWdoPy/BuCMxMsrsnk+8UAGLIrZtOFEZJ1qa9ZknoilFjpDu9L6GHDupF4+j5DYksniMxF/XW04BqHUgrq48pyeUWyUfBfFpv/BiDNP/3TNqpzJrkG27PRSWc50e8Z4f+i29I67u1/eiw8tZ2tVAGytHeiKJl1L/hkjvJ/NI5+t8amRIjG8OIhXkco23AXdvKNssVvuxqiaSCIdyJj87OEkfkcxI6CxxXF2lItlDYUxEiLQmE+p/jb2kk8B3r1iWpVlgK1nknH2ntlDtrhrQI9MGNxDVm+fXooWIrgMWKT88Cs/V7GvRU13lT7g4GVAujMeLLR95YhaQMzbQTLl8IvlPMKI2gcX/B0CXdVg8p3o2M6QX7oRRuIxXFRpXOPWRs62fVVFaCk974mfCrQ6OeAX7qSFeVtMQU5GTqfMk/OVp8dxzUsq//IqUWLEs6HrVHRPA62PbxZcUv4iAmQ6FxyjC1zjmBQhypyqc4lZQCGNYl8plBjzHswIXHfMy1NbBDYRjUmGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1007,"cache_read_input_tokens":40643,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1007},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4ifuDVhh1qqsVdT86h","type":"assistant","uuid":"1e4eb905-ffeb-4289-82b7-ffe76e8779bc","timestamp":"2026-02-20T09:13:43.773Z"}
{"parentUuid":"1e4eb905-ffeb-4289-82b7-ffe76e8779bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01UXeKefWXh2yVPZKS1B2Xwo","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013vUiUrNaLmXJETdnvq4d9z","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":359,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1007,"cache_read_input_tokens":40643,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1007},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4ifuDVhh1qqsVdT86h","type":"assistant","uuid":"a4ac38cd-c8d4-42c0-9634-7505e7178e95","timestamp":"2026-02-20T09:13:44.335Z"}
{"parentUuid":"a4ac38cd-c8d4-42c0-9634-7505e7178e95","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013vUiUrNaLmXJETdnvq4d9z","toolUseID":"toolu_013vUiUrNaLmXJETdnvq4d9z","timestamp":"2026-02-20T09:13:44.345Z","uuid":"151aa76e-573d-4e62-8c2b-aa6eda208b5f"}
{"parentUuid":"a4ac38cd-c8d4-42c0-9634-7505e7178e95","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013vUiUrNaLmXJETdnvq4d9z","type":"tool_result","content":"   359→fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n   360→    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n   361→    conn.execute_batch(&format!(\n   362→        r#\"\n   363→        PRAGMA journal_mode=WAL;\n   364→        PRAGMA synchronous=NORMAL;\n   365→        PRAGMA temp_store=MEMORY;\n   366→        PRAGMA busy_timeout={busy_timeout_ms};\n   367→        \"#,\n   368→    ))\n   369→    .map_err(|e| e.to_string())?;\n   370→    Ok(conn)\n   371→}\n   372→\n   373→pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n   374→    db_connection_with_timeout(db_path, 3000)\n   375→}\n   376→\n   377→fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n   378→    let conn = db_connection_with_timeout(db_path, 200)?;\n   379→    conn.execute_batch(\n   380→        \"PRAGMA cache_size = -32768;\n   381→         PRAGMA mmap_size = 268435456;\",\n   382→    )\n   383→    .map_err(|e| e.to_string())?;\n   384→    Ok(conn)\n   385→}\n   386→\n   387→pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n   388→    conn.execute_batch(\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b36caac4-faf2-4dac-afbf-ac978103c998","timestamp":"2026-02-20T09:13:44.344Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(","numLines":30,"startLine":359,"totalLines":5087}},"sourceToolAssistantUUID":"a4ac38cd-c8d4-42c0-9634-7505e7178e95"}
{"parentUuid":"b36caac4-faf2-4dac-afbf-ac978103c998","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01A2eNeSUBeBjH3p4FVpyCuM","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"So the db_connection has a 3000ms busy timeout set. The WAL mode is being set. But in WAL mode, multiple readers and one writer are allowed. However, if two writers try to write at the same time, one will wait for the busy timeout.\n\nThe issue is: on startup, `start_full_index_worker` AND `start_fsevent_watcher_worker` are both spawned. The FSEvents watcher may receive historical events (from the `since_event_id`) and try to write to the DB while the full index is running.\n\nLet me look at the `start_full_index_worker` to see if there's a connection that stays open for a long time during indexing.\n\n\nActually, I need to trace through the startup logic more carefully. There's a conditional path here: if we have a stored event ID and the index is already complete, we skip the full scan and just replay the watcher events. Otherwise, if the index isn't complete, we run the full indexing. So depending on the state, either the watcher or the full index worker gets spawned, not necessarily both.\n\nBut looking at the else branch more closely, it seems like both workers are being started—the full indexer runs its long transaction while the watcher immediately begins listening for FSEvents. The watcher has a guard though: it checks if indexing is active and bails out early if so, which should prevent conflicts. The user mentioned the issue reproduces immediately on restart, so there's something about the timing or the conditional logic that's causing the problem.\n\nLet me trace through what might be holding the database connection open or causing multiple writers to collide. The `apply_path_changes` function opens a fresh connection each time rather than reusing a pooled one, and with WAL mode enabled and a 3-second timeout, that should handle concurrent access fine unless there's an unexpectedly long write operation blocking things. I should check whether the main app state is holding onto a shared database connection somewhere.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":785,"cache_read_input_tokens":41650,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":785},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4j4jQQQxKtswzXWQGX","type":"assistant","uuid":"de76ac2f-e606-43d1-8259-ae6bca49910c","timestamp":"2026-02-20T09:13:59.235Z"}
{"parentUuid":"de76ac2f-e606-43d1-8259-ae6bca49910c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01A2eNeSUBeBjH3p4FVpyCuM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01684Be9obSH1W2cyW9Q9RKk","name":"Grep","input":{"pattern":"db_conn|db: Arc|db_path|Connection.*state","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":2,"head_limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":785,"cache_read_input_tokens":41650,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":785},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4j4jQQQxKtswzXWQGX","type":"assistant","uuid":"68fc9b0e-67e7-47e2-8f7f-f30344b039ca","timestamp":"2026-02-20T09:13:59.723Z"}
{"parentUuid":"68fc9b0e-67e7-47e2-8f7f-f30344b039ca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01684Be9obSH1W2cyW9Q9RKk","toolUseID":"toolu_01684Be9obSH1W2cyW9Q9RKk","timestamp":"2026-02-20T09:14:00.517Z","uuid":"ff6da9e6-0c00-4352-8f2c-1db0ce359e70"}
{"parentUuid":"68fc9b0e-67e7-47e2-8f7f-f30344b039ca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01684Be9obSH1W2cyW9Q9RKk","type":"tool_result","content":"193-    completed_at: i64,\n194-    home_dir: String,\n195:    db_path: String,\n196-    index_wait_ms: u128,\n197-    index_scanned: u64,\n--\n273-#[derive(Debug, Clone)]\n274-pub(crate) struct AppState {\n275:    pub(crate) db_path: PathBuf,\n276-    pub(crate) home_dir: PathBuf,\n277-    pub(crate) scan_root: PathBuf,\n--\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360:    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n--\n371-}\n372-\n373:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n374:    db_connection_with_timeout(db_path, 3000)\n375-}\n376-\n377:fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n378:    let conn = db_connection_with_timeout(db_path, 200)?;\n379-    conn.execute_batch(\n380-        \"PRAGMA cache_size = -32768;\n--\n412-}\n413-\n414:fn init_db(db_path: &Path) -> AppResult<()> {\n415-    let t = Instant::now();\n416:    let conn = db_connection(db_path)?;\n417:    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n418-\n419-    let current_version: i32 = conn\n--\n498-\n\n[Showing results with pagination = limit: 40, offset: 0]"}]},"uuid":"89cfeb09-1a83-4525-ba61-27c353871f09","timestamp":"2026-02-20T09:14:00.515Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"193-    completed_at: i64,\n194-    home_dir: String,\n195:    db_path: String,\n196-    index_wait_ms: u128,\n197-    index_scanned: u64,\n--\n273-#[derive(Debug, Clone)]\n274-pub(crate) struct AppState {\n275:    pub(crate) db_path: PathBuf,\n276-    pub(crate) home_dir: PathBuf,\n277-    pub(crate) scan_root: PathBuf,\n--\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360:    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n--\n371-}\n372-\n373:pub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n374:    db_connection_with_timeout(db_path, 3000)\n375-}\n376-\n377:fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n378:    let conn = db_connection_with_timeout(db_path, 200)?;\n379-    conn.execute_batch(\n380-        \"PRAGMA cache_size = -32768;\n--\n412-}\n413-\n414:fn init_db(db_path: &Path) -> AppResult<()> {\n415-    let t = Instant::now();\n416:    let conn = db_connection(db_path)?;\n417:    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n418-\n419-    let current_version: i32 = conn\n--\n498-","numLines":40,"appliedLimit":40},"sourceToolAssistantUUID":"68fc9b0e-67e7-47e2-8f7f-f30344b039ca"}
{"parentUuid":"89cfeb09-1a83-4525-ba61-27c353871f09","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01VbZnE6QgopWNSMJkx8PH7s","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Def11ngCJhrXL82UzTxYuX","name":"Grep","input":{"pattern":"fn start_full_index_worker|indexing_active.*store\\(true\\)|busy_timeout","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1274,"cache_read_input_tokens":42435,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1274},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4kFKAXeJrsfoKayARZ","type":"assistant","uuid":"db3dde1b-2217-4429-883b-c7a756d7c891","timestamp":"2026-02-20T09:14:03.980Z"}
{"parentUuid":"db3dde1b-2217-4429-883b-c7a756d7c891","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01Def11ngCJhrXL82UzTxYuX","toolUseID":"toolu_01Def11ngCJhrXL82UzTxYuX","timestamp":"2026-02-20T09:14:04.782Z","uuid":"b12c14a4-4de4-459b-9485-b3f64b6d6b9e"}
{"parentUuid":"db3dde1b-2217-4429-883b-c7a756d7c891","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Def11ngCJhrXL82UzTxYuX","type":"tool_result","content":"356-    }\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n363-        PRAGMA journal_mode=WAL;\n364-        PRAGMA synchronous=NORMAL;\n365-        PRAGMA temp_store=MEMORY;\n366:        PRAGMA busy_timeout={busy_timeout_ms};\n367-        \"#,\n368-    ))\n369-    .map_err(|e| e.to_string())?;\n--\n1836-    state.status.lock().last_updated = Some(now_epoch());\n1837-}\n1838-\n1839:pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n1840-    start_full_index_worker_inner(app, state, false)\n1841-}\n1842-\n1843:pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n1844-    start_full_index_worker_inner(app, state, true)\n1845-}\n1846-\n1847:fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n1848-    if state\n1849-        .indexing_active\n1850-        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)"}]},"uuid":"5e6f751a-d1dd-49fb-90bf-2f33c0737c86","timestamp":"2026-02-20T09:14:04.781Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"356-    }\n357-}\n358-\n359:fn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n360-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n361-    conn.execute_batch(&format!(\n362-        r#\"\n363-        PRAGMA journal_mode=WAL;\n364-        PRAGMA synchronous=NORMAL;\n365-        PRAGMA temp_store=MEMORY;\n366:        PRAGMA busy_timeout={busy_timeout_ms};\n367-        \"#,\n368-    ))\n369-    .map_err(|e| e.to_string())?;\n--\n1836-    state.status.lock().last_updated = Some(now_epoch());\n1837-}\n1838-\n1839:pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n1840-    start_full_index_worker_inner(app, state, false)\n1841-}\n1842-\n1843:pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n1844-    start_full_index_worker_inner(app, state, true)\n1845-}\n1846-\n1847:fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n1848-    if state\n1849-        .indexing_active\n1850-        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)","numLines":30},"sourceToolAssistantUUID":"db3dde1b-2217-4429-883b-c7a756d7c891"}
{"parentUuid":"5e6f751a-d1dd-49fb-90bf-2f33c0737c86","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_011qo6rfci3WXPQ1JbaSUZbx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RK7RDbuGNP9PkyEdQZ9sjk","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1847,"limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":589,"cache_read_input_tokens":43709,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":589},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4kZbknzHBEE86fbsdz","type":"assistant","uuid":"0088df9f-3f25-4740-ab5a-e3388d3ca81a","timestamp":"2026-02-20T09:14:06.752Z"}
{"parentUuid":"0088df9f-3f25-4740-ab5a-e3388d3ca81a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01RK7RDbuGNP9PkyEdQZ9sjk","toolUseID":"toolu_01RK7RDbuGNP9PkyEdQZ9sjk","timestamp":"2026-02-20T09:14:06.764Z","uuid":"2754ac39-aa96-4c4b-a782-2e7b7db49ce7"}
{"parentUuid":"0088df9f-3f25-4740-ab5a-e3388d3ca81a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RK7RDbuGNP9PkyEdQZ9sjk","type":"tool_result","content":"  1847→fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n  1848→    if state\n  1849→        .indexing_active\n  1850→        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n  1851→        .is_err()\n  1852→    {\n  1853→        perf_log(\"index_start_skipped already_active=true\");\n  1854→        return Ok(());\n  1855→    }\n  1856→\n  1857→    // Mark index as incomplete — cleared when run_incremental_index succeeds\n  1858→    if let Ok(c) = db_connection(&state.db_path) {\n  1859→        let _ = set_meta(&c, \"index_complete\", \"0\");\n  1860→    }\n  1861→\n  1862→    if !silent {\n  1863→        {\n  1864→            let mut status = state.status.lock();\n  1865→            status.state = IndexState::Indexing;\n  1866→            status.message = None;\n  1867→            status.scanned = 0;\n  1868→            status.indexed = 0;\n  1869→            status.current_path.clear();\n  1870→        }\n  1871→\n  1872→        emit_index_state(&app, \"Indexing\", None);\n  1873→        perf_log(\"index_state=Indexing\");\n  1874→    } else {\n  1875→        perf_log(\"index_start silent=true (background reindex)\");\n  1876→    }\n  1877→\n  1878→    std::thread::spawn(move || {\n  1879→        let result = run_incremental_index(&app, &state);\n  1880→        if let Err(ref err) = result {\n  1881→            eprintln!(\"[index] run_incremental_index failed: {err}\");\n  1882→            if !silent {\n  1883→                set_state(&state, IndexState::Error, Some(err.clone()));\n  1884→                emit_index_state(&app, \"Error\", Some(err.clone()));\n  1885→            }\n  1886→            // Silent mode: keep Ready state, just log the error\n  1887→        }\n  1888→        state.indexing_active.store(false, AtomicOrdering::Release);\n  1889→    });\n  1890→\n  1891→    Ok(())\n  1892→}\n  1893→\n  1894→fn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n  1895→    path.parent() == Some(home_dir)\n  1896→        && path\n  1897→            .file_name()\n  1898→            .and_then(|n| n.to_str())\n  1899→            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n  1900→            .unwrap_or(false)\n  1901→}\n  1902→\n  1903→fn preload_existing_entries(\n  1904→    conn: &Connection,\n  1905→    dir_prefix: &str,\n  1906→) -> HashMap<String, (Option<i64>, Option<i64>)> {\n  1907→    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n  1908→    let mut stmt = match conn.prepare(\n  1909→        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n  1910→    ) {\n  1911→        Ok(s) => s,\n  1912→        Err(_) => return HashMap::new(),\n  1913→    };\n  1914→\n  1915→    let mut map = HashMap::new();\n  1916→    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n  1917→        Ok((\n  1918→            row.get::<_, String>(0)?,\n  1919→            row.get::<_, Option<i64>>(1)?,\n  1920→            row.get::<_, Option<i64>>(2)?,\n  1921→        ))\n  1922→    }) {\n  1923→        Ok(r) => r,\n  1924→        Err(_) => return map,\n  1925→    };\n  1926→\n  1927→    for row in rows.flatten() {\n  1928→        map.insert(row.0, (row.1, row.2));\n  1929→    }\n  1930→    map\n  1931→}\n  1932→\n  1933→fn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n  1934→    if paths.is_empty() {\n  1935→        return Ok(());\n  1936→    }\n  1937→\n  1938→    let tx = conn.transaction().map_err(|e| e.to_string())?;\n  1939→    {\n  1940→        let mut stmt = tx\n  1941→            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n  1942→            .map_err(|e| e.to_string())?;\n  1943→        for path in paths {\n  1944→            stmt.execute(params![run_id, path])\n  1945→                .map_err(|e| e.to_string())?;\n  1946→        }\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"be595fad-9a13-4ac4-b01f-9f45eccf8484","timestamp":"2026-02-20T09:14:06.763Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }","numLines":100,"startLine":1847,"totalLines":5087}},"sourceToolAssistantUUID":"0088df9f-3f25-4740-ab5a-e3388d3ca81a"}
{"parentUuid":"be595fad-9a13-4ac4-b01f-9f45eccf8484","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Wu4kemw3UJRY6SGoGZJQHn","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me look at `run_incremental_index` to understand what DB connection it uses and how long it holds it:","signature":"EpECCkYICxgCKkAEPJcOS9pnkCIHlZP+uz5ZRCX1G8wpQXLk5JL1i4NT8tY1JnJXTyz1vdHhwnwoGqp4QNd0zWpZidqE9VeFArNrEgxegs0uuo2gHrV9ZSwaDE/ds0M7ySG/UpY5wyIwbbrqLPdDuoKigA/28MI7JV0Jbqybc0OduL15ftCniBwXgMAX5I3/InISu8YmwYY6KnnXh6xHKAyy65OhBxYJXTkDppiNXvQsnS/m55h8Jyyvb38xeiiDtB1ooBMpEjwxIXwP+y2q35vnmLQkPbda+BNVCtqiOH1AJiyWiN3eF0jfdt+xFWihykrD0IKwama6pbGV9deCcxixXD8kyqtvA3WNrfzdZowlNqIuGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1629,"cache_read_input_tokens":44298,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1629},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4ki5VAVJTcd8aCjXuu","type":"assistant","uuid":"ea7790c0-8083-4371-83e4-ef91820e1490","timestamp":"2026-02-20T09:14:09.131Z"}
{"parentUuid":"ea7790c0-8083-4371-83e4-ef91820e1490","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Wu4kemw3UJRY6SGoGZJQHn","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EGFnhREj8JhRWFZGrp43Uy","name":"Grep","input":{"pattern":"fn run_incremental_index","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1629,"cache_read_input_tokens":44298,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1629},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4ki5VAVJTcd8aCjXuu","type":"assistant","uuid":"e87e2115-a804-44b8-860b-41ba6afe27c8","timestamp":"2026-02-20T09:14:10.530Z"}
{"parentUuid":"e87e2115-a804-44b8-860b-41ba6afe27c8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01EGFnhREj8JhRWFZGrp43Uy","toolUseID":"toolu_01EGFnhREj8JhRWFZGrp43Uy","timestamp":"2026-02-20T09:14:11.314Z","uuid":"447c73a0-5a21-42e0-8cf3-713a27304886"}
{"parentUuid":"e87e2115-a804-44b8-860b-41ba6afe27c8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EGFnhREj8JhRWFZGrp43Uy","type":"tool_result","content":"1949-    Ok(())\n1950-}\n1951-\n1952:fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n1953-    let started = Instant::now();\n1954-    perf_log(format!(\n1955-        \"index_run_start home={} db={}\",\n--\n1991-    result\n1992-}\n1993-\n1994:fn run_incremental_index_inner(\n1995-    app: &AppHandle,\n1996-    state: &AppState,\n1997-    conn: &mut Connection,"}]},"uuid":"d27cc37d-0502-40ad-95e6-34a5d653c489","timestamp":"2026-02-20T09:14:11.312Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"1949-    Ok(())\n1950-}\n1951-\n1952:fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n1953-    let started = Instant::now();\n1954-    perf_log(format!(\n1955-        \"index_run_start home={} db={}\",\n--\n1991-    result\n1992-}\n1993-\n1994:fn run_incremental_index_inner(\n1995-    app: &AppHandle,\n1996-    state: &AppState,\n1997-    conn: &mut Connection,","numLines":15},"sourceToolAssistantUUID":"e87e2115-a804-44b8-860b-41ba6afe27c8"}
{"parentUuid":"d27cc37d-0502-40ad-95e6-34a5d653c489","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01HksVNp9o4NfiCxTvPypGzM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JYj7xvSvx9NipA2EBHPYCL","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1952,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":447,"cache_read_input_tokens":45927,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":447},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4m3UoDKmuQWGHmKrXQ","type":"assistant","uuid":"d1462018-6703-4537-9043-3fa671971b06","timestamp":"2026-02-20T09:14:13.349Z"}
{"parentUuid":"d1462018-6703-4537-9043-3fa671971b06","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JYj7xvSvx9NipA2EBHPYCL","toolUseID":"toolu_01JYj7xvSvx9NipA2EBHPYCL","timestamp":"2026-02-20T09:14:13.362Z","uuid":"fc16abe9-eacf-4352-9c8c-a5621f23034f"}
{"parentUuid":"d1462018-6703-4537-9043-3fa671971b06","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JYj7xvSvx9NipA2EBHPYCL","type":"tool_result","content":"  1952→fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n  1953→    let started = Instant::now();\n  1954→    perf_log(format!(\n  1955→        \"index_run_start home={} db={}\",\n  1956→        state.home_dir.to_string_lossy(),\n  1957→        state.db_path.to_string_lossy(),\n  1958→    ));\n  1959→\n  1960→    let mut conn = db_connection(&state.db_path)?;\n  1961→    set_indexing_pragmas(&conn)?;\n  1962→\n  1963→    let result = run_incremental_index_inner(app, state, &mut conn);\n  1964→\n  1965→    let _ = conn.execute_batch(\"ANALYZE\");\n  1966→    let _ = restore_normal_pragmas(&conn);\n  1967→\n  1968→    match &result {\n  1969→        Ok(_) => {\n  1970→            let _ = set_meta(&conn, \"index_complete\", \"1\");\n  1971→            let snapshot = state.status.lock().clone();\n  1972→            perf_log(format!(\n  1973→                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n  1974→                started.elapsed().as_millis(),\n  1975→                snapshot.scanned,\n  1976→                snapshot.indexed,\n  1977→                snapshot.entries_count,\n  1978→                snapshot.permission_errors,\n  1979→                snapshot.message,\n  1980→            ));\n  1981→        }\n  1982→        Err(err) => {\n  1983→            perf_log(format!(\n  1984→                \"index_run_error elapsed_ms={} err={}\",\n  1985→                started.elapsed().as_millis(),\n  1986→                err,\n  1987→            ));\n  1988→        }\n  1989→    }\n  1990→\n  1991→    result\n  1992→}\n  1993→\n  1994→fn run_incremental_index_inner(\n  1995→    app: &AppHandle,\n  1996→    state: &AppState,\n  1997→    conn: &mut Connection,\n  1998→) -> AppResult<()> {\n  1999→    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n  2000→        &state.home_dir,\n  2001→        &state.cwd,\n  2002→        state.path_ignores.as_ref(),\n  2003→        state.path_ignore_patterns.as_ref(),\n  2004→    );\n  2005→    let gi_filter = state.gitignore.get();\n  2006→\n  2007→    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n  2008→        .and_then(|v| v.parse().ok())\n  2009→        .unwrap_or(0);\n  2010→    let current_run_id = last_run_id + 1;\n  2011→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f34a1c7d-54af-4243-86f1-d97a4be7adc3","timestamp":"2026-02-20T09:14:13.360Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n","numLines":60,"startLine":1952,"totalLines":5087}},"sourceToolAssistantUUID":"d1462018-6703-4537-9043-3fa671971b06"}
{"parentUuid":"f34a1c7d-54af-4243-86f1-d97a4be7adc3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Kmo6fC7JsocwcrdTHSNhw2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the issue. Let me check what `set_indexing_pragmas` does - it might set EXCLUSIVE locking mode or something else that causes the database to be locked for other connections.","signature":"EucCCkYICxgCKkBaqk+jYm7MRRHRkIw28Vn3h6U7pfmlczitnU+kGgnshZ1y4B83rhqH6n6V7ewmiyawBNHwED1RymFcbTFT1CZdEgyVD5ImREzkDBM560MaDDSw9wFCrpPSh45Z2iIw0nt0bEWtAILw5VBEBl40JMYNWr4WRSjtoY6XmuDErgBisoS9s1RBQ+NuWY2tx6iiKs4BRDf4c5bsDlNzolT3P9iukCPnD/GvMJHFo8c7cWwphdyr4Hq+4W+lSssbSxyljY2dG57W1a9YoLsPhQGa03cZazro4KVFNkI+I/LzfgSEElNTdMxF4iT6Ah9zRuakszywLwIb5PAMM5geCvL9bt/4AgDTkZEsga5tdeNU3BaAJRN+F7G7ojCdGxJDee5qcgaWnEqvWy2K+7sJds2vqxlJkDQw9oVkZ+lc6p9+8OeFug/K2ywjW2Kq2Fj5IGBRK6BzwpcTt0gNjBob4T5meUMYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1027,"cache_read_input_tokens":46374,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1027},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4mCXGKjzbDF3wcifPv","type":"assistant","uuid":"ecc68fc9-a798-4c4d-a810-38d5b75e7002","timestamp":"2026-02-20T09:14:15.884Z"}
{"parentUuid":"ecc68fc9-a798-4c4d-a810-38d5b75e7002","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Kmo6fC7JsocwcrdTHSNhw2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VXVfNFfvgdEirSq4YgzAbY","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":387,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1027,"cache_read_input_tokens":46374,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1027},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4mCXGKjzbDF3wcifPv","type":"assistant","uuid":"f569f978-e463-4e06-a19d-9ddee4ed7b71","timestamp":"2026-02-20T09:14:16.550Z"}
{"parentUuid":"f569f978-e463-4e06-a19d-9ddee4ed7b71","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01VXVfNFfvgdEirSq4YgzAbY","toolUseID":"toolu_01VXVfNFfvgdEirSq4YgzAbY","timestamp":"2026-02-20T09:14:16.564Z","uuid":"abd335c1-3078-4519-a301-db62bfcd070b"}
{"parentUuid":"f569f978-e463-4e06-a19d-9ddee4ed7b71","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VXVfNFfvgdEirSq4YgzAbY","type":"tool_result","content":"   387→pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n   388→    conn.execute_batch(\n   389→        r#\"\n   390→        PRAGMA synchronous = NORMAL;\n   391→        PRAGMA cache_size = -65536;\n   392→        PRAGMA mmap_size = 268435456;\n   393→        PRAGMA wal_autocheckpoint = 0;\n   394→        \"#,\n   395→    )\n   396→    .map_err(|e| e.to_string())\n   397→}\n   398→\n   399→pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n   400→    conn.execute_batch(\n   401→        r#\"\n   402→        PRAGMA synchronous = NORMAL;\n   403→        PRAGMA cache_size = -16384;\n   404→        PRAGMA mmap_size = 0;\n   405→        PRAGMA wal_autocheckpoint = 1000;\n   406→        \"#,\n   407→    )\n   408→    .map_err(|e| e.to_string())?;\n   409→    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n   410→        .map_err(|e| e.to_string())?;\n   411→    Ok(())\n   412→}\n   413→\n   414→fn init_db(db_path: &Path) -> AppResult<()> {\n   415→    let t = Instant::now();\n   416→    let conn = db_connection(db_path)?;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"4aba4cef-6f51-45e4-831f-91c7f3fa5d2a","timestamp":"2026-02-20T09:14:16.562Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;","numLines":30,"startLine":387,"totalLines":5087}},"sourceToolAssistantUUID":"f569f978-e463-4e06-a19d-9ddee4ed7b71"}
{"parentUuid":"4aba4cef-6f51-45e4-831f-91c7f3fa5d2a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_019fRef5Xo8LQrXYhbdfmk8z","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see a potential issue! `PRAGMA wal_checkpoint(TRUNCATE)` in `restore_normal_pragmas` requires exclusive access. But this isn't the main issue since it's called after indexing is complete.\n\nWait, let me re-read `start_full_index_worker_inner`:\n\n1. It opens a db connection at line 1858 (`db_connection` with 3s timeout) to mark `index_complete = 0`\n2. This connection is `c` - a local variable, so it should be dropped immediately after the if block\n3. Then in `run_incremental_index`, it opens ANOTHER connection at line 1960 with 3s timeout\n\n\n4. `set_indexing_pragmas` disables WAL autocheckpointing, and later `restore_normal_pragmas` forces a checkpoint with truncation, which blocks if there are active readers\n\nBut the user says it reproduces immediately on restart, so I need to look at what happens during startup to understand the actual deadlock scenario.\n\nOn the second restart after a successful index, if there's a stored event ID and indexing is complete, the system takes a conditional startup path where the watcher replays historical filesystem events since that last checkpoint. When it processes these replayed events during the history replay, it tries to access the database connection, but something about the state initialization or the checkpoint timing is causing the lock.\n\nLet me trace through the actual connection lifecycle more carefully. When `init_db` runs during startup, it opens a connection for schema initialization, but that connection should be dropped immediately after. Then in the full index worker, another connection is opened briefly just to set metadata before being dropped. So the question is whether one of these connections is somehow being held open or if there's a timing issue where the watcher tries to access the database while one of these setup connections still has a lock on it. On conditional startup, the watcher receives historical filesystem events while `indexing_active` is false, so it attempts to write to the database—but something else is holding a lock. I need to trace through the startup sequence more carefully to find what's keeping that connection open.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":666,"cache_read_input_tokens":47401,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":666},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4mSAZ7KHvzkrctHb8X","type":"assistant","uuid":"47a8452a-9d7e-4add-8ae8-91f0586d9265","timestamp":"2026-02-20T09:14:39.282Z"}
{"parentUuid":"47a8452a-9d7e-4add-8ae8-91f0586d9265","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_019fRef5Xo8LQrXYhbdfmk8z","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WSovYEahAnby55Cgh5T2zL","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":4490,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":666,"cache_read_input_tokens":47401,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":666},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4mSAZ7KHvzkrctHb8X","type":"assistant","uuid":"0db413df-f586-4107-baa2-aead07204d7e","timestamp":"2026-02-20T09:14:39.300Z"}
{"parentUuid":"0db413df-f586-4107-baa2-aead07204d7e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01WSovYEahAnby55Cgh5T2zL","toolUseID":"toolu_01WSovYEahAnby55Cgh5T2zL","timestamp":"2026-02-20T09:14:39.313Z","uuid":"a9d55503-32eb-445e-9f19-3d643da42d47"}
{"parentUuid":"0db413df-f586-4107-baa2-aead07204d7e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WSovYEahAnby55Cgh5T2zL","type":"tool_result","content":"  4490→        state.db_ready.store(true, AtomicOrdering::Release);\n  4491→        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n  4492→\n  4493→        // Deferred housekeeping — purge + status counts run in background\n  4494→        {\n  4495→            let hk_app = app_handle.clone();\n  4496→            let hk_state = state.clone();\n  4497→            std::thread::spawn(move || {\n  4498→                // Brief pause so indexing thread can start first\n  4499→                std::thread::sleep(std::time::Duration::from_millis(500));\n  4500→                let hk_started = std::time::Instant::now();\n  4501→                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n  4502→                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n  4503→                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n  4504→                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n  4505→                }\n  4506→                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n  4507→            });\n  4508→        }\n  4509→\n  4510→        #[cfg(target_os = \"macos\")]\n  4511→        {\n  4512→            if bench_mode {\n  4513→                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n  4514→            } else {\n  4515→                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n  4516→                    .ok()\n  4517→                    .map(|c| {\n  4518→                        let eid = get_meta(&c, \"last_event_id\")\n  4519→                            .and_then(|v| v.parse::<u64>().ok());\n  4520→                        let complete = get_meta(&c, \"index_complete\")\n  4521→                            .map(|v| v == \"1\")\n  4522→                            .unwrap_or(false);\n  4523→                        (eid, complete)\n  4524→                    })\n  4525→                    .unwrap_or((None, false));\n  4526→\n  4527→                if stored_event_id.is_some() && index_complete {\n  4528→                    // Conditional startup: try watcher replay first, skip full scan if OK\n  4529→                    start_fsevent_watcher_worker(\n  4530→                        app_handle.clone(),\n  4531→                        state.clone(),\n  4532→                        stored_event_id,\n  4533→                        true,\n  4534→                    );\n  4535→                } else {\n  4536→                    if !index_complete {\n  4537→                        eprintln!(\"[mac] index incomplete — starting full index\");\n  4538→                    }\n  4539→                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n  4540→                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n  4541→                }\n  4542→            }\n  4543→        }\n  4544→\n  4545→        #[cfg(target_os = \"windows\")]\n  4546→        {\n  4547→            win::start_windows_indexing(app_handle.clone(), state.clone());\n  4548→        }\n  4549→\n  4550→        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n  4551→        {\n  4552→            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n  4553→        }\n  4554→\n  4555→        if bench_mode {\n  4556→            start_bench_runner(app_handle.clone(), state.clone());\n  4557→        }\n  4558→\n  4559→        if !bench_mode {\n  4560→            let icon_cache = state.icon_cache.clone();\n  4561→            std::thread::spawn(move || {\n  4562→                let exts = [\n  4563→                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n  4564→                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n  4565→                ];\n  4566→                for ext in &exts {\n  4567→                    let key = ext.to_string();\n  4568→                    if icon_cache.lock().contains_key(&key) {\n  4569→                        continue;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d4a7e208-b2cb-4e5b-8c5f-0804d330bba3","timestamp":"2026-02-20T09:14:39.311Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;","numLines":80,"startLine":4490,"totalLines":5087}},"sourceToolAssistantUUID":"0db413df-f586-4107-baa2-aead07204d7e"}
{"parentUuid":"d4a7e208-b2cb-4e5b-8c5f-0804d330bba3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01V86F4mEGRTUiYxfdjZdwri","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I can see the structure. On startup (line 4515):\n- A connection `c` is opened to read `last_event_id` and `index_complete`\n- This connection is immediately dropped after the map closure (no move)\n- `stored_event_id` is set, `index_complete` is set\n- Then either the watcher or the full indexer starts\n\nNow I also see that there's a housekeeping thread that:\n1. Sleeps 500ms\n2. Calls `refresh_and_emit_status_counts` \n3. Calls `purge_ignored_entries`\n\nThe `purge_ignored_entries` could be holding a DB write lock. \n\nSo the conditional startup path means if `stored_event_id.is_some() && index_complete`, only the watcher starts with `since_event_id` to replay history while `indexing_active` is `false`. The watcher calls `apply_path_changes` which opens a new connection, and meanwhile the housekeeping thread is also opening connections and calling `purge_ignored_entries`. This creates a race condition where both threads are trying to write to the database simultaneously.\n\nWith WAL mode and the 3000ms busy_timeout, SQLite should theoretically allow multiple readers and one writer to coexist. But I'm noticing that `restore_normal_pragmas` calls `PRAGMA wal_checkpoint(TRUNCATE)`, which requires exclusive write access to the WAL file. If another writer connection is active, this checkpoint will block or fail. Since this is called from `run_incremental_index`, it's not involved in the conditional startup path, but it could still be interfering. Let me examine `purge_ignored_entries` to see if that's where the actual conflict is happening.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2498,"cache_read_input_tokens":48067,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2498},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4o7BrNH9CbDxSdrCj1","type":"assistant","uuid":"9408d2fc-3753-4309-96f5-d76c64ec2462","timestamp":"2026-02-20T09:14:52.267Z"}
{"parentUuid":"9408d2fc-3753-4309-96f5-d76c64ec2462","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01V86F4mEGRTUiYxfdjZdwri","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01J5nU59uSTDgW4r4GGWcx15","name":"Grep","input":{"pattern":"fn purge_ignored_entries|fn refresh_and_emit_status_counts","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2498,"cache_read_input_tokens":48067,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2498},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4o7BrNH9CbDxSdrCj1","type":"assistant","uuid":"2422468d-9618-4b6f-98f0-4f68c9922b64","timestamp":"2026-02-20T09:14:52.355Z"}
{"parentUuid":"2422468d-9618-4b6f-98f0-4f68c9922b64","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01J5nU59uSTDgW4r4GGWcx15","toolUseID":"toolu_01J5nU59uSTDgW4r4GGWcx15","timestamp":"2026-02-20T09:14:53.130Z","uuid":"4217f6ac-155a-4489-9ad6-3e70bd681e32"}
{"parentUuid":"2422468d-9618-4b6f-98f0-4f68c9922b64","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01J5nU59uSTDgW4r4GGWcx15","type":"tool_result","content":"1083-    hasher.finish()\n1084-}\n1085-\n1086:fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n1087-    if ignored_roots.is_empty() {\n1088-        return Ok(());\n1089-    }\n--\n1792-    );\n1793-}\n1794-\n1795:pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n1796-    let (entries_count, last_updated) = update_status_counts(state)?;\n1797-    // Persist cached counts so next startup can read them instantly\n1798-    if let Ok(conn) = db_connection(&state.db_path) {"}]},"uuid":"b5471680-76ec-4b90-8f82-4b9b4699ebf1","timestamp":"2026-02-20T09:14:53.128Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"1083-    hasher.finish()\n1084-}\n1085-\n1086:fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n1087-    if ignored_roots.is_empty() {\n1088-        return Ok(());\n1089-    }\n--\n1792-    );\n1793-}\n1794-\n1795:pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n1796-    let (entries_count, last_updated) = update_status_counts(state)?;\n1797-    // Persist cached counts so next startup can read them instantly\n1798-    if let Ok(conn) = db_connection(&state.db_path) {","numLines":15},"sourceToolAssistantUUID":"2422468d-9618-4b6f-98f0-4f68c9922b64"}
{"parentUuid":"b5471680-76ec-4b90-8f82-4b9b4699ebf1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_013e2UZ1kxtm4KeUBHtyXowy","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PEKjNCQXbrbot825djwzgi","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1086,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":835,"cache_read_input_tokens":50565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":835},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4p8L6AHsUcQiqBN48p","type":"assistant","uuid":"06a85b81-0954-4862-a536-2d16b0ef2be1","timestamp":"2026-02-20T09:14:55.150Z"}
{"parentUuid":"06a85b81-0954-4862-a536-2d16b0ef2be1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01PEKjNCQXbrbot825djwzgi","toolUseID":"toolu_01PEKjNCQXbrbot825djwzgi","timestamp":"2026-02-20T09:14:55.169Z","uuid":"04ff8c7a-6245-49cc-8526-c0b4a2a61eb2"}
{"parentUuid":"06a85b81-0954-4862-a536-2d16b0ef2be1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PEKjNCQXbrbot825djwzgi","type":"tool_result","content":"  1086→fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n  1087→    if ignored_roots.is_empty() {\n  1088→        return Ok(());\n  1089→    }\n  1090→\n  1091→    let conn = db_connection(db_path)?;\n  1092→    for root in ignored_roots {\n  1093→        let root_str = root.to_string_lossy().to_string();\n  1094→        if root_str.is_empty() {\n  1095→            continue;\n  1096→        }\n  1097→\n  1098→        if root_str == \"/\" {\n  1099→            conn.execute(\"DELETE FROM entries\", [])\n  1100→                .map_err(|e| e.to_string())?;\n  1101→            break;\n  1102→        }\n  1103→\n  1104→        let prefix = root_str.trim_end_matches('/');\n  1105→        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n  1106→        conn.execute(\n  1107→            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n  1108→            params![prefix, descendant_like],\n  1109→        )\n  1110→        .map_err(|e| e.to_string())?;\n  1111→    }\n  1112→\n  1113→    Ok(())\n  1114→}\n  1115→\n  1116→fn glob_match_path(pattern: &str, text: &str) -> bool {\n  1117→    let pat = pattern.as_bytes();\n  1118→    let txt = text.as_bytes();\n  1119→    let (pn, tn) = (pat.len(), txt.len());\n  1120→\n  1121→    let mut px = 0usize;\n  1122→    let mut tx = 0usize;\n  1123→    let mut star_px = usize::MAX;\n  1124→    let mut star_tx = 0usize;\n  1125→    let mut star_is_double = false;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"238dfe47-dcf8-4abb-a8ee-6ed85ec97a00","timestamp":"2026-02-20T09:14:55.168Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;","numLines":40,"startLine":1086,"totalLines":5087}},"sourceToolAssistantUUID":"06a85b81-0954-4862-a536-2d16b0ef2be1"}
{"parentUuid":"238dfe47-dcf8-4abb-a8ee-6ed85ec97a00","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01XdFS9mYhYBrfSGB25bs8bE","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I see the issue more clearly. Let me trace through the conditional startup sequence:1. Startup begins\n2. DB connection opened at line 4515 to read `last_event_id` and `index_complete`\n3. If `index_complete=true` and `stored_event_id` is Some, start conditional watcher\n4. Housekeeping thread starts (500ms sleep, then `refresh_and_emit_status_counts` and `purge_ignored_entries`)\n5. The FSEvents watcher starts AND immediately starts replaying historical events\n6. After `HistoryDone`, `process_watcher_paths` is called which calls `apply_path_changes` → `db_connection`\n\n\n7. Meanwhile, the housekeeping thread (after 500ms) runs `purge_ignored_entries` which also opens a `db_connection`\n\nSo I've got concurrent database writes happening—the watcher thread replaying events and the housekeeping thread purging entries. SQLite's WAL mode should handle this with the 3000ms busy_timeout, but I'm wondering if a previous index run left a WAL checkpoint in TRUNCATE mode that's blocking writes, or if the historical replay is generating so many events that it keeps the watcher locked for too long and starves the housekeeping thread.\n\nActually, let me reconsider. The \"database is locked\" error means something is holding a RESERVED or EXCLUSIVE lock beyond the 3000ms timeout. In WAL mode, this typically happens when a write transaction runs too long or when a `wal_checkpoint(TRUNCATE)` operation tries to acquire exclusive access. I'm executing that checkpoint during startup, and if the previous run crashed, it might not have completed cleanly. But WAL mode should handle recovery gracefully on the next startup.\n\nLet me look more closely at what the FSEvents watcher replay is actually doing—that might be where the bottleneck is. When the watcher replays events during conditional startup, the full indexer shouldn't run unless the `index_complete` check fails. But the error reproduces immediately on restart, which makes me think the issue might be related to a massive WAL file from a previous run—when `restore_normal_pragmas` tries to execute `PRAGMA wal_checkpoint(TRUNCATE)`, it could block if there are active readers, and that's likely what's holding the write lock for longer than the 3-second timeout.\n\nLet me trace through what happens in `init_db` during startup to see where exactly this collision occurs.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":762,"cache_read_input_tokens":51400,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":762},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4pH1yGrdev4ko8pYz2","type":"assistant","uuid":"992d6172-2302-4fae-9512-6cab08ece7c5","timestamp":"2026-02-20T09:15:21.484Z"}
{"parentUuid":"992d6172-2302-4fae-9512-6cab08ece7c5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01XdFS9mYhYBrfSGB25bs8bE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ho7S6qmAWptvXGU4obngZz","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":414,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":762,"cache_read_input_tokens":51400,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":762},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4pH1yGrdev4ko8pYz2","type":"assistant","uuid":"03d94349-fa47-4d17-9c48-864de545cb96","timestamp":"2026-02-20T09:15:21.605Z"}
{"parentUuid":"03d94349-fa47-4d17-9c48-864de545cb96","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Ho7S6qmAWptvXGU4obngZz","toolUseID":"toolu_01Ho7S6qmAWptvXGU4obngZz","timestamp":"2026-02-20T09:15:21.624Z","uuid":"534883f3-f5f3-4277-8631-bb86e153a072"}
{"parentUuid":"03d94349-fa47-4d17-9c48-864de545cb96","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ho7S6qmAWptvXGU4obngZz","type":"tool_result","content":"   414→fn init_db(db_path: &Path) -> AppResult<()> {\n   415→    let t = Instant::now();\n   416→    let conn = db_connection(db_path)?;\n   417→    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n   418→\n   419→    let current_version: i32 = conn\n   420→        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n   421→        .unwrap_or(0);\n   422→    if current_version != DB_VERSION {\n   423→        conn.execute_batch(\n   424→            r#\"\n   425→            DROP TRIGGER IF EXISTS entries_ai;\n   426→            DROP TRIGGER IF EXISTS entries_ad;\n   427→            DROP TRIGGER IF EXISTS entries_au;\n   428→            DROP TABLE IF EXISTS entries_fts;\n   429→            DROP TABLE IF EXISTS entries;\n   430→            \"#,\n   431→        )\n   432→        .map_err(|e| e.to_string())?;\n   433→        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n   434→            .map_err(|e| e.to_string())?;\n   435→    }\n   436→    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n   437→\n   438→    conn.execute_batch(\n   439→        r#\"\n   440→        CREATE TABLE IF NOT EXISTS entries (\n   441→          id INTEGER PRIMARY KEY,\n   442→          path TEXT NOT NULL UNIQUE,\n   443→          name TEXT NOT NULL,\n   444→          dir TEXT NOT NULL,\n   445→          is_dir INTEGER NOT NULL,\n   446→          ext TEXT,\n   447→          mtime INTEGER,\n   448→          size INTEGER,\n   449→          indexed_at INTEGER NOT NULL,\n   450→          run_id INTEGER NOT NULL DEFAULT 0\n   451→        );\n   452→\n   453→        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n   454→        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n   455→        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n   456→        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n   457→\n   458→        CREATE TABLE IF NOT EXISTS meta (\n   459→          key TEXT PRIMARY KEY,\n   460→          value TEXT NOT NULL\n   461→        );\n   462→        \"#,\n   463→    )\n   464→    .map_err(|e| e.to_string())?;\n   465→    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n   466→\n   467→    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n   468→    let migrated = get_meta(&conn, legacy_index_migration_key)\n   469→        .map(|v| v == \"1\")\n   470→        .unwrap_or(false);\n   471→    if !migrated {\n   472→        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n   473→            .map_err(|e| e.to_string())?;\n   474→        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n   475→    }\n   476→    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n   477→\n   478→    Ok(())\n   479→}\n   480→\n   481→pub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n   482→    conn.query_row(\n   483→        \"SELECT value FROM meta WHERE key = ?1\",\n   484→        params![key],\n   485→        |row| row.get(0),\n   486→    )\n   487→    .ok()\n   488→}\n   489→\n   490→pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n   491→    conn.execute(\n   492→        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n   493→        params![key, value],\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"07cd19e6-785c-48e4-ab25-18e0453ba581","timestamp":"2026-02-20T09:15:21.622Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],","numLines":80,"startLine":414,"totalLines":5087}},"sourceToolAssistantUUID":"03d94349-fa47-4d17-9c48-864de545cb96"}
{"parentUuid":"07cd19e6-785c-48e4-ab25-18e0453ba581","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01A1dPVt4gK6qmx7PHo1sDJw","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"OK. I see that `init_db` opens a connection, does various schema operations, and then that connection goes out of scope (dropped). This should be fine.\n\nLet me now look at the sequence more carefully. I think the issue might be the `restore_normal_pragmas` function. It calls:\n```rust\nconn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n```\n\nIn WAL mode, `PRAGMA wal_checkpoint(TRUNCATE)` will return an error if there are active readers. But it shouldn't block. However, in WAL mode, \"database is locked\" in the sense that another writer is trying to write... \n\n\nActually, I need to reconsider how WAL mode works. Multiple readers can coexist with a single writer, and the writer won't block readers. The `SQLITE_BUSY` error only happens when a writer tries to write while another writer is active, or when a checkpoint runs into active readers or writers. With the `busy_timeout` set to 3 seconds, SQLite will retry automatically, so \"database is locked\" would only surface if that timeout gets exceeded.\n\nBut there's a race condition I'm seeing: the watcher checks if indexing is active before writing, but the indexer might finish and call `wal_checkpoint(TRUNCATE)` right as the watcher tries to write. The checkpoint operation needs exclusive access to truncate the WAL file, which could block the watcher's write attempt even though the indexer itself isn't holding a lock anymore. transaction that started before the checkpoint point. \n\nThe \"database is locked\" error in SQLite is `SQLITE_BUSY`, and with a 3-second timeout, that makes sense. I'm wondering if the problem is specifically in `restore_normal_pragmas` at the end of indexing—when it calls `PRAGMA wal_checkpoint(TRUNCATE)`, the FSEvents watcher might simultaneously try to write, or if there are active read connections, the checkpoint will block and timeout.\n\nLet me think about this differently. The user says it reproduces immediately on restart with 1.1M entries. The FSEvents history probably contains many changes, and when the conditional startup watcher processes these historical events through `apply_path_changes`, it opens a new connection each time. Since the watcher is single-threaded, those calls can't overlap, so that's not the issue.\n\nWhat's actually running concurrently at startup? The housekeeping thread wakes up every 500ms and calls `refresh_and_emit_status_counts`, which also needs database access.\n\nExamining the timeline: the watcher starts processing historical events, then around 300ms the debounce triggers `process_watcher_paths` for a database write, and at 500ms the housekeeping thread kicks in with its own database operations. Meanwhile the watcher is still churning through historical events. The most likely culprit is either the housekeeping thread holding a write lock longer than expected, or something else I'm missing in `refresh_and_emit_status_counts`.","signature":"EuohCkYICxgCKkB0AcolU/aLtBQWZAykm/2+aa0K7Hrjs/W8fy044BV+Se3VX0f8JzonMRpXvuLmeNDFSdbdWy6jixq8+ris3eClEgwqWE8o5zMYIwENCcMaDI2VSn1+XZE2SpEUUCIw8zFbpxbgCSKD93ZZHdxkNX9SsCiFpZRnwmrtzQme80AEyjV7tjj3LB0/h8JVOvrcKtEgbT3WJ0YsIPjVUr4ZGQpziiXe5i5cuU065OZE55K1PQw/hXqTNokZUsehmEuNqzQFCFGu5IulJ8/RaSdSzldVoeQXfnlPdly8y4Mz4r33s3l27PQ3IIBD5P1Ko+oVue3HZ8x3njepBaI9tsyTmvi+HSThQTnoPPRBJCO3nCmravx/+2QiJAglNko70Al0rv7KC41e5gkBnSsRBk7EVQgoh1yBVYLaJn8oEGzr/UjTQqrZxX0F08h+MPmPo/Y0utjLIV02LkRK7zyHz6znxgHjEuw6oTTISgYLXkJf6hDAo2XUWNbLP1IN5O3WkEuOOkcuBgs6THkmux/7rrJRoyAMZEKPsvCpfBQXixqRhEnViZCxIaQI6wFLiyR5UO6bGpP1w+FSbVIH2k864kB4V+Sr8G8nKmkUfQVMWdZsqR4lF5FeVeFGpXFg7aDJB5wwlJO5T1VdONDx3cKhiPo4tSOIBvDNAJ1pvhi0qeZ2XiFIC7E6SLYeQ5hjac6M5qy29ZxjXjLnl5OJRWU8l7F8YUWNNRKSMe6e6Vw3E5UAejejM0TutVJnufd4ppv0WnJMT7tMbzo3AWot8pWX/H+9sQurs4FhET34lUmh1iiJAKQv89A4QI/HY7YGDriJmtd1UDCRQaAjBskNuO75d2x41VxH9RRXgfspMJyej5MdzFhMT2H/ms+mWaMsVByFhVZ49tHnzrKnF2eOJlNhrcsT4FZ5cnRCbu/l3X6bhdK+1gO/pq6UwO3xi6c/5D7ekezj5GdTci81RAf3uBJNcxbxpoZeUZf1rbK/5TdwUvLg+CRScNXsVP1gtW+rcSvfp8jjyoUjKFdpH04/cKyV8s6XWTcqKz98mprlsI57gqu2PXQGM10ocL8NZhC0ylCOnKejBtBTSBIvsVbtJx2GIWTDqKQsoAN+1yQSKDFkJAUEysbHdwV8FhRTmh0GSCkFj27xSn6lTxNmaY/1v5Lqd91Ww2oR5ChnjdSkTOurhy83t32ILCer1X44F3fUTCCWK3kyMRrPLlxOI8dd5Jrfrd4vA7bnjPn272UqY3TSZFkFX8rf7hg/qykC8Jp4a54D4N8VtH4ZyiDGtWaluYKOfLfFgqp79YR3YhHMIw+xDLlJveWdX1Vqc3gfeDeuWdYVAvxISgU8kia52dFQOnHWBb/BXlfthWep0D4ZOehRO+c00d9Hvn5nE02YuYgmU2k7fpfMAaXZOG5Rr0+MRUymHwu5oKvRDOmnT7bH7RT49mehRMRBoM3DXXeizCVkZwxQPV6N1uvFlfda8OG3rwOPAGFnWphzMOQhI+rYCOPuJSXvCQwYkzPd/0TRPo6XO1a1IPbpkW8QtVtCU2VZ5OEqP2LfIHHCqGOP3hGeDpOoIoIndsSAVInQDydUbHP+GW+oO5BzzG1jXs4DR+l+D1omkRIhI97UnnF8TDzsRRz7vJ3YADyWHlODPyYTFhOXnLOsc3UELWpsZ/5NH7MHBxY1Hep6aWMyBHLqFZtg1OIlfdP9NrsCdtHHyIlebr6zOdXqIBLqg1PAb6GOC3KOWxcYY6lmj+xb/rXnzLCr7dQ6GUrKJ9RVvMafCoPf6bzKt5fonk/Kx0yYh94J7Eoxl4GqnPavz2T7TuRSog/8AOYgOa93ErprfHtOiNFpacCOYUm7mIuq7Ct8JfAJ4QKL83bJDLlwzyFCa/bdVj4Owfrubh5iMXhpHfpLvJtDJahH6Rr8FExWRxf2G1Xk8XNlQQrM3LuovcU4fW6LZlT3ye67SBFGd+jp52YGUDI1I4OKkrMHlUuZgGFHACtH/BD3qU++LKaZIR8aZgR44DSMSIW6roQEJ4tmlpcDeq84ORVhJikpVDvZ/UFzY3njllWFb+3S2mV+zPmT6ca5mPzjbuvCCNM53WD6xLUYuATjwE2P2ce3OPnVauy79t8uBb7/I0GzTgFzta6bJCm3G1JtCdhW813vsfYjVGO0xMt0pQS4tu5T95N9hTeIl52PMnrdw0MqeM5zhs2NjV04I0cKh5G6YzUkHPicm1DaWBR1yysZz7lzJyH29brP2CSMBXT/6trPYEnaT3fK1iOVZdfXvp+bUsykW1F7Grw9WgyKPoue0vl4F5oz98lUbZThcabJ4Tlaks/KAxX+1gVa9kJzLdek5ALk0wDmep69DfuYVREvRV1JkMtn1MUzFpW+x+AbqyDJsSgmHjDJw2Lk+3Cg1Ad6ByXJlcowXw4pqVjDvKJZ+elMFztpJb+zaZRwzzJ7aXuM/szFPa2b6m1lbvfrOHfftQ3TQ8AsPpp5v76gm9TP4aZ9BDYsnD97uARGPKvDFX3w0gHsf2hRBEegeHF517QPMwVSFgdc2KwNpH116/qLwLVJUWUGe7DWCtZ+a9eemtHVA9fdTX2RJ2Q1thh+hKwPJEYcybN8HH40smzQKiKwZkZ+rrIOmECFjKGUoctMoJsqAdcDrdtMil38Bai/f7P8QX5PPmwEELaYKheY+VfE2VgzL0Tgg3UxD+pQV+NvqqA16WlResBTca9KmCYTLgEagJ82SKG5puI7KNjtqyt5M6A64mcS18y8uWjujGbkUR5mRL81B0tWvhZl6xtzmjsfOY8MANTr3w6l9Sc8kwM3yuqQPXFC1kJdp7MATAkqcaDb+gzmoy2WsP4tV4YEcVIbrHpwtzAWzT+iOKaK5mqPBZz4jv3KFPXnf4ZPb+YBBmoGXAV0XleYtz2WQ/9D6++umW07g2lukiEyctFUAW4qv2iEKkjO64iAAPXT+ghFmPm5sRf76+mORStaHVsc1un9vYmS58RwfjtPJc2hVVr4EXwcrBe6N9iUoJl5ScXi8Ah34qtQvSeb1cwK1qATDkUrdV8HOD80HsMpiJLpQs8rdRGrs8qFfmk/lu6KeM3GqmctigbvC6jL+8wvL+SCJWdtn7QblEa5oITp1x6mc7PGjE7E2JHYJ8xI2qmTBIl7wiG6lEU5pYCyu4RaaQahvtKYyApz/15ie8eB8bv9Qz0rM2XNclJ+Pey8SwiotlAm4hnQIhGz2ktKnMe+9MSVeyhXXrW6pbVRcypkupwhJddlWWHXiByAz4xVf8tUdcvRy9NLV5Iw3xsa+FYhptY+ko/HbxQtpsgXjP5V2Ge5hfdF9JgRYEVZ2fhzw3rngAQvzw0uXqhK6y01MvmsDikHmncP4/tlBxRtrmGU917X1nEYVgdZg186TlGyYk8kiAynUrW0yIjGQZw040jMiqFbk+o3I4Cmvb9fO/z5FszSCHXOaTloGkBaMLCNLuwB1zFWbM3FyVfD0JzDidL4nBY6kvTV47p+64o2yarhvBbytKo/E00jObF5Jppb+7IUODA5yXW1VSGCvrjCJnujo+zl/qPnC422gTvuy+kKxrysCHUY+cHdaUTeFcIok0K1BZeAPT37gT468ZVKvtQD2r1y6qf2Qa7Md4zloRRg/eYQ/Qp9o0dCG/sH2jGqui9UI39l6c63rc8dstvnG/6VtuAZO93p3hAaAUDAWbvgSdquXMqHe/NF5/rtKPx/4uBXLcj+0C2eFVFQS+qzs9o/yd4IXUkY8MWp+jxltYNSMKkA/agNXyT/fg6v1joJp/rVGlZRRAOs97XH5AncfWYsvILLDUXAyQWPCnxT75+YgYhOaMP2lacairoxMpErx6/ghM27gU0gifyze0DPCUP+lZPQV1rXSe6Jjw9ImcVJQCmHjDmMStLkiGnb94q951IP07l4QIoJvQOWDPpvGRpjhlEGFxZdZEBVO7GtKFVsOivIS6YlzbXp9321Bk1BsxWjtUpp+Yq7RcuX6l42dfvTr0fyOCCEj8ZiYVvCQVcepkbM7mTDgH86EL9aUaNKE1lW1xz3cHA5gpXIJ4UOqVW8qA19oD+jCtwoUZwrnPzx9N6k1DEXE0sYvNQ2VdLI0uzYQvjnIBinSm6iY/YeGnPOAQJSM/08HJ5pWNUyxrfUObnbSMUSOgQBg/UeZ1lzFOhU8JAvY8Yspos51croL7exvfwfGvkz+aBIHd7UrO7QXFcFhi1aLqiB8BDz/aoHzJ+oKuJwD1M4yKjqKotN3eaw41Xip9ApH3fIvY3D/xa3hDMqkxCnulQivpP7KFI8MEsljsllp0QqeARR9o2sZ4U/BEPx2s44C7+3bNEmj5PWn8hjGDp4Ffl0lrZKRlvqkXTk6rKicaZzmiBffu3Dytuf7Bl96nCy85XizTvdJ8TMAMfYdsXyYgf0EkvDlDOy+BUg2NqkGlr0oVfHxo0q9UqmRbYSDnnQEpH6dDcJg783IctPm8FXpbd/dc7wNikYAaAgCOVpoOqBqaxhDOrf7CTFWSIbM213gEanP3Ny74wWyTN2Q/DZF1Tvwf7btyiqJ8gY4yzXPXK4UcL5VT3uKmYh5IZCUOoc1h5GTvGvYQI//OR6ffCDKFZ3xdaK4+yZw0FXOhGZxWefFjlne4e5am8QDklWXCtWGLcgJUdqy4SS8DCSdm884pymUgNNo6CinC/xCW0WLuIDGgGC4ugpTvaGLgN6N7/YHt785Ui6GpbRwKwUZUNHRG1N1fhyisQqPx/+d9h/xrMnPfn40fFfxxXSFwI22FuKDJ3f2M4DylfsC3Y9gDi6yoWkzC6mBVk2/E4SIYA0LXfGSSg4VeFN7RSsVKMegtOte8/Q57AHZoyrbMO1j8S7KtbMHsbixpTmjD9TcuHhst/X05ARjxfyBySw+te5taNlKk0C1mvlA9ZwM6/N140fMaCvszaMaNKAe7mHNrgFnxKXKdLB47AgXdUsb8PD+dIJvKeY9um+ZmjGC5hlAyPBSxdzH1BuMvTytWUvwDIm5iVXXB3JJwOCVh7GSNnehz/NZSGxFnRvr7C7sB2LsU2sjrkIzb9xJnKxnCMoHEGe+9IlRiVr7yXkyUlfPuP5jcMWYakDHAK5nUaFBdoG2/oIlclVQHMldsjkCDcO3ip4hJi0CBQePr/QGFovxeyleMIRojKFyWJcD4oBEScYFu161IUbZhaTdN7kcp71YPezqKLwpu57s8j5RHJxOXAZGttIwwXR72DPUfjy9b6DnSbPX/hvo/MEv9E/aLZh3FVNbdBKq+NoF6oS0ItP2XnHhU9bg/YfNqkEj98HHWrWo/8woT/Lo5hm836MkipEAKHh4AEvmlskMkN4Nq3pfJ4Fj4qQ+wDegna8Yan9bx+qylE/OIInwzt4cZylSLmBIGCU7nzu7UzKyi1xH1D3xqkgdVImjixfovC3ZDK+n4ZdcfLCnOn4vPO9U68/wnmOcIXcCJqQnjsO7uCjtkT0ZIveS1P+PZ8cyMc5PpVhiVGI6lKnIuNRUmVeMJ0C1iRMAhols/se8UkRSCQ0I052fDHuM4F+t8AW8ZwyhJHJuXlIu8Je4IQnfncMGZLH0CVQffWJ9TTcCoy2eC4YfipvjtycrScmkHBdPy8usoG9HCLnMR5QbjaA2CjXexePLOL7N2/thPQ2QUoSQgR81A/hUxAYSLHTgfib2upU0+0A0P1MyiFU8zV0h/KQ2SQ/tdiIt2QGgvkYakmTdQuXNvQRfYt/Vxhljru/fiFtfCdUTtigea9Kj1nsqx5cY+e/KhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2408,"cache_read_input_tokens":52162,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2408},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4rEJZVLmwiBQcLq1B2","type":"assistant","uuid":"9ffaf921-c416-496f-a6c1-30703b133f11","timestamp":"2026-02-20T09:15:49.432Z"}
{"parentUuid":"9ffaf921-c416-496f-a6c1-30703b133f11","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01A1dPVt4gK6qmx7PHo1sDJw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XAHVyisfodxmVvdW1vqSkA","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1795,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2408,"cache_read_input_tokens":52162,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2408},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4rEJZVLmwiBQcLq1B2","type":"assistant","uuid":"ba9a2757-c8f3-46ed-ada4-c9e3b75fcc6b","timestamp":"2026-02-20T09:15:49.502Z"}
{"parentUuid":"ba9a2757-c8f3-46ed-ada4-c9e3b75fcc6b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01XAHVyisfodxmVvdW1vqSkA","toolUseID":"toolu_01XAHVyisfodxmVvdW1vqSkA","timestamp":"2026-02-20T09:15:49.518Z","uuid":"4d117907-cfb4-4e6c-8591-0c26b84eb691"}
{"parentUuid":"ba9a2757-c8f3-46ed-ada4-c9e3b75fcc6b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XAHVyisfodxmVvdW1vqSkA","type":"tool_result","content":"  1795→pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n  1796→    let (entries_count, last_updated) = update_status_counts(state)?;\n  1797→    // Persist cached counts so next startup can read them instantly\n  1798→    if let Ok(conn) = db_connection(&state.db_path) {\n  1799→        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n  1800→        if let Some(lu) = last_updated {\n  1801→            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n  1802→        }\n  1803→    }\n  1804→    emit_status_counts(app, state);\n  1805→    Ok(())\n  1806→}\n  1807→\n  1808→/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n  1809→/// Used on Windows startup paths where the index is already complete from a prior run.\n  1810→pub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n  1811→    let (count, last_updated) = db_connection(&state.db_path)\n  1812→        .ok()\n  1813→        .map(|conn| {\n  1814→            let c = get_meta(&conn, \"cached_entries_count\")\n  1815→                .and_then(|v| v.parse::<u64>().ok())\n  1816→                .unwrap_or(0);\n  1817→            let lu = get_meta(&conn, \"cached_last_updated\")\n  1818→                .and_then(|v| v.parse::<i64>().ok());\n  1819→            (c, lu)\n  1820→        })\n  1821→        .unwrap_or((0, None));\n  1822→\n  1823→    {\n  1824→        let mut status = state.status.lock();\n  1825→        status.state = IndexState::Ready;\n  1826→        status.entries_count = count;\n  1827→        status.last_updated = last_updated;\n  1828→    }\n  1829→\n  1830→    emit_index_state(app, \"Ready\", None);\n  1831→    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n  1832→}\n  1833→\n  1834→#[cfg(target_os = \"macos\")]\n  1835→fn touch_status_updated(state: &AppState) {\n  1836→    state.status.lock().last_updated = Some(now_epoch());\n  1837→}\n  1838→\n  1839→pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n  1840→    start_full_index_worker_inner(app, state, false)\n  1841→}\n  1842→\n  1843→pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n  1844→    start_full_index_worker_inner(app, state, true)\n  1845→}\n  1846→\n  1847→fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n  1848→    if state\n  1849→        .indexing_active\n  1850→        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n  1851→        .is_err()\n  1852→    {\n  1853→        perf_log(\"index_start_skipped already_active=true\");\n  1854→        return Ok(());\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"32f7c1de-d4d4-48bc-9422-05caf1eb0768","timestamp":"2026-02-20T09:15:49.516Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());","numLines":60,"startLine":1795,"totalLines":5087}},"sourceToolAssistantUUID":"ba9a2757-c8f3-46ed-ada4-c9e3b75fcc6b"}
{"parentUuid":"32f7c1de-d4d4-48bc-9422-05caf1eb0768","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_013NtJhvRTtzeAaqtMvzUPzv","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me look at `update_status_counts` which is called by `refresh_and_emit_status_counts`:","signature":"EoICCkYICxgCKkAbB9di84c+VTrXzZL++UPk7aVmkr9/eVvLq2yAiuJG5jo0DELZnmqhrZJO+/QwQ5x6oTwh0DMe6YQrSiD2f82+EgzHWNhVirE/lV51oGMaDAWX4gYYvknOrKrAfCIw/QCMsJcGR3iIgHHN8HPOwxso8OndJynS/UHo9DgVAVZowAxiDxAtiOfvAH2FlPqtKmpKLksCPUX+NJVcFeEsA3+ZAEPTYmna3e5SmfyNyyOIK2E7Q/0RXYsWk+NxK+8Rig4R7lkvFs489ZUojSlxc+d0iDo+mARFCu5qzb7m4cHx/Z5uOkX0FRj6Db7XT80w10ajThwUydkjhsf4GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2309,"cache_read_input_tokens":54570,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2309},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4tHWqviaHgjRUUh4d5","type":"assistant","uuid":"5deda12b-cfad-4061-a6fa-5f4efe186ad3","timestamp":"2026-02-20T09:15:51.867Z"}
{"parentUuid":"5deda12b-cfad-4061-a6fa-5f4efe186ad3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_013NtJhvRTtzeAaqtMvzUPzv","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01H3ocSjU17bFwuk3oFETEMQ","name":"Grep","input":{"pattern":"fn update_status_counts","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2309,"cache_read_input_tokens":54570,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2309},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4tHWqviaHgjRUUh4d5","type":"assistant","uuid":"311207b3-704e-43c5-ba25-05c104dd3cb4","timestamp":"2026-02-20T09:15:53.072Z"}
{"parentUuid":"311207b3-704e-43c5-ba25-05c104dd3cb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01H3ocSjU17bFwuk3oFETEMQ","toolUseID":"toolu_01H3ocSjU17bFwuk3oFETEMQ","timestamp":"2026-02-20T09:15:53.908Z","uuid":"169304cb-248a-46bc-95b6-e6f5c5eb084e"}
{"parentUuid":"311207b3-704e-43c5-ba25-05c104dd3cb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01H3ocSjU17bFwuk3oFETEMQ","type":"tool_result","content":"498-\n499-fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n500-    let conn = db_connection(&state.db_path)?;\n501-\n502-    let entries_count = conn\n503-        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n504-            row.get::<_, i64>(0)\n505-        })\n506-        .map_err(|e| e.to_string())?\n507-        .max(0) as u64;\n508-\n509-    let last_updated = conn\n510-        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n511-            row.get::<_, Option<i64>>(0)\n512-        })\n513-        .map_err(|e| e.to_string())?;\n514-\n515-    Ok((entries_count, last_updated))\n516-}\n517-\n518:pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n519-    let (entries_count, last_updated) = update_counts(state)?;\n520-    let mut status = state.status.lock();\n521-    status.entries_count = entries_count;\n522-    status.last_updated = last_updated;\n523-    Ok((entries_count, last_updated))\n524-}\n525-\n526-pub(crate) fn invalidate_search_caches(state: &AppState) {\n527-    state.fd_search_cache.lock().take();\n528-    state.negative_name_cache.lock().clear();\n529-}\n530-\n531-fn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n532-    let now = Instant::now();\n533-    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n534-}\n535-\n536-fn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n537-    if query.is_empty() {\n538-        return None;"}]},"uuid":"20141a68-deec-478c-929f-b59597bc462c","timestamp":"2026-02-20T09:15:53.906Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"498-\n499-fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n500-    let conn = db_connection(&state.db_path)?;\n501-\n502-    let entries_count = conn\n503-        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n504-            row.get::<_, i64>(0)\n505-        })\n506-        .map_err(|e| e.to_string())?\n507-        .max(0) as u64;\n508-\n509-    let last_updated = conn\n510-        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n511-            row.get::<_, Option<i64>>(0)\n512-        })\n513-        .map_err(|e| e.to_string())?;\n514-\n515-    Ok((entries_count, last_updated))\n516-}\n517-\n518:pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n519-    let (entries_count, last_updated) = update_counts(state)?;\n520-    let mut status = state.status.lock();\n521-    status.entries_count = entries_count;\n522-    status.last_updated = last_updated;\n523-    Ok((entries_count, last_updated))\n524-}\n525-\n526-pub(crate) fn invalidate_search_caches(state: &AppState) {\n527-    state.fd_search_cache.lock().take();\n528-    state.negative_name_cache.lock().clear();\n529-}\n530-\n531-fn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n532-    let now = Instant::now();\n533-    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n534-}\n535-\n536-fn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n537-    if query.is_empty() {\n538-        return None;","numLines":41},"sourceToolAssistantUUID":"311207b3-704e-43c5-ba25-05c104dd3cb4"}
{"parentUuid":"20141a68-deec-478c-929f-b59597bc462c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_018eQcSq7W1qAGj4yWJ3CpdU","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"OK so `update_counts` opens a DB connection and does `COUNT(*)` which is a read operation. This is fine in WAL mode.\n\nNow let me check if the issue might be related to the `start_fsevent_watcher_worker` using the `watcher_active` and `watcher_stop` flags. Specifically, let me look at where `watcher_active` is set to true and false:","signature":"EvQDCkYICxgCKkCv2D/IqgA5cEYh5IuTxQcyh5XCKNvqNwpNehNOnNxSK01GLiLxkTOF7larVM3Ur+H0ltwuH19IWW9/K4PkYwd8EgwFgf78jeO5IZXO2XsaDLWhgsosQyLt4r00/yIw/3F9QkhsIK6vi2X5u+P6u9y7rTT8JqN7CaZmfRby9x2umSdSfH4O3FcLLT9PbIsHKtsCVqq1yvB+QxW9GMOnpLgGv9oEPb8//6RsHlr7nArsBxP3Mv1YfH+mONOXXL2kh3Y578ZgutHynCtUX3qjR9cBzkfXJswV8JyIOSTqhps6932hi3tz9x/54hhG+wkQglXzRZzAMUZTl5aFG+sUWJa+ivifWC5tk1CtGor3hrn+ASdtp71cX8kknz0jYoQp6rap9W6UBaPW5jBHYV0KPrkH7eIiLfWkXbT4+Avb6uMhmDiyPxnbQadUnFJFN5d8xazCWz/AwO4Pk9ryhLkf/qbu0BGAZnFSSW3mhTDxp3VipVv91+Y2K7q+hN/kdSa2bbvtIm4HTK8p+x0RJbOa0t6CaDAvFr9NpviMM3amA1kKo89uKuIHg3eiyvmt2mr8g20H3+1Qg4PxZmveRXEiEGTuHEcaZzajMU/zm794h9WV50hDeF30K+4DNxp/BnkXEaaVBJ877+VTvKS8eqUYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":738,"cache_read_input_tokens":56879,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":738},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4tcEyqBVtSbBG56Q6A","type":"assistant","uuid":"e89c985d-e3f6-4e7a-a669-00b6ac50e99f","timestamp":"2026-02-20T09:15:57.469Z"}
{"parentUuid":"e89c985d-e3f6-4e7a-a669-00b6ac50e99f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_018eQcSq7W1qAGj4yWJ3CpdU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NKfxbKr35STduCpj3nRqPF","name":"Grep","input":{"pattern":"watcher_active|watcher_stop","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":738,"cache_read_input_tokens":56879,"output_tokens":242,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":738,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK4tcEyqBVtSbBG56Q6A","type":"assistant","uuid":"15ecef47-50b3-48bd-a3ba-39709ba974c3","timestamp":"2026-02-20T09:15:58.294Z"}
{"parentUuid":"15ecef47-50b3-48bd-a3ba-39709ba974c3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01NKfxbKr35STduCpj3nRqPF","toolUseID":"toolu_01NKfxbKr35STduCpj3nRqPF","timestamp":"2026-02-20T09:15:59.100Z","uuid":"dd090eb4-ef3b-436a-889d-2fc6598e5445"}
{"parentUuid":"15ecef47-50b3-48bd-a3ba-39709ba974c3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NKfxbKr35STduCpj3nRqPF","type":"tool_result","content":"291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295-    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n--\n2789-        }\n2790-\n2791-        // Stop existing file watcher and wait for it to fully exit\n2792:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2794:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2795-            if std::time::Instant::now() >= deadline {\n2796-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2797-                break;\n--\n2821-        emit_index_updated(&app, 0, now_epoch(), 0);\n2822-\n2823-        // Allow new watcher to start\n2824:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2825-\n2826-        #[cfg(target_os = \"windows\")]\n2827-        {\n--\n4456-        ignore_cache: Arc::new(Mutex::new(None)),\n4457-        gitignore,\n4458-        mem_index: Arc::new(RwLock::new(None)),\n4459:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4460:        watcher_active: Arc::new(AtomicBool::new(false)),\n4461-    };\n4462-\n4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n--\n4668-            ignore_cache: Arc::new(Mutex::new(None)),\n4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4670-            mem_index: Arc::new(RwLock::new(None)),\n4671:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4672:            watcher_active: Arc::new(AtomicBool::new(false)),\n4673-        }\n4674-    }\n4675-"}]},"uuid":"c1cb083c-f4ac-49b4-8ec9-c710a727cb8f","timestamp":"2026-02-20T09:15:59.098Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295-    /// Set to true while a file watcher event loop is running.\n296:    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n--\n2789-        }\n2790-\n2791-        // Stop existing file watcher and wait for it to fully exit\n2792:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2794:        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2795-            if std::time::Instant::now() >= deadline {\n2796-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2797-                break;\n--\n2821-        emit_index_updated(&app, 0, now_epoch(), 0);\n2822-\n2823-        // Allow new watcher to start\n2824:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2825-\n2826-        #[cfg(target_os = \"windows\")]\n2827-        {\n--\n4456-        ignore_cache: Arc::new(Mutex::new(None)),\n4457-        gitignore,\n4458-        mem_index: Arc::new(RwLock::new(None)),\n4459:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4460:        watcher_active: Arc::new(AtomicBool::new(false)),\n4461-    };\n4462-\n4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n--\n4668-            ignore_cache: Arc::new(Mutex::new(None)),\n4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4670-            mem_index: Arc::new(RwLock::new(None)),\n4671:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4672:            watcher_active: Arc::new(AtomicBool::new(false)),\n4673-        }\n4674-    }\n4675-","numLines":45},"sourceToolAssistantUUID":"15ecef47-50b3-48bd-a3ba-39709ba974c3"}
{"parentUuid":"c1cb083c-f4ac-49b4-8ec9-c710a727cb8f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_012a3xwLc6RD25XAShh4EASd","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I notice that `watcher_active` is defined in `AppState` but I don't see where it's set to `true` in the watcher thread! Let me search for where it's stored as `true`:","signature":"Es8CCkYICxgCKkDTDI7EfxDvrRs0f3jPU3uM8oHs5wpbKoRf+Ri5xuUhVLWc745Bvy8H8+0t+xe8zRugswR6SATpEocDAB26PIftEgxQ5NwasbK2TvaRnK4aDE7eLo1JsYDwzei0tyIwl0fcPzn04w4FRvv3CLCALGSOqp0hNySdjeR/mI0tXJOirbSEvu8U7h1Zyi0S6NYFKrYBmVwcQK7tEzxbdyHFQM2krwObkWdOt1lS63ptjkwOjwEGZ3zHavEzx3b9Y8aYxdiFmzKOyQjMhvGHW2wu4IHK2FzeGq3/16JUfunth4ZnaSycH/edfp0RWGdlB/PhZZOOLMTm9CU4DcPOYB+36RggwXMlJmYP0t2BaKXVtDOoLzLR6/XCAzW8qUL5OOovSnlcOl3PgAs9vEsXOxEDVOjfyr63RhtI+b8hEe9YqBmKmxmF7rEqIGYYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":953,"cache_read_input_tokens":57617,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":953},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4tzLWSDFfyQhocAZWT","type":"assistant","uuid":"209d986a-78a8-47e9-858e-699c40b96891","timestamp":"2026-02-20T09:16:01.436Z"}
{"parentUuid":"209d986a-78a8-47e9-858e-699c40b96891","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_012a3xwLc6RD25XAShh4EASd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01R19ftnoEDkyXG37x4o4Fqd","name":"Grep","input":{"pattern":"watcher_active\\.store","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":5},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":953,"cache_read_input_tokens":57617,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":953},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4tzLWSDFfyQhocAZWT","type":"assistant","uuid":"b5feda3d-92cc-4e26-b5ca-2a53cb5d7707","timestamp":"2026-02-20T09:16:02.225Z"}
{"parentUuid":"b5feda3d-92cc-4e26-b5ca-2a53cb5d7707","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01R19ftnoEDkyXG37x4o4Fqd","toolUseID":"toolu_01R19ftnoEDkyXG37x4o4Fqd","timestamp":"2026-02-20T09:16:02.997Z","uuid":"d617f5aa-87c5-42ea-b9c6-ea735eeefe31"}
{"parentUuid":"b5feda3d-92cc-4e26-b5ca-2a53cb5d7707","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01R19ftnoEDkyXG37x4o4Fqd","type":"tool_result","content":"No matches found"}]},"uuid":"70524e54-2908-4109-9a67-c3f0eeb7d8f1","timestamp":"2026-02-20T09:16:02.996Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"","numLines":0},"sourceToolAssistantUUID":"b5feda3d-92cc-4e26-b5ca-2a53cb5d7707"}
{"parentUuid":"70524e54-2908-4109-9a67-c3f0eeb7d8f1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01WRz4Lc7LaqxbWtRpvoqkNL","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The `watcher_active` is never set to `true`! That means the `reset_index` command's wait loop will immediately exit since `watcher_active` is always false. But that's a different issue.\n\nLet me look at whether the non-macOS or macOS-specific watcher code sets `watcher_active`:","signature":"ErwDCkYICxgCKkD83COQyzgG++g2PqN1Fp0Y8kdqObn3mSvyPUeSrHk9a2GtagWtrI48cv/8qAsVu5v7WZlUeU7l9nrdpjseEpqTEgy009lcUfugzuf7OFgaDEwaNFQVgtMOMBM43SIw4fLl9NZwRwqeSFzEC5d85cOaIBJqdBcm5woLErU9HtjgUtZjEPhOv5t2RsJ0JYgTKqMCQ0hPtksQVNhLl2bAzd+oXSxOkd+YxKpn6UPdPcLGW3yxxZcmJ1I1Q0v43r9KIGzDQ7N33uuwhwC8s+N2uDfKQAxRngNGZY6Ue6aG0H0WVqn5HQcUoj+gcy6Cybc5LNiouwxkoWk/GAAqq46rzb4QIrGJSgroWAN+qr9douHoHL3RVAH6cNBPuFVl44F2HxiHkpJCbbsZF7NFjJnc6uCQO/Tjzy98WdPEjwRjfdjbNah3sfXYBN1aZRIvAYMQa16yXG2ZCWkx5iLwtJ56WQwd0Vw0h+7S9Movj+r+kBkUGcXXKsNUX0SjBuTV33i/CQb10BHDc+7DB87EVT/1Me/GH7nspXjiI9re5+nkemO50xNsXQgCNoTPGilCu6yvTzs62iKgGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":316,"cache_read_input_tokens":58570,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":316},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4uGyPFc5c7Lv1LE4Db","type":"assistant","uuid":"c1dae7d9-66a1-46c9-ae2d-b45b06bfe6aa","timestamp":"2026-02-20T09:16:05.751Z"}
{"parentUuid":"c1dae7d9-66a1-46c9-ae2d-b45b06bfe6aa","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01WRz4Lc7LaqxbWtRpvoqkNL","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VyDJM2q7MaBbZL119q3DTk","name":"Grep","input":{"pattern":"watcher_active","path":"/Users/al02402336/everything/src-tauri/src","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":316,"cache_read_input_tokens":58570,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":316},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4uGyPFc5c7Lv1LE4Db","type":"assistant","uuid":"4d24adba-3829-400e-8122-1ee3dcc0189e","timestamp":"2026-02-20T09:16:06.481Z"}
{"parentUuid":"4d24adba-3829-400e-8122-1ee3dcc0189e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01VyDJM2q7MaBbZL119q3DTk","toolUseID":"toolu_01VyDJM2q7MaBbZL119q3DTk","timestamp":"2026-02-20T09:16:07.222Z","uuid":"e9e3404d-9ef0-499a-ad0a-8a21624b4c3b"}
{"parentUuid":"4d24adba-3829-400e-8122-1ee3dcc0189e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VyDJM2q7MaBbZL119q3DTk","type":"tool_result","content":"/Users/al02402336/everything/src-tauri/src/main.rs-293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\nsrc-tauri/src/main.rs-294-    pub(crate) watcher_stop: Arc<AtomicBool>,\n/Users/al02402336/everything/src-tauri/src/main.rs-295-    /// Set to true while a file watcher event loop is running.\nsrc-tauri/src/main.rs:296:    pub(crate) watcher_active: Arc<AtomicBool>,\n/Users/al02402336/everything/src-tauri/src/main.rs-297-}\n/Users/al02402336/everything/src-tauri/src/main.rs-298-\n/Users/al02402336/everything/src-tauri/src/main.rs-299-#[derive(Debug, Clone)]\n--\n/Users/al02402336/everything/src-tauri/src/main.rs-2791-        // Stop existing file watcher and wait for it to fully exit\nsrc-tauri/src/main.rs-2792-        state.watcher_stop.store(true, AtomicOrdering::Release);\nsrc-tauri/src/main.rs-2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\nsrc-tauri/src/main.rs:2794:        while state.watcher_active.load(AtomicOrdering::Acquire) {\nsrc-tauri/src/main.rs-2795-            if std::time::Instant::now() >= deadline {\n/Users/al02402336/everything/src-tauri/src/main.rs-2796-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n/Users/al02402336/everything/src-tauri/src/main.rs-2797-                break;\n--\n/Users/al02402336/everything/src-tauri/src/main.rs-4457-        gitignore,\nsrc-tauri/src/main.rs-4458-        mem_index: Arc::new(RwLock::new(None)),\nsrc-tauri/src/main.rs-4459-        watcher_stop: Arc::new(AtomicBool::new(false)),\nsrc-tauri/src/main.rs:4460:        watcher_active: Arc::new(AtomicBool::new(false)),\n/Users/al02402336/everything/src-tauri/src/main.rs-4461-    };\n/Users/al02402336/everything/src-tauri/src/main.rs-4462-\n/Users/al02402336/everything/src-tauri/src/main.rs-4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n--\nsrc-tauri/src/main.rs-4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\nsrc-tauri/src/main.rs-4670-            mem_index: Arc::new(RwLock::new(None)),\nsrc-tauri/src/main.rs-4671-            watcher_stop: Arc::new(AtomicBool::new(false)),\nsrc-tauri/src/main.rs:4672:            watcher_active: Arc::new(AtomicBool::new(false)),\n/Users/al02402336/everything/src-tauri/src/main.rs-4673-        }\n/Users/al02402336/everything/src-tauri/src/main.rs-4674-    }\n/Users/al02402336/everything/src-tauri/src/main.rs-4675-\n--\nsrc-tauri/src/win/rdcw_watcher.rs-46-        .map_err(|e| format!(\"notify watch failed: {e}\"))?;\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-47-\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-48-    eprintln!(\"[win/rdcw] watcher started on {}\", watch_root.display());\nsrc-tauri/src/win/rdcw_watcher.rs:49:    state.watcher_active.store(true, AtomicOrdering::Release);\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-50-\nsrc-tauri/src/win/rdcw_watcher.rs-51-    std::thread::spawn(move || {\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-52-        event_loop(&app, &state, rx);\nsrc-tauri/src/win/rdcw_watcher.rs:53:        state.watcher_active.store(false, AtomicOrdering::Release);\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-54-        // Keep watcher alive until event_loop exits — drop ends the watch\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-55-        drop(watcher);\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-56-        eprintln!(\"[win/rdcw] watcher stopped\");"}]},"uuid":"19580f15-bd98-4b77-83ac-f5addb553e09","timestamp":"2026-02-20T09:16:07.221Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"/Users/al02402336/everything/src-tauri/src/main.rs-293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\nsrc-tauri/src/main.rs-294-    pub(crate) watcher_stop: Arc<AtomicBool>,\n/Users/al02402336/everything/src-tauri/src/main.rs-295-    /// Set to true while a file watcher event loop is running.\nsrc-tauri/src/main.rs:296:    pub(crate) watcher_active: Arc<AtomicBool>,\n/Users/al02402336/everything/src-tauri/src/main.rs-297-}\n/Users/al02402336/everything/src-tauri/src/main.rs-298-\n/Users/al02402336/everything/src-tauri/src/main.rs-299-#[derive(Debug, Clone)]\n--\n/Users/al02402336/everything/src-tauri/src/main.rs-2791-        // Stop existing file watcher and wait for it to fully exit\nsrc-tauri/src/main.rs-2792-        state.watcher_stop.store(true, AtomicOrdering::Release);\nsrc-tauri/src/main.rs-2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\nsrc-tauri/src/main.rs:2794:        while state.watcher_active.load(AtomicOrdering::Acquire) {\nsrc-tauri/src/main.rs-2795-            if std::time::Instant::now() >= deadline {\n/Users/al02402336/everything/src-tauri/src/main.rs-2796-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n/Users/al02402336/everything/src-tauri/src/main.rs-2797-                break;\n--\n/Users/al02402336/everything/src-tauri/src/main.rs-4457-        gitignore,\nsrc-tauri/src/main.rs-4458-        mem_index: Arc::new(RwLock::new(None)),\nsrc-tauri/src/main.rs-4459-        watcher_stop: Arc::new(AtomicBool::new(false)),\nsrc-tauri/src/main.rs:4460:        watcher_active: Arc::new(AtomicBool::new(false)),\n/Users/al02402336/everything/src-tauri/src/main.rs-4461-    };\n/Users/al02402336/everything/src-tauri/src/main.rs-4462-\n/Users/al02402336/everything/src-tauri/src/main.rs-4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n--\nsrc-tauri/src/main.rs-4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\nsrc-tauri/src/main.rs-4670-            mem_index: Arc::new(RwLock::new(None)),\nsrc-tauri/src/main.rs-4671-            watcher_stop: Arc::new(AtomicBool::new(false)),\nsrc-tauri/src/main.rs:4672:            watcher_active: Arc::new(AtomicBool::new(false)),\n/Users/al02402336/everything/src-tauri/src/main.rs-4673-        }\n/Users/al02402336/everything/src-tauri/src/main.rs-4674-    }\n/Users/al02402336/everything/src-tauri/src/main.rs-4675-\n--\nsrc-tauri/src/win/rdcw_watcher.rs-46-        .map_err(|e| format!(\"notify watch failed: {e}\"))?;\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-47-\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-48-    eprintln!(\"[win/rdcw] watcher started on {}\", watch_root.display());\nsrc-tauri/src/win/rdcw_watcher.rs:49:    state.watcher_active.store(true, AtomicOrdering::Release);\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-50-\nsrc-tauri/src/win/rdcw_watcher.rs-51-    std::thread::spawn(move || {\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-52-        event_loop(&app, &state, rx);\nsrc-tauri/src/win/rdcw_watcher.rs:53:        state.watcher_active.store(false, AtomicOrdering::Release);\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-54-        // Keep watcher alive until event_loop exits — drop ends the watch\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-55-        drop(watcher);\n/Users/al02402336/everything/src-tauri/src/win/rdcw_watcher.rs-56-        eprintln!(\"[win/rdcw] watcher stopped\");","numLines":43},"sourceToolAssistantUUID":"4d24adba-3829-400e-8122-1ee3dcc0189e"}
{"parentUuid":"19580f15-bd98-4b77-83ac-f5addb553e09","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01UD1wQz7PuQeetgVkrsWw54","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see it now. The `watcher_active` flag is only set on Windows (`win/rdcw_watcher.rs`), NOT on macOS! The macOS watcher (`start_fsevent_watcher_worker`) never sets `watcher_active`. This means on macOS, when `reset_index` runs, it immediately proceeds without waiting for the watcher to stop, because `watcher_active` is always `false`.\n\nBUT more importantly - the macOS watcher doesn't check `watcher_stop` either! Let me verify:","signature":"EtUECkYICxgCKkA+m2I4QdzvIeijIUCz+vXO6E3ONQJ4k519a/ssry0XtbjyGDuydgICaCAqT5Y6xAhczxuZeLqCcVco6A9CAgp3EgxSM05t3PVVh+p5TIgaDPIkpT9XozD/Vnm6NiIwNoHgwzRCaIqLBcoB8PSTn2D2NdTmg+WDedicsayb7xutEYbmbZmM67uggkonp0SrKrwDvoX1hTHoOWVfKcIoLMeiXO1tk0hgMpneDbFwC2p96bZbCn9O/LtOo8Bye2NIVDvKngxqWQDMzHMgvV9RdKB6cWPQk7eDxgNe9aafS8mrMWWH0wX2FX3R8HkP+CbZUkdnAaqgPQjdKbEmfZMGouW5Mhxsv0La5KhAkYCVs+1xqbwR25AgZptOGVaaPaXcEpagDAveL6yUh2PtWDPIiqDu5+5dplXuZmnC7APGhk0NdNmioyOTmgAygvu19WcxYaTBnhxtrMO2PxqS96xcpDDs8bSTvSOketuaGtyHAZNJ9vHZjovVsmer1wEVK7RTbCXdFqh2N2tk1i/qPVjhiuag4t9fzfRcUe+fSI+0Z512lcXnRlm2WJEui0+ECgT6x9hUPfVC2ihjCBpGVJXEuDeM692k+npsk/nZBokprUCoVJoCOeH8REuwNy9jh8MKKMEjtdfVV2muDIkwjiHS7YPJBp6wSzEnZQbz512U1RsPxmKw81jNVjJ5BiQh+xG4wwV+oEyFHli+TATxPW92+XnivktUPnn7IQMR7apqe6kzkzNFksNp5+jQ/DYa2U5pzj/vVRIO5hg6h1DQDdJmGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1632,"cache_read_input_tokens":58886,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1632},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4ub6JRSz8GBzCavvXB","type":"assistant","uuid":"2eab5a72-66ee-4e16-bd06-b25401ebfcb8","timestamp":"2026-02-20T09:16:11.789Z"}
{"parentUuid":"2eab5a72-66ee-4e16-bd06-b25401ebfcb8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01UD1wQz7PuQeetgVkrsWw54","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FZftfRXcfjfSyAKq9HMRUj","name":"Grep","input":{"pattern":"watcher_stop","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":5},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1632,"cache_read_input_tokens":58886,"output_tokens":266,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1632,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK4ub6JRSz8GBzCavvXB","type":"assistant","uuid":"a99cafff-930b-45ea-9851-da0ae2088d8d","timestamp":"2026-02-20T09:16:12.932Z"}
{"parentUuid":"a99cafff-930b-45ea-9851-da0ae2088d8d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01FZftfRXcfjfSyAKq9HMRUj","toolUseID":"toolu_01FZftfRXcfjfSyAKq9HMRUj","timestamp":"2026-02-20T09:16:13.713Z","uuid":"50ba3c8b-e753-4315-b816-95a532263a05"}
{"parentUuid":"a99cafff-930b-45ea-9851-da0ae2088d8d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FZftfRXcfjfSyAKq9HMRUj","type":"tool_result","content":"289-    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n290-    /// In-memory index for instant search while DB upsert runs in background.\n291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295-    /// Set to true while a file watcher event loop is running.\n296-    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n--\n2787-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n2788-            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n2789-        }\n2790-\n2791-        // Stop existing file watcher and wait for it to fully exit\n2792:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2794-        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2795-            if std::time::Instant::now() >= deadline {\n2796-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2797-                break;\n--\n2819-        invalidate_search_caches(&state);\n2820-\n2821-        emit_index_updated(&app, 0, now_epoch(), 0);\n2822-\n2823-        // Allow new watcher to start\n2824:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2825-\n2826-        #[cfg(target_os = \"windows\")]\n2827-        {\n2828-            win::start_windows_indexing(app, state);\n2829-            Ok(())\n--\n4454-        fd_search_cache: Arc::new(Mutex::new(None)),\n4455-        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4456-        ignore_cache: Arc::new(Mutex::new(None)),\n4457-        gitignore,\n4458-        mem_index: Arc::new(RwLock::new(None)),\n4459:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4460-        watcher_active: Arc::new(AtomicBool::new(false)),\n4461-    };\n4462-\n4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n4464-    app.manage(state.clone());\n--\n4666-            fd_search_cache: Arc::new(Mutex::new(None)),\n4667-            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4668-            ignore_cache: Arc::new(Mutex::new(None)),\n4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4670-            mem_index: Arc::new(RwLock::new(None)),\n4671:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4672-            watcher_active: Arc::new(AtomicBool::new(false)),\n4673-        }\n4674-    }\n4675-\n4676-    #[test]"}]},"uuid":"a233a44d-f55b-4c58-8e12-cbeed7ca8041","timestamp":"2026-02-20T09:16:13.711Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"289-    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n290-    /// In-memory index for instant search while DB upsert runs in background.\n291-    /// Set by MFT scan, cleared after background DB upsert completes.\n292-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n293-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n294:    pub(crate) watcher_stop: Arc<AtomicBool>,\n295-    /// Set to true while a file watcher event loop is running.\n296-    pub(crate) watcher_active: Arc<AtomicBool>,\n297-}\n298-\n299-#[derive(Debug, Clone)]\n--\n2787-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n2788-            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n2789-        }\n2790-\n2791-        // Stop existing file watcher and wait for it to fully exit\n2792:        state.watcher_stop.store(true, AtomicOrdering::Release);\n2793-        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n2794-        while state.watcher_active.load(AtomicOrdering::Acquire) {\n2795-            if std::time::Instant::now() >= deadline {\n2796-                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n2797-                break;\n--\n2819-        invalidate_search_caches(&state);\n2820-\n2821-        emit_index_updated(&app, 0, now_epoch(), 0);\n2822-\n2823-        // Allow new watcher to start\n2824:        state.watcher_stop.store(false, AtomicOrdering::Release);\n2825-\n2826-        #[cfg(target_os = \"windows\")]\n2827-        {\n2828-            win::start_windows_indexing(app, state);\n2829-            Ok(())\n--\n4454-        fd_search_cache: Arc::new(Mutex::new(None)),\n4455-        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4456-        ignore_cache: Arc::new(Mutex::new(None)),\n4457-        gitignore,\n4458-        mem_index: Arc::new(RwLock::new(None)),\n4459:        watcher_stop: Arc::new(AtomicBool::new(false)),\n4460-        watcher_active: Arc::new(AtomicBool::new(false)),\n4461-    };\n4462-\n4463-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n4464-    app.manage(state.clone());\n--\n4666-            fd_search_cache: Arc::new(Mutex::new(None)),\n4667-            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n4668-            ignore_cache: Arc::new(Mutex::new(None)),\n4669-            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n4670-            mem_index: Arc::new(RwLock::new(None)),\n4671:            watcher_stop: Arc::new(AtomicBool::new(false)),\n4672-            watcher_active: Arc::new(AtomicBool::new(false)),\n4673-        }\n4674-    }\n4675-\n4676-    #[test]","numLines":59},"sourceToolAssistantUUID":"a99cafff-930b-45ea-9851-da0ae2088d8d"}
{"parentUuid":"a233a44d-f55b-4c58-8e12-cbeed7ca8041","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01SnsjhnL3HUdyNdLpairNu2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I don't see `watcher_stop` being checked in `start_fsevent_watcher_worker`. Let me verify that:","signature":"EocCCkYICxgCKkC/VeIjw0JSKO0LWXTwo6f15s+6peq+iXQF7ueRzXgBD64ptK6Y7E2ujjPF+uJGMBo0O+WGlfJjHvo7V2Rs6sZvEgw6Z2/QOsblr8k+ybgaDGqlD5c6W5eFnhqkwCIwrfmSYiYbJ66iniERSkPOo42MiBn65taBBsQn6SYhrxEV1dtJH/P6H/I37N4kEE50Km8LusfsiUswh74qQpIHW+xK/nW0I3zo5wcd8t54yswc+ZCutKjCL5gTXZ/8321u1SdOG98ZW0BznZo4ccrcHV9Txt3T36Y0MBMNboyVSgu8nMvAfbSsPe5W2DeWiP6BY4bi20Sqb/1i+993cDml04gYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1236,"cache_read_input_tokens":60518,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1236},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4v4t8iqkbo6n4S3acP","type":"assistant","uuid":"bebdf308-0012-4740-ab92-5fe22994eee4","timestamp":"2026-02-20T09:16:16.899Z"}
{"parentUuid":"bebdf308-0012-4740-ab92-5fe22994eee4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01SnsjhnL3HUdyNdLpairNu2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Lf7jMhaDmMHYw76k7WehCp","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2530,"limit":130},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1236,"cache_read_input_tokens":60518,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1236},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4v4t8iqkbo6n4S3acP","type":"assistant","uuid":"24c72c7b-9574-462b-8597-e79b3cbb7f58","timestamp":"2026-02-20T09:16:17.951Z"}
{"parentUuid":"24c72c7b-9574-462b-8597-e79b3cbb7f58","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Lf7jMhaDmMHYw76k7WehCp","toolUseID":"toolu_01Lf7jMhaDmMHYw76k7WehCp","timestamp":"2026-02-20T09:16:17.962Z","uuid":"f04e9a85-25aa-46ad-8401-190ece8bce0b"}
{"parentUuid":"24c72c7b-9574-462b-8597-e79b3cbb7f58","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Lf7jMhaDmMHYw76k7WehCp","type":"tool_result","content":"  2530→        let mut pending_status_emit = false;\n  2531→        let mut last_count_refresh = Instant::now();\n  2532→        let mut must_scan_count: usize = 0;\n  2533→        let mut replay_phase = conditional;\n  2534→        let mut full_scan_triggered = false;\n  2535→\n  2536→        loop {\n  2537→            let wait = match deadline {\n  2538→                Some(due) => {\n  2539→                    let now = Instant::now();\n  2540→                    if now >= due {\n  2541→                        Duration::from_millis(0)\n  2542→                    } else {\n  2543→                        due - now\n  2544→                    }\n  2545→                }\n  2546→                None => Duration::from_secs(1),\n  2547→            };\n  2548→            match rx.recv_timeout(wait) {\n  2549→                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n  2550→                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n  2551→                    let prev_len = pending_paths.len();\n  2552→                    for path in paths {\n  2553→                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n  2554→                            pending_paths.insert(path);\n  2555→                        }\n  2556→                    }\n  2557→                    if pending_paths.len() > prev_len {\n  2558→                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n  2559→                    }\n  2560→                }\n  2561→                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n  2562→                    must_scan_count += 1;\n  2563→                    if replay_phase\n  2564→                        && must_scan_count >= MUST_SCAN_THRESHOLD\n  2565→                        && !full_scan_triggered\n  2566→                    {\n  2567→                        perf_log(format!(\n  2568→                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n  2569→                            must_scan_count\n  2570→                        ));\n  2571→                        full_scan_triggered = true;\n  2572→                        let _ = start_full_index_worker(app.clone(), state.clone());\n  2573→                    }\n  2574→                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n  2575→                        let (ignored_roots, ignored_patterns) =\n  2576→                            cached_effective_ignore_rules(&state);\n  2577→                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n  2578→                        if !rows.is_empty() {\n  2579→                            if let Ok(mut conn) = db_connection(&state.db_path) {\n  2580→                                if upsert_rows(&mut conn, &rows).is_ok() {\n  2581→                                    invalidate_search_caches(&state);\n  2582→                                    touch_status_updated(&state);\n  2583→                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2584→                                        let _ = refresh_and_emit_status_counts(&app, &state);\n  2585→                                        last_status_emit = Instant::now();\n  2586→                                        pending_status_emit = false;\n  2587→                                    } else {\n  2588→                                        pending_status_emit = true;\n  2589→                                    }\n  2590→                                }\n  2591→                            }\n  2592→                        }\n  2593→                    }\n  2594→                }\n  2595→                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n  2596→                    process_watcher_paths(\n  2597→                        &app,\n  2598→                        &state,\n  2599→                        &mut pending_paths,\n  2600→                        &mut last_status_emit,\n  2601→                        &mut pending_status_emit,\n  2602→                    );\n  2603→                    deadline = None;\n  2604→                    if replay_phase {\n  2605→                        replay_phase = false;\n  2606→                        if !full_scan_triggered {\n  2607→                            perf_log(format!(\n  2608→                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n  2609→                                must_scan_count\n  2610→                            ));\n  2611→                            let _ = refresh_and_emit_status_counts(&app, &state);\n  2612→                            last_status_emit = Instant::now();\n  2613→                            pending_status_emit = false;\n  2614→                        }\n  2615→                    }\n  2616→                }\n  2617→                Err(RecvTimeoutError::Timeout) => {}\n  2618→                Err(RecvTimeoutError::Disconnected) => break,\n  2619→            }\n  2620→\n  2621→            if let Some(due) = deadline {\n  2622→                if Instant::now() >= due {\n  2623→                    process_watcher_paths(\n  2624→                        &app,\n  2625→                        &state,\n  2626→                        &mut pending_paths,\n  2627→                        &mut last_status_emit,\n  2628→                        &mut pending_status_emit,\n  2629→                    );\n  2630→                    deadline = None;\n  2631→                }\n  2632→            }\n  2633→\n  2634→            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2635→                let _ = refresh_and_emit_status_counts(&app, &state);\n  2636→                last_status_emit = Instant::now();\n  2637→                pending_status_emit = false;\n  2638→            }\n  2639→\n  2640→            // Periodic event_id flush\n  2641→            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n  2642→                let eid = watcher.last_event_id();\n  2643→                let _ = persist_event_id(&state.db_path, eid);\n  2644→                last_flush = Instant::now();\n  2645→            }\n  2646→\n  2647→            // Periodic count refresh to keep in-memory counts accurate\n  2648→            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n  2649→                let _ = update_status_counts(&state);\n  2650→                last_count_refresh = Instant::now();\n  2651→            }\n  2652→        }\n  2653→\n  2654→        // Final flush on shutdown\n  2655→        let eid = watcher.last_event_id();\n  2656→        let _ = persist_event_id(&state.db_path, eid);\n  2657→        watcher.stop();\n  2658→    });\n  2659→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"299b67e4-ab53-4310-9cb2-af24736d4b7e","timestamp":"2026-02-20T09:16:17.960Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}","numLines":130,"startLine":2530,"totalLines":5087}},"sourceToolAssistantUUID":"24c72c7b-9574-462b-8597-e79b3cbb7f58"}
{"parentUuid":"299b67e4-ab53-4310-9cb2-af24736d4b7e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01QKtN3mouhtB22f5tb1hgQr","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I can see the issue clearly. Looking at `start_fsevent_watcher_worker`:\n\n1. The macOS FSEvents watcher loop does NOT check `watcher_stop` at all in its loop! \n2. The macOS watcher also does NOT set `watcher_active`\n\nSo on macOS, the watcher never responds to the `reset_index` stop signal, and `reset_index` immediately proceeds since `watcher_active` is always false.\n\nNow for the \"database is locked\" issue: the watcher loop and the `reset_index` command both try to write to the DB at the same time when \"Reset Index\" is clicked.\n\n\nBut wait—the user says it reproduces immediately on restart without clicking Reset Index, so the problem must be happening during startup itself. When the app restarts with `index_complete=true` and a stored event ID, it calls the watcher with those parameters to replay historical events. While the watcher is processing potentially many `MustScanSubDirs` events and writing to the database, the housekeeping thread also starts up after a 500ms delay and tries to access the database, causing the lock contention.\n\nThe issue might not be a crashed WAL file from the previous run—it's more likely that multiple threads are trying to write simultaneously during the startup sequence, and even with WAL mode and a 3-second timeout, something is holding the connection long enough to trigger the lock error. Let me check whether the read connection during initialization might be interfering with the write operations.\n\nActually, I think I found it: when the watcher starts with `conditional=true`, it processes historical events that could include many `MustScanSubDirs` events, each triggering immediate database writes. If there are 10 or more of these events, it also kicks off a full index worker, which means multiple write operations are competing for the database connection at startup. I see the race condition now—when `must_scan_count` hits the threshold, `start_full_index_worker` is called and spawns a thread to set `indexing_active`, but there's a window where the flag hasn't been set yet, so the `MustScanSubDirs` write could still execute before the full indexer actually acquires the write lock. _inner` before the thread is spawned... wait, let me check:\n\nThe `indexing_active` flag gets set to `true` via `compare_exchange` before the thread spawns, so after `start_full_index_worker_inner` returns, the flag is already true and subsequent checks would skip the MustScanSubDirs write. That race condition probably isn't the issue.\n\nLet me reconsider what's actually causing the \"database is locked\" error. With SQLite in WAL mode and a 3-second busy timeout, that error only surfaces when another writer holds the database for longer than that window—and the full indexer is the only operation that could realistically lock the database for that long.\n\nEven though WAL mode allows concurrent readers and writers, there's still only one writer at a time, so if the indexer is mid-transaction, the watcher's write attempt gets blocked. The watcher does check `indexing_active` before attempting writes, but there's a window where the flag might not be set yet or the check happens at the wrong moment.\n\nLooking at the actual race condition: the watcher checks if indexing is active and finds it's false, so it proceeds to drain pending paths and apply changes to the database. But right in that gap between the check and the actual write operation, the indexer could start and acquire the write lock, causing the watcher's write to fail with `SQLITE_BUSY`.\n\nThe issue happens consistently during conditional startup when a `MustScanSubDirs` event with a count at or above the threshold triggers `start_full_index_worker`, which sets `indexing_active` to true—but by then the watcher has already passed its safety check and is committed to writing. I'm realizing the actual problem might be different—the watcher is starting simultaneously with the full indexer, both competing for database access, and when the housekeeping thread tries to write during a long indexer lock, the watcher's subsequent operations time out and fail. wait. Let me re-read the scenario again.\n\nIn the non-conditional startup path:\n1. `start_full_index_worker` starts - sets `indexing_active = true`\n2. `start_fsevent_watcher_worker` starts with `conditional=false`\n3. The watcher receives live FSEvents (from the current moment)\n4. If the user's system has active file changes, the watcher might accumulate paths and call `process_watcher_paths`\n5. `process_watcher_paths` checks `indexing_active` → true → returns early\n\nSo in this case, the watcher should properly skip.\n\nBut in the conditional startup path:\n1. `start_fsevent_watcher_worker` with `conditional=true` and `since_event_id`\n2. The watcher starts BEFORE any full scan is triggered\n3. Historical events replay, and if there are enough `MustScanSubDirs` events to hit the threshold, a full scan kicks off\n4. Once `HistoryDone` arrives, `process_watcher_paths` runs and checks `indexing_active` - which should already be true from the full scan, so it returns early\n\nNow I'm wondering about the edge case where historical events don't trigger a full scan because they're below the threshold. In that scenario, `HistoryDone` still calls `process_watcher_paths`, but `indexing_active` would be false, so it would proceed with database writes. That should work fine though.\n\nThe real question is whether multiple `MustScanSubDirs` events during history replay could each try to write to the database concurrently, and if opening new connections for each write could cause contention that locks things up for several seconds.\n\nActually, I'm overthinking this. The watcher runs single-threaded, so writes happen sequentially anyway. Let me step back—the user wants logging to pinpoint what's actually causing the delay, so I should add targeted logging around `apply_path_changes` to see when it's called, when it fails, and what's happening during those critical moments. actual error message from SQLite\n3. Log `indexing_active` state at the time of failure\n4. Log what thread/context is calling\n5. Log when `purge_ignored_entries` is running\n\nThe key places to add logging:\n1. In `process_watcher_paths` when error occurs - already has some logging but the error message already appears\n2. In `apply_path_changes` - add logging at entry and on error\n3. In the watcher loop - log when `MustScanSubDirs` writes happen\n4. Log when housekeeping runs and what it does\n\nBut wait - the user can already SEE the error message \"Watcher update failed: database is locked\". What they NEED is context about WHY the lock is happening. We need to add logging BEFORE the error to understand the state at the time of failure.\n\nSo I need to instrument the code to capture whether `indexing_active` is true when the write fails, which thread is holding the lock, whether housekeeping is running concurrently, and what startup path was taken. I'll add logging at the entry points of `apply_path_changes` and `process_watcher_paths` to capture the `indexing_active` state, log when `MustScanSubDirs` attempts writes in the watcher loop, and track when `purge_ignored_entries` and `refresh_and_emit_status_counts` are executing. the `wal_checkpoint(TRUNCATE)` call. So the full indexer disables auto-checkpointing with a pragma, runs a massive indexing operation that grows the WAL file enormously, then tries to checkpoint when done. Meanwhile, the watcher is running in parallel and skips writes during indexing, but the MustScanSubDirs handler opens a separate connection and attempts to write, which is probably where the lock contention happens. I'm seeing a potential race condition where `MustScanSubDirs` could slip through the `indexing_active` check right before the indexer sets it to true, but that window is tiny since `compare_exchange` happens before thread spawning. Let me step back—the user says this reproduces immediately on restart, which points to something happening early in the startup sequence rather than a subtle race. I should trace through what actually happens during that initial startup that triggered the error.\n\nLooking at the two possible startup paths: either the index was already complete and we're doing a conditional startup with history replay, or we're doing a full index alongside the watcher. Given 1.1M entries and what looks like a completed index, it's probably the conditional path. That means something else is writing to the database while the watcher replays historical events. I need to figure out what's contending for the database during that replay phase.\n\nWait, I'm seeing it now. The `start_full_index_worker` function marks the index as incomplete by writing to the meta table right at startup, and this gets called from the watcher's directory scan handler. Meanwhile the watcher is also doing its own database operations in that same handler. These happen sequentially in the watcher thread, so there shouldn't be concurrent writes there, but...\n\nActually, the real issue is that `start_full_index_worker` spawns a separate thread. The meta table write happens immediately on the calling thread, then the actual indexing work runs on the spawned thread. So I've got two separate database writes that could potentially race with each other or conflict with other concurrent operations happening elsewhere.\n\nI think the best approach here is to add strategic logging so the user can run it and show me what's actually happening. The most useful places to instrument would be: logging when the watcher starts processing paths and what the `indexing_active` state is at that moment, capturing the full error details if something fails in the path application logic, tracking when the purge operation runs, and noting when that initial meta table write happens. Let me add logging at those key points to make the concurrent behavior visible.\n\nWait, I'm realizing something important—with 1.1M entries in the database, that `PRAGMA wal_checkpoint(TRUNCATE)` call at the end of indexing could be a serious bottleneck. It needs exclusive access to the database, and if the FSEvents watcher still has an active connection reading, that checkpoint will block and potentially cause the exact kind of hangs we're seeing.\n\nThe watcher does open connections for writes, and while those are brief, the search function uses short-lived read connections too with a 200ms timeout. But here's the thing—if a previous run's checkpoint never completed because the app was killed, the WAL file could be massive on restart, and the first write from the watcher would trigger an automatic checkpoint that takes way longer than expected. Though actually, with WAL mode that should be quick if there are no active readers...\n\nI think I've been overcomplicating this.  Let me add diagnostic logging at the critical points—before the database connection in `apply_path_changes`, when `purge_ignored_entries` runs, and when the checkpoint starts—so I can see what's actually blocking. I notice the error handler already emits the error message from `apply_path_changes` to the UI, so I need to trace where the actual delay is happening.\n\nAdding logging statements... Adding more debug logging points...\n\nNow I need to figure out what's actually causing the lock contention lasting over 3 seconds. The WAL checkpoint in `restore_normal_pragmas` seems like the most likely culprit, so I should focus my investigation there first. is blocking other writers.\n- Log: Add timing to `restore_normal_pragmas`\n- This runs AFTER indexing, so if the watcher fails at startup, this might not be the issue\n\n**Scenario 2**: `start_full_index_worker_inner`'s `set_meta(\"index_complete\", \"0\")` connection conflicts with a concurrent watcher write.\n- Both are short operations, but they overlap in time\n\n**Scenario 3**: The housekeeping thread's `purge_ignored_entries` holds a write lock while the watcher also tries to write.\n- Both with 3000ms timeout, but if `purge_ignored_entries` takes >3s...\n\nWith 1.1M entries, `DELETE FROM entries WHERE path = ?1 OR path LIKE ?2` could take a while if there are many matching rows. But `ignored_roots` might be empty (line 1087), so `purge_ignored_entries` returns immediately.\n\n**Scenario 4**: The watcher's `MustScanSubDirs` handler opens a connection and writes while the `HistoryDone` handler also tries to write (but these are sequential in the same thread).\n\nActually, I think I found it—looking at the `MustScanSubDirs` handler, it's triggering a full index worker when the must-scan count hits the threshold during the replay phase, which could be creating a database connection conflict. The `run_incremental_index` thread opens its own connection and sets up indexing pragmas, while back in the current event handler, the `indexing_active` flag is now true, so the write gets skipped—this prevents the race condition. But I'm realizing I need to trace through what happens on that very first call to `start_full_index_worker_inner` to understand the full picture. I'm realizing the connection from step (A) is already dropped by the time step (C) runs in the new thread, so there's no actual contention there. But I should add logging to verify what's actually happening. I'm also noticing the `watcher_stop` flag isn't being checked in the macOS watcher loop — when a user clicks \"Reset Index\", the flag gets set but the watcher doesn't respect it, so `reset_index` proceeds immediately and opens a connection to clear entries.\n\nThis creates a real race condition: the old watcher keeps running and processing FSEvents while the new indexer opens a long write transaction, causing both to contend for the database. Though the user mentioned this happens on a fresh restart rather than after clicking Reset Index, so maybe they did click the button from the error state without realizing it.\n\nActually, looking at the error message more carefully—it shows the Reset Index button is always present—but the user says restarting reproduces it immediately without any interaction. So the bug must be happening during startup itself. Let me trace through what happens when the index is already complete: the watcher replays history, accumulates enough MustScanSubDirs events to trigger the full indexer, which opens a long write transaction, and then HistoryDone arrives after the indexer has already started, creating that write contention.\n\nBut wait, there's another path I should consider. If there are fewer MustScanSubDirs events than the threshold, each one tries to write directly to the database and succeeds initially. Then when HistoryDone arrives and tries to write, it could collide with the housekeeping thread that wakes up around 500ms—that's where the SQLITE_BUSY error comes from.\n\nThough actually, `set_meta` is just a single row update and shouldn't hold a lock that long, and `purge_ignored_entries` exits immediately if there's nothing to purge. So maybe I'm looking at the wrong place. Let me trace through the non-conditional startup path more carefully.\n\nWhen the index isn't complete or there's no stored event ID, the code starts a full indexer and the watcher simultaneously. The full indexer takes minutes with 1.1M entries, holding write locks in batch transactions while the watcher stays idle since indexing is active. But then after indexing finishes, `restore_normal_pragmas` runs with its checkpoint operation right as `indexing_active` is about to flip to false—that timing could be the issue.\n\nThe real problem is that `wal_checkpoint(TRUNCATE)` blocks until all readers disconnect, and if the watcher or search functionality has an active connection during this window, it creates a deadlock scenario where the checkpoint can't complete and the watcher can't proceed. I need to clarify the locking behavior here. When `wal_checkpoint(TRUNCATE)` is called, it acquires a writer lock that blocks new writers while it waits for existing readers to finish. So if a reader is slow, the checkpoint holds that lock and prevents any new writes from starting until it completes or times out.\n\nThe problem is that `restore_normal_pragmas` runs inside the indexer thread's scope before releasing the connection, so the checkpoint lock is held while `indexing_active` is set to false. When the watcher thread sees the flag change and tries to write, it hits the checkpoint's lock and waits up to 3 seconds before timing out with \"database is locked.\"\n\nLet me trace through the indexer thread's execution... Checking the `restore_normal_pragmas` function itself — it's resetting SQLite pragmas and then calling `wal_checkpoint(TRUNCATE)`, which should complete before the indexer marks `indexing_active` as false, so the watcher shouldn't encounter contention there either. I can't figure out the root cause through static analysis, so I need to add comprehensive logging at key points throughout the indexing pipeline—tracking when connections open, when the indexing flag changes, and timing critical operations like pragma restoration and status updates—then have the user run the app and capture the logs to see what's actually happening.\n\nNow I'm checking the `persist_event_id` function and whether it could cause issues when called periodically from the watcher loop and also from `reset_index`, but since it's single-threaded there shouldn't be concurrency problems. I'm also wondering if there's something about how WAL checkpoints interact with multiple active connections in rusqlite.\n\nLooking at the WAL mode behavior more carefully: connections hold shared locks on the WAL file when idle, allowing multiple readers simultaneously. But I think I've been overcomplicating this—the real issue is that `set_indexing_pragmas` disables auto-checkpointing and the WAL file can balloon to gigabytes with over a million entries, then when `restore_normal_pragmas` runs the manual checkpoint, it has to process that massive WAL file all at once.\n\nThe critical problem is that `restore_normal_pragmas` is called before setting `indexing_active` to false, which should prevent the watcher from writing during the checkpoint. However, if the checkpoint itself fails because readers are still active, the error gets silently ignored since the return value is discarded. This means the WAL never gets truncated and remains huge when the watcher resumes writing.\n\nNow I'm realizing the real bottleneck: the indexer holds a mutable connection for the entire scan of 1.1M entries across 4 threads, which could take hours. During each batch transaction, the WAL write lock is held for several seconds, and if the watcher's 3000ms timeout expires while a batch is still running, that's when the lock contention becomes critical.\n\nBut wait—the watcher should be checking `indexing_active` to avoid writing during indexing. Unless there's a race condition there, or the watcher isn't actually respecting that flag. Actually, I think I found it: the watcher doesn't check `watcher_stop` at all, so when the user clicks \"Reset Index,\" the old watcher keeps running and writing to the database while the reset is happening, causing the lock conflicts.\n\nThe user mentioned it happens on a fresh restart though, not just after clicking Reset Index. So maybe the previous session had an indexing error and the user reset it, then restarted? Either way, I need to add strategic logging to see what's actually happening. I'll log the `indexing_active` state in the watcher's path processing, track when the database is being accessed, and add timing around the checkpoint operations to see where the delays are coming from.\n\nImplementing the logging now...","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2153,"cache_read_input_tokens":61754,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2153},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4vPTLV6RA3oAoRuk4B","type":"assistant","uuid":"349082dd-7051-4529-b3e8-bd11a0b941dd","timestamp":"2026-02-20T09:19:45.753Z"}
{"parentUuid":"349082dd-7051-4529-b3e8-bd11a0b941dd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01QKtN3mouhtB22f5tb1hgQr","type":"message","role":"assistant","content":[{"type":"text","text":"이제 충분히 파악했습니다. 로그를 추가할 위치를 정확히 짚겠습니다. 의심 지점이 여러 곳이므로 동시성 충돌 원인을 추적할 수 있는 타임스탬프 포함 로그를 넣겠습니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2153,"cache_read_input_tokens":61754,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2153},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4vPTLV6RA3oAoRuk4B","type":"assistant","uuid":"3a367d22-a2d5-4221-bd80-21bebf58f56a","timestamp":"2026-02-20T09:19:47.644Z"}
{"parentUuid":"3a367d22-a2d5-4221-bd80-21bebf58f56a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01QKtN3mouhtB22f5tb1hgQr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Eq9ykbXbx16jcD34HF6pPF","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2413,"limit":15},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2153,"cache_read_input_tokens":61754,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2153},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK4vPTLV6RA3oAoRuk4B","type":"assistant","uuid":"6b775c10-0678-47d5-a9c6-b3c00d16abdc","timestamp":"2026-02-20T09:19:48.629Z"}
{"parentUuid":"6b775c10-0678-47d5-a9c6-b3c00d16abdc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Eq9ykbXbx16jcD34HF6pPF","toolUseID":"toolu_01Eq9ykbXbx16jcD34HF6pPF","timestamp":"2026-02-20T09:19:48.640Z","uuid":"bca91441-d473-4815-96f6-ab6e45401abf"}
{"parentUuid":"6b775c10-0678-47d5-a9c6-b3c00d16abdc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Eq9ykbXbx16jcD34HF6pPF","type":"tool_result","content":"  2413→    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n  2414→\n  2415→    if to_upsert.is_empty() && to_delete.is_empty() {\n  2416→        return Ok(0);\n  2417→    }\n  2418→\n  2419→    let mut conn = db_connection(&state.db_path)?;\n  2420→    let mut changed = 0;\n  2421→\n  2422→    changed += upsert_rows(&mut conn, &to_upsert)?;\n  2423→    changed += delete_paths(&mut conn, &to_delete)?;\n  2424→\n  2425→    Ok(changed)\n  2426→}\n  2427→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"66d41f6b-1aa6-4d0b-a340-1f0e5fa19b44","timestamp":"2026-02-20T09:19:48.639Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n","numLines":15,"startLine":2413,"totalLines":5087}},"sourceToolAssistantUUID":"6b775c10-0678-47d5-a9c6-b3c00d16abdc"}
{"parentUuid":"66d41f6b-1aa6-4d0b-a340-1f0e5fa19b44","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01C9oBATHQ32xfPMAuB9crzL","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013yaEM5csKSZbhWBdPsGnzV","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2439,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":12207,"cache_read_input_tokens":63907,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12207},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5Bv2XXgUzrQSWdPYsV","type":"assistant","uuid":"4399bfa0-3713-4842-839a-be0da4cc6df2","timestamp":"2026-02-20T09:19:51.818Z"}
{"parentUuid":"4399bfa0-3713-4842-839a-be0da4cc6df2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013yaEM5csKSZbhWBdPsGnzV","toolUseID":"toolu_013yaEM5csKSZbhWBdPsGnzV","timestamp":"2026-02-20T09:19:51.831Z","uuid":"50f129c8-6a9f-4f43-88c5-49c370f0271b"}
{"parentUuid":"4399bfa0-3713-4842-839a-be0da4cc6df2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013yaEM5csKSZbhWBdPsGnzV","type":"tool_result","content":"  2439→    if pending.is_empty() {\n  2440→        return;\n  2441→    }\n  2442→\n  2443→    if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2444→        return;\n  2445→    }\n  2446→\n  2447→    let mut batch: Vec<PathBuf> = pending.drain().collect();\n  2448→    batch.sort();\n  2449→\n  2450→    match apply_path_changes(state, &batch) {\n  2451→        Ok(changed) => {\n  2452→            if changed > 0 {\n  2453→                invalidate_search_caches(state);\n  2454→                touch_status_updated(state);\n  2455→                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n  2456→                    let _ = refresh_and_emit_status_counts(app, state);\n  2457→                    *last_status_emit = Instant::now();\n  2458→                    *pending_status_emit = false;\n  2459→                } else {\n  2460→                    *pending_status_emit = true;\n  2461→                }\n  2462→            }\n  2463→        }\n  2464→        Err(err) => {\n  2465→            if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2466→                return;\n  2467→            }\n  2468→            let mut status = state.status.lock();\n  2469→            if !matches!(status.state, IndexState::Indexing) {\n  2470→                status.state = IndexState::Error;\n  2471→            }\n  2472→            status.message = Some(format!(\"Watcher update failed: {err}\"));\n  2473→            drop(status);\n  2474→            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n  2475→        }\n  2476→    }\n  2477→}\n  2478→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e8929d40-6b11-48a0-81df-0c40fad3d5b2","timestamp":"2026-02-20T09:19:51.830Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n","numLines":40,"startLine":2439,"totalLines":5087}},"sourceToolAssistantUUID":"4399bfa0-3713-4842-839a-be0da4cc6df2"}
{"parentUuid":"e8929d40-6b11-48a0-81df-0c40fad3d5b2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_0186oZyA5MmWUBRLwzPs2kCw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UEqD6xECh7S5hnXqzoDMXA","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1847,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":727,"cache_read_input_tokens":76114,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":727},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5C9Tuf46ndBB49Srcx","type":"assistant","uuid":"c1303631-7ce9-431c-a7e3-9112ce4f2950","timestamp":"2026-02-20T09:19:53.927Z"}
{"parentUuid":"c1303631-7ce9-431c-a7e3-9112ce4f2950","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01UEqD6xECh7S5hnXqzoDMXA","toolUseID":"toolu_01UEqD6xECh7S5hnXqzoDMXA","timestamp":"2026-02-20T09:19:53.943Z","uuid":"90e7493a-859e-40f0-8bf7-6df1f0739546"}
{"parentUuid":"c1303631-7ce9-431c-a7e3-9112ce4f2950","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UEqD6xECh7S5hnXqzoDMXA","type":"tool_result","content":"  1847→fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n  1848→    if state\n  1849→        .indexing_active\n  1850→        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n  1851→        .is_err()\n  1852→    {\n  1853→        perf_log(\"index_start_skipped already_active=true\");\n  1854→        return Ok(());\n  1855→    }\n  1856→\n  1857→    // Mark index as incomplete — cleared when run_incremental_index succeeds\n  1858→    if let Ok(c) = db_connection(&state.db_path) {\n  1859→        let _ = set_meta(&c, \"index_complete\", \"0\");\n  1860→    }\n  1861→\n  1862→    if !silent {\n  1863→        {\n  1864→            let mut status = state.status.lock();\n  1865→            status.state = IndexState::Indexing;\n  1866→            status.message = None;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c4fbd1a2-f7df-434e-937f-d3f044161ed8","timestamp":"2026-02-20T09:19:53.941Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;","numLines":20,"startLine":1847,"totalLines":5087}},"sourceToolAssistantUUID":"c1303631-7ce9-431c-a7e3-9112ce4f2950"}
{"parentUuid":"c4fbd1a2-f7df-434e-937f-d3f044161ed8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01UxudHMfbkVsMLaz7auaaHB","type":"message","role":"assistant","content":[{"type":"text","text":"이제 필요한 부분들에 로그를 추가하겠습니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":496,"cache_read_input_tokens":76841,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":496},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5CJvRuRcqsTR2ZnY56","type":"assistant","uuid":"3c4074ae-9208-4da7-a37d-755784e4d395","timestamp":"2026-02-20T09:19:55.965Z"}
{"type":"file-history-snapshot","messageId":"7cea481d-eae8-4313-b36f-fb0a7326cd1c","snapshot":{"messageId":"6c135ae7-deb9-45d0-bdfd-39ed1fcc89e0","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v1","version":1,"backupTime":"2026-02-20T09:20:01.186Z"}},"timestamp":"2026-02-20T09:13:19.001Z"},"isSnapshotUpdate":true}
{"parentUuid":"3c4074ae-9208-4da7-a37d-755784e4d395","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01UxudHMfbkVsMLaz7auaaHB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VTgGRg6XxE6MQtWEEH9dXC","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}","new_string":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":496,"cache_read_input_tokens":76841,"output_tokens":552,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":496,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK5CJvRuRcqsTR2ZnY56","type":"assistant","uuid":"7cea481d-eae8-4313-b36f-fb0a7326cd1c","timestamp":"2026-02-20T09:20:01.178Z"}
{"parentUuid":"7cea481d-eae8-4313-b36f-fb0a7326cd1c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01VTgGRg6XxE6MQtWEEH9dXC","toolUseID":"toolu_01VTgGRg6XxE6MQtWEEH9dXC","timestamp":"2026-02-20T09:20:01.196Z","uuid":"b57de6be-b757-445a-b41b-5aac1dec7329"}
{"parentUuid":"7cea481d-eae8-4313-b36f-fb0a7326cd1c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VTgGRg6XxE6MQtWEEH9dXC","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"72738464-e8c0-4a26-a3bc-594b59a4de60","timestamp":"2026-02-20T09:20:01.195Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}","newString":"    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let mut conn = db_connection(&state.db_path)?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2416,"oldLines":11,"newStart":2416,"newLines":20,"lines":["         return Ok(0);","     }"," ","+    eprintln!(","+        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",","+        to_upsert.len(),","+        to_delete.len(),","+        state.indexing_active.load(AtomicOrdering::Acquire)","+    );","+    let t = Instant::now();","     let mut conn = db_connection(&state.db_path)?;","+    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());","     let mut changed = 0;"," ","     changed += upsert_rows(&mut conn, &to_upsert)?;","     changed += delete_paths(&mut conn, &to_delete)?;","+    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());"," ","     Ok(changed)"," }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"7cea481d-eae8-4313-b36f-fb0a7326cd1c"}
{"parentUuid":"72738464-e8c0-4a26-a3bc-594b59a4de60","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01227HQLCWhsTA93AKzyR9aC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01ASKRK92wg3WrVjqxJbL6GM","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}","new_string":"    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":609,"cache_read_input_tokens":77337,"output_tokens":945,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":609,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK5CrVyLBS6kxkKnL919","type":"assistant","uuid":"96bac4a5-da2e-4a1e-a09a-7436f6a1c124","timestamp":"2026-02-20T09:20:12.259Z"}
{"parentUuid":"96bac4a5-da2e-4a1e-a09a-7436f6a1c124","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01ASKRK92wg3WrVjqxJbL6GM","toolUseID":"toolu_01ASKRK92wg3WrVjqxJbL6GM","timestamp":"2026-02-20T09:20:12.269Z","uuid":"fb6dae36-3776-4e22-aa07-cd8ea6017877"}
{"parentUuid":"96bac4a5-da2e-4a1e-a09a-7436f6a1c124","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01ASKRK92wg3WrVjqxJbL6GM","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"cc23487c-5a3b-46aa-b503-6372c68fe18c","timestamp":"2026-02-20T09:20:12.268Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}","newString":"    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2449,"oldLines":7,"newStart":2449,"newLines":13,"lines":["         return;","     }"," ","-    if state.indexing_active.load(AtomicOrdering::Acquire) {","+    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);","+    eprintln!(","+        \"[watcher/process_paths] pending={} indexing_active={}\",","+        pending.len(),","+        indexing_now","+    );","+    if indexing_now {","         return;","     }"," "]},{"oldStart":2471,"oldLines":6,"newStart":2477,"newLines":10,"lines":["             }","         }","         Err(err) => {","+            eprintln!(","+                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",","+                state.indexing_active.load(AtomicOrdering::Acquire)","+            );","             if state.indexing_active.load(AtomicOrdering::Acquire) {","                 return;","             }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"96bac4a5-da2e-4a1e-a09a-7436f6a1c124"}
{"parentUuid":"cc23487c-5a3b-46aa-b503-6372c68fe18c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_017fT1VTDSaAmjq995t2RPoN","type":"message","role":"assistant","content":[{"type":"text","text":"이제 `restore_normal_pragmas`의 `wal_checkpoint`와 housekeeping 로그:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1113,"cache_read_input_tokens":77946,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1113},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5Dg1isiU4Xq9feAL81","type":"assistant","uuid":"1bd443c6-7132-4491-be5b-7639604da14e","timestamp":"2026-02-20T09:20:14.907Z"}
{"parentUuid":"1bd443c6-7132-4491-be5b-7639604da14e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_017fT1VTDSaAmjq995t2RPoN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XcDcX2LkTkycCjaCd39DV2","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}","new_string":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");\n    let t = Instant::now();\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());\n    Ok(())\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1113,"cache_read_input_tokens":77946,"output_tokens":526,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1113,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK5Dg1isiU4Xq9feAL81","type":"assistant","uuid":"e8f603cc-0ee1-4894-a040-36846554e9d5","timestamp":"2026-02-20T09:20:20.825Z"}
{"parentUuid":"e8f603cc-0ee1-4894-a040-36846554e9d5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01XcDcX2LkTkycCjaCd39DV2","toolUseID":"toolu_01XcDcX2LkTkycCjaCd39DV2","timestamp":"2026-02-20T09:20:20.833Z","uuid":"3b464e69-99ba-4346-944d-0e29f76f5f82"}
{"parentUuid":"e8f603cc-0ee1-4894-a040-36846554e9d5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XcDcX2LkTkycCjaCd39DV2","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"3a0a87cb-341c-4766-98c0-2116bc30178c","timestamp":"2026-02-20T09:20:20.833Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}","newString":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");\n    let t = Instant::now();\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());\n    Ok(())\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":406,"oldLines":8,"newStart":406,"newLines":11,"lines":["         \"#,","     )","     .map_err(|e| e.to_string())?;","+    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");","+    let t = Instant::now();","     conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")","         .map_err(|e| e.to_string())?;","+    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());","     Ok(())"," }"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"e8f603cc-0ee1-4894-a040-36846554e9d5"}
{"parentUuid":"3a0a87cb-341c-4766-98c0-2116bc30178c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01AbHmmus44nacC7EiXqUsWq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012di3itCRT1h5zDvSUYTdTj","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }","new_string":"    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    eprintln!(\"[indexer] marking index_complete=0 (db write on calling thread)\");\n    let t0 = Instant::now();\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n    eprintln!(\"[indexer] index_complete=0 done in {}ms\", t0.elapsed().as_millis());"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":583,"cache_read_input_tokens":79059,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":583},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5EJVwVYMm9tRdWGMky","type":"assistant","uuid":"67655763-0060-4688-91dd-8a33d8eff0e9","timestamp":"2026-02-20T09:20:25.768Z"}
{"parentUuid":"67655763-0060-4688-91dd-8a33d8eff0e9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_012di3itCRT1h5zDvSUYTdTj","toolUseID":"toolu_012di3itCRT1h5zDvSUYTdTj","timestamp":"2026-02-20T09:20:25.777Z","uuid":"468263c2-1c9d-4eda-b611-f38b8890001c"}
{"parentUuid":"67655763-0060-4688-91dd-8a33d8eff0e9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012di3itCRT1h5zDvSUYTdTj","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"b4822e40-699a-4c0a-a047-257f2b047e1c","timestamp":"2026-02-20T09:20:25.776Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }","newString":"    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    eprintln!(\"[indexer] marking index_complete=0 (db write on calling thread)\");\n    let t0 = Instant::now();\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n    eprintln!(\"[indexer] index_complete=0 done in {}ms\", t0.elapsed().as_millis());","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");\n    let t = Instant::now();\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":1858,"oldLines":9,"newStart":1858,"newLines":12,"lines":["     }"," ","     // Mark index as incomplete — cleared when run_incremental_index succeeds","+    eprintln!(\"[indexer] marking index_complete=0 (db write on calling thread)\");","+    let t0 = Instant::now();","     if let Ok(c) = db_connection(&state.db_path) {","         let _ = set_meta(&c, \"index_complete\", \"0\");","     }","+    eprintln!(\"[indexer] index_complete=0 done in {}ms\", t0.elapsed().as_millis());"," ","     if !silent {","         {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"67655763-0060-4688-91dd-8a33d8eff0e9"}
{"parentUuid":"b4822e40-699a-4c0a-a047-257f2b047e1c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01LujUqduVq9Wzo4uQmRYRKD","type":"message","role":"assistant","content":[{"type":"text","text":"이제 housekeeping 로그:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":351,"cache_read_input_tokens":79642,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":351},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5Eet2uHTEwXhZq7ryS","type":"assistant","uuid":"5353674e-10c3-41f8-bc85-92c353218f27","timestamp":"2026-02-20T09:20:27.274Z"}
{"parentUuid":"5353674e-10c3-41f8-bc85-92c353218f27","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01LujUqduVq9Wzo4uQmRYRKD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VqDn6MtPjXVAQtdhG6cDUD","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"        std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });","new_string":"        std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] start: indexing_active={}\",\n                    hk_state.indexing_active.load(AtomicOrdering::Acquire)\n                );\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                let purge_t = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] purge_ignored_entries start: roots={}\",\n                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)\n                );\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] purge_ignored_entries done in {}ms\", purge_t.elapsed().as_millis());\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":351,"cache_read_input_tokens":79642,"output_tokens":759,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":351,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK5Eet2uHTEwXhZq7ryS","type":"assistant","uuid":"9bbe7a97-fa13-4ff4-bf4b-d91eee955274","timestamp":"2026-02-20T09:20:35.046Z"}
{"parentUuid":"9bbe7a97-fa13-4ff4-bf4b-d91eee955274","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01VqDn6MtPjXVAQtdhG6cDUD","toolUseID":"toolu_01VqDn6MtPjXVAQtdhG6cDUD","timestamp":"2026-02-20T09:20:35.056Z","uuid":"6de9a939-7e1f-41ec-bd73-2f6285754318"}
{"parentUuid":"9bbe7a97-fa13-4ff4-bf4b-d91eee955274","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VqDn6MtPjXVAQtdhG6cDUD","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"40c66dd9-b308-467c-9980-37f5b8ed19fc","timestamp":"2026-02-20T09:20:35.055Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"        std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });","newString":"        std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] start: indexing_active={}\",\n                    hk_state.indexing_active.load(AtomicOrdering::Acquire)\n                );\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                let purge_t = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] purge_ignored_entries start: roots={}\",\n                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)\n                );\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] purge_ignored_entries done in {}ms\", purge_t.elapsed().as_millis());\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");\n    let t = Instant::now();\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    eprintln!(\"[indexer] marking index_complete=0 (db write on calling thread)\");\n    let t0 = Instant::now();\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n    eprintln!(\"[indexer] index_complete=0 done in {}ms\", t0.elapsed().as_millis());\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":4523,"oldLines":11,"newStart":4523,"newLines":21,"lines":["                 // Brief pause so indexing thread can start first","                 std::thread::sleep(std::time::Duration::from_millis(500));","                 let hk_started = std::time::Instant::now();","+                eprintln!(","+                    \"[startup/housekeeping] start: indexing_active={}\",","+                    hk_state.indexing_active.load(AtomicOrdering::Acquire)","+                );","                 let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);","                 eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());","+                let purge_t = std::time::Instant::now();","+                eprintln!(","+                    \"[startup/housekeeping] purge_ignored_entries start: roots={}\",","+                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)","+                );","                 if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {","                     eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");","                 }","+                eprintln!(\"[startup/housekeeping] purge_ignored_entries done in {}ms\", purge_t.elapsed().as_millis());","                 eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());","             });","         }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"9bbe7a97-fa13-4ff4-bf4b-d91eee955274"}
{"parentUuid":"40c66dd9-b308-467c-9980-37f5b8ed19fc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01XomKZLaZAaFvVHCDDutMZR","type":"message","role":"assistant","content":[{"type":"text","text":"마지막으로 watcher loop의 `MustScanSubDirs` DB 쓰기와 `HistoryDone` 처리에도 로그 추가:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":797,"cache_read_input_tokens":79993,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":797},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5FLWWypt3EbTu4x7xw","type":"assistant","uuid":"3478a621-0303-4fd4-8008-38ef7dc3fc52","timestamp":"2026-02-20T09:20:37.732Z"}
{"parentUuid":"3478a621-0303-4fd4-8008-38ef7dc3fc52","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01XomKZLaZAaFvVHCDDutMZR","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014WgXHdSHdipgPMTVvQDSkC","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {","new_string":"                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher/MustScanSubDirs] opening db: rows={} path={}\",\n                                rows.len(), path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":797,"cache_read_input_tokens":79993,"output_tokens":480,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":797,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYK5FLWWypt3EbTu4x7xw","type":"assistant","uuid":"a39f7c62-a8f9-4a0d-9173-bdade46dbc6e","timestamp":"2026-02-20T09:20:42.631Z"}
{"parentUuid":"a39f7c62-a8f9-4a0d-9173-bdade46dbc6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_014WgXHdSHdipgPMTVvQDSkC","toolUseID":"toolu_014WgXHdSHdipgPMTVvQDSkC","timestamp":"2026-02-20T09:20:42.647Z","uuid":"afe2e7de-8950-4709-b079-79fa18b9d170"}
{"parentUuid":"a39f7c62-a8f9-4a0d-9173-bdade46dbc6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014WgXHdSHdipgPMTVvQDSkC","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"f80a6255-95f3-4a7e-b425-820484270d93","timestamp":"2026-02-20T09:20:42.645Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {","newString":"                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher/MustScanSubDirs] opening db: rows={} path={}\",\n                                rows.len(), path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");\n    let t = Instant::now();\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    eprintln!(\"[indexer] marking index_complete=0 (db write on calling thread)\");\n    let t0 = Instant::now();\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n    eprintln!(\"[indexer] index_complete=0 done in {}ms\", t0.elapsed().as_millis());\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] start: indexing_active={}\",\n                    hk_state.indexing_active.load(AtomicOrdering::Acquire)\n                );\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                let purge_t = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] purge_ignored_entries start: roots={}\",\n                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)\n                );\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] purge_ignored_entries done in {}ms\", purge_t.elapsed().as_millis());\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2601,"oldLines":6,"newStart":2601,"newLines":10,"lines":["                             cached_effective_ignore_rules(&state);","                         let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);","                         if !rows.is_empty() {","+                            eprintln!(","+                                \"[watcher/MustScanSubDirs] opening db: rows={} path={}\",","+                                rows.len(), path.display()","+                            );","                             if let Ok(mut conn) = db_connection(&state.db_path) {","                                 if upsert_rows(&mut conn, &rows).is_ok() {","                                     invalidate_search_caches(&state);"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"a39f7c62-a8f9-4a0d-9173-bdade46dbc6e"}
{"parentUuid":"f80a6255-95f3-4a7e-b425-820484270d93","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01CEy6c5fA5Mn2zRp9fHmRzZ","type":"message","role":"assistant","content":[{"type":"text","text":"이제 빌드해서 컴파일 에러가 없는지 확인:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":518,"cache_read_input_tokens":80790,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":518},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5FtgmzJGqGos19Bu1r","type":"assistant","uuid":"40801430-c6e3-4084-bccc-4a4554082c42","timestamp":"2026-02-20T09:20:45.069Z"}
{"parentUuid":"40801430-c6e3-4084-bccc-4a4554082c42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01CEy6c5fA5Mn2zRp9fHmRzZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014u394dg4efQ7FzB5Bgf5Sy","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | tail -20","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":518,"cache_read_input_tokens":80790,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":518},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5FtgmzJGqGos19Bu1r","type":"assistant","uuid":"26a2a8c9-2795-4fbe-b9e1-1e62bbb22b68","timestamp":"2026-02-20T09:20:45.974Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-20T09:20:49.017Z","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","content":"{\"task_id\":\"b4c8e70\",\"tool_use_id\":\"toolu_014u394dg4efQ7FzB5Bgf5Sy\",\"description\":\"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | tail -20\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"26a2a8c9-2795-4fbe-b9e1-1e62bbb22b68","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b4c8e70","timeoutMs":60000},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_014u394dg4efQ7FzB5Bgf5Sy","uuid":"a182ee0b-9814-43ba-8515-af62aba72540","timestamp":"2026-02-20T09:20:49.017Z"}
{"parentUuid":"26a2a8c9-2795-4fbe-b9e1-1e62bbb22b68","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014u394dg4efQ7FzB5Bgf5Sy","type":"tool_result","content":"    Checking everything v0.2.0 (/Users/al02402336/everything/src-tauri)\nerror[E0599]: no method named `map` found for reference `&Vec<PathBuf>` in the current scope\n    --> src/main.rs:4539:52\n     |\n4539 |                     hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)\n     |                                                    ^^^ `&Vec<PathBuf>` is not an iterator\n     |\nhelp: call `.into_iter()` first\n     |\n4539 |                     hk_state.path_ignores.as_ref().into_iter().map(|v| v.len()).unwrap_or(0)\n     |                                                    ++++++++++++\n\nFor more information about this error, try `rustc --explain E0599`.\nerror: could not compile `everything` (bin \"everything\") due to 1 previous error","is_error":false}]},"uuid":"575bc981-a93a-463e-9566-6012c0de1eb9","timestamp":"2026-02-20T09:20:49.086Z","toolUseResult":{"stdout":"    Checking everything v0.2.0 (/Users/al02402336/everything/src-tauri)\nerror[E0599]: no method named `map` found for reference `&Vec<PathBuf>` in the current scope\n    --> src/main.rs:4539:52\n     |\n4539 |                     hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)\n     |                                                    ^^^ `&Vec<PathBuf>` is not an iterator\n     |\nhelp: call `.into_iter()` first\n     |\n4539 |                     hk_state.path_ignores.as_ref().into_iter().map(|v| v.len()).unwrap_or(0)\n     |                                                    ++++++++++++\n\nFor more information about this error, try `rustc --explain E0599`.\nerror: could not compile `everything` (bin \"everything\") due to 1 previous error","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"26a2a8c9-2795-4fbe-b9e1-1e62bbb22b68"}
{"parentUuid":"575bc981-a93a-463e-9566-6012c0de1eb9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01WacSoWVs84poxUTXdrtPG6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UxMmeArEvj84zRhC7kxegE","name":"Grep","input":{"pattern":"path_ignores.*type|path_ignores:","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":2,"head_limit":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":373,"cache_read_input_tokens":81308,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":373},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5GNFU9iTzvrbBZHS9g","type":"assistant","uuid":"41b4cb7d-03a7-4510-bdf7-9bc6ee4436f2","timestamp":"2026-02-20T09:20:52.048Z"}
{"parentUuid":"41b4cb7d-03a7-4510-bdf7-9bc6ee4436f2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01UxMmeArEvj84zRhC7kxegE","toolUseID":"toolu_01UxMmeArEvj84zRhC7kxegE","timestamp":"2026-02-20T09:20:52.855Z","uuid":"498dc712-3c18-41cf-aabc-65c9d8e9f79a"}
{"parentUuid":"41b4cb7d-03a7-4510-bdf7-9bc6ee4436f2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UxMmeArEvj84zRhC7kxegE","type":"tool_result","content":"277-    pub(crate) scan_root: PathBuf,\n278-    pub(crate) cwd: PathBuf,\n279:    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n280-    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n281-    pub(crate) db_ready: Arc<AtomicBool>,\n--\n4474-        scan_root,\n4475-        cwd,\n4476:        path_ignores: Arc::new(path_ignores),\n4477-        path_ignore_patterns: Arc::new(path_ignore_patterns),\n\n[Showing results with pagination = limit: 10, offset: 0]"}]},"uuid":"a82c110b-21f3-4928-a9e3-f9bdadb8dd77","timestamp":"2026-02-20T09:20:52.853Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"277-    pub(crate) scan_root: PathBuf,\n278-    pub(crate) cwd: PathBuf,\n279:    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n280-    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n281-    pub(crate) db_ready: Arc<AtomicBool>,\n--\n4474-        scan_root,\n4475-        cwd,\n4476:        path_ignores: Arc::new(path_ignores),\n4477-        path_ignore_patterns: Arc::new(path_ignore_patterns),","numLines":10,"appliedLimit":10},"sourceToolAssistantUUID":"41b4cb7d-03a7-4510-bdf7-9bc6ee4436f2"}
{"parentUuid":"a82c110b-21f3-4928-a9e3-f9bdadb8dd77","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01YDpnE5ST8bbCHonfp4h83r","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0197vqPKjfYbEu7mpzS8DFjy","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)","new_string":"                    hk_state.path_ignores.len()"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":453,"cache_read_input_tokens":81681,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":453},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5GeHdCuP1TaC1hGXqA","type":"assistant","uuid":"b3a18a3f-be78-4790-a6a7-33b69fea1c31","timestamp":"2026-02-20T09:20:55.499Z"}
{"parentUuid":"b3a18a3f-be78-4790-a6a7-33b69fea1c31","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_0197vqPKjfYbEu7mpzS8DFjy","toolUseID":"toolu_0197vqPKjfYbEu7mpzS8DFjy","timestamp":"2026-02-20T09:20:55.514Z","uuid":"f384f79b-c70d-4362-b546-063b0afcfb62"}
{"parentUuid":"b3a18a3f-be78-4790-a6a7-33b69fea1c31","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0197vqPKjfYbEu7mpzS8DFjy","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"85fa05b1-159d-4f48-bd2c-f804a2402b5a","timestamp":"2026-02-20T09:20:55.513Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)","newString":"                    hk_state.path_ignores.len()","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nconst JWALK_NUM_THREADS: usize = 4;\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<Vec<NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    query_lower: String,\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 200)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -65536;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 0;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) starting...\");\n    let t = Instant::now();\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    eprintln!(\"[indexer/restore_pragmas] wal_checkpoint(TRUNCATE) done in {}ms\", t.elapsed().as_millis());\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut Vec<NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .find(|entry| q.contains(&entry.query_lower))\n        .map(|entry| NegativeCacheHit {\n            query_lower: entry.query_lower.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache\n        .iter()\n        .any(|existing| existing.query_lower == normalized)\n    {\n        return;\n    }\n\n    cache.push(NegativeNameEntry {\n        query_lower: normalized,\n        created_at: Instant::now(),\n        fallback_checked: false,\n    });\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        cache.drain(0..drop_count);\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    cache.retain(|entry| entry.query_lower != normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache\n        .iter_mut()\n        .find(|entry| entry.query_lower == query_lower)\n    {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else if dir_hint.starts_with('/') {\n        PathBuf::from(dir_hint)\n    } else {\n        home_dir.join(dir_hint)\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = match dir_hint.rsplit('/').next() {\n        Some(s) if !s.is_empty() => s,\n        _ => dir_hint,\n    };\n    let sep = std::path::MAIN_SEPARATOR;\n    let native_hint = dir_hint.replace('/', &sep.to_string());\n    let escaped_sep = escape_like(&sep.to_string());\n    let path_pattern = format!(\"%{escaped_sep}{}\", escape_like(&native_hint));\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories\n        PathBuf::from(\"C:\\\\Windows\"),\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\nfn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| BUILTIN_SKIP_NAMES.contains(&seg)) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query: &str) -> u8 {\n    let q = query.trim().to_lowercase();\n    if q.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == q {\n        return 0;\n    }\n    if name.starts_with(&q) {\n        return 1;\n    }\n    if name.contains(&q) {\n        return 2;\n    }\n    if path.ends_with(&format!(\"/{q}\")) {\n        return 3;\n    }\n    if path.contains(&q) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    if query.trim().is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, query);\n        let rb = relevance_rank(b, query);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete — cleared when run_incremental_index succeeds\n    eprintln!(\"[indexer] marking index_complete=0 (db write on calling thread)\");\n    let t0 = Instant::now();\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n    eprintln!(\"[indexer] index_complete=0 done in {}ms\", t0.elapsed().as_millis());\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= BATCH_SIZE {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n    for pass in 0..2u8 {\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n            let existing = preload_existing_entries(conn, &root_str);\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(JWALK_NUM_THREADS));\n            if pass == 0 {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1: skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= BATCH_SIZE {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= BATCH_SIZE {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass, emit progress so UI shows searchable state early\n        if pass == 0 {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    eprintln!(\n        \"[watcher/apply_path_changes] opening db: upsert={} delete={} indexing_active={}\",\n        to_upsert.len(),\n        to_delete.len(),\n        state.indexing_active.load(AtomicOrdering::Acquire)\n    );\n    let t = Instant::now();\n    let mut conn = db_connection(&state.db_path)?;\n    eprintln!(\"[watcher/apply_path_changes] db opened in {}ms\", t.elapsed().as_millis());\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n    eprintln!(\"[watcher/apply_path_changes] done: changed={} in {}ms\", changed, t.elapsed().as_millis());\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    let indexing_now = state.indexing_active.load(AtomicOrdering::Acquire);\n    eprintln!(\n        \"[watcher/process_paths] pending={} indexing_active={}\",\n        pending.len(),\n        indexing_now\n    );\n    if indexing_now {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            eprintln!(\n                \"[watcher/process_paths] apply_path_changes FAILED: {err} | indexing_active={}\",\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher/MustScanSubDirs] opening db: rows={} path={}\",\n                                rows.len(), path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    deadline = None;\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let snapshot = state.status.lock().clone();\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if state.indexing_active.load(AtomicOrdering::Acquire)\n        || !state.db_ready.load(AtomicOrdering::Acquire)\n    {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    }\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n                        let prefix_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&prefix_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let native_hint = dir_hint.replace('/', &sep.to_string());\n                        let escaped_sep = escape_like(&sep.to_string());\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                elapsed_ms,\n                top,\n            ));\n        }\n\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        let mut cache = state.fd_search_cache.lock();\n\n        let cache_hit = cache\n            .as_ref()\n            .map(|c| {\n                c.query == query\n                    && c.sort_by == sort_by\n                    && c.sort_dir == sort_dir\n                    && c.ignore_fingerprint == ignore_fingerprint\n            })\n            .unwrap_or(false);\n\n        let mut timed_out = false;\n\n        if !cache_hit {\n            let result = fd_search::run_fd_search(\n                &state.scan_root,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                &query,\n                &sort_by,\n                &sort_dir,\n            );\n            timed_out = result.timed_out;\n\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        let cached = cache.as_ref().unwrap();\n        let total = cached.entries.len() as u64;\n        let end = (offset + limit).min(cached.entries.len());\n        let page = if offset < cached.entries.len() {\n            cached.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(target_os = \"windows\"))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows\".to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(ext: String, state: State<'_, AppState>) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let key = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        if let Some(cached) = state.icon_cache.lock().get(&key).cloned() {\n            return cached;\n        }\n\n        let icon = load_system_icon_png(&key).unwrap_or_default();\n        state.icon_cache.lock().insert(key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use window_vibrancy::{apply_vibrancy, NSVisualEffectMaterial};\n        if let Err(e) = apply_vibrancy(&window, NSVisualEffectMaterial::UnderWindowBackground, None, None) {\n            eprintln!(\"[vibrancy] apply failed: {e}\");\n        }\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        // Show window after background color is set to avoid white flash.\n        // The skeleton HTML renders on top of this matching background.\n        let _ = window.show();\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true — launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping — purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] start: indexing_active={}\",\n                    hk_state.indexing_active.load(AtomicOrdering::Acquire)\n                );\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                let purge_t = std::time::Instant::now();\n                eprintln!(\n                    \"[startup/housekeeping] purge_ignored_entries start: roots={}\",\n                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)\n                );\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                }\n                eprintln!(\"[startup/housekeeping] purge_ignored_entries done in {}ms\", purge_t.elapsed().as_millis());\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete — starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    tauri::Builder::default()\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_window_state::Builder::default().build())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build())\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            frontend_log\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        std::env::temp_dir().join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(Vec::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" — dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" — name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" — none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":4536,"oldLines":7,"newStart":4536,"newLines":7,"lines":["                 let purge_t = std::time::Instant::now();","                 eprintln!(","                     \"[startup/housekeeping] purge_ignored_entries start: roots={}\",","-                    hk_state.path_ignores.as_ref().map(|v| v.len()).unwrap_or(0)","+                    hk_state.path_ignores.len()","                 );","                 if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {","                     eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"b3a18a3f-be78-4790-a6a7-33b69fea1c31"}
{"parentUuid":"85fa05b1-159d-4f48-bd2c-f804a2402b5a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01BNDVuReJsytAX2o6sHzHFq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015DE11ZYvL4a85YLQXrGBpt","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | tail -10","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":210,"cache_read_input_tokens":82134,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":210},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5GqkSXzNrLN6Qr2sqj","type":"assistant","uuid":"9665bf25-44db-41d7-986d-f08a9343fd77","timestamp":"2026-02-20T09:20:57.546Z"}
{"parentUuid":"9665bf25-44db-41d7-986d-f08a9343fd77","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015DE11ZYvL4a85YLQXrGBpt","type":"tool_result","content":" 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 1.21s","is_error":false}]},"uuid":"6c772cdc-3126-40a2-a130-d068dc9ccc4d","timestamp":"2026-02-20T09:20:59.031Z","toolUseResult":{"stdout":" 60 | impl MemIndex {\n    | ------------- associated items in this implementation\n 61 |     pub fn build(entries: Vec<CompactEntry>) -> Self {\n    |            ^^^^^\n...\n114 |     pub fn entries(&self) -> &[CompactEntry] {\n    |            ^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 3 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 1.21s","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"9665bf25-44db-41d7-986d-f08a9343fd77"}
{"parentUuid":"6c772cdc-3126-40a2-a130-d068dc9ccc4d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","message":{"model":"claude-sonnet-4-6","id":"msg_01Tw19Vixhjs9wxTsmqWzPty","type":"message","role":"assistant","content":[{"type":"text","text":"컴파일 성공. 이제 `npm run tauri dev` 실행 후 stderr 로그를 확인하면 됩니다:\n\n```bash\nnpm run tauri dev 2>&1 | grep -E '\\[watcher|indexer|startup/housekeeping\\]'\n```\n\n추가된 로그 목록:\n\n| 로그 태그 | 위치 | 확인 목적 |\n|---|---|---|\n| `[watcher/process_paths]` | `process_watcher_paths` 진입부 | `indexing_active` 상태 확인 |\n| `[watcher/apply_path_changes]` | DB 연결 전/후 | 잠금 대기 시간 측정 |\n| `[watcher/apply_path_changes] FAILED` | 에러 발생 시 | 실패 시 `indexing_active` 재확인 |\n| `[watcher/MustScanSubDirs]` | FSEvents 디렉토리 스캔 | 동시 DB 쓰기 여부 |\n| `[indexer] marking index_complete=0` | 인덱서 시작 시 | 동시성 충돌 타이밍 |\n| `[indexer/restore_pragmas]` | `wal_checkpoint(TRUNCATE)` | 체크포인트가 블로킹하는지 확인 |\n| `[startup/housekeeping] start` | 500ms 후 | `indexing_active` 상태 |\n| `[startup/housekeeping] purge_ignored_entries` | 삭제 작업 | 장시간 잠금 여부 |\n\n재실행 후 stderr 로그를 복사해주시면 원인을 정확히 파악할 수 있습니다."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":222,"cache_read_input_tokens":82344,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":222},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYK5H7VEXXMACcdA4qJ7d","type":"assistant","uuid":"a92539f7-151b-4aac-b21a-a22b8ed22a92","timestamp":"2026-02-20T09:21:09.553Z"}
{"parentUuid":"a92539f7-151b-4aac-b21a-a22b8ed22a92","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"ede066fc-a492-42d9-a8a4-eb9fbd0e6969","toolUseID":"ede066fc-a492-42d9-a8a4-eb9fbd0e6969","timestamp":"2026-02-20T09:21:09.605Z","uuid":"9cf4b673-3bad-4dac-b407-20b2bc202519"}
{"type":"queue-operation","operation":"remove","timestamp":"2026-02-20T09:21:10.633Z","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b"}
{"parentUuid":"9cf4b673-3bad-4dac-b407-20b2bc202519","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1007}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-20T09:21:10.613Z","uuid":"0e346f5b-011f-4133-9d07-4fee9a1e1854","toolUseID":"ede066fc-a492-42d9-a8a4-eb9fbd0e6969"}
{"parentUuid":"0e346f5b-011f-4133-9d07-4fee9a1e1854","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"system","subtype":"turn_duration","durationMs":471612,"timestamp":"2026-02-20T09:21:10.615Z","uuid":"913b5fee-54ff-43a9-80f8-285b5baa53fd","isMeta":false}
{"type":"file-history-snapshot","messageId":"8a7e3106-be39-47f6-99e5-617287d1a5b3","snapshot":{"messageId":"8a7e3106-be39-47f6-99e5-617287d1a5b3","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-20T09:42:44.414Z"}},"timestamp":"2026-02-20T09:42:44.413Z"},"isSnapshotUpdate":false}
{"parentUuid":"913b5fee-54ff-43a9-80f8-285b5baa53fd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":"재실행시 Ready인 상태에서 갑자기 Index: Error\nEntries: 1,171,663\nReset Index\nWatcher update failed: database is locked 로 바뀐다. 이 이슈를 추적하게 로그 넣어줘"},"uuid":"8a7e3106-be39-47f6-99e5-617287d1a5b3","timestamp":"2026-02-20T09:42:44.411Z","permissionMode":"bypassPermissions"}
{"parentUuid":"8a7e3106-be39-47f6-99e5-617287d1a5b3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"1073a9fc-2514-40be-8f82-2811d2db672b","version":"2.1.49","gitBranch":"main","slug":"gleaming-coalescing-kay","type":"user","message":{"role":"user","content":[{"type":"text","text":"[Request interrupted by user]"}]},"uuid":"781a00b3-9cae-4837-a409-869dc6408eeb","timestamp":"2026-02-20T09:42:44.449Z"}
