{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:startup","command":"entire hooks claude-code session-start"},"parentToolUseID":"f3f07527-ded1-4db3-9831-14c3ce9d19ad","toolUseID":"f3f07527-ded1-4db3-9831-14c3ce9d19ad","timestamp":"2026-02-22T08:16:53.213Z","uuid":"77ef38c0-f0f6-4119-ab9d-19ce0ed23534"}
{"type":"file-history-snapshot","messageId":"d21bd882-d4b7-4245-8b90-df7cecf1f692","snapshot":{"messageId":"d21bd882-d4b7-4245-8b90-df7cecf1f692","trackedFileBackups":{},"timestamp":"2026-02-22T09:29:21.012Z"},"isSnapshotUpdate":false}
{"parentUuid":"77ef38c0-f0f6-4119-ab9d-19ce0ed23534","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","type":"user","message":{"role":"user","content":"system dark theme에서 light theme로 설정한 뒤에 타이틀바 더블클릭(전체화면)으로 동작할 때 배경이 dark theme로 창이 확대되다가 웹 화면이 커지는 이슈가 있어. 어떻게 수정할까?"},"uuid":"d21bd882-d4b7-4245-8b90-df7cecf1f692","timestamp":"2026-02-22T09:29:15.128Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"d21bd882-d4b7-4245-8b90-df7cecf1f692","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is describing a visual issue where:\n1. System is set to dark theme\n2. They switch to light theme\n3. When they double-click the title bar (to maximize/fullscreen)\n4. The background appears dark (dark theme) during the window expansion animation, then the web content appears larger\n\nThis sounds like a flash of wrong theme/background color during window resize animation. Let me look at the codebase to understand how theming is handled.\n\nLet me check the relevant files first.","signature":"EooFCkYICxgCKkANNZBD6nnWCe0mIgOuETG5qDgVF/e8vdSS+CFRVh/WqU3YaoAFgOnKpxtwYg+kZDCGcwF2y06/Q0RHrQOTWzBkEgxvWQGiqBKM8ATa+vAaDL/h6aGV/A71tyS8HCIwmU4LHDQjkhsPRqpSjiP3rkzQ9IblXg2SafpxJDqPzQ9ukONQ4IxO2D8Uauxe1fDxKvED6yYLd/0K+NWkekMOPc51VjhjXqe+ixMYyXdVJejqAvZxDxC5pEWON+njTrXZWFdCVXyymCF1gUvvizblfJbSdjLRGT3ggjdszFlF78BedvO/0UvMnOgy2sjOoBcqypsDxUZk9SFy2WIQFpdVXMLad6d2+tKHVysGfwfqKWbVkX1VPHsUNf1MBd+bMRcMbB70fppLaz4CqUpVOXUvwkjKlmzC5Zk8oAc2j+1dN0NvDl9PCee1aRtTyiElQ2GeKPl6I/3PASXQrvcYtQQawsZfPauvrmU3bLOp+wwPkP08+hg+lGzwMEn0QfMBCMKGfOQTOa5OmT/T6KoJ8//EDDzHVv25wnRKR5dPH/3DPp7WdSd8C9duMYutxATJTbIXxlrbIHIY1INlZYbl/KMvBhTp5HQlNM56hCmW0SAXT2UbY3qm3KGtqnmnhMUkjhK5BgDQ05aZkIHy67hV3SvXLDhd4YTJv2hCt+K0dv9tOH9izvsMWialhI0pcVHAbGxEDMy4R2k3K6i8npEmwBcgBoZQQ0sazA6KyAOuRenzex8JMRECKf2IvBUx06/5BCSMokkQkjn1+oTlmCCmioS6X7cIf3VFDVGHrt7Ak5R7YQXCELHqPhxWQnsjijnvx/5//hisZvC6eQMTVqg7pT9g05vrfVwYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"2dd64469-5520-4873-b5bb-ffa4e5024a3b","timestamp":"2026-02-22T09:29:25.665Z"}
{"parentUuid":"2dd64469-5520-4873-b5bb-ffa4e5024a3b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"text","text":"현재 코드를 먼저 파악해볼게요."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"173f2d8f-7762-4e34-ab26-e374d445e594","timestamp":"2026-02-22T09:29:26.143Z"}
{"parentUuid":"173f2d8f-7762-4e34-ab26-e374d445e594","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BMsU1C6wcZM1N9Kj4saf9L","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"321b7d9e-15dc-4e22-a8b7-a901c84719a5","timestamp":"2026-02-22T09:29:26.588Z"}
{"parentUuid":"321b7d9e-15dc-4e22-a8b7-a901c84719a5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"File content (27568 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","is_error":true,"tool_use_id":"toolu_01BMsU1C6wcZM1N9Kj4saf9L"}]},"uuid":"eac28fc2-1024-4be0-ac93-7901c1ccc5aa","timestamp":"2026-02-22T09:29:26.932Z","toolUseResult":"Error: File content (27568 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","sourceToolAssistantUUID":"321b7d9e-15dc-4e22-a8b7-a901c84719a5"}
{"parentUuid":"eac28fc2-1024-4be0-ac93-7901c1ccc5aa","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01AX3sn67QiVH48Q2v6vx2JK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JTqFHdacDxk4RLWazwLQMi","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/tauri.conf.json"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":22328,"cache_read_input_tokens":11451,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22328},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsXy2nMiv29GNSgoK41","type":"assistant","uuid":"fa76f54e-94c1-4378-ba86-153a82055ea3","timestamp":"2026-02-22T09:29:27.013Z"}
{"parentUuid":"fa76f54e-94c1-4378-ba86-153a82055ea3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>Sibling tool call errored</tool_use_error>","is_error":true,"tool_use_id":"toolu_01JTqFHdacDxk4RLWazwLQMi"}]},"uuid":"56b023ba-a7cd-4715-bab2-8209030ebd4c","timestamp":"2026-02-22T09:29:27.013Z","toolUseResult":"Sibling tool call errored","sourceToolAssistantUUID":"fa76f54e-94c1-4378-ba86-153a82055ea3"}
{"parentUuid":"56b023ba-a7cd-4715-bab2-8209030ebd4c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_014QXgWU3qd72wF6zvr1GNEk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VELqzGSnYuzXzWArFZqhzb","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte","offset":1,"limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":389,"cache_read_input_tokens":33779,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":389},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYNVAjcbmjgDpvMNqM","type":"assistant","uuid":"61941bf2-fd5f-4be7-b409-7258c4f5dd36","timestamp":"2026-02-22T09:29:29.379Z"}
{"parentUuid":"61941bf2-fd5f-4be7-b409-7258c4f5dd36","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01VELqzGSnYuzXzWArFZqhzb","toolUseID":"toolu_01VELqzGSnYuzXzWArFZqhzb","timestamp":"2026-02-22T09:29:29.388Z","uuid":"c7be933a-db97-4f47-a1c8-92b5e44d3389"}
{"parentUuid":"61941bf2-fd5f-4be7-b409-7258c4f5dd36","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VELqzGSnYuzXzWArFZqhzb","type":"tool_result","content":"     1→<script>\n     2→  import { onDestroy, onMount, tick } from 'svelte';\n     3→  import { invoke } from '@tauri-apps/api/core';\n     4→  import { listen } from '@tauri-apps/api/event';\n     5→  import { getCurrentWindow } from '@tauri-apps/api/window';\n     6→  import { startDrag } from '@crabnebula/tauri-plugin-drag';\n     7→  import 'overlayscrollbars/overlayscrollbars.css';\n     8→  import { OverlayScrollbars } from 'overlayscrollbars';\n     9→  import {\n    10→    SEARCH_DEBOUNCE_MS,\n    11→    computeSearchFetchLimit,\n    12→    extractLeafQuery,\n    13→    shouldApplyPreserveResults\n    14→  } from './search-utils';\n    15→  let osInstance = null;\n    16→  let osViewport = null;\n    17→  let scrollCleanup = null;\n    18→  function getScrollEl() {\n    19→    return osViewport || tableContainer;\n    20→  }\n    21→\n    22→  const rowHeight = 26;\n    23→  const PAGE_SIZE = 500;\n    24→  let homePrefix = '';\n    25→  const COL_WIDTHS_KEY = 'REDACTED';\n    26→  const THEME_KEY = 'everything-theme';\n    27→  const columnKeys = ['name', 'path', 'size', 'modified'];\n    28→  const minColumnWidth = {\n    29→    name: 180,\n    30→    path: 240,\n    31→    size: 62,\n    32→    modified: 150\n    33→  };\n    34→  const defaultColumnRatios = {\n    35→    name: 0.32,\n    36→    path: 0.48,\n    37→    size: 0.05\n    38→  };\n    39→  const DEBUG_STARTUP = false;\n    40→\n    41→  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n    42→  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n    43→  function cycleTheme() {\n    44→    theme = theme === 'dark' ? 'light' : 'dark';\n    45→    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n    46→    invoke('set_native_theme', { theme });\n    47→  }\n    48→\n    49→  function sortIconHtml(dir) {\n    50→    const d = dir === 'asc' ? 'M2.5 6.5 L5 4 L7.5 6.5' : 'M2.5 3.5 L5 6 L7.5 3.5';\n    51→    return `<svg class=\"sort-icon\" viewBox=\"0 0 10 10\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"${d}\"/></svg>`;\n    52→  }\n    53→\n    54→  let query = '';\n    55→  let results = [];\n    56→  let totalResults = 0;\n    57→  let totalResultsKnown = false;\n    58→\n    59→  let dbLatencyMs = null;\n    60→  let dbLastQuery = '';\n    61→  let searchModeLabel = '';\n    62→  let selectedIndices = new Set();\n    63→  let selectionAnchor = -1;\n    64→  let lastSelectedIndex = -1;\n    65→  let editing = {\n    66→    active: false,\n    67→    path: '',\n    68→    index: -1,\n    69→    draftName: ''\n    70→  };\n    71→\n    72→  let renameOverlay = { top: 0, left: 0, maxWidth: 0 };\n    73→\n    74→  let indexStatus = {\n    75→    state: 'Indexing',\n    76→    entriesCount: 0,\n    77→    lastUpdated: null,\n    78→    permissionErrors: 0,\n    79→    message: null,\n    80→    isCatchup: false\n    81→  };\n    82→\n    83→  let indexingStartTime = null;\n    84→  let indexingElapsed = '';\n    85→  let indexingFinishedAt = '';\n    86→\n    87→  let sortBy = 'name';\n    88→  let sortDir = 'asc';\n    89→\n    90→  let hasMore = true;\n    91→  let loadingMore = false;\n    92→  let searchGeneration = 0;\n    93→  let scheduleGeneration = 0;\n    94→  let searchPending = false;\n    95→\n    96→  let scanned = 0;\n    97→  let indexed = 0;\n    98→  let currentPath = '';\n    99→\n   100→  let searchInputEl;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1b1648c4-8867-4a64-8206-0602115acee0","timestamp":"2026-02-22T09:29:29.387Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src/App.svelte","content":"<script>\n  import { onDestroy, onMount, tick } from 'svelte';\n  import { invoke } from '@tauri-apps/api/core';\n  import { listen } from '@tauri-apps/api/event';\n  import { getCurrentWindow } from '@tauri-apps/api/window';\n  import { startDrag } from '@crabnebula/tauri-plugin-drag';\n  import 'overlayscrollbars/overlayscrollbars.css';\n  import { OverlayScrollbars } from 'overlayscrollbars';\n  import {\n    SEARCH_DEBOUNCE_MS,\n    computeSearchFetchLimit,\n    extractLeafQuery,\n    shouldApplyPreserveResults\n  } from './search-utils';\n  let osInstance = null;\n  let osViewport = null;\n  let scrollCleanup = null;\n  function getScrollEl() {\n    return osViewport || tableContainer;\n  }\n\n  const rowHeight = 26;\n  const PAGE_SIZE = 500;\n  let homePrefix = '';\n  const COL_WIDTHS_KEY = 'REDACTED';\n  const THEME_KEY = 'everything-theme';\n  const columnKeys = ['name', 'path', 'size', 'modified'];\n  const minColumnWidth = {\n    name: 180,\n    path: 240,\n    size: 62,\n    modified: 150\n  };\n  const defaultColumnRatios = {\n    name: 0.32,\n    path: 0.48,\n    size: 0.05\n  };\n  const DEBUG_STARTUP = false;\n\n  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n  function cycleTheme() {\n    theme = theme === 'dark' ? 'light' : 'dark';\n    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n    invoke('set_native_theme', { theme });\n  }\n\n  function sortIconHtml(dir) {\n    const d = dir === 'asc' ? 'M2.5 6.5 L5 4 L7.5 6.5' : 'M2.5 3.5 L5 6 L7.5 3.5';\n    return `<svg class=\"sort-icon\" viewBox=\"0 0 10 10\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"${d}\"/></svg>`;\n  }\n\n  let query = '';\n  let results = [];\n  let totalResults = 0;\n  let totalResultsKnown = false;\n\n  let dbLatencyMs = null;\n  let dbLastQuery = '';\n  let searchModeLabel = '';\n  let selectedIndices = new Set();\n  let selectionAnchor = -1;\n  let lastSelectedIndex = -1;\n  let editing = {\n    active: false,\n    path: '',\n    index: -1,\n    draftName: ''\n  };\n\n  let renameOverlay = { top: 0, left: 0, maxWidth: 0 };\n\n  let indexStatus = {\n    state: 'Indexing',\n    entriesCount: 0,\n    lastUpdated: null,\n    permissionErrors: 0,\n    message: null,\n    isCatchup: false\n  };\n\n  let indexingStartTime = null;\n  let indexingElapsed = '';\n  let indexingFinishedAt = '';\n\n  let sortBy = 'name';\n  let sortDir = 'asc';\n\n  let hasMore = true;\n  let loadingMore = false;\n  let searchGeneration = 0;\n  let scheduleGeneration = 0;\n  let searchPending = false;\n\n  let scanned = 0;\n  let indexed = 0;\n  let currentPath = '';\n\n  let searchInputEl;","numLines":100,"startLine":1,"totalLines":2738}},"sourceToolAssistantUUID":"61941bf2-fd5f-4be7-b409-7258c4f5dd36"}
{"parentUuid":"1b1648c4-8867-4a64-8206-0602115acee0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_014QXgWU3qd72wF6zvr1GNEk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013k1TE5VL2VMq5iM1BmDoh1","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/tauri.conf.json"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":389,"cache_read_input_tokens":33779,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":389},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYNVAjcbmjgDpvMNqM","type":"assistant","uuid":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7","timestamp":"2026-02-22T09:29:29.681Z"}
{"parentUuid":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013k1TE5VL2VMq5iM1BmDoh1","toolUseID":"toolu_013k1TE5VL2VMq5iM1BmDoh1","timestamp":"2026-02-22T09:29:29.688Z","uuid":"bb48db25-1b00-44b7-aca8-74e852fbaa1e"}
{"parentUuid":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013k1TE5VL2VMq5iM1BmDoh1","type":"tool_result","content":"     1→{\n     2→  \"$schema\": \"../node_modules/@tauri-apps/cli/config.schema.json\",\n     3→  \"productName\": \"Everything\",\n     4→  \"version\": \"0.2.0\",\n     5→  \"identifier\": \"com.everything.app\",\n     6→  \"build\": {\n     7→    \"beforeDevCommand\": \"npm run dev\",\n     8→    \"devUrl\": \"http://127.0.0.1:1420\",\n     9→    \"beforeBuildCommand\": \"npm run build\",\n    10→    \"frontendDist\": \"../dist\"\n    11→  },\n    12→  \"app\": {\n    13→    \"macOSPrivateApi\": true,\n    14→    \"windows\": [\n    15→      {\n    16→        \"title\": \"\",\n    17→        \"label\": \"main\",\n    18→        \"width\": 600,\n    19→        \"height\": 380,\n    20→        \"transparent\": true,\n    21→        \"titleBarStyle\": \"Overlay\",\n    22→        \"trafficLightPosition\": {\n    23→          \"x\": 12,\n    24→          \"y\": 12\n    25→        },\n    26→        \"visible\": false,\n    27→        \"minWidth\": 400,\n    28→        \"minHeight\": 300,\n    29→        \"resizable\": true,\n    30→        \"fullscreen\": false\n    31→      }\n    32→    ],\n    33→    \"security\": {\n    34→      \"csp\": \"default-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; script-src 'self'\"\n    35→    }\n    36→  },\n    37→  \"bundle\": {\n    38→    \"active\": true,\n    39→    \"targets\": \"all\",\n    40→    \"category\": \"DeveloperTool\",\n    41→    \"icon\": [\n    42→      \"icons/32x32.png\",\n    43→      \"icons/128x128.png\",\n    44→      \"icons/icon.png\",\n    45→      \"icons/icon.icns\",\n    46→      \"icons/icon.ico\"\n    47→    ],\n    48→    \"resources\": {\n    49→      \"../everything.icon\": \"everything.icon\"\n    50→    },\n    51→    \"macOS\": {\n    52→      \"signingIdentity\": null,\n    53→      \"entitlements\": \"Entitlements.plist\",\n    54→      \"minimumSystemVersion\": \"11.0\",\n    55→      \"infoPlist\": \"Info.plist\"\n    56→    },\n    57→    \"windows\": {\n    58→      \"nsis\": {\n    59→        \"displayLanguageSelector\": false,\n    60→        \"languages\": [\n    61→          \"Korean\",\n    62→          \"English\"\n    63→        ],\n    64→        \"installerIcon\": \"icons/icon.ico\"\n    65→      }\n    66→    }\n    67→  }\n    68→}\n    69→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"207acb11-bba8-40cc-8ae8-481a219a69d7","timestamp":"2026-02-22T09:29:29.688Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/tauri.conf.json","content":"{\n  \"$schema\": \"../node_modules/@tauri-apps/cli/config.schema.json\",\n  \"productName\": \"Everything\",\n  \"version\": \"0.2.0\",\n  \"identifier\": \"com.everything.app\",\n  \"build\": {\n    \"beforeDevCommand\": \"npm run dev\",\n    \"devUrl\": \"http://127.0.0.1:1420\",\n    \"beforeBuildCommand\": \"npm run build\",\n    \"frontendDist\": \"../dist\"\n  },\n  \"app\": {\n    \"macOSPrivateApi\": true,\n    \"windows\": [\n      {\n        \"title\": \"\",\n        \"label\": \"main\",\n        \"width\": 600,\n        \"height\": 380,\n        \"transparent\": true,\n        \"titleBarStyle\": \"Overlay\",\n        \"trafficLightPosition\": {\n          \"x\": 12,\n          \"y\": 12\n        },\n        \"visible\": false,\n        \"minWidth\": 400,\n        \"minHeight\": 300,\n        \"resizable\": true,\n        \"fullscreen\": false\n      }\n    ],\n    \"security\": {\n      \"csp\": \"default-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; script-src 'self'\"\n    }\n  },\n  \"bundle\": {\n    \"active\": true,\n    \"targets\": \"all\",\n    \"category\": \"DeveloperTool\",\n    \"icon\": [\n      \"icons/32x32.png\",\n      \"icons/128x128.png\",\n      \"icons/icon.png\",\n      \"icons/icon.icns\",\n      \"icons/icon.ico\"\n    ],\n    \"resources\": {\n      \"../everything.icon\": \"everything.icon\"\n    },\n    \"macOS\": {\n      \"signingIdentity\": null,\n      \"entitlements\": \"Entitlements.plist\",\n      \"minimumSystemVersion\": \"11.0\",\n      \"infoPlist\": \"Info.plist\"\n    },\n    \"windows\": {\n      \"nsis\": {\n        \"displayLanguageSelector\": false,\n        \"languages\": [\n          \"Korean\",\n          \"English\"\n        ],\n        \"installerIcon\": \"icons/icon.ico\"\n      }\n    }\n  }\n}\n","numLines":69,"startLine":1,"totalLines":69}},"sourceToolAssistantUUID":"d9fd9d70-3f61-4804-a6ef-b78fcfdbc4e7"}
{"parentUuid":"207acb11-bba8-40cc-8ae8-481a219a69d7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TS3aks6UCP71tyPtf5Z6h2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YZPLK72DthRzVrGcQSrAsk","name":"Grep","input":{"pattern":"background|--bg|body|html|theme|color-scheme","path":"/Users/al02402336/everything/src/App.svelte","output_mode":"content","-n":true,"head_limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2496,"cache_read_input_tokens":34168,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2496},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYZkax6o6wVGYqgZmm","type":"assistant","uuid":"35560c70-6d59-4696-abdd-29e023370e2f","timestamp":"2026-02-22T09:29:33.221Z"}
{"parentUuid":"35560c70-6d59-4696-abdd-29e023370e2f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TS3aks6UCP71tyPtf5Z6h2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2496,"cache_read_input_tokens":34168,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2496},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYZkax6o6wVGYqgZmm","type":"assistant","uuid":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d","timestamp":"2026-02-22T09:29:33.885Z"}
{"parentUuid":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","toolUseID":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","timestamp":"2026-02-22T09:29:33.894Z","uuid":"5627621f-4b04-4e26-a0a5-ca8d04405ab1"}
{"parentUuid":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Hrc2ftXvbW6dgqcRLUupNP","type":"tool_result","content":"     1→#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n     2→\n     3→use std::{\n     4→    cmp::Ordering,\n     5→    collections::{HashMap, HashSet},\n     6→    fs,\n     7→    hash::{Hash, Hasher},\n     8→    io::{self, BufRead, BufReader, Write},\n     9→    path::{Path, PathBuf},\n    10→    process::{Command, Stdio},\n    11→    sync::{\n    12→        atomic::{AtomicBool, Ordering as AtomicOrdering},\n    13→        Arc, OnceLock,\n    14→    },\n    15→    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n    16→};\n    17→\n    18→use parking_lot::{Mutex, RwLock};\n    19→use rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\n    20→use serde::Serialize;\n    21→use tauri::{AppHandle, Emitter, Manager, State};\n    22→#[cfg(target_os = \"macos\")]\n    23→use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n    24→#[cfg(target_os = \"windows\")]\n    25→use std::os::windows::process::CommandExt;\n    26→use walkdir::WalkDir;\n    27→\n    28→mod fd_search;\n    29→mod gitignore_filter;\n    30→#[cfg(target_os = \"macos\")]\n    31→mod mac;\n    32→mod mem_search;\n    33→mod query;\n    34→#[cfg(target_os = \"windows\")]\n    35→mod win;\n    36→use fd_search::{FdSearchCache, FdSearchResultDto};\n    37→use query::{escape_like, parse_query, SearchMode};\n    38→\n    39→const DEFAULT_LIMIT: u32 = 300;\n    40→const SHORT_QUERY_LIMIT: u32 = 100;\n    41→const MAX_LIMIT: u32 = 1000;\n    42→pub(crate) const BATCH_SIZE: usize = 10_000;\n    43→const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n    44→pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n    45→const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n    46→const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n    47→const DB_VERSION: i32 = 5;\n    48→const DEFERRED_DIR_NAMES: &[&str] = &[\n    49→    \"Library\", \".Trash\", \".Trashes\",\n    50→    // Windows system directories (deferred when scan_root is C:\\)\n    51→    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    52→    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n    53→];\n    54→const SHALLOW_SCAN_DEPTH: usize = 6;\n    55→fn jwalk_num_threads() -> usize {\n    56→    std::thread::available_parallelism()\n    57→        .map(|n| (n.get() / 2).max(4).min(16))\n    58→        .unwrap_or(8)\n    59→}\n    60→\n    61→fn jwalk_num_threads_fresh() -> usize {\n    62→    std::thread::available_parallelism()\n    63→        .map(|n| n.get().max(4).min(16))\n    64→        .unwrap_or(8)\n    65→}\n    66→\n    67→pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    68→    \".git\",\n    69→    \"node_modules\",\n    70→    \".Trash\",\n    71→    \".Trashes\",\n    72→    \".npm\",\n    73→    \".cache\",\n    74→    \"CMakeFiles\",\n    75→    \".qtc_clangd\",\n    76→    \"__pycache__\",\n    77→    \".gradle\",\n    78→    \"DerivedData\",\n    79→];\n    80→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"503aabe2-57cb-4a06-8c6a-c276744c9617","timestamp":"2026-02-22T09:29:33.893Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n","numLines":80,"startLine":1,"totalLines":5880}},"sourceToolAssistantUUID":"5ceae58d-02d7-47bd-ac9d-0ca4365e3d9d"}
{"parentUuid":"503aabe2-57cb-4a06-8c6a-c276744c9617","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01YZPLK72DthRzVrGcQSrAsk","toolUseID":"toolu_01YZPLK72DthRzVrGcQSrAsk","timestamp":"2026-02-22T09:29:33.966Z","uuid":"9d1ba3e7-ce06-4823-aeb6-ffbae38da024"}
{"parentUuid":"35560c70-6d59-4696-abdd-29e023370e2f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YZPLK72DthRzVrGcQSrAsk","type":"tool_result","content":"26:  const THEME_KEY = 'everything-theme';\n41:  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n42:  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n44:    theme = theme === 'dark' ? 'light' : 'dark';\n45:    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n46:    invoke('set_native_theme', { theme });\n454:      document.body.style.cursor = '';\n455:      document.body.style.userSelect = '';\n464:    document.body.style.cursor = 'col-resize';\n465:    document.body.style.userSelect = 'none';\n811:    const isDark = theme === 'dark';\n1452:    invoke('set_native_theme', { theme });\n1596:          theme: 'os-theme-dark',\n1689:<div class=\"app-shell\" data-theme={theme} data-platform={platform}>\n1743:            Name{#if sortBy === 'name'}{@html sortIconHtml(sortDir)}{/if}\n1756:            Path{#if sortBy === 'dir'}{@html sortIconHtml(sortDir)}{/if}\n1769:            Size{#if sortBy === 'size'}{@html sortIconHtml(sortDir)}{/if}\n1775:            Modified{#if sortBy === 'mtime'}{@html sortIconHtml(sortDir)}{/if}\n1782:      class=\"table-body\"\n1845:      <button class=\"status-btn\" on:click={cycleTheme} title=\"Switch theme\">\n1846:        {#if theme === 'dark'}\n1847:[Omitted long matching line]\n1850:          <svg class=\"theme-icon\" viewBox=\"0 0 16 16\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.3\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M13.5 9.2A5.5 5.5 0 0 1 6.8 2.5 5.5 5.5 0 1 0 13.5 9.2z\"/></svg>\n1908:    color-scheme: light dark;\n1909:    --bg-app: transparent;\n1935:  @media (prefers-color-scheme: dark) {\n1937:      --bg-app: transparent;\n1965:  :global([data-theme=\"dark\"]) {\n1966:    color-scheme: dark;\n1967:    --bg-app: #1E1E21;\n1974:    --bg-input: #161618;\n1996:  :global([data-theme=\"light\"]) {\n1997:    color-scheme: light;\n1998:    --bg-app: #F5F5F7;\n2005:    --bg-input: #FFFFFF;\n2027:  :global([data-theme]) {\n2028:    background: var(--bg-app);\n2032:  :global([data-theme]) .search-bar {\n2035:    background: var(--bg-app);\n2039:  :global([data-theme]) .search-input {\n2049:  :global([data-theme]) .table-header {\n2050:    background: var(--bg-app);\n2053:  :global([data-theme]) .col-button {\n2057:  :global([data-theme]) .col.name .col-button {\n2062:  :global([data-theme]) .cell {\n2066:  :global([data-theme]) .cell.name {\n2073:  :global([data-theme]) .cell.path {\n2078:  :global([data-theme]) .cell.size {\n2082:  :global([data-theme]) .cell.modified {\n2088:  :global([data-theme]) .row.selected {\n2092:  /* Dim path/size/date cells in themed mode */\n2093:  :global([data-theme]) .cell.path,\n2094:  :global([data-theme]) .cell.size,\n2095:  :global([data-theme]) .cell.modified {\n2100:    background: transparent;\n2103:  :global(html, body) {\n2108:    background: transparent;\n2132:    background: var(--surface-header);\n2185:    background: transparent;\n2193:    background: var(--row-hover);\n\n[Showing results with pagination = limit: 60, offset: 0]"}]},"uuid":"defc7995-d0a5-4099-b1be-3c0c9a9a8140","timestamp":"2026-02-22T09:29:33.964Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"26:  const THEME_KEY = 'everything-theme';\n41:  const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n42:  let theme = (() => { try { return localStorage.getItem(THEME_KEY) || systemTheme; } catch { return systemTheme; } })();\n44:    theme = theme === 'dark' ? 'light' : 'dark';\n45:    try { localStorage.setItem(THEME_KEY, theme); } catch {}\n46:    invoke('set_native_theme', { theme });\n454:      document.body.style.cursor = '';\n455:      document.body.style.userSelect = '';\n464:    document.body.style.cursor = 'col-resize';\n465:    document.body.style.userSelect = 'none';\n811:    const isDark = theme === 'dark';\n1452:    invoke('set_native_theme', { theme });\n1596:          theme: 'os-theme-dark',\n1689:<div class=\"app-shell\" data-theme={theme} data-platform={platform}>\n1743:            Name{#if sortBy === 'name'}{@html sortIconHtml(sortDir)}{/if}\n1756:            Path{#if sortBy === 'dir'}{@html sortIconHtml(sortDir)}{/if}\n1769:            Size{#if sortBy === 'size'}{@html sortIconHtml(sortDir)}{/if}\n1775:            Modified{#if sortBy === 'mtime'}{@html sortIconHtml(sortDir)}{/if}\n1782:      class=\"table-body\"\n1845:      <button class=\"status-btn\" on:click={cycleTheme} title=\"Switch theme\">\n1846:        {#if theme === 'dark'}\n1847:[Omitted long matching line]\n1850:          <svg class=\"theme-icon\" viewBox=\"0 0 16 16\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.3\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M13.5 9.2A5.5 5.5 0 0 1 6.8 2.5 5.5 5.5 0 1 0 13.5 9.2z\"/></svg>\n1908:    color-scheme: light dark;\n1909:    --bg-app: transparent;\n1935:  @media (prefers-color-scheme: dark) {\n1937:      --bg-app: transparent;\n1965:  :global([data-theme=\"dark\"]) {\n1966:    color-scheme: dark;\n1967:    --bg-app: #1E1E21;\n1974:    --bg-input: #161618;\n1996:  :global([data-theme=\"light\"]) {\n1997:    color-scheme: light;\n1998:    --bg-app: #F5F5F7;\n2005:    --bg-input: #FFFFFF;\n2027:  :global([data-theme]) {\n2028:    background: var(--bg-app);\n2032:  :global([data-theme]) .search-bar {\n2035:    background: var(--bg-app);\n2039:  :global([data-theme]) .search-input {\n2049:  :global([data-theme]) .table-header {\n2050:    background: var(--bg-app);\n2053:  :global([data-theme]) .col-button {\n2057:  :global([data-theme]) .col.name .col-button {\n2062:  :global([data-theme]) .cell {\n2066:  :global([data-theme]) .cell.name {\n2073:  :global([data-theme]) .cell.path {\n2078:  :global([data-theme]) .cell.size {\n2082:  :global([data-theme]) .cell.modified {\n2088:  :global([data-theme]) .row.selected {\n2092:  /* Dim path/size/date cells in themed mode */\n2093:  :global([data-theme]) .cell.path,\n2094:  :global([data-theme]) .cell.size,\n2095:  :global([data-theme]) .cell.modified {\n2100:    background: transparent;\n2103:  :global(html, body) {\n2108:    background: transparent;\n2132:    background: var(--surface-header);\n2185:    background: transparent;\n2193:    background: var(--row-hover);","numLines":60,"appliedLimit":60},"sourceToolAssistantUUID":"35560c70-6d59-4696-abdd-29e023370e2f"}
{"parentUuid":"defc7995-d0a5-4099-b1be-3c0c9a9a8140","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01EtPJL8svMGXqifYyVe8vr4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019YQoxDW3bcejaAxzjLxFVD","name":"Grep","input":{"pattern":"set_native_theme|background_color|window_background","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1250,"cache_creation_input_tokens":1427,"cache_read_input_tokens":36664,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1427},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYtAMrRNfsNjWMzoqj","type":"assistant","uuid":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5","timestamp":"2026-02-22T09:29:37.229Z"}
{"parentUuid":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_019YQoxDW3bcejaAxzjLxFVD","toolUseID":"toolu_019YQoxDW3bcejaAxzjLxFVD","timestamp":"2026-02-22T09:29:37.900Z","uuid":"3c34ff4b-3a45-4ff8-9f37-b20235f11ac4"}
{"parentUuid":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019YQoxDW3bcejaAxzjLxFVD","type":"tool_result","content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n5068:        let _ = window.set_background_color(Some(bg));\n5082:        let _ = window.set_background_color(Some(bg));\n5389:            set_native_theme,"}]},"uuid":"0468735c-82c4-4dce-9e8e-b29415a91bd5","timestamp":"2026-02-22T09:29:37.899Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n5068:        let _ = window.set_background_color(Some(bg));\n5082:        let _ = window.set_background_color(Some(bg));\n5389:            set_native_theme,","numLines":4},"sourceToolAssistantUUID":"ef3b8697-d8c5-45cd-a903-7fac3b9d3ac5"}
{"parentUuid":"0468735c-82c4-4dce-9e8e-b29415a91bd5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01EtPJL8svMGXqifYyVe8vr4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte","offset":1900,"limit":120},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1250,"cache_creation_input_tokens":1427,"cache_read_input_tokens":36664,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1427},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsYtAMrRNfsNjWMzoqj","type":"assistant","uuid":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a","timestamp":"2026-02-22T09:29:38.118Z"}
{"parentUuid":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","toolUseID":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","timestamp":"2026-02-22T09:29:38.126Z","uuid":"538696e4-33b3-4150-9cab-7a0c01899e58"}
{"parentUuid":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HyUdJxnZhC8PpuiEKQtVhv","type":"tool_result","content":"  1900→\n  1901→  {#if toast}\n  1902→    <div class=\"toast\">{toast}</div>\n  1903→  {/if}\n  1904→</div>\n  1905→\n  1906→<style>\n  1907→  :global(:root) {\n  1908→    color-scheme: light dark;\n  1909→    --bg-app: transparent;\n  1910→    --text-primary: #0d1826;\n  1911→    --text-muted: #48596c;\n  1912→    --bar-grad-top: rgba(255, 255, 255, 0.48);\n  1913→    --bar-grad-bottom: rgba(248, 250, 253, 0.42);\n  1914→    --surface-header: rgba(252, 252, 255, 0.40);\n  1915→    --surface: rgba(255, 255, 255, 0.22);\n  1916→    --border-soft: rgba(0, 0, 0, 0.07);\n  1917→    --border-input: rgba(0, 0, 0, 0.13);\n  1918→    --focus-ring: #6f96e6;\n  1919→    --row-border: rgba(0, 0, 0, 0.032);\n  1920→    --row-hover: rgba(0, 0, 0, 0.06);\n  1921→    --row-selected: rgba(0, 0, 0, 0.12);\n  1922→    --button-bg: rgba(255, 255, 255, 0.62);\n  1923→    --button-border: rgba(0, 0, 0, 0.10);\n  1924→    --button-text: #2c3e50;\n  1925→    --menu-bg: rgba(240, 241, 248, 0.90);\n  1926→    --menu-border: rgba(0, 0, 0, 0.06);\n  1927→    --menu-hover: rgba(255, 255, 255, 0.62);\n  1928→    --menu-text: #1a2a38;\n  1929→    --error-text: #b64545;\n  1930→    --warning-text: #8f6500;\n  1931→    --toast-bg: rgba(18, 22, 32, 0.90);\n  1932→    --toast-text: #ffffff;\n  1933→  }\n  1934→\n  1935→  @media (prefers-color-scheme: dark) {\n  1936→    :global(:root) {\n  1937→      --bg-app: transparent;\n  1938→      --text-primary: #e6e6ea;\n  1939→      --text-muted: #9494a4;\n  1940→      --bar-grad-top: rgba(38, 38, 46, 0.52);\n  1941→      --bar-grad-bottom: rgba(30, 30, 38, 0.46);\n  1942→      --surface-header: rgba(32, 32, 40, 0.46);\n  1943→      --surface: rgba(18, 18, 26, 0.32);\n  1944→      --border-soft: rgba(255, 255, 255, 0.065);\n  1945→      --border-input: rgba(255, 255, 255, 0.14);\n  1946→      --focus-ring: #5b8bd9;\n  1947→      --row-border: rgba(255, 255, 255, 0.026);\n  1948→      --row-hover: rgba(255, 255, 255, 0.08);\n  1949→      --row-selected: rgba(255, 255, 255, 0.14);\n  1950→      --button-bg: rgba(255, 255, 255, 0.072);\n  1951→      --button-border: rgba(255, 255, 255, 0.11);\n  1952→      --button-text: #d6d6e0;\n  1953→      --menu-bg: rgba(36, 36, 46, 0.90);\n  1954→      --menu-border: rgba(255, 255, 255, 0.066);\n  1955→      --menu-hover: rgba(255, 255, 255, 0.062);\n  1956→      --menu-text: #e0e0e8;\n  1957→      --error-text: #ff9d9d;\n  1958→      --warning-text: #e0c670;\n  1959→      --toast-bg: rgba(10, 10, 16, 0.93);\n  1960→      --toast-text: #f2f2f6;\n  1961→    }\n  1962→  }\n  1963→\n  1964→  /* Theme: Dark */\n  1965→  :global([data-theme=\"dark\"]) {\n  1966→    color-scheme: dark;\n  1967→    --bg-app: #1E1E21;\n  1968→    --text-primary: #B8BDC5;\n  1969→    --text-muted: #94A3B8;\n  1970→    --bar-grad-top: #1E1E21;\n  1971→    --bar-grad-bottom: #1E1E21;\n  1972→    --surface-header: #1E1E21;\n  1973→    --surface: #1E1E21;\n  1974→    --bg-input: #161618;\n  1975→    --border-soft: #2A2A2D;\n  1976→    --border-input: rgba(255, 255, 255, 0.06);\n  1977→    --focus-ring: #4DA8FF;\n  1978→    --accent: #4DA8FF;\n  1979→    --row-border: rgba(255, 255, 255, 0.02);\n  1980→    --row-hover: #282828;\n  1981→    --row-selected: rgba(77, 168, 255, 0.10);\n  1982→    --button-bg: rgba(255, 255, 255, 0.05);\n  1983→    --button-border: #2A2A2D;\n  1984→    --button-text: #94A3B8;\n  1985→    --menu-bg: #252528;\n  1986→    --menu-border: #2A2A2D;\n  1987→    --menu-hover: rgba(255, 255, 255, 0.04);\n  1988→    --menu-text: #E2E8F0;\n  1989→    --error-text: #ff9d9d;\n  1990→    --warning-text: #e0c670;\n  1991→    --toast-bg: rgba(10, 10, 16, 0.93);\n  1992→    --toast-text: #f2f2f6;\n  1993→  }\n  1994→\n  1995→  /* Theme: Light */\n  1996→  :global([data-theme=\"light\"]) {\n  1997→    color-scheme: light;\n  1998→    --bg-app: #F5F5F7;\n  1999→    --text-primary: #1C1C1E;\n  2000→    --text-muted: #6E6E7A;\n  2001→    --bar-grad-top: #F5F5F7;\n  2002→    --bar-grad-bottom: #F5F5F7;\n  2003→    --surface-header: #F5F5F7;\n  2004→    --surface: #F5F5F7;\n  2005→    --bg-input: #FFFFFF;\n  2006→    --border-soft: #D1D1D6;\n  2007→    --border-input: rgba(0, 0, 0, 0.10);\n  2008→    --focus-ring: #3A8BF5;\n  2009→    --accent: #3A8BF5;\n  2010→    --row-border: rgba(0, 0, 0, 0.04);\n  2011→    --row-hover: rgba(0, 0, 0, 0.04);\n  2012→    --row-selected: rgba(58, 139, 245, 0.10);\n  2013→    --button-bg: #FFFFFF;\n  2014→    --button-border: #D1D1D6;\n  2015→    --button-text: #3C3C43;\n  2016→    --menu-bg: #FFFFFF;\n  2017→    --menu-border: #D1D1D6;\n  2018→    --menu-hover: rgba(0, 0, 0, 0.05);\n  2019→    --menu-text: #1C1C1E;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d955d1bf-a95f-47da-8ac2-a009a2a0334c","timestamp":"2026-02-22T09:29:38.125Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src/App.svelte","content":"\n  {#if toast}\n    <div class=\"toast\">{toast}</div>\n  {/if}\n</div>\n\n<style>\n  :global(:root) {\n    color-scheme: light dark;\n    --bg-app: transparent;\n    --text-primary: #0d1826;\n    --text-muted: #48596c;\n    --bar-grad-top: rgba(255, 255, 255, 0.48);\n    --bar-grad-bottom: rgba(248, 250, 253, 0.42);\n    --surface-header: rgba(252, 252, 255, 0.40);\n    --surface: rgba(255, 255, 255, 0.22);\n    --border-soft: rgba(0, 0, 0, 0.07);\n    --border-input: rgba(0, 0, 0, 0.13);\n    --focus-ring: #6f96e6;\n    --row-border: rgba(0, 0, 0, 0.032);\n    --row-hover: rgba(0, 0, 0, 0.06);\n    --row-selected: rgba(0, 0, 0, 0.12);\n    --button-bg: rgba(255, 255, 255, 0.62);\n    --button-border: rgba(0, 0, 0, 0.10);\n    --button-text: #2c3e50;\n    --menu-bg: rgba(240, 241, 248, 0.90);\n    --menu-border: rgba(0, 0, 0, 0.06);\n    --menu-hover: rgba(255, 255, 255, 0.62);\n    --menu-text: #1a2a38;\n    --error-text: #b64545;\n    --warning-text: #8f6500;\n    --toast-bg: rgba(18, 22, 32, 0.90);\n    --toast-text: #ffffff;\n  }\n\n  @media (prefers-color-scheme: dark) {\n    :global(:root) {\n      --bg-app: transparent;\n      --text-primary: #e6e6ea;\n      --text-muted: #9494a4;\n      --bar-grad-top: rgba(38, 38, 46, 0.52);\n      --bar-grad-bottom: rgba(30, 30, 38, 0.46);\n      --surface-header: rgba(32, 32, 40, 0.46);\n      --surface: rgba(18, 18, 26, 0.32);\n      --border-soft: rgba(255, 255, 255, 0.065);\n      --border-input: rgba(255, 255, 255, 0.14);\n      --focus-ring: #5b8bd9;\n      --row-border: rgba(255, 255, 255, 0.026);\n      --row-hover: rgba(255, 255, 255, 0.08);\n      --row-selected: rgba(255, 255, 255, 0.14);\n      --button-bg: rgba(255, 255, 255, 0.072);\n      --button-border: rgba(255, 255, 255, 0.11);\n      --button-text: #d6d6e0;\n      --menu-bg: rgba(36, 36, 46, 0.90);\n      --menu-border: rgba(255, 255, 255, 0.066);\n      --menu-hover: rgba(255, 255, 255, 0.062);\n      --menu-text: #e0e0e8;\n      --error-text: #ff9d9d;\n      --warning-text: #e0c670;\n      --toast-bg: rgba(10, 10, 16, 0.93);\n      --toast-text: #f2f2f6;\n    }\n  }\n\n  /* Theme: Dark */\n  :global([data-theme=\"dark\"]) {\n    color-scheme: dark;\n    --bg-app: #1E1E21;\n    --text-primary: #B8BDC5;\n    --text-muted: #94A3B8;\n    --bar-grad-top: #1E1E21;\n    --bar-grad-bottom: #1E1E21;\n    --surface-header: #1E1E21;\n    --surface: #1E1E21;\n    --bg-input: #161618;\n    --border-soft: #2A2A2D;\n    --border-input: rgba(255, 255, 255, 0.06);\n    --focus-ring: #4DA8FF;\n    --accent: #4DA8FF;\n    --row-border: rgba(255, 255, 255, 0.02);\n    --row-hover: #282828;\n    --row-selected: rgba(77, 168, 255, 0.10);\n    --button-bg: rgba(255, 255, 255, 0.05);\n    --button-border: #2A2A2D;\n    --button-text: #94A3B8;\n    --menu-bg: #252528;\n    --menu-border: #2A2A2D;\n    --menu-hover: rgba(255, 255, 255, 0.04);\n    --menu-text: #E2E8F0;\n    --error-text: #ff9d9d;\n    --warning-text: #e0c670;\n    --toast-bg: rgba(10, 10, 16, 0.93);\n    --toast-text: #f2f2f6;\n  }\n\n  /* Theme: Light */\n  :global([data-theme=\"light\"]) {\n    color-scheme: light;\n    --bg-app: #F5F5F7;\n    --text-primary: #1C1C1E;\n    --text-muted: #6E6E7A;\n    --bar-grad-top: #F5F5F7;\n    --bar-grad-bottom: #F5F5F7;\n    --surface-header: #F5F5F7;\n    --surface: #F5F5F7;\n    --bg-input: #FFFFFF;\n    --border-soft: #D1D1D6;\n    --border-input: rgba(0, 0, 0, 0.10);\n    --focus-ring: #3A8BF5;\n    --accent: #3A8BF5;\n    --row-border: rgba(0, 0, 0, 0.04);\n    --row-hover: rgba(0, 0, 0, 0.04);\n    --row-selected: rgba(58, 139, 245, 0.10);\n    --button-bg: #FFFFFF;\n    --button-border: #D1D1D6;\n    --button-text: #3C3C43;\n    --menu-bg: #FFFFFF;\n    --menu-border: #D1D1D6;\n    --menu-hover: rgba(0, 0, 0, 0.05);\n    --menu-text: #1C1C1E;","numLines":120,"startLine":1900,"totalLines":2738}},"sourceToolAssistantUUID":"29c79f3c-e1ad-489d-b20c-4ce3baa9155a"}
{"parentUuid":"d955d1bf-a95f-47da-8ac2-a009a2a0334c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Tr7kHTbK3JdCNfYeoHJrTq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":4650,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3975,"cache_read_input_tokens":38091,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3975},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZBwgpwH6AWKoETPiD","type":"assistant","uuid":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba","timestamp":"2026-02-22T09:29:40.673Z"}
{"parentUuid":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","toolUseID":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","timestamp":"2026-02-22T09:29:40.699Z","uuid":"3a098788-20e2-4ae3-a464-b7e9a6b8012a"}
{"parentUuid":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Lz6rQJYXrh54yjZ7iagWm2","type":"tool_result","content":"  4650→    .await\n  4651→    .map_err(|e| e.to_string())?\n  4652→}\n  4653→\n  4654→#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n  4655→#[tauri::command]\n  4656→async fn show_context_menu(\n  4657→    _paths: Vec<String>,\n  4658→    _x: f64,\n  4659→    _y: f64,\n  4660→    _single_selection: bool,\n  4661→    _app: AppHandle,\n  4662→) -> AppResult<()> {\n  4663→    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n  4664→}\n  4665→\n  4666→#[tauri::command]\n  4667→async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n  4668→    let window = app\n  4669→        .get_webview_window(\"main\")\n  4670→        .ok_or_else(|| \"Main window not found\".to_string())?;\n  4671→    let t = if theme == \"light\" {\n  4672→        tauri::Theme::Light\n  4673→    } else {\n  4674→        tauri::Theme::Dark\n  4675→    };\n  4676→    window.set_theme(Some(t)).map_err(|e| e.to_string())\n  4677→}\n  4678→\n  4679→#[tauri::command]\n  4680→async fn get_file_icon(\n  4681→    path: Option<String>,\n  4682→    ext: String,\n  4683→    state: State<'_, AppState>,\n  4684→) -> AppResult<Vec<u8>> {\n  4685→    let state = state.inner().clone();\n  4686→    Ok(tauri::async_runtime::spawn_blocking(move || {\n  4687→        let ext_lower = if ext.trim().is_empty() {\n  4688→            \"__default__\".to_string()\n  4689→        } else {\n  4690→            ext.to_lowercase()\n  4691→        };\n  4692→\n  4693→        #[cfg(target_os = \"windows\")]\n  4694→        let cache_key = {\n  4695→            if is_per_file_icon_ext(&ext_lower) {\n  4696→                path.as_deref().unwrap_or(&ext_lower).to_string()\n  4697→            } else {\n  4698→                ext_lower.clone()\n  4699→            }\n  4700→        };\n  4701→        #[cfg(not(target_os = \"windows\"))]\n  4702→        let cache_key = ext_lower.clone();\n  4703→\n  4704→        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n  4705→            return cached;\n  4706→        }\n  4707→\n  4708→        #[cfg(target_os = \"windows\")]\n  4709→        let icon = {\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"cefc6ea9-5ed8-49e5-95da-d6e87e6314fc","timestamp":"2026-02-22T09:29:40.696Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {","numLines":60,"startLine":4650,"totalLines":5880}},"sourceToolAssistantUUID":"8bfe943f-85be-448c-8ab1-f49a42e9d6ba"}
{"parentUuid":"cefc6ea9-5ed8-49e5-95da-d6e87e6314fc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Tr7kHTbK3JdCNfYeoHJrTq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LP4AYdW9tSLrciZetrFgho","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":5055,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3975,"cache_read_input_tokens":38091,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3975},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZBwgpwH6AWKoETPiD","type":"assistant","uuid":"78838d6e-ed24-4bf1-9e53-21a81123ab1d","timestamp":"2026-02-22T09:29:41.385Z"}
{"parentUuid":"78838d6e-ed24-4bf1-9e53-21a81123ab1d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01LP4AYdW9tSLrciZetrFgho","toolUseID":"toolu_01LP4AYdW9tSLrciZetrFgho","timestamp":"2026-02-22T09:29:41.400Z","uuid":"c1b23085-69be-4c51-a978-1ac8c3c015f3"}
{"parentUuid":"78838d6e-ed24-4bf1-9e53-21a81123ab1d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LP4AYdW9tSLrciZetrFgho","type":"tool_result","content":"  5055→\n  5056→    #[cfg(target_os = \"macos\")]\n  5057→    if let Some(window) = app.get_webview_window(\"main\") {\n  5058→        use tauri::window::Color;\n  5059→        let is_dark = window\n  5060→            .theme()\n  5061→            .map(|t| t == tauri::Theme::Dark)\n  5062→            .unwrap_or(false);\n  5063→        let bg = if is_dark {\n  5064→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5065→        } else {\n  5066→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5067→        };\n  5068→        let _ = window.set_background_color(Some(bg));\n  5069→        let _ = window.show();\n  5070→    }\n  5071→\n  5072→    #[cfg(target_os = \"windows\")]\n  5073→    if let Some(window) = app.get_webview_window(\"main\") {\n  5074→        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n  5075→        use tauri::window::Color;\n  5076→        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n  5077→        let bg = if is_dark {\n  5078→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5079→        } else {\n  5080→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5081→        };\n  5082→        let _ = window.set_background_color(Some(bg));\n  5083→        if let Err(e) = window.set_decorations(false) {\n  5084→            eprintln!(\n  5085→                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n  5086→                startup_elapsed_ms(),\n  5087→                e\n  5088→            );\n  5089→        }\n  5090→        let _ = window.show();\n  5091→        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n  5092→    }\n  5093→\n  5094→    let app_data_dir = app\n  5095→        .path()\n  5096→        .app_data_dir()\n  5097→        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n  5098→    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n  5099→\n  5100→    let db_path = app_data_dir.join(\"index.db\");\n  5101→    let home_dir = PathBuf::from(\n  5102→        std::env::var(\"HOME\")\n  5103→            .or_else(|_| std::env::var(\"USERPROFILE\"))\n  5104→            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ea584d30-9f4f-41db-964c-867a78dc9d14","timestamp":"2026-02-22T09:29:41.399Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),","numLines":50,"startLine":5055,"totalLines":5880}},"sourceToolAssistantUUID":"78838d6e-ed24-4bf1-9e53-21a81123ab1d"}
{"parentUuid":"ea584d30-9f4f-41db-964c-867a78dc9d14","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Si14DYjXLezbfNa8tjiTu2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the issue. Let me analyze what's happening:\n\n1. System dark theme → user switches to light theme in the app (via `cycleTheme()`)\n2. `cycleTheme()` calls `invoke('set_native_theme', { theme })` which calls the Rust `set_native_theme` command\n3. `set_native_theme` only calls `window.set_theme(Some(t))` - it does NOT update the window background color\n4. At app startup, `set_background_color` is called based on the system theme to avoid flash\n5. But when the user manually switches theme, `set_background_color` is never updated\n\n\n6. When the window is maximized/fullscreen via title bar double-click, the OS shows the native window background during the animation, and since it's still set to dark (from startup), it flashes against the new light theme\n\nThe solution is to update `set_native_theme` to also call `window.set_background_color()` with the appropriate color for the new theme.\n\nUpdating the Rust command... I need to use the CSS color values for consistency since there's a mismatch between what the startup code sets and what the user preference system should use. The real issue is that the startup only respects the system theme, so if a user's stored preference differs from their system theme, the background color won't update when they switch themes through the app.\n\nLooking at how the frontend initializes, it reads the stored theme preference from localStorage and calls `set_native_theme` on mount to sync with the native window, but since that function doesn't update the background color, there's a disconnect between what the native window shows and what the frontend displays.\n\nThe fix is straightforward: I need to update `set_native_theme` to also set the background color when the theme changes, so both the initial sync and any subsequent theme switches will keep everything in sync.","signature":"EocfCkYICxgCKkA0wTtxMuSfIdxKduWadwWgoE+CLATh5FWKAoehWJ08mX+zVb+mwcv/HA7omGIbTnz3JzyqNREtFE4PakYpzA2XEgyQCVlE6+DWJ1rdT60aDFlCN1pi1TG48TVjbyIwG8N5Gm2IJyQwJ+p83H/oLEtiKl0a6VQoP5LvRpCxQqyZag6NZgiJjn8V9mTCmpJfKu4di/kz7KQYaLZBb64YyayVTnwK6u7Bu6KO/ZSYU647uE4M8P7bUE6tBe1JBJ1MbiyFujENhNazbLcNPyVt/qNLEx4saLuw/MCPEOruHjF5sdZ4CRSjWGZJHDuOtL45z4//zsNWEyIFrQ6LH2Fog7LlTOZDmoiHBj0Y9GCgzHaBWX8uYnvWJMl8zCLqJx/6XcWqGqonvZdI1Sb3mxenvmw2mq2CAmnvvxFI526Bj+N3DprSpty2An0Ts/CVecQ7U/4yJHkw7aCg+8xFUAzMtPY32H4SUQdrCODp4BSKKY/sdbJzgzuH0PhcGBP4pOvx02WvIcaYcPToGplo7fIoq4AdT6QEBoat6mZmYIBKBBuyD9ZSo1bWkUzFO5tVDSw16SZ64G7t3xQXVTh7kIes9/4q1ZB7Cz970j4VxQjpsDiOM000bXO/Eu5jSEo6b1agPJDDN2hXLGZSBBevjCd/vmoqMbqrEJ+H2F6jUk1HaEI7BDVlZzgPSVb3GihzGTPtUSG7AljzUAEBV8be6tB+6F/rVSJ+nT5+hHuaElHQvl3mdANH06IYjgFAuE6YmuiV9JtscRNEr4O1hMGNisNTx0vbCXQrjTyYMNblpYpUAYRSrELzKM3SQsRyeejmSPFhe4KZt0y3Dl6NZuie7JtHHvKG0djD4mFtNTWF5WeTw2cLD859x7jT+PAqOf3rtRO6fQzoh1AkmUtJc9t3VrCyHhHZQE3HocYW9YPidmbsWDEAM6TZTjXp8MOZU6SVQcnIDb/idebWAHECQ4okImWJ5vAOf/TJ29NLPPBPS25rYujAEC4hTUlKhpRJESaDU0iAgyox6cOIII4S4Ql6ezz2NYT1EgYv4/FEL1k/kpAG8t6Nr0amzPUscKOcFGDQpkp8nRZ3U2xIitrbDdf1kmC7ipqOZ4D/Yn+ec+aSidkG6nE40R5XtWmbC5YqsxQxmWV8pPMEIDIEryiazOFy3wjYkgqlOxwqJKf+Cs69NuOJNi5ACKXx42fvLA2a0xpu6+d1DU4QICrSorJ81K5IBYAOMzlzO2gAPJmeg/P0MDki9ZpbnrTjNY076zMEPUyCUYV8aBqL6xaBoAeHm1ew6azYFRfPfmq9ArEXZl7ZMFkReKr1OI72e2woQUVTNbycv5JjxiTT5NH5w1eYZtOFH5w2zrn6NPseIJy2bX4A0hkE/pUzJzXBXwEXS5CFdq8dyaGq6F9QG7s82p4264xCTS1uatXoKInTRcTflGs8N63QDd32MdfHuVwy7qLh0gKsUK9vRntgBUPPIY3Lm7qCi/E+NpSxgsnxOIm64g1qF1V/eSW89vzJHsm7SOPqGcMDdDb6/tc/gn3LPgoGEro5bR2oqvWYLF2V1dJwY+yD+RFy43cWEAll3e5yayJqOpbRWJt3fVTyLEDBHBOfFNqMw4ipTqcWb2XXr/v5U5VHKoc7332ElfFm5djIiuWormwznZQTEiGJPQ/Ll67ODxnnbUbWCK6bjPafRqvNKXCmi4+Rn0JEKvryMeQm5UO+DueQN+tc8pnwHgZD7FK0fyX2uaEyrN+mvqCvRjoVDSLSNnLvzGh0tvLQeA31ducC3ndXH9HjXdDNDB1C/EIYuJKbWjBNTsvcC0QhOeoqOO3Y39K8XswzJJE5RBbtQLigyt0n1i+e0k2Bim161yaP5+7HJbo5r0Tk4ix/JeKd3MUaobCbc3kBChjVw9zP5g4Jqph/66CRT0UbjtZYPlmjPx1xfEWA1JytYPpm4tYriUnK4icSfTT2rp+XxA3QIhIl6wZdWL9moLmpFWwWlVaHwGaMkxGY51U5pQNoy+2LDR7SQYgW/IOHAL5nnsMq2Yt3xWnfZ0pX7OFvvq9O717EVB/gWAmiXyDTcgSjepw9AQH+GsTq77YEu2zSn5BXX4D+r3dHV2vc2503IVUNW27xX1D25I1eG4aAZG80D8GzvbzG/LunjmbYt6AIvn6u9Q73iNLpYOCoU1ZC/mJC8X5NpaX2WWHTiFdCqtVWypTU1LsFfpY7Kq9hLkCB4EubpjbazTN2unJlr6hFwoX+QySssWZahr8jNWRgRBWArqlgJB3tMJlPCGdHOYslwMGMTevgRStRARs/pGs+hdle0Iq3u8FPpwilhXdOzquM3HUco+M9A01kHtT3fqT5r/tOKi6HmRjEDfNRzOhGej4U1f0jryIEaZqkMLR2F2fKnPQ9AKZge35+Bo+LJJ5L5g5vMh03+zIVGN9H4U0g8wYiwu2lUB+BBQA+AbeXm/pphZD5nqwTq/Lq/PmCZZ5ef/ud3ajDs9xIIKb2zqq2qt/33RfaDjMnMK/zioyZ1EKyEYpnwAm9TlE8Zj9niqfg4G8eF2C5OaRo1VqCOioU/j6L/4XcHFhN8PRVMnrx5iMLEbps6stQUfn/14M5b2fwRL7MPVHDL/5c1lEOYbJnRj0ailcs8fzz4916Vm8kbDjBQtKjLDZ5fwDFQ0CkSGdPgMIUwwoJ9fgbGRYppy82aRMmENTiLkHdCOCWyctRxVA3qanE9h9jdbGKMPfOahlT7JmEeHc2zj5AiHzWEDjUupozgnlvIY9FMX4EjtqC2QpAKhXbaCQ3JbNtlZsyV5QubZZMIqqB0Ht0BUJa/VfzBWjBv1TV+dsI26qc8lCYJXljWqubN4qBbGDdLrCfns+FwzgIf498r1jw6Ahe2jAOzpR/SUDCCMM5n5bq6y3pyZQ69qP5WtDiUVky0g25Py8k/Oyq8phOSwLLgy/Hdw0syNJWDKVSxKcOGVU2E3xAwBZaNaoV5nJXWPBWY/VhWRbRjArZxjp2SM1xwvafgWWNRK/eN/PFPJtohOXcB5jhdKqPOqHr13MK5JslMvs+EmsbHWHXNbDHHZlBtCrjv8T5l1t2dDsp5cWWFP4B08/IfGhLIQz3bdJYbLZmcMDA+8zKWM1RrOGL1fayPxWirgpdzQEtuhPgnf4KxTF131KVuJfNptAl8fB3ETFSkaOAqwOY5ppwIbOMtKucT7AYTOxNX0HfdibLqOMrBKMOOPuYzZPAlklM5WlUadqY7vZ9voNHcVFAvK6HPb/s6Ih37NvzahEZeF4Wz5PxJ3WyXosGlC/8Zol4cH+eC77BeBN0ygDUtObMaReUFFIlf9q/kWuDV342ZAEINehHh9az/TM/OvNWq6sBxM40X3/IHHRao7ZL5aqNEhdeWMLAtHZgD7dVQq1bJb/VqlH0kbvOBWaZsH78KUX9gAsKny/yxWN3OiJEHz6luFuGb59Jo2oq8s/VHxjt2Ssam6txBRWUeU3TgekBV6hLLhRk+Q1MCPjoDUIOdGVthy08bwd5UzYYfN2FiTXeY8tIHtONHD0gVsAqOl/UhFR4LmhHHZjDmkIrvuSieu6z4GFXX5z5gYB/eehJN9FYBv7V33K/8kh90xo33v+NHu8WfJOMmzVQPhLr2wwSe+f7SrO+wbWTUadT+3tTasmbT+Qw2C+3VgUyQCe0jcJADC2Ig6CMrdZUwyDMQ3TX0eKh2JxgU+jVdLIzTGzQ8n0ph25rFNSpHXob7rl707BaiY13wavU/+GROJbDkQiCLppduOwnxSWwZ/APWK1mLhFIFewd/+UYTyJ5QlBIflvDMWbH0789RfSFSGrE9n8CZD1ZCi8zNeptX7KBZhYGahCxHCXaL4zFvfBDFXsGheeUoRPKKB1mP4Ge+uNySp0IBxCZly5vypn1xMoAMEQ/OME21WyQHrD4BMA8IBGwYOQw34osW5q5zaqXvTbI/QLjRMSikBwTIeNR3i5HVmQtoLrqas21PbOPGR33PX8fS+H1WwnsDkebHOYDWPb3DCLdAa0njdFRWWLJPyCXWjPryKgKAj79uS33CEGPdV8vLoJIdXdWOslxRapoekCAc/7UWx2SbTThxlarH1exCqA65vSUL0vhgpL5ZLatlVa4JXDvEuddjKPQCEd+5JWi4l8a5V1XxIWsA4Az8CkFPahzGPXepmMjMb26x/d00UUnuiB9lEOj4DayRYFx0VknAg64XoXWdPrIpBcgfB7ISmRAENT8f86Qlqrh9Zv9MyNGodSxAL1f18Jcr7TqsG0oIif/4FMew/7rVcbGYuUiAbtTX4P+EntKHUfZH3WHOhjVfQc+lmRQMAity3rrovcSMWQBbvN8JS2S4s/H2ifjv4pjIJDTOMjcU2NIOunMyQh+30y3s8zKthPegxC8NMvHxk7uFiZG94+AxMVfBBhZDmdc380gtjEIGsROy7HiRi1ixqKOfwWW4JSOu2mSjv43uW3gPw+OM/3JnpbW/h/14gCPyXeEmE6rCmesYRRxNOpGtZc6h61w0M7FvQ7d71ARdZMFticWtArmZWIwR0xhJPFO7cpg496ZHR1rrNc8duHCj5dHB6PPCX4xnuajHglJgZuqblwgCod7tKKNuWko1zb7h+g93ey73jbnl/Nj/+Bc3RJUIkzL6edmWgrwRNNLSALR20f+bZp5/0RtO6SwdpnY4skI8mtQUIq0G4UCAW6D6mJJbaQLYFq0jf4+f63xCHeFn3Vg/gxADohpmhJPo+pEdkFov44Xe+oSss64dTJwwkWzJddocfS7TVivrJRz85cxp26fMV1TArQ9cLJzRmQoWc5shHr9OFwBMBdiSz4MI3p0H+/4OY6yzm6GMExAmdzWDi1RLXx5ZGHwvTynodqLMeuTX/UMQO2nu+8Oo75CuM5TbvsADPk6Ni6iRTaq4JcWwM7ap31hde70pEMvGpoJ5YWtJdI9lAjBycBC3mp9+lb1TPbXBdYd0v0aNUUM0QXPnT/kGvXpgcPVF6F/7XVcIAL0AcpkchdosBvJtHaRIFRLGkGNZ0L49tUBhuKU6v7AbpmvAsWE/MH0/j5KICokAd30VtUktWiZaXzLZmP+forrGFPBc93Ylz6mFHkO+Sg6dN8byjiI/yzFPMsnZucDM6cPi5VWu9YUtZ3xyf0/v0O6Mi7tEpeEWQ9MSBFEFDjdVmRKRvoIINJAnxkEDXCXdHbUhLiMuPW8dZO3V28yUMffYE+F4boGURFr3ybJmSWwgl5JSblBaerybjViBy8JwNDje5fDL6wr87zFLtHei94dOlsD60sv9GlGw/n/GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2190,"cache_read_input_tokens":42066,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2190},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZS1HBD1hy9yt4j51h","type":"assistant","uuid":"0e501162-31d4-42a8-a07a-b7a7cbe0f93f","timestamp":"2026-02-22T09:30:01.387Z"}
{"parentUuid":"0e501162-31d4-42a8-a07a-b7a7cbe0f93f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01Si14DYjXLezbfNa8tjiTu2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","name":"Read","input":{"file_path":"/Users/al02402336/everything/src/App.svelte","offset":1440,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2190,"cache_read_input_tokens":42066,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2190},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsZS1HBD1hy9yt4j51h","type":"assistant","uuid":"9d8b88d8-0218-4067-ba50-8fde16214449","timestamp":"2026-02-22T09:30:01.724Z"}
{"parentUuid":"9d8b88d8-0218-4067-ba50-8fde16214449","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","toolUseID":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","timestamp":"2026-02-22T09:30:01.735Z","uuid":"7cc3afb1-18a1-4010-8e52-9c2bf6b8c46c"}
{"parentUuid":"9d8b88d8-0218-4067-ba50-8fde16214449","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UrPaCJ7AoR7a6HFvw8EmBW","type":"tool_result","content":"  1440→          `[startup/fe] +${ms()}ms ${name} failed (${Math.round(performance.now() - startedAt)}ms): ${String(err)}`\n  1441→        );\n  1442→        throw err;\n  1443→      }\n  1444→    };\n  1445→\n  1446→    startupLog('[startup/fe] onMount entered');\n  1447→    try {\n  1448→\n  1449→    updateViewportHeight();\n  1450→    startupLog(`[startup/fe] +${ms()}ms updateViewportHeight done`);\n  1451→\n  1452→    invoke('set_native_theme', { theme });\n  1453→\n  1454→    platform = await step('invoke(get_platform)', () => invoke('get_platform'));\n  1455→\n  1456→    let unlistenResized = null;\n  1457→    if (platform === 'windows') {\n  1458→      try {\n  1459→        isMaximized = await appWindow.isMaximized().catch(() => false);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1936f7b4-39db-4e43-976c-1d4b212eb925","timestamp":"2026-02-22T09:30:01.734Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src/App.svelte","content":"          `[startup/fe] +${ms()}ms ${name} failed (${Math.round(performance.now() - startedAt)}ms): ${String(err)}`\n        );\n        throw err;\n      }\n    };\n\n    startupLog('[startup/fe] onMount entered');\n    try {\n\n    updateViewportHeight();\n    startupLog(`[startup/fe] +${ms()}ms updateViewportHeight done`);\n\n    invoke('set_native_theme', { theme });\n\n    platform = await step('invoke(get_platform)', () => invoke('get_platform'));\n\n    let unlistenResized = null;\n    if (platform === 'windows') {\n      try {\n        isMaximized = await appWindow.isMaximized().catch(() => false);","numLines":20,"startLine":1440,"totalLines":2738}},"sourceToolAssistantUUID":"9d8b88d8-0218-4067-ba50-8fde16214449"}
{"parentUuid":"1936f7b4-39db-4e43-976c-1d4b212eb925","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01JdZA1L9b7aQeNMZ5pkCrVu","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I fully understand the issue:\n\n1. App starts with system dark theme\n2. `app.run()` (startup) calls `window.set_background_color(Color(0x1f, 0x1f, 0x1f, 0xff))` — dark background\n3. Frontend loads, reads localStorage and finds \"light\" theme preference\n4. `onMount` calls `invoke('set_native_theme', { theme: 'light' })` which changes window theme to light but does NOT call `set_background_color`\n5. Background color stays dark `0x1f, 0x1f, 0x1f`\n\n\n6. When user double-clicks title bar to fullscreen, the native macOS window expansion animation briefly shows the native background (dark) before the WebView content is drawn in the expanded size\n\nThe fix is to update `set_native_theme` to also call `set_background_color` with the appropriate color for each theme — `0xF5F5F7` for light mode and `0x1E1E21` for dark mode.\n\nI'm noticing the startup code uses slightly different values, but I think it's fine to keep those as-is and just ensure the theme switching uses the exact CSS colors for consistency. Actually, I should check if there's a similar flash issue happening at startup when the background color is first set.\n\nLooking at the sequence: the window gets a background color from the system theme before the frontend loads, then the frontend switches to the user's stored theme preference. There could be a flash there too if they differ, but that seems like expected behavior. The real issue the user is asking about is the title bar double-click problem, which I can fix by making sure `set_native_theme` also updates the background color to keep everything in sync.\n\nLet me implement that fix now.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1540,"cache_read_input_tokens":44256,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1540},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsavofTHtrzi3rHuJ8H","type":"assistant","uuid":"0655f213-dba3-45bc-b289-f9775a297026","timestamp":"2026-02-22T09:30:14.646Z"}
{"parentUuid":"0655f213-dba3-45bc-b289-f9775a297026","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01JdZA1L9b7aQeNMZ5pkCrVu","type":"message","role":"assistant","content":[{"type":"text","text":"원인 파악했습니다.\n\n**문제:**\n- 앱 시작 시 `app.run()`에서 시스템 테마(dark) 기준으로 `set_background_color(dark)`를 설정\n- 프론트엔드가 localStorage의 light 테마를 읽어 `set_native_theme(\"light\")` 호출\n- 그런데 `set_native_theme`은 `window.set_theme()`만 바꾸고 **`set_background_color`는 업데이트하지 않음**\n- 타이틀바 더블클릭 시 macOS 윈도우 확대 애니메이션 중에 네이티브 배경색(dark)이 잠깐 노출\n\n**수정:** `set_native_theme`에서 배경색도 함께 업데이트."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1540,"cache_read_input_tokens":44256,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1540},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsavofTHtrzi3rHuJ8H","type":"assistant","uuid":"2e462383-028c-4c26-aeb7-3030f31ceae7","timestamp":"2026-02-22T09:30:17.187Z"}
{"type":"file-history-snapshot","messageId":"c4c660b8-6144-48f3-8805-337c6c50fdb4","snapshot":{"messageId":"d21bd882-d4b7-4245-8b90-df7cecf1f692","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v1","version":1,"backupTime":"2026-02-22T09:30:20.781Z"}},"timestamp":"2026-02-22T09:29:21.012Z"},"isSnapshotUpdate":true}
{"parentUuid":"2e462383-028c-4c26-aeb7-3030f31ceae7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01JdZA1L9b7aQeNMZ5pkCrVu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}","new_string":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1540,"cache_read_input_tokens":44256,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1540},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsavofTHtrzi3rHuJ8H","type":"assistant","uuid":"c4c660b8-6144-48f3-8805-337c6c50fdb4","timestamp":"2026-02-22T09:30:20.774Z"}
{"parentUuid":"c4c660b8-6144-48f3-8805-337c6c50fdb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","toolUseID":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","timestamp":"2026-02-22T09:30:20.791Z","uuid":"e4f1ea7e-31ea-424b-9023-c9c0777b0be8"}
{"parentUuid":"c4c660b8-6144-48f3-8805-337c6c50fdb4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01S55C1XuL2GM5VP3VQ2yZRb","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"3008c51a-aff4-4a0b-863f-dd660d138e69","timestamp":"2026-02-22T09:30:20.790Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}","newString":"#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\n/// Phase 1: creates tables only. Fast even on large DBs.\nfn init_db_tables(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\n/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n/// when new indexes are added; runs after db_ready so it does not block startup.\nfn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n\n    conn.execute_batch(\n        r#\"\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n\n    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n        // range-scan optimization when an ESCAPE clause is present, causing a full\n        // table scan even though `path` has a UNIQUE (implicit) index.\n        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n        let lo = format!(\"{prefix}/\");\n        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n            params![prefix, lo, hi],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let conn = db_connection(&state.db_path)?;\n    let (entries_count, last_updated) = update_counts(&conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts so next startup can read them instantly\n    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_counts(conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(10),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":4668,"oldLines":12,"newStart":4668,"newLines":21,"lines":["     let window = app","         .get_webview_window(\"main\")","         .ok_or_else(|| \"Main window not found\".to_string())?;","-    let t = if theme == \"light\" {","+    let is_light = theme == \"light\";","+    let t = if is_light {","         tauri::Theme::Light","     } else {","         tauri::Theme::Dark","     };","-    window.set_theme(Some(t)).map_err(|e| e.to_string())","+    window.set_theme(Some(t)).map_err(|e| e.to_string())?;","+    use tauri::window::Color;","+    let bg = if is_light {","+        Color(0xF5, 0xF5, 0xF7, 0xFF)","+    } else {","+        Color(0x1E, 0x1E, 0x21, 0xFF)","+    };","+    let _ = window.set_background_color(Some(bg));","+    Ok(())"," }"," "," #[tauri::command]"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"c4c660b8-6144-48f3-8805-337c6c50fdb4"}
{"parentUuid":"3008c51a-aff4-4a0b-863f-dd660d138e69","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0128KRzFLRs85pzA4FdGQkX8","type":"message","role":"assistant","content":[{"type":"text","text":"이제 startup 코드의 배경색 값도 CSS와 일치시킵니다 (현재 `0x1f, 0x1f, 0x1f` vs CSS `#1E1E21`, `0xf4` vs `0xf5`):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1429,"cache_read_input_tokens":45796,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1429},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNscLH5RcD2f42pM5gLZ","type":"assistant","uuid":"9b6cbbb8-7419-49f2-a9bf-c6f8fa9904e8","timestamp":"2026-02-22T09:30:24.089Z"}
{"parentUuid":"9b6cbbb8-7419-49f2-a9bf-c6f8fa9904e8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0128KRzFLRs85pzA4FdGQkX8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":5056,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1429,"cache_read_input_tokens":45796,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1429},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNscLH5RcD2f42pM5gLZ","type":"assistant","uuid":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad","timestamp":"2026-02-22T09:30:24.751Z"}
{"parentUuid":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","toolUseID":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","timestamp":"2026-02-22T09:30:24.766Z","uuid":"dcb08923-676e-4802-9aa2-219ded61310b"}
{"parentUuid":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JhrBwfKUJYpkSUsM6K1zQE","type":"tool_result","content":"  5056→fn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n  5057→    Ok(())\n  5058→}\n  5059→\n  5060→fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n  5061→    let setup_started = std::time::Instant::now();\n  5062→    eprintln!(\"[startup] setup_app() entered\");\n  5063→    let bench_mode = bench_mode_enabled();\n  5064→\n  5065→    #[cfg(target_os = \"macos\")]\n  5066→    if let Some(window) = app.get_webview_window(\"main\") {\n  5067→        use tauri::window::Color;\n  5068→        let is_dark = window\n  5069→            .theme()\n  5070→            .map(|t| t == tauri::Theme::Dark)\n  5071→            .unwrap_or(false);\n  5072→        let bg = if is_dark {\n  5073→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5074→        } else {\n  5075→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5076→        };\n  5077→        let _ = window.set_background_color(Some(bg));\n  5078→        let _ = window.show();\n  5079→    }\n  5080→\n  5081→    #[cfg(target_os = \"windows\")]\n  5082→    if let Some(window) = app.get_webview_window(\"main\") {\n  5083→        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n  5084→        use tauri::window::Color;\n  5085→        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n  5086→        let bg = if is_dark {\n  5087→            Color(0x1f, 0x1f, 0x1f, 0xff)\n  5088→        } else {\n  5089→            Color(0xf4, 0xf5, 0xf7, 0xff)\n  5090→        };\n  5091→        let _ = window.set_background_color(Some(bg));\n  5092→        if let Err(e) = window.set_decorations(false) {\n  5093→            eprintln!(\n  5094→                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n  5095→                startup_elapsed_ms(),\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d6f21170-884c-4938-b0c1-1e9f6b2ac142","timestamp":"2026-02-22T09:30:24.764Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),","numLines":40,"startLine":5056,"totalLines":5889}},"sourceToolAssistantUUID":"5fc4b2fc-1dce-4f29-8e1d-cb4355f1ecad"}
{"parentUuid":"d6f21170-884c-4938-b0c1-1e9f6b2ac142","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01CpzYp7DGGFgWwfeFNhnEZF","type":"message","role":"assistant","content":[{"type":"text","text":"startup 색상 값도 CSS 값과 일치시켜 일관성을 높입니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":956,"cache_read_input_tokens":47225,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":956},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNscdHGxgaUCW8fSV6k5","type":"assistant","uuid":"6b39aa7e-140e-45d1-a836-7d6bf089ba19","timestamp":"2026-02-22T09:30:26.845Z"}
{"parentUuid":"6b39aa7e-140e-45d1-a836-7d6bf089ba19","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01CpzYp7DGGFgWwfeFNhnEZF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UcHinwxMZf82uTwy7z7jKh","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };","new_string":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":956,"cache_read_input_tokens":47225,"output_tokens":840,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":956,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNscdHGxgaUCW8fSV6k5","type":"assistant","uuid":"794f0db6-0dd0-44a0-b608-7d95f2967b6e","timestamp":"2026-02-22T09:30:32.155Z"}
{"parentUuid":"794f0db6-0dd0-44a0-b608-7d95f2967b6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01UcHinwxMZf82uTwy7z7jKh","toolUseID":"toolu_01UcHinwxMZf82uTwy7z7jKh","timestamp":"2026-02-22T09:30:32.170Z","uuid":"a5aa740a-d671-41ab-9a0f-1939400799e9"}
{"parentUuid":"794f0db6-0dd0-44a0-b608-7d95f2967b6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UcHinwxMZf82uTwy7z7jKh","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"11bcf2e2-0282-4ce5-a092-310124c01166","timestamp":"2026-02-22T09:30:32.168Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };","newString":"    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1E, 0x1E, 0x21, 0xFF)\n        } else {\n            Color(0xF5, 0xF5, 0xF7, 0xFF)\n        };","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 5;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\n/// Phase 1: creates tables only. Fast even on large DBs.\nfn init_db_tables(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\n/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n/// when new indexes are added; runs after db_ready so it does not block startup.\nfn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n\n    conn.execute_batch(\n        r#\"\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n\n    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n        // range-scan optimization when an ESCAPE clause is present, causing a full\n        // table scan even though `path` has a UNIQUE (implicit) index.\n        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n        let lo = format!(\"{prefix}/\");\n        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n            params![prefix, lo, hi],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let conn = db_connection(&state.db_path)?;\n    let (entries_count, last_updated) = update_counts(&conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts so next startup can read them instantly\n    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_counts(conn)?;\n    {\n        let mut status = state.status.lock();\n        status.entries_count = entries_count;\n        status.last_updated = last_updated;\n    }\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(10),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let is_light = theme == \"light\";\n    let t = if is_light {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n    use tauri::window::Color;\n    let bg = if is_light {\n        Color(0xF5, 0xF5, 0xF7, 0xFF)\n    } else {\n        Color(0x1E, 0x1E, 0x21, 0xFF)\n    };\n    let _ = window.set_background_color(Some(bg));\n    Ok(())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db_tables(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n        {\n            let idx_db_path = state.db_path.clone();\n            std::thread::spawn(move || {\n                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n                }\n            });\n        }\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db_tables(&db_path).unwrap();\n        ensure_db_indexes(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":5070,"oldLines":9,"newStart":5070,"newLines":9,"lines":["             .map(|t| t == tauri::Theme::Dark)","             .unwrap_or(false);","         let bg = if is_dark {","-            Color(0x1f, 0x1f, 0x1f, 0xff)","+            Color(0x1E, 0x1E, 0x21, 0xFF)","         } else {","-            Color(0xf4, 0xf5, 0xf7, 0xff)","+            Color(0xF5, 0xF5, 0xF7, 0xFF)","         };","         let _ = window.set_background_color(Some(bg));","         let _ = window.show();"]},{"oldStart":5084,"oldLines":9,"newStart":5084,"newLines":9,"lines":["         use tauri::window::Color;","         let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);","         let bg = if is_dark {","-            Color(0x1f, 0x1f, 0x1f, 0xff)","+            Color(0x1E, 0x1E, 0x21, 0xFF)","         } else {","-            Color(0xf4, 0xf5, 0xf7, 0xff)","+            Color(0xF5, 0xF5, 0xF7, 0xFF)","         };","         let _ = window.set_background_color(Some(bg));","         if let Err(e) = window.set_decorations(false) {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"794f0db6-0dd0-44a0-b608-7d95f2967b6e"}
{"parentUuid":"11bcf2e2-0282-4ce5-a092-310124c01166","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TuAQDnuRHs18C1VEmcLRQz","type":"message","role":"assistant","content":[{"type":"text","text":"변경 내용을 확인합니다:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":897,"cache_read_input_tokens":48181,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsdB1VWVLrTnZ9T8gDP","type":"assistant","uuid":"f61f8998-8e6f-44af-8d2c-0215718949a2","timestamp":"2026-02-22T09:30:34.155Z"}
{"parentUuid":"f61f8998-8e6f-44af-8d2c-0215718949a2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01TuAQDnuRHs18C1VEmcLRQz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HsXewPjEr7dkErMPdH3y25","name":"Grep","input":{"pattern":"set_background_color|set_native_theme|0x1E|0xF5","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","-n":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":897,"cache_read_input_tokens":48181,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsdB1VWVLrTnZ9T8gDP","type":"assistant","uuid":"07e3890c-e830-43f2-8c7c-e61342a1bcc8","timestamp":"2026-02-22T09:30:35.380Z"}
{"parentUuid":"07e3890c-e830-43f2-8c7c-e61342a1bcc8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01HsXewPjEr7dkErMPdH3y25","toolUseID":"toolu_01HsXewPjEr7dkErMPdH3y25","timestamp":"2026-02-22T09:30:36.150Z","uuid":"94bf897e-72dd-42c0-80ce-c4186ecf253b"}
{"parentUuid":"07e3890c-e830-43f2-8c7c-e61342a1bcc8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HsXewPjEr7dkErMPdH3y25","type":"tool_result","content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n4680:        Color(0xF5, 0xF5, 0xF7, 0xFF)\n4682:        Color(0x1E, 0x1E, 0x21, 0xFF)\n4684:    let _ = window.set_background_color(Some(bg));\n5073:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5075:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5077:        let _ = window.set_background_color(Some(bg));\n5087:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5089:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5091:        let _ = window.set_background_color(Some(bg));\n5398:            set_native_theme,"}]},"uuid":"900d4755-6fb2-4c00-8807-b9cdc75e04ca","timestamp":"2026-02-22T09:30:36.149Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"4667:async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n4680:        Color(0xF5, 0xF5, 0xF7, 0xFF)\n4682:        Color(0x1E, 0x1E, 0x21, 0xFF)\n4684:    let _ = window.set_background_color(Some(bg));\n5073:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5075:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5077:        let _ = window.set_background_color(Some(bg));\n5087:            Color(0x1E, 0x1E, 0x21, 0xFF)\n5089:            Color(0xF5, 0xF5, 0xF7, 0xFF)\n5091:        let _ = window.set_background_color(Some(bg));\n5398:            set_native_theme,","numLines":11},"sourceToolAssistantUUID":"07e3890c-e830-43f2-8c7c-e61342a1bcc8"}
{"parentUuid":"900d4755-6fb2-4c00-8807-b9cdc75e04ca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_011mfunRKFuZWvP39JN8EAR3","type":"message","role":"assistant","content":[{"type":"text","text":"정리하면:\n\n**수정 요약:**\n\n| 위치 | 변경 전 | 변경 후 |\n|------|---------|---------|\n| `set_native_theme()` | `set_theme()` 만 호출 | `set_theme()` + `set_background_color()` 함께 호출 |\n| startup 배경색 (macOS/Windows) | `0x1f,0x1f,0x1f` / `0xf4,0xf5,0xf7` | `#1E1E21` / `#F5F5F7` (CSS와 일치) |\n\n**동작 방식:**\n- 앱 시작 → 시스템 테마로 native 배경 설정 (기존)\n- `onMount`에서 `set_native_theme(stored_theme)` 호출 → 이제 배경색도 업데이트됨\n- 테마 버튼 클릭 → 배경색도 즉시 업데이트됨\n- 타이틀바 더블클릭 애니메이션 중에는 올바른 배경색이 노출됨"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":434,"cache_read_input_tokens":49078,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":434},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNsdU3BDdtk8Z58yMLYd","type":"assistant","uuid":"a1688af8-bee0-4160-9240-79f48ae62eca","timestamp":"2026-02-22T09:30:42.944Z"}
{"parentUuid":"a1688af8-bee0-4160-9240-79f48ae62eca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6cbd0ca6-08bb-45b3-af9a-a3c6f580fcf0","toolUseID":"6cbd0ca6-08bb-45b3-af9a-a3c6f580fcf0","timestamp":"2026-02-22T09:30:42.980Z","uuid":"53fcf34b-ead0-43eb-86e7-b657a911b02f"}
{"parentUuid":"53fcf34b-ead0-43eb-86e7-b657a911b02f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":3974}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-22T09:30:46.955Z","uuid":"e00157cb-782e-4dc8-bc87-42a0eaf54a8f","toolUseID":"6cbd0ca6-08bb-45b3-af9a-a3c6f580fcf0"}
{"parentUuid":"e00157cb-782e-4dc8-bc87-42a0eaf54a8f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"system","subtype":"turn_duration","durationMs":85946,"timestamp":"2026-02-22T09:30:46.960Z","uuid":"20ac3687-9112-4281-80be-73046c6c6842","isMeta":false}
{"type":"file-history-snapshot","messageId":"4246c5e2-49d3-44b4-8410-d3988349200b","snapshot":{"messageId":"4246c5e2-49d3-44b4-8410-d3988349200b","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v2","version":2,"backupTime":"2026-02-22T09:36:47.635Z"}},"timestamp":"2026-02-22T09:36:47.634Z"},"isSnapshotUpdate":false}
{"parentUuid":"20ac3687-9112-4281-80be-73046c6c6842","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":"commit"},"uuid":"4246c5e2-49d3-44b4-8410-d3988349200b","timestamp":"2026-02-22T09:36:43.123Z","todos":[],"permissionMode":"bypassPermissions"}
{"parentUuid":"4246c5e2-49d3-44b4-8410-d3988349200b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01HxSCSXUt8M2yC11e8TuskB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LM4socjeFeqWfAruHeVjQF","name":"Bash","input":{"command":"git diff src-tauri/src/main.rs","description":"Show diff of changes"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":114,"cache_read_input_tokens":49826,"output_tokens":94,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":114,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNt6s23YfBHiECX1tebW","type":"assistant","uuid":"ce50938d-006f-4365-a061-06b75685a6e5","timestamp":"2026-02-22T09:36:50.296Z"}
{"parentUuid":"ce50938d-006f-4365-a061-06b75685a6e5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LM4socjeFeqWfAruHeVjQF","type":"tool_result","content":"diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs\nindex bf73d63..2f873f9 100644\n--- a/src-tauri/src/main.rs\n+++ b/src-tauri/src/main.rs\n@@ -44,7 +44,7 @@ const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n-const DB_VERSION: i32 = 4;\n+const DB_VERSION: i32 = 5;\n const DEFERRED_DIR_NAMES: &[&str] = &[\n     \"Library\", \".Trash\", \".Trashes\",\n     // Windows system directories (deferred when scan_root is C:\\)\n@@ -58,6 +58,12 @@ fn jwalk_num_threads() -> usize {\n         .unwrap_or(8)\n }\n \n+fn jwalk_num_threads_fresh() -> usize {\n+    std::thread::available_parallelism()\n+        .map(|n| n.get().max(4).min(16))\n+        .unwrap_or(8)\n+}\n+\n pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n     \".git\",\n     \"node_modules\",\n@@ -93,6 +99,18 @@ pub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n ];\n \n type AppResult<T> = Result<T, String>;\n+\n+// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\n+static BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\n+fn builtin_skip_path_checks() -> &'static [(String, String)] {\n+    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n+        BUILTIN_SKIP_PATHS\n+            .iter()\n+            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n+            .collect()\n+    })\n+}\n+\n static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n@@ -281,10 +299,27 @@ pub(crate) struct RecentOp {\n \n #[derive(Debug, Clone, PartialEq, Eq)]\n pub(crate) enum IgnorePattern {\n-    AnySegment(String),\n+    /// Matches any path segment equal to `segment`.\n+    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n+    /// per-call format! allocations in the hot path.\n+    AnySegment {\n+        segment: String,\n+        suffix: String,\n+        infix: String,\n+    },\n     Glob(String),\n }\n \n+impl IgnorePattern {\n+    pub(crate) fn any_segment(segment: &str) -> Self {\n+        IgnorePattern::AnySegment {\n+            suffix: format!(\"/{segment}\"),\n+            infix: format!(\"/{segment}/\"),\n+            segment: segment.to_string(),\n+        }\n+    }\n+}\n+\n #[derive(Debug, Clone)]\n pub(crate) struct IgnoreRulesCache {\n     roots: Vec<PathBuf>,\n@@ -411,10 +446,10 @@ fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n     conn.execute_batch(\n         r#\"\n-        PRAGMA synchronous = NORMAL;\n-        PRAGMA cache_size = -65536;\n-        PRAGMA mmap_size = 268435456;\n-        PRAGMA wal_autocheckpoint = 10000;\n+        PRAGMA synchronous = OFF;\n+        PRAGMA cache_size = -131072;\n+        PRAGMA mmap_size = 536870912;\n+        PRAGMA wal_autocheckpoint = 0;\n         \"#,\n     )\n     .map_err(|e| e.to_string())\n@@ -430,12 +465,16 @@ pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n+    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n+    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n+    // when the next auto-checkpoint threshold is hit.\n+    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n         .map_err(|e| e.to_string())?;\n     Ok(())\n }\n \n-fn init_db(db_path: &Path) -> AppResult<()> {\n+/// Phase 1: creates tables only. Fast even on large DBs.\n+fn init_db_tables(db_path: &Path) -> AppResult<()> {\n     let t = Instant::now();\n     let conn = db_connection(db_path)?;\n     eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n@@ -474,11 +513,6 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n           run_id INTEGER NOT NULL DEFAULT 0\n         );\n \n-        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n-        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n-\n         CREATE TABLE IF NOT EXISTS meta (\n           key TEXT PRIMARY KEY,\n           value TEXT NOT NULL\n@@ -486,18 +520,39 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n+\n+    Ok(())\n+}\n+\n+/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n+/// when new indexes are added; runs after db_ready so it does not block startup.\n+fn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n+    let t = Instant::now();\n+    let conn = db_connection(db_path)?;\n+\n+    conn.execute_batch(\n+        r#\"\n+        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n+        \"#,\n+    )\n+    .map_err(|e| e.to_string())?;\n+    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n \n-    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n-    let migrated = get_meta(&conn, legacy_index_migration_key)\n+    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n+    let migrated = get_meta(&conn, legacy_key)\n         .map(|v| v == \"1\")\n         .unwrap_or(false);\n     if !migrated {\n         conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n             .map_err(|e| e.to_string())?;\n-        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n+        set_meta(&conn, legacy_key, \"1\")?;\n     }\n-    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n \n     Ok(())\n }\n@@ -520,9 +575,7 @@ pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<(\n     Ok(())\n }\n \n-fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let conn = db_connection(&state.db_path)?;\n-\n+fn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n     let entries_count = conn\n         .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n             row.get::<_, i64>(0)\n@@ -539,14 +592,6 @@ fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n     Ok((entries_count, last_updated))\n }\n \n-pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let (entries_count, last_updated) = update_counts(state)?;\n-    let mut status = state.status.lock();\n-    status.entries_count = entries_count;\n-    status.last_updated = last_updated;\n-    Ok((entries_count, last_updated))\n-}\n-\n pub(crate) fn invalidate_search_caches(state: &AppState) {\n     state.fd_search_cache.lock().take();\n     state.negative_name_cache.lock().clear();\n@@ -745,7 +790,7 @@ fn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n }\n \n fn normalize_slashes(s: String) -> String {\n-    s.replace('\\\\', \"/\")\n+    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n }\n \n fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n@@ -791,7 +836,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n     if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n         if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n-            return Some(IgnorePattern::AnySegment(segment.to_string()));\n+            return Some(IgnorePattern::any_segment(segment));\n         }\n     }\n \n@@ -802,7 +847,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n+        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n         IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n     }\n }\n@@ -1144,10 +1189,15 @@ fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult\n         }\n \n         let prefix = root_str.trim_end_matches('/');\n-        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n+        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n+        // range-scan optimization when an ESCAPE clause is present, causing a full\n+        // table scan even though `path` has a UNIQUE (implicit) index.\n+        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n+        let lo = format!(\"{prefix}/\");\n+        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n         conn.execute(\n-            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n-            params![prefix, descendant_like],\n+            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n+            params![prefix, lo, hi],\n         )\n         .map_err(|e| e.to_string())?;\n     }\n@@ -1208,10 +1258,8 @@ fn glob_match_path(pattern: &str, text: &str) -> bool {\n \n pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => {\n-            let suffix = format!(\"/{segment}\");\n-            let infix = format!(\"/{segment}/\");\n-            path.ends_with(&suffix) || path.contains(&infix)\n+        IgnorePattern::AnySegment { suffix, infix, .. } => {\n+            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n         }\n         IgnorePattern::Glob(glob) => {\n             let mut cur = path;\n@@ -1261,11 +1309,10 @@ pub(crate) fn should_skip_path_ext(\n     }\n \n     // Multi-component builtin paths\n-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n-        let infix = format!(\"/{pat}/\");\n-        let suffix = format!(\"/{pat}\");\n-        s.contains(&infix) || s.ends_with(&suffix)\n-    }) {\n+    if builtin_skip_path_checks()\n+        .iter()\n+        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n+    {\n         return true;\n     }\n \n@@ -1354,10 +1401,6 @@ fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n     index_row_from_path_and_metadata(entry.path(), &metadata)\n }\n \n-fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n-    let metadata = entry.metadata().ok()?;\n-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n-}\n \n fn collect_rows_recursive(\n     root: &Path,\n@@ -1839,13 +1882,17 @@ fn emit_status_counts(app: &AppHandle, state: &AppState) {\n }\n \n pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let conn = db_connection(&state.db_path)?;\n+    let (entries_count, last_updated) = update_counts(&conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts so next startup can read them instantly\n-    if let Ok(conn) = db_connection(&state.db_path) {\n-        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n-        if let Some(lu) = last_updated {\n-            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n-        }\n+    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n+    if let Some(lu) = last_updated {\n+        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n     }\n     emit_status_counts(app, state);\n     Ok(())\n@@ -2009,10 +2056,41 @@ fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n     let mut conn = db_connection(&state.db_path)?;\n     set_indexing_pragmas(&conn)?;\n \n+    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n+    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n+    // which can be 3-5x faster when loading hundreds of thousands of rows.\n+    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n+        .and_then(|v| v.parse::<i64>().ok())\n+        .unwrap_or(0)\n+        == 0;\n+    if is_fresh_run {\n+        let _ = conn.execute_batch(\n+            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_mtime;\n+             DROP INDEX IF EXISTS idx_entries_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n+        );\n+    }\n+\n     let result = run_incremental_index_inner(app, state, &mut conn);\n \n+    if is_fresh_run {\n+        let t_idx = Instant::now();\n+        let _ = conn.execute_batch(\n+            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n+        );\n+        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n+    }\n+\n+    let t_analyze = Instant::now();\n     let _ = conn.execute_batch(\"ANALYZE\");\n+    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n+    let t_checkpoint = Instant::now();\n     let _ = restore_normal_pragmas(&conn);\n+    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n \n     match &result {\n         Ok(_) => {\n@@ -2061,12 +2139,16 @@ fn run_incremental_index_inner(\n     // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n     let is_fresh = last_run_id == 0;\n \n+    // Fresh index has no secondary indexes to maintain, so we can use larger\n+    // batches to reduce transaction overhead (fewer commits = faster).\n+    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n+\n     let mut scanned: u64 = 0;\n     let mut indexed: u64 = 0;\n     let mut permission_errors: u64 = 0;\n     let mut current_path = String::new();\n-    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n-    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n+    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n+    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n     let mut last_emit = Instant::now();\n     let mut last_perf_emit = Instant::now();\n \n@@ -2135,7 +2217,7 @@ fn run_incremental_index_inner(\n \n \n     // Flush home-level stamp batch\n-    if stamp_batch.len() >= BATCH_SIZE {\n+    if stamp_batch.len() >= flush_batch_size {\n         stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n         stamp_batch.clear();\n     }\n@@ -2184,43 +2266,59 @@ fn run_incremental_index_inner(\n             let skip_roots = arc_ignored_roots.clone();\n             let skip_patterns = arc_ignored_patterns.clone();\n \n-            let mut builder = jwalk::WalkDir::new(root)\n+            // Use more threads for fresh index: stat() calls are the bottleneck,\n+            // more rayon threads = more parallel stat() calls.\n+            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n+            let current_pass = pass;\n+            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                 .follow_links(false)\n                 .skip_hidden(false)\n-                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n+                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n             // Fresh index: no depth limit -- walk everything in one pass\n             if pass == 0 && !is_fresh {\n                 builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n             }\n             let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n-                children.retain(|entry_result| {\n-                    entry_result\n-                        .as_ref()\n-                        .map(|entry| {\n+                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n+                // Running stat() here parallelizes it across rayon threads (one per directory).\n+                children.retain_mut(|entry_result| {\n+                    match entry_result {\n+                        Ok(entry) => {\n                             let full_path = path.join(&entry.file_name);\n                             let is_dir = Some(entry.file_type.is_dir());\n-                            !should_skip_path_ext(\n+                            if should_skip_path_ext(\n                                 &full_path,\n                                 &skip_roots,\n                                 &skip_patterns,\n                                 Some(&gi_ref),\n                                 is_dir,\n-                            )\n-                        })\n-                        .unwrap_or(false)\n+                            ) {\n+                                return false;\n+                            }\n+                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n+                            // main thread). Skip for pass-1 shallow entries that will be\n+                            // discarded in the main loop anyway.\n+                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n+                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n+                            }\n+                            true\n+                        }\n+                        Err(_) => false,\n+                    }\n                 });\n             });\n \n             for result in walker {\n                 match result {\n                     Ok(entry) => {\n+                        let entry_depth = entry.depth;\n                         let path = entry.path();\n                         if path == root.as_path() {\n                             continue;\n                         }\n \n                         // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n-                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n+                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                             continue;\n                         }\n \n@@ -2228,7 +2326,18 @@ fn run_incremental_index_inner(\n                         root_scanned += 1;\n                         current_path = path.to_string_lossy().to_string();\n \n-                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n+                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n+                        let metadata = match entry.client_state {\n+                            Some(m) => m,\n+                            None => {\n+                                // pre-fetch failed (permission error or race condition)\n+                                permission_errors += 1;\n+                                root_permission_errors += 1;\n+                                continue;\n+                            }\n+                        };\n+\n+                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                             row.run_id = current_run_id;\n                             if is_fresh {\n                                 // Fresh index: all entries are new, skip existing check\n@@ -2250,12 +2359,12 @@ fn run_incremental_index_inner(\n                             }\n                         }\n \n-                        if batch.len() >= BATCH_SIZE {\n+                        if batch.len() >= flush_batch_size {\n                             upsert_rows(conn, &batch)?;\n                             batch.clear();\n                         }\n \n-                        if stamp_batch.len() >= BATCH_SIZE {\n+                        if stamp_batch.len() >= flush_batch_size {\n                             stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                             stamp_batch.clear();\n                         }\n@@ -2373,7 +2482,12 @@ fn run_incremental_index_inner(\n         invalidate_search_caches(state);\n     }\n \n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let (entries_count, last_updated) = update_counts(conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts for instant startup next time\n     let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n     if let Some(lu) = last_updated {\n@@ -2645,7 +2759,7 @@ fn start_fsevent_watcher_worker(\n         let mut last_flush = Instant::now();\n         let mut last_status_emit = Instant::now();\n         let mut pending_status_emit = false;\n-        let mut last_count_refresh = Instant::now();\n+\n         let mut must_scan_count: usize = 0;\n         let mut replay_phase = conditional;\n         let mut full_scan_triggered = false;\n@@ -2660,7 +2774,7 @@ fn start_fsevent_watcher_worker(\n                         due - now\n                     }\n                 }\n-                None => Duration::from_secs(1),\n+                None => Duration::from_secs(10),\n             };\n             match rx.recv_timeout(wait) {\n                 Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n@@ -2771,11 +2885,6 @@ fn start_fsevent_watcher_worker(\n                 last_flush = Instant::now();\n             }\n \n-            // Periodic count refresh to keep in-memory counts accurate\n-            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n-                let _ = update_status_counts(&state);\n-                last_count_refresh = Instant::now();\n-            }\n         }\n \n         // Final flush on shutdown\n@@ -2953,6 +3062,10 @@ async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()\n         }\n \n         let conn = db_connection(&state.db_path)?;\n+        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n+        let _ = conn.execute_batch(\n+            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n+        );\n         conn.execute(\"DELETE FROM entries\", [])\n             .map_err(|e| e.to_string())?;\n         conn.execute(\"DELETE FROM meta\", [])\n@@ -4555,12 +4668,21 @@ async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n     let window = app\n         .get_webview_window(\"main\")\n         .ok_or_else(|| \"Main window not found\".to_string())?;\n-    let t = if theme == \"light\" {\n+    let is_light = theme == \"light\";\n+    let t = if is_light {\n         tauri::Theme::Light\n     } else {\n         tauri::Theme::Dark\n     };\n-    window.set_theme(Some(t)).map_err(|e| e.to_string())\n+    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n+    use tauri::window::Color;\n+    let bg = if is_light {\n+        Color(0xF5, 0xF5, 0xF7, 0xFF)\n+    } else {\n+        Color(0x1E, 0x1E, 0x21, 0xFF)\n+    };\n+    let _ = window.set_background_color(Some(bg));\n+    Ok(())\n }\n \n #[tauri::command]\n@@ -4948,9 +5070,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n             .map(|t| t == tauri::Theme::Dark)\n             .unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         let _ = window.show();\n@@ -4962,9 +5084,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         use tauri::window::Color;\n         let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         if let Err(e) = window.set_decorations(false) {\n@@ -5070,17 +5192,27 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         let thread_started = std::time::Instant::now();\n         eprintln!(\"[startup/thread] init thread started\");\n \n-        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n-        if let Err(err) = init_db(&state.db_path) {\n+        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n+        if let Err(err) = init_db_tables(&state.db_path) {\n             set_state(&state, IndexState::Error, Some(err.clone()));\n             emit_index_state(&app_handle, \"Error\", Some(err));\n             return;\n         }\n-        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n+        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n \n         state.db_ready.store(true, AtomicOrdering::Release);\n         eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n \n+        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n+        {\n+            let idx_db_path = state.db_path.clone();\n+            std::thread::spawn(move || {\n+                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n+                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n+                }\n+            });\n+        }\n+\n         // Deferred housekeeping -- purge + status counts run in background\n         {\n             let hk_app = app_handle.clone();\n@@ -5372,7 +5504,7 @@ mod tests {\n \n     #[test]\n     fn should_skip_path_for_glob_any_segment_target() {\n-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n+        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n \n         assert!(should_skip_path(\n             Path::new(\"/Users/al02402336/work/rust/target\"),\n@@ -5436,7 +5568,8 @@ mod tests {\n         fs::create_dir_all(&dir_b).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let mut conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5478,7 +5611,8 @@ mod tests {\n         fs::create_dir_all(&archived_src).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5606,7 +5740,8 @@ mod tests {\n         fs::create_dir_all(&sub_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5715,7 +5850,8 @@ mod tests {\n         fs::create_dir_all(&proj_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();","is_error":false}]},"uuid":"e3c047ed-3601-41e4-9898-c494e404f3ce","timestamp":"2026-02-22T09:36:50.891Z","toolUseResult":{"stdout":"diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs\nindex bf73d63..2f873f9 100644\n--- a/src-tauri/src/main.rs\n+++ b/src-tauri/src/main.rs\n@@ -44,7 +44,7 @@ const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n-const DB_VERSION: i32 = 4;\n+const DB_VERSION: i32 = 5;\n const DEFERRED_DIR_NAMES: &[&str] = &[\n     \"Library\", \".Trash\", \".Trashes\",\n     // Windows system directories (deferred when scan_root is C:\\)\n@@ -58,6 +58,12 @@ fn jwalk_num_threads() -> usize {\n         .unwrap_or(8)\n }\n \n+fn jwalk_num_threads_fresh() -> usize {\n+    std::thread::available_parallelism()\n+        .map(|n| n.get().max(4).min(16))\n+        .unwrap_or(8)\n+}\n+\n pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n     \".git\",\n     \"node_modules\",\n@@ -93,6 +99,18 @@ pub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n ];\n \n type AppResult<T> = Result<T, String>;\n+\n+// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\n+static BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\n+fn builtin_skip_path_checks() -> &'static [(String, String)] {\n+    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n+        BUILTIN_SKIP_PATHS\n+            .iter()\n+            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n+            .collect()\n+    })\n+}\n+\n static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n@@ -281,10 +299,27 @@ pub(crate) struct RecentOp {\n \n #[derive(Debug, Clone, PartialEq, Eq)]\n pub(crate) enum IgnorePattern {\n-    AnySegment(String),\n+    /// Matches any path segment equal to `segment`.\n+    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n+    /// per-call format! allocations in the hot path.\n+    AnySegment {\n+        segment: String,\n+        suffix: String,\n+        infix: String,\n+    },\n     Glob(String),\n }\n \n+impl IgnorePattern {\n+    pub(crate) fn any_segment(segment: &str) -> Self {\n+        IgnorePattern::AnySegment {\n+            suffix: format!(\"/{segment}\"),\n+            infix: format!(\"/{segment}/\"),\n+            segment: segment.to_string(),\n+        }\n+    }\n+}\n+\n #[derive(Debug, Clone)]\n pub(crate) struct IgnoreRulesCache {\n     roots: Vec<PathBuf>,\n@@ -411,10 +446,10 @@ fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n     conn.execute_batch(\n         r#\"\n-        PRAGMA synchronous = NORMAL;\n-        PRAGMA cache_size = -65536;\n-        PRAGMA mmap_size = 268435456;\n-        PRAGMA wal_autocheckpoint = 10000;\n+        PRAGMA synchronous = OFF;\n+        PRAGMA cache_size = -131072;\n+        PRAGMA mmap_size = 536870912;\n+        PRAGMA wal_autocheckpoint = 0;\n         \"#,\n     )\n     .map_err(|e| e.to_string())\n@@ -430,12 +465,16 @@ pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n+    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n+    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n+    // when the next auto-checkpoint threshold is hit.\n+    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n         .map_err(|e| e.to_string())?;\n     Ok(())\n }\n \n-fn init_db(db_path: &Path) -> AppResult<()> {\n+/// Phase 1: creates tables only. Fast even on large DBs.\n+fn init_db_tables(db_path: &Path) -> AppResult<()> {\n     let t = Instant::now();\n     let conn = db_connection(db_path)?;\n     eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n@@ -474,11 +513,6 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n           run_id INTEGER NOT NULL DEFAULT 0\n         );\n \n-        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n-        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n-        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n-\n         CREATE TABLE IF NOT EXISTS meta (\n           key TEXT PRIMARY KEY,\n           value TEXT NOT NULL\n@@ -486,18 +520,39 @@ fn init_db(db_path: &Path) -> AppResult<()> {\n         \"#,\n     )\n     .map_err(|e| e.to_string())?;\n-    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms tables ensured\", t.elapsed().as_millis());\n+\n+    Ok(())\n+}\n+\n+/// Phase 2: creates indexes and runs legacy migrations. May be slow on large DBs\n+/// when new indexes are added; runs after db_ready so it does not block startup.\n+fn ensure_db_indexes(db_path: &Path) -> AppResult<()> {\n+    let t = Instant::now();\n+    let conn = db_connection(db_path)?;\n+\n+    conn.execute_batch(\n+        r#\"\n+        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n+        CREATE INDEX IF NOT EXISTS idx_entries_indexed_at ON entries(indexed_at);\n+        \"#,\n+    )\n+    .map_err(|e| e.to_string())?;\n+    eprintln!(\"[init_db] +{}ms indexes ensured\", t.elapsed().as_millis());\n \n-    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n-    let migrated = get_meta(&conn, legacy_index_migration_key)\n+    let legacy_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n+    let migrated = get_meta(&conn, legacy_key)\n         .map(|v| v == \"1\")\n         .unwrap_or(false);\n     if !migrated {\n         conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n             .map_err(|e| e.to_string())?;\n-        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n+        set_meta(&conn, legacy_key, \"1\")?;\n     }\n-    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n+    eprintln!(\"[init_db] +{}ms total (indexes + migration)\", t.elapsed().as_millis());\n \n     Ok(())\n }\n@@ -520,9 +575,7 @@ pub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<(\n     Ok(())\n }\n \n-fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let conn = db_connection(&state.db_path)?;\n-\n+fn update_counts(conn: &Connection) -> AppResult<(u64, Option<i64>)> {\n     let entries_count = conn\n         .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n             row.get::<_, i64>(0)\n@@ -539,14 +592,6 @@ fn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n     Ok((entries_count, last_updated))\n }\n \n-pub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n-    let (entries_count, last_updated) = update_counts(state)?;\n-    let mut status = state.status.lock();\n-    status.entries_count = entries_count;\n-    status.last_updated = last_updated;\n-    Ok((entries_count, last_updated))\n-}\n-\n pub(crate) fn invalidate_search_caches(state: &AppState) {\n     state.fd_search_cache.lock().take();\n     state.negative_name_cache.lock().clear();\n@@ -745,7 +790,7 @@ fn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n }\n \n fn normalize_slashes(s: String) -> String {\n-    s.replace('\\\\', \"/\")\n+    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n }\n \n fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n@@ -791,7 +836,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n     if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n         if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n-            return Some(IgnorePattern::AnySegment(segment.to_string()));\n+            return Some(IgnorePattern::any_segment(segment));\n         }\n     }\n \n@@ -802,7 +847,7 @@ fn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<I\n \n fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n+        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n         IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n     }\n }\n@@ -1144,10 +1189,15 @@ fn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult\n         }\n \n         let prefix = root_str.trim_end_matches('/');\n-        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n+        // Use range condition instead of LIKE+ESCAPE: SQLite disables the index\n+        // range-scan optimization when an ESCAPE clause is present, causing a full\n+        // table scan even though `path` has a UNIQUE (implicit) index.\n+        // \"\\u{10FFFF}\" is the maximum Unicode code point; any valid path sorts below it.\n+        let lo = format!(\"{prefix}/\");\n+        let hi = format!(\"{prefix}/\\u{10FFFF}\");\n         conn.execute(\n-            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n-            params![prefix, descendant_like],\n+            \"DELETE FROM entries WHERE path = ?1 OR (path >= ?2 AND path < ?3)\",\n+            params![prefix, lo, hi],\n         )\n         .map_err(|e| e.to_string())?;\n     }\n@@ -1208,10 +1258,8 @@ fn glob_match_path(pattern: &str, text: &str) -> bool {\n \n pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n     match pattern {\n-        IgnorePattern::AnySegment(segment) => {\n-            let suffix = format!(\"/{segment}\");\n-            let infix = format!(\"/{segment}/\");\n-            path.ends_with(&suffix) || path.contains(&infix)\n+        IgnorePattern::AnySegment { suffix, infix, .. } => {\n+            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n         }\n         IgnorePattern::Glob(glob) => {\n             let mut cur = path;\n@@ -1261,11 +1309,10 @@ pub(crate) fn should_skip_path_ext(\n     }\n \n     // Multi-component builtin paths\n-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n-        let infix = format!(\"/{pat}/\");\n-        let suffix = format!(\"/{pat}\");\n-        s.contains(&infix) || s.ends_with(&suffix)\n-    }) {\n+    if builtin_skip_path_checks()\n+        .iter()\n+        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n+    {\n         return true;\n     }\n \n@@ -1354,10 +1401,6 @@ fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n     index_row_from_path_and_metadata(entry.path(), &metadata)\n }\n \n-fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n-    let metadata = entry.metadata().ok()?;\n-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n-}\n \n fn collect_rows_recursive(\n     root: &Path,\n@@ -1839,13 +1882,17 @@ fn emit_status_counts(app: &AppHandle, state: &AppState) {\n }\n \n pub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let conn = db_connection(&state.db_path)?;\n+    let (entries_count, last_updated) = update_counts(&conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts so next startup can read them instantly\n-    if let Ok(conn) = db_connection(&state.db_path) {\n-        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n-        if let Some(lu) = last_updated {\n-            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n-        }\n+    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n+    if let Some(lu) = last_updated {\n+        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n     }\n     emit_status_counts(app, state);\n     Ok(())\n@@ -2009,10 +2056,41 @@ fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n     let mut conn = db_connection(&state.db_path)?;\n     set_indexing_pragmas(&conn)?;\n \n+    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n+    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n+    // which can be 3-5x faster when loading hundreds of thousands of rows.\n+    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n+        .and_then(|v| v.parse::<i64>().ok())\n+        .unwrap_or(0)\n+        == 0;\n+    if is_fresh_run {\n+        let _ = conn.execute_batch(\n+            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_mtime;\n+             DROP INDEX IF EXISTS idx_entries_name_nocase;\n+             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n+        );\n+    }\n+\n     let result = run_incremental_index_inner(app, state, &mut conn);\n \n+    if is_fresh_run {\n+        let t_idx = Instant::now();\n+        let _ = conn.execute_batch(\n+            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n+             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n+             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n+        );\n+        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n+    }\n+\n+    let t_analyze = Instant::now();\n     let _ = conn.execute_batch(\"ANALYZE\");\n+    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n+    let t_checkpoint = Instant::now();\n     let _ = restore_normal_pragmas(&conn);\n+    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n \n     match &result {\n         Ok(_) => {\n@@ -2061,12 +2139,16 @@ fn run_incremental_index_inner(\n     // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n     let is_fresh = last_run_id == 0;\n \n+    // Fresh index has no secondary indexes to maintain, so we can use larger\n+    // batches to reduce transaction overhead (fewer commits = faster).\n+    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n+\n     let mut scanned: u64 = 0;\n     let mut indexed: u64 = 0;\n     let mut permission_errors: u64 = 0;\n     let mut current_path = String::new();\n-    let mut batch: Vec<IndexRow> = Vec::with_capacity(BATCH_SIZE);\n-    let mut stamp_batch: Vec<String> = Vec::with_capacity(BATCH_SIZE);\n+    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n+    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n     let mut last_emit = Instant::now();\n     let mut last_perf_emit = Instant::now();\n \n@@ -2135,7 +2217,7 @@ fn run_incremental_index_inner(\n \n \n     // Flush home-level stamp batch\n-    if stamp_batch.len() >= BATCH_SIZE {\n+    if stamp_batch.len() >= flush_batch_size {\n         stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n         stamp_batch.clear();\n     }\n@@ -2184,43 +2266,59 @@ fn run_incremental_index_inner(\n             let skip_roots = arc_ignored_roots.clone();\n             let skip_patterns = arc_ignored_patterns.clone();\n \n-            let mut builder = jwalk::WalkDir::new(root)\n+            // Use more threads for fresh index: stat() calls are the bottleneck,\n+            // more rayon threads = more parallel stat() calls.\n+            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n+            let current_pass = pass;\n+            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                 .follow_links(false)\n                 .skip_hidden(false)\n-                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n+                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n             // Fresh index: no depth limit -- walk everything in one pass\n             if pass == 0 && !is_fresh {\n                 builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n             }\n             let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n-                children.retain(|entry_result| {\n-                    entry_result\n-                        .as_ref()\n-                        .map(|entry| {\n+                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n+                // Running stat() here parallelizes it across rayon threads (one per directory).\n+                children.retain_mut(|entry_result| {\n+                    match entry_result {\n+                        Ok(entry) => {\n                             let full_path = path.join(&entry.file_name);\n                             let is_dir = Some(entry.file_type.is_dir());\n-                            !should_skip_path_ext(\n+                            if should_skip_path_ext(\n                                 &full_path,\n                                 &skip_roots,\n                                 &skip_patterns,\n                                 Some(&gi_ref),\n                                 is_dir,\n-                            )\n-                        })\n-                        .unwrap_or(false)\n+                            ) {\n+                                return false;\n+                            }\n+                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n+                            // main thread). Skip for pass-1 shallow entries that will be\n+                            // discarded in the main loop anyway.\n+                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n+                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n+                            }\n+                            true\n+                        }\n+                        Err(_) => false,\n+                    }\n                 });\n             });\n \n             for result in walker {\n                 match result {\n                     Ok(entry) => {\n+                        let entry_depth = entry.depth;\n                         let path = entry.path();\n                         if path == root.as_path() {\n                             continue;\n                         }\n \n                         // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n-                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n+                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                             continue;\n                         }\n \n@@ -2228,7 +2326,18 @@ fn run_incremental_index_inner(\n                         root_scanned += 1;\n                         current_path = path.to_string_lossy().to_string();\n \n-                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n+                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n+                        let metadata = match entry.client_state {\n+                            Some(m) => m,\n+                            None => {\n+                                // pre-fetch failed (permission error or race condition)\n+                                permission_errors += 1;\n+                                root_permission_errors += 1;\n+                                continue;\n+                            }\n+                        };\n+\n+                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                             row.run_id = current_run_id;\n                             if is_fresh {\n                                 // Fresh index: all entries are new, skip existing check\n@@ -2250,12 +2359,12 @@ fn run_incremental_index_inner(\n                             }\n                         }\n \n-                        if batch.len() >= BATCH_SIZE {\n+                        if batch.len() >= flush_batch_size {\n                             upsert_rows(conn, &batch)?;\n                             batch.clear();\n                         }\n \n-                        if stamp_batch.len() >= BATCH_SIZE {\n+                        if stamp_batch.len() >= flush_batch_size {\n                             stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                             stamp_batch.clear();\n                         }\n@@ -2373,7 +2482,12 @@ fn run_incremental_index_inner(\n         invalidate_search_caches(state);\n     }\n \n-    let (entries_count, last_updated) = update_status_counts(state)?;\n+    let (entries_count, last_updated) = update_counts(conn)?;\n+    {\n+        let mut status = state.status.lock();\n+        status.entries_count = entries_count;\n+        status.last_updated = last_updated;\n+    }\n     // Persist cached counts for instant startup next time\n     let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n     if let Some(lu) = last_updated {\n@@ -2645,7 +2759,7 @@ fn start_fsevent_watcher_worker(\n         let mut last_flush = Instant::now();\n         let mut last_status_emit = Instant::now();\n         let mut pending_status_emit = false;\n-        let mut last_count_refresh = Instant::now();\n+\n         let mut must_scan_count: usize = 0;\n         let mut replay_phase = conditional;\n         let mut full_scan_triggered = false;\n@@ -2660,7 +2774,7 @@ fn start_fsevent_watcher_worker(\n                         due - now\n                     }\n                 }\n-                None => Duration::from_secs(1),\n+                None => Duration::from_secs(10),\n             };\n             match rx.recv_timeout(wait) {\n                 Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n@@ -2771,11 +2885,6 @@ fn start_fsevent_watcher_worker(\n                 last_flush = Instant::now();\n             }\n \n-            // Periodic count refresh to keep in-memory counts accurate\n-            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n-                let _ = update_status_counts(&state);\n-                last_count_refresh = Instant::now();\n-            }\n         }\n \n         // Final flush on shutdown\n@@ -2953,6 +3062,10 @@ async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()\n         }\n \n         let conn = db_connection(&state.db_path)?;\n+        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n+        let _ = conn.execute_batch(\n+            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n+        );\n         conn.execute(\"DELETE FROM entries\", [])\n             .map_err(|e| e.to_string())?;\n         conn.execute(\"DELETE FROM meta\", [])\n@@ -4555,12 +4668,21 @@ async fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n     let window = app\n         .get_webview_window(\"main\")\n         .ok_or_else(|| \"Main window not found\".to_string())?;\n-    let t = if theme == \"light\" {\n+    let is_light = theme == \"light\";\n+    let t = if is_light {\n         tauri::Theme::Light\n     } else {\n         tauri::Theme::Dark\n     };\n-    window.set_theme(Some(t)).map_err(|e| e.to_string())\n+    window.set_theme(Some(t)).map_err(|e| e.to_string())?;\n+    use tauri::window::Color;\n+    let bg = if is_light {\n+        Color(0xF5, 0xF5, 0xF7, 0xFF)\n+    } else {\n+        Color(0x1E, 0x1E, 0x21, 0xFF)\n+    };\n+    let _ = window.set_background_color(Some(bg));\n+    Ok(())\n }\n \n #[tauri::command]\n@@ -4948,9 +5070,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n             .map(|t| t == tauri::Theme::Dark)\n             .unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         let _ = window.show();\n@@ -4962,9 +5084,9 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         use tauri::window::Color;\n         let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n         let bg = if is_dark {\n-            Color(0x1f, 0x1f, 0x1f, 0xff)\n+            Color(0x1E, 0x1E, 0x21, 0xFF)\n         } else {\n-            Color(0xf4, 0xf5, 0xf7, 0xff)\n+            Color(0xF5, 0xF5, 0xF7, 0xFF)\n         };\n         let _ = window.set_background_color(Some(bg));\n         if let Err(e) = window.set_decorations(false) {\n@@ -5070,17 +5192,27 @@ fn setup_app(app: &mut tauri::App) -> AppResult<()> {\n         let thread_started = std::time::Instant::now();\n         eprintln!(\"[startup/thread] init thread started\");\n \n-        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n-        if let Err(err) = init_db(&state.db_path) {\n+        eprintln!(\"[startup/thread] +{}ms calling init_db_tables...\", thread_started.elapsed().as_millis());\n+        if let Err(err) = init_db_tables(&state.db_path) {\n             set_state(&state, IndexState::Error, Some(err.clone()));\n             emit_index_state(&app_handle, \"Error\", Some(err));\n             return;\n         }\n-        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n+        eprintln!(\"[startup/thread] +{}ms init_db_tables done\", thread_started.elapsed().as_millis());\n \n         state.db_ready.store(true, AtomicOrdering::Release);\n         eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n \n+        // Ensure indexes in background -- may be slow if new indexes were added to an existing DB.\n+        {\n+            let idx_db_path = state.db_path.clone();\n+            std::thread::spawn(move || {\n+                if let Err(e) = ensure_db_indexes(&idx_db_path) {\n+                    eprintln!(\"[init_db] ensure_db_indexes error: {e}\");\n+                }\n+            });\n+        }\n+\n         // Deferred housekeeping -- purge + status counts run in background\n         {\n             let hk_app = app_handle.clone();\n@@ -5372,7 +5504,7 @@ mod tests {\n \n     #[test]\n     fn should_skip_path_for_glob_any_segment_target() {\n-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n+        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n \n         assert!(should_skip_path(\n             Path::new(\"/Users/al02402336/work/rust/target\"),\n@@ -5436,7 +5568,8 @@ mod tests {\n         fs::create_dir_all(&dir_b).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let mut conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5478,7 +5611,8 @@ mod tests {\n         fs::create_dir_all(&archived_src).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5606,7 +5740,8 @@ mod tests {\n         fs::create_dir_all(&sub_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();\n \n@@ -5715,7 +5850,8 @@ mod tests {\n         fs::create_dir_all(&proj_dir).unwrap();\n \n         let db_path = root.join(\"index.db\");\n-        init_db(&db_path).unwrap();\n+        init_db_tables(&db_path).unwrap();\n+        ensure_db_indexes(&db_path).unwrap();\n         let conn = db_connection(&db_path).unwrap();\n         let now = now_epoch();","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"ce50938d-006f-4365-a061-06b75685a6e5"}
{"parentUuid":"e3c047ed-3601-41e4-9898-c494e404f3ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0117h9HwiHJBUPbvx6K2jET6","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"There are many other changes in the diff beyond what I just modified. These are pre-existing uncommitted changes from before. My changes are only the ones related to `set_native_theme` and the `0x1E/0xF5` color fixes. Let me commit just the relevant changes.\n\nLooking at the diff, the changes that are \"mine\" are:\n1. Lines at `4668-4688` (set_native_theme function)\n2. Lines at `5070-5092` (startup background colors)\n\nBut all the other changes were already in the working tree before my edit. The git status shows `M src-tauri/src/main.rs` as an unstaged modification - these were already there.\n\n\nSince the file has pre-existing modifications mixed in with my changes, I can't easily separate them with a partial commit. I should just commit all the changes in main.rs together, since the user is asking me to commit.\n\nLet me check what other files are modified as well.\n\nLooking at the git status output, I can see the staging and working tree states for each file. Most changes are unstaged in the working tree, but the macOS schema is already staged. Since the user wants to commit the theme fix and that's in main.rs, I should stage just that file and commit it separately from these other pending changes.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":9607,"cache_read_input_tokens":49940,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9607},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNt76NUMT1g7BWy2UmKr","type":"assistant","uuid":"e60ed2b6-0150-4d9f-9ee6-fba17a1d25e9","timestamp":"2026-02-22T09:37:07.587Z"}
{"parentUuid":"e60ed2b6-0150-4d9f-9ee6-fba17a1d25e9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_0117h9HwiHJBUPbvx6K2jET6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EFUq6ukwRCUYHfk8pJSNRp","name":"Bash","input":{"command":"git log --oneline -3","description":"Show recent commits"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":9607,"cache_read_input_tokens":49940,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9607},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNt76NUMT1g7BWy2UmKr","type":"assistant","uuid":"86e73602-1a83-4d4f-9310-aba1f27087c3","timestamp":"2026-02-22T09:37:07.825Z"}
{"parentUuid":"86e73602-1a83-4d4f-9310-aba1f27087c3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EFUq6ukwRCUYHfk8pJSNRp","type":"tool_result","content":"64775cb Fix idle CPU, optimize search, add backslash path support\nd82d44a Fix Svelte 5 app mount: use mount() instead of class constructor\nbe6f315 Add Windows NSIS build support and CI/CD","is_error":false}]},"uuid":"ecd47a86-4765-4e27-a87f-9bd7dbe6a6c4","timestamp":"2026-02-22T09:37:08.011Z","toolUseResult":{"stdout":"64775cb Fix idle CPU, optimize search, add backslash path support\nd82d44a Fix Svelte 5 app mount: use mount() instead of class constructor\nbe6f315 Add Windows NSIS build support and CI/CD","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"86e73602-1a83-4d4f-9310-aba1f27087c3"}
{"parentUuid":"ecd47a86-4765-4e27-a87f-9bd7dbe6a6c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01MDK1nA4gUfcxAK1v2335gU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012BZHcEocggzjNkPVsvYPTH","name":"Bash","input":{"command":"git add src-tauri/src/main.rs && git commit -m \"$(cat <<'EOF'\nFix window background flash on fullscreen when theme differs from system\n\nset_native_theme() was only calling set_theme() without updating\nset_background_color(). On macOS, the native window background was set\nat startup based on the system theme, so when the user's stored theme\ndiffered (e.g. light vs system dark), the native background stayed dark.\nDouble-clicking the title bar to fullscreen revealed this stale color\nduring the expansion animation.\n\nAlso align startup background color values with CSS theme constants\n(#1E1E21 / #F5F5F7) across macOS and Windows.\nEOF\n)\"","description":"Commit theme background fix"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":944,"cache_read_input_tokens":59547,"output_tokens":238,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":944,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNt8MhzFx2sdapxieqNQ","type":"assistant","uuid":"7247d0f9-2699-4a51-83d5-0683b92a5277","timestamp":"2026-02-22T09:37:14.510Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T09:37:17.544Z","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","content":"{\"task_id\":\"b11349b\",\"tool_use_id\":\"toolu_012BZHcEocggzjNkPVsvYPTH\",\"description\":\"Commit theme background fix\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"7247d0f9-2699-4a51-83d5-0683b92a5277","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"b1d55df5-e8fa-4243-a38b-2d000e5a5ec6","timestamp":"2026-02-22T09:37:17.544Z"}
{"parentUuid":"b1d55df5-e8fa-4243-a38b-2d000e5a5ec6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":4,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-1","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"ef8aff97-2be5-477c-8e70-892e1c25a856","timestamp":"2026-02-22T09:37:18.545Z"}
{"parentUuid":"ef8aff97-2be5-477c-8e70-892e1c25a856","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":5,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-2","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"338150ec-c6d3-4c82-a558-e97f261b0b78","timestamp":"2026-02-22T09:37:19.545Z"}
{"parentUuid":"338150ec-c6d3-4c82-a558-e97f261b0b78","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":6,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-3","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"3653eebc-b950-4d35-9edb-16b2ee9e148c","timestamp":"2026-02-22T09:37:20.546Z"}
{"parentUuid":"3653eebc-b950-4d35-9edb-16b2ee9e148c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":7,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-4","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"2e93f579-0b2e-43ac-a03a-a93b18762952","timestamp":"2026-02-22T09:37:21.547Z"}
{"parentUuid":"2e93f579-0b2e-43ac-a03a-a93b18762952","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":8,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-5","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"da3a219f-afe9-42d8-bcd5-feaa03e778cf","timestamp":"2026-02-22T09:37:22.548Z"}
{"parentUuid":"da3a219f-afe9-42d8-bcd5-feaa03e778cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":9,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-6","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"ae4994a3-3ff6-4bcd-82a0-8d93ac31ef2e","timestamp":"2026-02-22T09:37:23.548Z"}
{"parentUuid":"ae4994a3-3ff6-4bcd-82a0-8d93ac31ef2e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":10,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-7","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"75cb8253-447a-4fef-8f86-69d4ced665cf","timestamp":"2026-02-22T09:37:24.549Z"}
{"parentUuid":"75cb8253-447a-4fef-8f86-69d4ced665cf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":11,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-8","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"f831625d-5310-4371-a573-bf9b719168bc","timestamp":"2026-02-22T09:37:25.550Z"}
{"parentUuid":"f831625d-5310-4371-a573-bf9b719168bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":12,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-9","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"d62ef3e2-d54f-45ba-95b9-251b4cbbac6c","timestamp":"2026-02-22T09:37:26.551Z"}
{"parentUuid":"d62ef3e2-d54f-45ba-95b9-251b4cbbac6c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":13,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-10","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"5f84fbe4-b81b-4962-9535-76d96220cf88","timestamp":"2026-02-22T09:37:27.552Z"}
{"parentUuid":"5f84fbe4-b81b-4962-9535-76d96220cf88","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":14,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-11","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"248c97ac-5171-4dca-a978-7b689ed6efa6","timestamp":"2026-02-22T09:37:28.553Z"}
{"parentUuid":"248c97ac-5171-4dca-a978-7b689ed6efa6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":15,"totalLines":0,"totalBytes":0,"taskId":"b11349b"},"toolUseID":"bash-progress-12","parentToolUseID":"toolu_012BZHcEocggzjNkPVsvYPTH","uuid":"311b3874-eb3d-481d-a8e2-470a1a7c47a6","timestamp":"2026-02-22T09:37:29.556Z"}
{"parentUuid":"7247d0f9-2699-4a51-83d5-0683b92a5277","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012BZHcEocggzjNkPVsvYPTH","type":"tool_result","content":"[main 258c99b] Fix window background flash on fullscreen when theme differs from system\n 1 file changed, 229 insertions(+), 93 deletions(-)","is_error":false}]},"uuid":"776f50fd-447c-4173-b038-5b2bb565b74f","timestamp":"2026-02-22T09:37:30.048Z","toolUseResult":{"stdout":"[main 258c99b] Fix window background flash on fullscreen when theme differs from system\n 1 file changed, 229 insertions(+), 93 deletions(-)","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"7247d0f9-2699-4a51-83d5-0683b92a5277"}
{"parentUuid":"776f50fd-447c-4173-b038-5b2bb565b74f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","message":{"model":"claude-sonnet-4-6","id":"msg_01M2FrseuZvz2aTSaaVoNmmZ","type":"message","role":"assistant","content":[{"type":"text","text":"커밋 완료했습니다 (`258c99b`)."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":290,"cache_read_input_tokens":60491,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":290},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNt9ygyLoJquxyFZbEVb","type":"assistant","uuid":"4bb1ed2d-26ab-4d49-a973-3b799756472f","timestamp":"2026-02-22T09:37:31.893Z"}
{"parentUuid":"4bb1ed2d-26ab-4d49-a973-3b799756472f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"80923829-31f5-4d01-a64b-e92bbdd80054","version":"2.1.50","gitBranch":"main","slug":"streamed-snacking-haven","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"96912e0d-bc32-498f-9d4e-bf1321a3dde5","toolUseID":"96912e0d-bc32-498f-9d4e-bf1321a3dde5","timestamp":"2026-02-22T09:37:31.940Z","uuid":"f413e359-877e-43fb-9e28-fb1158259f1b"}
