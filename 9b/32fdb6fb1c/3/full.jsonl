{"type":"file-history-snapshot","messageId":"7575415e-a878-4909-9845-28bc168efb5f","snapshot":{"messageId":"7575415e-a878-4909-9845-28bc168efb5f","trackedFileBackups":{},"timestamp":"2026-02-22T07:39:00.522Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:clear","command":"entire hooks claude-code session-start"},"parentToolUseID":"cfbb0f07-63d9-423b-9f38-5520015a709f","toolUseID":"cfbb0f07-63d9-423b-9f38-5520015a709f","timestamp":"2026-02-22T07:38:58.343Z","uuid":"9c01f694-d112-48b8-8d8e-f3f26d22eb01"}
{"parentUuid":"9c01f694-d112-48b8-8d8e-f3f26d22eb01","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-caveat>Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.</local-command-caveat>"},"isMeta":true,"uuid":"4e17f832-62cb-4430-af22-b8053baa2e0e","timestamp":"2026-02-22T07:39:00.522Z"}
{"parentUuid":"4e17f832-62cb-4430-af22-b8053baa2e0e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<command-name>/clear</command-name>\n            <command-message>clear</command-message>\n            <command-args></command-args>"},"uuid":"7575415e-a878-4909-9845-28bc168efb5f","timestamp":"2026-02-22T07:38:57.981Z"}
{"parentUuid":"7575415e-a878-4909-9845-28bc168efb5f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-stdout></local-command-stdout>"},"uuid":"c8eba22c-1a44-45bd-9247-d5c03a52fe9a","timestamp":"2026-02-22T07:39:00.522Z"}
{"type":"file-history-snapshot","messageId":"192713d9-061f-43d9-b09d-c33b1dc64725","snapshot":{"messageId":"192713d9-061f-43d9-b09d-c33b1dc64725","trackedFileBackups":{},"timestamp":"2026-02-22T07:39:06.444Z"},"isSnapshotUpdate":false}
{"parentUuid":"c8eba22c-1a44-45bd-9247-d5c03a52fe9a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"아직도 reset 후 완료까지 1분 18초걸려. 50초 미만이 될 때까지 테스트하고 시간 측정과 개선을 반복해"},"uuid":"192713d9-061f-43d9-b09d-c33b1dc64725","timestamp":"2026-02-22T07:39:02.507Z","permissionMode":"bypassPermissions"}
{"parentUuid":"192713d9-061f-43d9-b09d-c33b1dc64725","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_018Lc4knQ3JeuoFNvNELr4eG","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants me to optimize the reset/index time so it completes in under 50 seconds (currently taking 1 minute 18 seconds). I need to test, measure, and improve iteratively until it's under 50 seconds.\n\nLet me start by reading the relevant code to understand the current implementation.","signature":"EsoDCkYICxgCKkDrqPMPgRCRqne6vPjWtqaacNFLXFi1+2m2cfBWg4kHAv87AFM/plNK7fMAZwsU8ZAG3TeqP8KBDWNyhf7E/PTXEgzXjpLbUf99DLS3K7oaDCoIe2f4c8IKSpFHSyIwPedYJ5vgDkAw9NSL0/dUngtm2f9kC3cGxbyOSboi8WUEB6qRF8N2uk1dO8bKF+cXKrECnDPQcVky83Q2oFzWoz/8/GY3GUFM/6ZwSUB1/XR282hoKupcwCf72uCiR9pJUsMAlHPK/3ovRmgggN/CBmnIC+bc6s/tJ8iHK+UZxzj9eIuD9QGoaU96HN1z+SbjYCJ4u/LUNjy4QMn3uzeM7tIDXaegcGgtRkd70QjPAb3+uGpAzuGXmiGhtXlefNC/0lGFeTBWzUtJihSVYBTMVFILjcIzRwBUK8Id8aPIX9BQ+WSpBMyNpMg+p19N7lAW0JjIV+FCM5PSLOH7y71HK7k7AlhSCTS0zUe5HkoYTUlucfYMyGBBaOT8qJ7foPzKbKHdAkm10euZqVJ8lxva78IaZvFdIhGLbnkqVkc6dR66KM1D1FugCE7xDmXWgRTv5NuEmbxYz5CBReUgV5p9Jd855C8YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":8257,"cache_read_input_tokens":25541,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8257},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj8LdwgpUVJGqVt2cfu","type":"assistant","uuid":"8584e4be-28ad-4b6d-8298-8208b4144bdb","timestamp":"2026-02-22T07:39:09.659Z"}
{"parentUuid":"8584e4be-28ad-4b6d-8298-8208b4144bdb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_018Lc4knQ3JeuoFNvNELr4eG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EecPv5UXZRWsRBvaZmQ4YC","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":8257,"cache_read_input_tokens":25541,"output_tokens":155,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":8257,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNj8LdwgpUVJGqVt2cfu","type":"assistant","uuid":"e4df9056-9001-4b13-a7c1-1c85c2b19e4a","timestamp":"2026-02-22T07:39:10.404Z"}
{"parentUuid":"e4df9056-9001-4b13-a7c1-1c85c2b19e4a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"File content (59966 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","is_error":true,"tool_use_id":"toolu_01EecPv5UXZRWsRBvaZmQ4YC"}]},"uuid":"cc06ddf0-0a3a-4476-8755-a0e4e3c403c6","timestamp":"2026-02-22T07:39:10.771Z","toolUseResult":"Error: File content (59966 tokens) exceeds maximum allowed tokens (25000). Please use offset and limit parameters to read specific portions of the file, or use the GrepTool to search for specific content.","sourceToolAssistantUUID":"e4df9056-9001-4b13-a7c1-1c85c2b19e4a"}
{"parentUuid":"cc06ddf0-0a3a-4476-8755-a0e4e3c403c6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01CJozomuZxs3y6vBBpuvHBV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GkzvnaNdGupvpP4eoqSaDN","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","limit":200},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":220,"cache_read_input_tokens":33798,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":220},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj8ezVywzWFi4kAgyD2","type":"assistant","uuid":"fc59723f-852c-41f7-9581-43638fb0ef48","timestamp":"2026-02-22T07:39:12.290Z"}
{"parentUuid":"fc59723f-852c-41f7-9581-43638fb0ef48","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01GkzvnaNdGupvpP4eoqSaDN","toolUseID":"toolu_01GkzvnaNdGupvpP4eoqSaDN","timestamp":"2026-02-22T07:39:12.298Z","uuid":"2a014fc7-e5b1-4e76-9029-36e06a81bcf1"}
{"parentUuid":"fc59723f-852c-41f7-9581-43638fb0ef48","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GkzvnaNdGupvpP4eoqSaDN","type":"tool_result","content":"     1→#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n     2→\n     3→use std::{\n     4→    cmp::Ordering,\n     5→    collections::{HashMap, HashSet},\n     6→    fs,\n     7→    hash::{Hash, Hasher},\n     8→    io::{self, BufRead, BufReader, Write},\n     9→    path::{Path, PathBuf},\n    10→    process::{Command, Stdio},\n    11→    sync::{\n    12→        atomic::{AtomicBool, Ordering as AtomicOrdering},\n    13→        Arc, OnceLock,\n    14→    },\n    15→    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n    16→};\n    17→\n    18→use parking_lot::{Mutex, RwLock};\n    19→use rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\n    20→use serde::Serialize;\n    21→use tauri::{AppHandle, Emitter, Manager, State};\n    22→#[cfg(target_os = \"macos\")]\n    23→use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n    24→#[cfg(target_os = \"windows\")]\n    25→use std::os::windows::process::CommandExt;\n    26→use walkdir::WalkDir;\n    27→\n    28→mod fd_search;\n    29→mod gitignore_filter;\n    30→#[cfg(target_os = \"macos\")]\n    31→mod mac;\n    32→mod mem_search;\n    33→mod query;\n    34→#[cfg(target_os = \"windows\")]\n    35→mod win;\n    36→use fd_search::{FdSearchCache, FdSearchResultDto};\n    37→use query::{escape_like, parse_query, SearchMode};\n    38→\n    39→const DEFAULT_LIMIT: u32 = 300;\n    40→const SHORT_QUERY_LIMIT: u32 = 100;\n    41→const MAX_LIMIT: u32 = 1000;\n    42→pub(crate) const BATCH_SIZE: usize = 10_000;\n    43→const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n    44→pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n    45→const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n    46→const NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\n    47→const DB_VERSION: i32 = 4;\n    48→const DEFERRED_DIR_NAMES: &[&str] = &[\n    49→    \"Library\", \".Trash\", \".Trashes\",\n    50→    // Windows system directories (deferred when scan_root is C:\\)\n    51→    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    52→    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n    53→];\n    54→const SHALLOW_SCAN_DEPTH: usize = 6;\n    55→fn jwalk_num_threads() -> usize {\n    56→    std::thread::available_parallelism()\n    57→        .map(|n| (n.get() / 2).max(4).min(16))\n    58→        .unwrap_or(8)\n    59→}\n    60→\n    61→pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    62→    \".git\",\n    63→    \"node_modules\",\n    64→    \".Trash\",\n    65→    \".Trashes\",\n    66→    \".npm\",\n    67→    \".cache\",\n    68→    \"CMakeFiles\",\n    69→    \".qtc_clangd\",\n    70→    \"__pycache__\",\n    71→    \".gradle\",\n    72→    \"DerivedData\",\n    73→];\n    74→\n    75→/// Path segments whose name ends with one of these suffixes are skipped.\n    76→/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\n    77→pub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    78→    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n    79→];\n    80→\n    81→pub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    82→    // macOS\n    83→    \"Library/Caches\",\n    84→    \"Library/Developer/CoreSimulator\",\n    85→    \"Library/Logs\",\n    86→    // Cross-platform\n    87→    \".vscode/extensions\",\n    88→    // Windows: noisy system directories under AppData\n    89→    \"AppData/Local/Temp\",\n    90→    \"AppData/Local/Microsoft\",\n    91→    \"AppData/Local/Google\",\n    92→    \"AppData/Local/Packages\",\n    93→];\n    94→\n    95→type AppResult<T> = Result<T, String>;\n    96→static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n    97→static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n    98→static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n    99→static STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n   100→\n   101→fn startup_elapsed_ms() -> u128 {\n   102→    STARTUP_T0\n   103→        .get()\n   104→        .map(|started| started.elapsed().as_millis())\n   105→        .unwrap_or(0)\n   106→}\n   107→\n   108→#[derive(Debug, Clone, Serialize)]\n   109→#[serde(rename_all = \"camelCase\")]\n   110→pub struct EntryDto {\n   111→    pub path: String,\n   112→    pub name: String,\n   113→    pub dir: String,\n   114→    pub is_dir: bool,\n   115→    pub ext: Option<String>,\n   116→    pub size: Option<i64>,\n   117→    pub mtime: Option<i64>,\n   118→}\n   119→\n   120→#[derive(Debug, Clone, Serialize)]\n   121→#[serde(rename_all = \"camelCase\")]\n   122→struct IndexStatusDto {\n   123→    state: String,\n   124→    entries_count: u64,\n   125→    last_updated: Option<i64>,\n   126→    permission_errors: u64,\n   127→    message: Option<String>,\n   128→    scanned: u64,\n   129→    indexed: u64,\n   130→    current_path: String,\n   131→}\n   132→\n   133→#[derive(Debug, Clone, Serialize)]\n   134→#[serde(rename_all = \"camelCase\")]\n   135→struct IndexProgressEvent {\n   136→    scanned: u64,\n   137→    indexed: u64,\n   138→    current_path: String,\n   139→}\n   140→\n   141→#[derive(Debug, Clone, Serialize)]\n   142→#[serde(rename_all = \"camelCase\")]\n   143→struct IndexStateEvent {\n   144→    state: String,\n   145→    message: Option<String>,\n   146→    is_catchup: bool,\n   147→}\n   148→\n   149→#[derive(Debug, Clone, Serialize)]\n   150→#[serde(rename_all = \"camelCase\")]\n   151→struct IndexUpdatedEvent {\n   152→    entries_count: u64,\n   153→    last_updated: i64,\n   154→    permission_errors: u64,\n   155→}\n   156→\n   157→#[derive(Debug, Clone)]\n   158→struct SearchExecution {\n   159→    query: String,\n   160→    sort_by: String,\n   161→    sort_dir: String,\n   162→    effective_limit: u32,\n   163→    offset: u32,\n   164→    mode_label: String,\n   165→    results: Vec<EntryDto>,\n   166→}\n   167→\n   168→#[derive(Debug, Clone, Serialize)]\n   169→#[serde(rename_all = \"camelCase\")]\n   170→struct SearchResultDto {\n   171→    entries: Vec<EntryDto>,\n   172→    mode_label: String,\n   173→    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n   174→    total_count: u32,\n   175→    /// True when total_count is exact. False means frontend should treat it as unknown.\n   176→    total_known: bool,\n   177→}\n   178→\n   179→#[allow(dead_code)]\n   180→#[derive(Debug, Clone)]\n   181→struct BenchCase {\n   182→    id: &'static str,\n   183→    query: &'static str,\n   184→    sort_by: &'static str,\n   185→    sort_dir: &'static str,\n   186→    limit: u32,\n   187→    offset: u32,\n   188→    expected_min_results: usize,\n   189→}\n   190→\n   191→#[allow(dead_code)]\n   192→#[derive(Debug, Clone, Serialize)]\n   193→#[serde(rename_all = \"camelCase\")]\n   194→struct BenchCaseResult {\n   195→    id: String,\n   196→    query: String,\n   197→    mode: String,\n   198→    sort_by: String,\n   199→    sort_dir: String,\n   200→    limit: u32,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1e32884d-be26-4d7b-8141-c1ba221c4334","timestamp":"2026-02-22T07:39:12.297Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,","numLines":200,"startLine":1,"totalLines":5786}},"sourceToolAssistantUUID":"fc59723f-852c-41f7-9581-43638fb0ef48"}
{"parentUuid":"1e32884d-be26-4d7b-8141-c1ba221c4334","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01F8cP49AYb4nHGeahfehziY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019nTZoJjyZBzLNRS4Dr2Rdo","name":"Grep","input":{"pattern":"fn full_index|fn run_index|fn start_full_index|fn index_filesystem|fn do_index|BATCH_SIZE|batch_upsert|fn upsert","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2757,"cache_read_input_tokens":34018,"output_tokens":165,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":2757,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNj8mkJN8WdHv4oLJTp7","type":"assistant","uuid":"870735c5-b453-4af6-81e0-895eefe62170","timestamp":"2026-02-22T07:39:15.545Z"}
{"parentUuid":"870735c5-b453-4af6-81e0-895eefe62170","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_019nTZoJjyZBzLNRS4Dr2Rdo","toolUseID":"toolu_019nTZoJjyZBzLNRS4Dr2Rdo","timestamp":"2026-02-22T07:39:16.230Z","uuid":"4361015e-fea7-4c3f-956d-46428b07c502"}
{"parentUuid":"870735c5-b453-4af6-81e0-895eefe62170","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019nTZoJjyZBzLNRS4Dr2Rdo","type":"tool_result","content":"39-const DEFAULT_LIMIT: u32 = 300;\n40-const SHORT_QUERY_LIMIT: u32 = 100;\n41-const MAX_LIMIT: u32 = 1000;\n42:pub(crate) const BATCH_SIZE: usize = 10_000;\n43-const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n44-pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n45-const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n--\n1678-    entries\n1679-}\n1680-\n1681:pub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n1682-    if rows.is_empty() {\n1683-        return Ok(0);\n1684-    }\n--\n1884-}\n1885-\n1886-#[cfg(not(target_os = \"windows\"))]\n1887:pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n1888-    start_full_index_worker_inner(app, state, false)\n1889-}\n1890-\n1891-#[cfg(target_os = \"windows\")]\n1892:pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n1893-    start_full_index_worker_inner(app, state, true)\n1894-}\n1895-\n1896:fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n1897-    if state\n1898-        .indexing_active\n1899-        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n--\n2088-\n2089-    // Fresh index has no secondary indexes to maintain, so we can use larger\n2090-    // batches to reduce transaction overhead (fewer commits = faster).\n2091:    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n2092-\n2093-    let mut scanned: u64 = 0;\n2094-    let mut indexed: u64 = 0;\n--\n2950-}\n2951-\n2952-#[tauri::command]\n2953:fn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n2954-    #[cfg(target_os = \"windows\")]\n2955-    {\n2956-        win::start_windows_indexing(app, state.inner().clone());\n--\n4306-        if original_is_dir {\n4307-            let rows =\n4308-                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n4309:            for chunk in rows.chunks(BATCH_SIZE) {\n4310-                let _ = upsert_rows(&mut conn, chunk)?;\n4311-            }\n4312-        } else {"}]},"uuid":"8197dacc-d709-4730-8c20-650fff090333","timestamp":"2026-02-22T07:39:16.229Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"39-const DEFAULT_LIMIT: u32 = 300;\n40-const SHORT_QUERY_LIMIT: u32 = 100;\n41-const MAX_LIMIT: u32 = 1000;\n42:pub(crate) const BATCH_SIZE: usize = 10_000;\n43-const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n44-pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n45-const NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\n--\n1678-    entries\n1679-}\n1680-\n1681:pub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n1682-    if rows.is_empty() {\n1683-        return Ok(0);\n1684-    }\n--\n1884-}\n1885-\n1886-#[cfg(not(target_os = \"windows\"))]\n1887:pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n1888-    start_full_index_worker_inner(app, state, false)\n1889-}\n1890-\n1891-#[cfg(target_os = \"windows\")]\n1892:pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n1893-    start_full_index_worker_inner(app, state, true)\n1894-}\n1895-\n1896:fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n1897-    if state\n1898-        .indexing_active\n1899-        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n--\n2088-\n2089-    // Fresh index has no secondary indexes to maintain, so we can use larger\n2090-    // batches to reduce transaction overhead (fewer commits = faster).\n2091:    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n2092-\n2093-    let mut scanned: u64 = 0;\n2094-    let mut indexed: u64 = 0;\n--\n2950-}\n2951-\n2952-#[tauri::command]\n2953:fn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n2954-    #[cfg(target_os = \"windows\")]\n2955-    {\n2956-        win::start_windows_indexing(app, state.inner().clone());\n--\n4306-        if original_is_dir {\n4307-            let rows =\n4308-                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n4309:            for chunk in rows.chunks(BATCH_SIZE) {\n4310-                let _ = upsert_rows(&mut conn, chunk)?;\n4311-            }\n4312-        } else {","numLines":56},"sourceToolAssistantUUID":"870735c5-b453-4af6-81e0-895eefe62170"}
{"parentUuid":"8197dacc-d709-4730-8c20-650fff090333","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01ETtSgeZtYDjg2Aw5dbE6Gh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JSNSQF39hMetF79z9AcsYo","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1681,"limit":150},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":991,"cache_read_input_tokens":36775,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":991},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj94UsvVPC755t7358e","type":"assistant","uuid":"43d019db-5c3d-441e-8f9b-4dda9c36f67a","timestamp":"2026-02-22T07:39:18.008Z"}
{"parentUuid":"43d019db-5c3d-441e-8f9b-4dda9c36f67a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JSNSQF39hMetF79z9AcsYo","toolUseID":"toolu_01JSNSQF39hMetF79z9AcsYo","timestamp":"2026-02-22T07:39:18.029Z","uuid":"54b0b439-6176-4843-a2fc-5ff62c45df74"}
{"parentUuid":"43d019db-5c3d-441e-8f9b-4dda9c36f67a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JSNSQF39hMetF79z9AcsYo","type":"tool_result","content":"  1681→pub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n  1682→    if rows.is_empty() {\n  1683→        return Ok(0);\n  1684→    }\n  1685→\n  1686→    let tx = conn.transaction().map_err(|e| e.to_string())?;\n  1687→    {\n  1688→        let mut stmt = tx\n  1689→            .prepare(\n  1690→                r#\"\n  1691→                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n  1692→                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n  1693→                ON CONFLICT(path) DO UPDATE SET\n  1694→                  name = excluded.name,\n  1695→                  dir = excluded.dir,\n  1696→                  is_dir = excluded.is_dir,\n  1697→                  ext = excluded.ext,\n  1698→                  mtime = excluded.mtime,\n  1699→                  size = excluded.size,\n  1700→                  indexed_at = excluded.indexed_at,\n  1701→                  run_id = excluded.run_id\n  1702→                \"#,\n  1703→            )\n  1704→            .map_err(|e| e.to_string())?;\n  1705→\n  1706→        for row in rows {\n  1707→            stmt.execute(params![\n  1708→                row.path,\n  1709→                row.name,\n  1710→                row.dir,\n  1711→                row.is_dir,\n  1712→                row.ext,\n  1713→                row.mtime,\n  1714→                row.size,\n  1715→                row.indexed_at,\n  1716→                row.run_id\n  1717→            ])\n  1718→            .map_err(|e| e.to_string())?;\n  1719→        }\n  1720→    }\n  1721→    tx.commit().map_err(|e| e.to_string())?;\n  1722→    Ok(rows.len())\n  1723→}\n  1724→\n  1725→pub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n  1726→    if raw_paths.is_empty() {\n  1727→        return Ok(0);\n  1728→    }\n  1729→\n  1730→    let tx = conn.transaction().map_err(|e| e.to_string())?;\n  1731→    let mut deleted = 0;\n  1732→\n  1733→    {\n  1734→        let mut stmt_exact = tx\n  1735→            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n  1736→            .map_err(|e| e.to_string())?;\n  1737→        let mut stmt_children = tx\n  1738→            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n  1739→            .map_err(|e| e.to_string())?;\n  1740→\n  1741→        for path in raw_paths {\n  1742→            let is_root = path == \"/\" || path == \"\\\\\";\n  1743→            let normalized = if is_root {\n  1744→                path.clone()\n  1745→            } else {\n  1746→                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n  1747→            };\n  1748→\n  1749→            if normalized.is_empty() {\n  1750→                continue;\n  1751→            }\n  1752→\n  1753→            if is_root {\n  1754→                deleted += tx\n  1755→                    .execute(\"DELETE FROM entries\", [])\n  1756→                    .map_err(|e| e.to_string())?;\n  1757→                continue;\n  1758→            }\n  1759→\n  1760→            deleted += stmt_exact\n  1761→                .execute(params![&normalized])\n  1762→                .map_err(|e| e.to_string())?;\n  1763→\n  1764→            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n  1765→            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n  1766→            let sep = std::path::MAIN_SEPARATOR;\n  1767→            let range_start = format!(\"{normalized}{sep}\");\n  1768→            let range_end = format!(\"{normalized}\\x7F\");\n  1769→            deleted += stmt_children\n  1770→                .execute(params![&range_start, &range_end])\n  1771→                .map_err(|e| e.to_string())?;\n  1772→        }\n  1773→    }\n  1774→\n  1775→    tx.commit().map_err(|e| e.to_string())?;\n  1776→    Ok(deleted)\n  1777→}\n  1778→\n  1779→pub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n  1780→    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n  1781→    let _ = app.emit(\n  1782→        \"index_state\",\n  1783→        IndexStateEvent {\n  1784→            state: state.to_string(),\n  1785→            message,\n  1786→            is_catchup,\n  1787→        },\n  1788→    );\n  1789→}\n  1790→\n  1791→pub(crate) fn emit_index_updated(\n  1792→    app: &AppHandle,\n  1793→    entries_count: u64,\n  1794→    last_updated: i64,\n  1795→    permission_errors: u64,\n  1796→) {\n  1797→    let _ = app.emit(\n  1798→        \"index_updated\",\n  1799→        IndexUpdatedEvent {\n  1800→            entries_count,\n  1801→            last_updated,\n  1802→            permission_errors,\n  1803→        },\n  1804→    );\n  1805→}\n  1806→\n  1807→pub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n  1808→    let _ = app.emit(\n  1809→        \"index_progress\",\n  1810→        IndexProgressEvent {\n  1811→            scanned,\n  1812→            indexed,\n  1813→            current_path,\n  1814→        },\n  1815→    );\n  1816→}\n  1817→\n  1818→pub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n  1819→    let mut status = state.status.lock();\n  1820→    status.state = next;\n  1821→    status.message = message;\n  1822→}\n  1823→\n  1824→pub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n  1825→    let mut status = state.status.lock();\n  1826→    status.scanned = scanned;\n  1827→    status.indexed = indexed;\n  1828→    status.current_path = current_path.to_string();\n  1829→}\n  1830→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5a116d82-e880-4815-8c36-f0b1e7a6e529","timestamp":"2026-02-22T07:39:18.027Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n","numLines":150,"startLine":1681,"totalLines":5786}},"sourceToolAssistantUUID":"43d019db-5c3d-441e-8f9b-4dda9c36f67a"}
{"parentUuid":"5a116d82-e880-4815-8c36-f0b1e7a6e529","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_017KDtk1vNCReJ77X9r2CriY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XJj9PVcpWLTLRzENuW3KaK","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1887,"limit":250},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2203,"cache_read_input_tokens":37766,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2203},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj9C24MRRp47jDnuHXZ","type":"assistant","uuid":"03bb30f9-3825-459c-81e0-689952104ca8","timestamp":"2026-02-22T07:39:20.456Z"}
{"parentUuid":"03bb30f9-3825-459c-81e0-689952104ca8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01XJj9PVcpWLTLRzENuW3KaK","toolUseID":"toolu_01XJj9PVcpWLTLRzENuW3KaK","timestamp":"2026-02-22T07:39:20.464Z","uuid":"51410c54-07fe-4b06-b4ca-297afcdabc37"}
{"parentUuid":"03bb30f9-3825-459c-81e0-689952104ca8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XJj9PVcpWLTLRzENuW3KaK","type":"tool_result","content":"  1887→pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n  1888→    start_full_index_worker_inner(app, state, false)\n  1889→}\n  1890→\n  1891→#[cfg(target_os = \"windows\")]\n  1892→pub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n  1893→    start_full_index_worker_inner(app, state, true)\n  1894→}\n  1895→\n  1896→fn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n  1897→    if state\n  1898→        .indexing_active\n  1899→        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n  1900→        .is_err()\n  1901→    {\n  1902→        perf_log(\"index_start_skipped already_active=true\");\n  1903→        return Ok(());\n  1904→    }\n  1905→\n  1906→    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n  1907→    if let Ok(c) = db_connection(&state.db_path) {\n  1908→        let _ = set_meta(&c, \"index_complete\", \"0\");\n  1909→    }\n  1910→\n  1911→    if !silent {\n  1912→        {\n  1913→            let mut status = state.status.lock();\n  1914→            status.state = IndexState::Indexing;\n  1915→            status.message = None;\n  1916→            status.scanned = 0;\n  1917→            status.indexed = 0;\n  1918→            status.current_path.clear();\n  1919→        }\n  1920→\n  1921→        emit_index_state(&app, \"Indexing\", None);\n  1922→        perf_log(\"index_state=Indexing\");\n  1923→    } else {\n  1924→        perf_log(\"index_start silent=true (background reindex)\");\n  1925→    }\n  1926→\n  1927→    std::thread::spawn(move || {\n  1928→        let result = run_incremental_index(&app, &state);\n  1929→        if let Err(ref err) = result {\n  1930→            eprintln!(\"[index] run_incremental_index failed: {err}\");\n  1931→            if !silent {\n  1932→                set_state(&state, IndexState::Error, Some(err.clone()));\n  1933→                emit_index_state(&app, \"Error\", Some(err.clone()));\n  1934→            }\n  1935→            // Silent mode: keep Ready state, just log the error\n  1936→        }\n  1937→        state.indexing_active.store(false, AtomicOrdering::Release);\n  1938→    });\n  1939→\n  1940→    Ok(())\n  1941→}\n  1942→\n  1943→fn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n  1944→    path.parent() == Some(home_dir)\n  1945→        && path\n  1946→            .file_name()\n  1947→            .and_then(|n| n.to_str())\n  1948→            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n  1949→            .unwrap_or(false)\n  1950→}\n  1951→\n  1952→fn preload_existing_entries(\n  1953→    conn: &Connection,\n  1954→    dir_prefix: &str,\n  1955→) -> HashMap<String, (Option<i64>, Option<i64>)> {\n  1956→    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n  1957→    let mut stmt = match conn.prepare(\n  1958→        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n  1959→    ) {\n  1960→        Ok(s) => s,\n  1961→        Err(_) => return HashMap::new(),\n  1962→    };\n  1963→\n  1964→    let mut map = HashMap::new();\n  1965→    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n  1966→        Ok((\n  1967→            row.get::<_, String>(0)?,\n  1968→            row.get::<_, Option<i64>>(1)?,\n  1969→            row.get::<_, Option<i64>>(2)?,\n  1970→        ))\n  1971→    }) {\n  1972→        Ok(r) => r,\n  1973→        Err(_) => return map,\n  1974→    };\n  1975→\n  1976→    for row in rows.flatten() {\n  1977→        map.insert(row.0, (row.1, row.2));\n  1978→    }\n  1979→    map\n  1980→}\n  1981→\n  1982→fn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n  1983→    if paths.is_empty() {\n  1984→        return Ok(());\n  1985→    }\n  1986→\n  1987→    let tx = conn.transaction().map_err(|e| e.to_string())?;\n  1988→    {\n  1989→        let mut stmt = tx\n  1990→            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n  1991→            .map_err(|e| e.to_string())?;\n  1992→        for path in paths {\n  1993→            stmt.execute(params![run_id, path])\n  1994→                .map_err(|e| e.to_string())?;\n  1995→        }\n  1996→    }\n  1997→    tx.commit().map_err(|e| e.to_string())?;\n  1998→    Ok(())\n  1999→}\n  2000→\n  2001→fn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n  2002→    let started = Instant::now();\n  2003→    perf_log(format!(\n  2004→        \"index_run_start home={} db={}\",\n  2005→        state.home_dir.to_string_lossy(),\n  2006→        state.db_path.to_string_lossy(),\n  2007→    ));\n  2008→\n  2009→    let mut conn = db_connection(&state.db_path)?;\n  2010→    set_indexing_pragmas(&conn)?;\n  2011→\n  2012→    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n  2013→    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n  2014→    // which can be 3-5x faster when loading hundreds of thousands of rows.\n  2015→    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n  2016→        .and_then(|v| v.parse::<i64>().ok())\n  2017→        .unwrap_or(0)\n  2018→        == 0;\n  2019→    if is_fresh_run {\n  2020→        let _ = conn.execute_batch(\n  2021→            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n  2022→             DROP INDEX IF EXISTS idx_entries_mtime;\n  2023→             DROP INDEX IF EXISTS idx_entries_name_nocase;\n  2024→             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n  2025→        );\n  2026→    }\n  2027→\n  2028→    let result = run_incremental_index_inner(app, state, &mut conn);\n  2029→\n  2030→    if is_fresh_run {\n  2031→        let _ = conn.execute_batch(\n  2032→            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n  2033→             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n  2034→             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n  2035→             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n  2036→        );\n  2037→    }\n  2038→\n  2039→    let _ = conn.execute_batch(\"ANALYZE\");\n  2040→    let _ = restore_normal_pragmas(&conn);\n  2041→\n  2042→    match &result {\n  2043→        Ok(_) => {\n  2044→            let _ = set_meta(&conn, \"index_complete\", \"1\");\n  2045→            let snapshot = state.status.lock().clone();\n  2046→            perf_log(format!(\n  2047→                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n  2048→                started.elapsed().as_millis(),\n  2049→                snapshot.scanned,\n  2050→                snapshot.indexed,\n  2051→                snapshot.entries_count,\n  2052→                snapshot.permission_errors,\n  2053→                snapshot.message,\n  2054→            ));\n  2055→        }\n  2056→        Err(err) => {\n  2057→            perf_log(format!(\n  2058→                \"index_run_error elapsed_ms={} err={}\",\n  2059→                started.elapsed().as_millis(),\n  2060→                err,\n  2061→            ));\n  2062→        }\n  2063→    }\n  2064→\n  2065→    result\n  2066→}\n  2067→\n  2068→fn run_incremental_index_inner(\n  2069→    app: &AppHandle,\n  2070→    state: &AppState,\n  2071→    conn: &mut Connection,\n  2072→) -> AppResult<()> {\n  2073→\n  2074→    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n  2075→        &state.home_dir,\n  2076→        &state.cwd,\n  2077→        state.path_ignores.as_ref(),\n  2078→        state.path_ignore_patterns.as_ref(),\n  2079→    );\n  2080→    let gi_filter = state.gitignore.get();\n  2081→\n  2082→    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n  2083→        .and_then(|v| v.parse().ok())\n  2084→        .unwrap_or(0);\n  2085→    let current_run_id = last_run_id + 1;\n  2086→    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n  2087→    let is_fresh = last_run_id == 0;\n  2088→\n  2089→    // Fresh index has no secondary indexes to maintain, so we can use larger\n  2090→    // batches to reduce transaction overhead (fewer commits = faster).\n  2091→    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n  2092→\n  2093→    let mut scanned: u64 = 0;\n  2094→    let mut indexed: u64 = 0;\n  2095→    let mut permission_errors: u64 = 0;\n  2096→    let mut current_path = String::new();\n  2097→    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n  2098→    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n  2099→    let mut last_emit = Instant::now();\n  2100→    let mut last_perf_emit = Instant::now();\n  2101→\n  2102→    // Preload scan_root-level entries (direct children only, not recursive)\n  2103→    let scan_str = state.scan_root.to_string_lossy().to_string();\n  2104→    let root_existing = preload_existing_entries(conn, &scan_str);\n  2105→\n  2106→    // Index scan_root itself\n  2107→    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n  2108→        scanned += 1;\n  2109→        row.run_id = current_run_id;\n  2110→        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n  2111→            if *old_mtime == row.mtime && *old_size == row.size {\n  2112→                stamp_batch.push(row.path);\n  2113→            } else {\n  2114→                batch.push(row);\n  2115→            }\n  2116→        } else {\n  2117→            batch.push(row);\n  2118→        }\n  2119→    }\n  2120→\n  2121→    // Partition direct children into priority vs deferred\n  2122→    let mut priority_roots: Vec<PathBuf> = Vec::new();\n  2123→    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n  2124→\n  2125→    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n  2126→        for dir_entry in entries.flatten() {\n  2127→            let child_path = dir_entry.path();\n  2128→\n  2129→            if should_skip_path_ext(\n  2130→                &child_path,\n  2131→                &runtime_ignored_roots,\n  2132→                &runtime_ignored_patterns,\n  2133→                Some(&gi_filter),\n  2134→                None,\n  2135→            ) {\n  2136→                continue;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"4858c690-ab87-4167-b612-62b17acfa4bb","timestamp":"2026-02-22T07:39:20.463Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;","numLines":250,"startLine":1887,"totalLines":5786}},"sourceToolAssistantUUID":"03bb30f9-3825-459c-81e0-689952104ca8"}
{"parentUuid":"4858c690-ab87-4167-b612-62b17acfa4bb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01PkNsU4s5ykgm7RxqvNdzQt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01K2khGsq9uT7b1RetXyYdn9","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2136,"limit":300},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3924,"cache_read_input_tokens":39969,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3924},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj9NWarphJw8PJcvBEo","type":"assistant","uuid":"69315636-cae6-4c0f-aeb7-0e8afc29c3f3","timestamp":"2026-02-22T07:39:22.764Z"}
{"parentUuid":"69315636-cae6-4c0f-aeb7-0e8afc29c3f3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01K2khGsq9uT7b1RetXyYdn9","toolUseID":"toolu_01K2khGsq9uT7b1RetXyYdn9","timestamp":"2026-02-22T07:39:22.771Z","uuid":"d400cb00-8357-4318-b0b2-9c042cf9b387"}
{"parentUuid":"69315636-cae6-4c0f-aeb7-0e8afc29c3f3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01K2khGsq9uT7b1RetXyYdn9","type":"tool_result","content":"  2136→                continue;\n  2137→            }\n  2138→\n  2139→            scanned += 1;\n  2140→            current_path = child_path.to_string_lossy().to_string();\n  2141→\n  2142→            if let Some(mut row) = index_row_from_path(&child_path) {\n  2143→                row.run_id = current_run_id;\n  2144→                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n  2145→                    if *old_mtime == row.mtime && *old_size == row.size {\n  2146→                        stamp_batch.push(row.path);\n  2147→                    } else {\n  2148→                        batch.push(row);\n  2149→                    }\n  2150→                } else {\n  2151→                    batch.push(row);\n  2152→                }\n  2153→            }\n  2154→\n  2155→            if child_path.is_dir() {\n  2156→                if is_deferred_dir(&child_path, &state.scan_root) {\n  2157→                    deferred_roots.push(child_path);\n  2158→                } else {\n  2159→                    priority_roots.push(child_path);\n  2160→                }\n  2161→            }\n  2162→        }\n  2163→    }\n  2164→\n  2165→\n  2166→    // Flush home-level stamp batch\n  2167→    if stamp_batch.len() >= flush_batch_size {\n  2168→        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2169→        stamp_batch.clear();\n  2170→    }\n  2171→\n  2172→    priority_roots.sort();\n  2173→    deferred_roots.sort();\n  2174→\n  2175→    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n  2176→    perf_log(format!(\n  2177→        \"index_scan_roots total={} priority+deferred\",\n  2178→        roots.len()\n  2179→    ));\n  2180→\n  2181→    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n  2182→    // Both passes use jwalk for parallel scanning\n  2183→    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n  2184→    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n  2185→\n  2186→\n  2187→    for pass in 0..2u8 {\n  2188→        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n  2189→        if pass == 1 && is_fresh {\n  2190→            break;\n  2191→        }\n  2192→        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n  2193→        let pass_started = Instant::now();\n  2194→        let mut pass_scanned = 0u64;\n  2195→        let mut pass_indexed = 0u64;\n  2196→\n  2197→        for root in &roots {\n  2198→            let root_started = Instant::now();\n  2199→            let mut root_scanned = 0u64;\n  2200→            let mut root_indexed = 0u64;\n  2201→            let mut root_permission_errors = 0u64;\n  2202→            let root_str = root.to_string_lossy().to_string();\n  2203→\n  2204→            // Fresh index: DB is empty, preload is unnecessary\n  2205→            let existing = if is_fresh {\n  2206→                HashMap::new()\n  2207→            } else {\n  2208→                let e = preload_existing_entries(conn, &root_str);\n  2209→                e\n  2210→            };\n  2211→\n  2212→            let gi_ref = gi_filter.clone();\n  2213→            let skip_roots = arc_ignored_roots.clone();\n  2214→            let skip_patterns = arc_ignored_patterns.clone();\n  2215→\n  2216→            let mut builder = jwalk::WalkDir::new(root)\n  2217→                .follow_links(false)\n  2218→                .skip_hidden(false)\n  2219→                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n  2220→            // Fresh index: no depth limit -- walk everything in one pass\n  2221→            if pass == 0 && !is_fresh {\n  2222→                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n  2223→            }\n  2224→            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n  2225→                children.retain(|entry_result| {\n  2226→                    entry_result\n  2227→                        .as_ref()\n  2228→                        .map(|entry| {\n  2229→                            let full_path = path.join(&entry.file_name);\n  2230→                            let is_dir = Some(entry.file_type.is_dir());\n  2231→                            !should_skip_path_ext(\n  2232→                                &full_path,\n  2233→                                &skip_roots,\n  2234→                                &skip_patterns,\n  2235→                                Some(&gi_ref),\n  2236→                                is_dir,\n  2237→                            )\n  2238→                        })\n  2239→                        .unwrap_or(false)\n  2240→                });\n  2241→            });\n  2242→\n  2243→            for result in walker {\n  2244→                match result {\n  2245→                    Ok(entry) => {\n  2246→                        let path = entry.path();\n  2247→                        if path == root.as_path() {\n  2248→                            continue;\n  2249→                        }\n  2250→\n  2251→                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n  2252→                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n  2253→                            continue;\n  2254→                        }\n  2255→\n  2256→                        scanned += 1;\n  2257→                        root_scanned += 1;\n  2258→                        current_path = path.to_string_lossy().to_string();\n  2259→\n  2260→                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n  2261→                            row.run_id = current_run_id;\n  2262→                            if is_fresh {\n  2263→                                // Fresh index: all entries are new, skip existing check\n  2264→                                indexed += 1;\n  2265→                                root_indexed += 1;\n  2266→                                batch.push(row);\n  2267→                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n  2268→                                if *old_mtime == row.mtime && *old_size == row.size {\n  2269→                                    stamp_batch.push(row.path);\n  2270→                                } else {\n  2271→                                    indexed += 1;\n  2272→                                    root_indexed += 1;\n  2273→                                    batch.push(row);\n  2274→                                }\n  2275→                            } else {\n  2276→                                indexed += 1;\n  2277→                                root_indexed += 1;\n  2278→                                batch.push(row);\n  2279→                            }\n  2280→                        }\n  2281→\n  2282→                        if batch.len() >= flush_batch_size {\n  2283→                            upsert_rows(conn, &batch)?;\n  2284→                            batch.clear();\n  2285→                        }\n  2286→\n  2287→                        if stamp_batch.len() >= flush_batch_size {\n  2288→                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2289→                            stamp_batch.clear();\n  2290→                        }\n  2291→\n  2292→                        if last_emit.elapsed() >= Duration::from_millis(200) {\n  2293→                            set_progress(state, scanned, indexed, &current_path);\n  2294→                            emit_index_progress(app, scanned, indexed, current_path.clone());\n  2295→                            last_emit = Instant::now();\n  2296→                        }\n  2297→                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n  2298→                        {\n  2299→                            perf_log(format!(\n  2300→                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n  2301→                                pass_label, scanned, indexed, current_path\n  2302→                            ));\n  2303→                            last_perf_emit = Instant::now();\n  2304→                        }\n  2305→                    }\n  2306→                    Err(err) => {\n  2307→                        scanned += 1;\n  2308→                        root_scanned += 1;\n  2309→                        permission_errors += 1;\n  2310→                        root_permission_errors += 1;\n  2311→                        if permission_errors <= 20 || perf_log_enabled() {\n  2312→                            eprintln!(\"[index] permission error: {}\", err);\n  2313→                        }\n  2314→                    }\n  2315→                }\n  2316→            }\n  2317→\n  2318→            pass_scanned += root_scanned;\n  2319→            pass_indexed += root_indexed;\n  2320→\n  2321→            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n  2322→                pass_label, root_str, root_started.elapsed().as_millis(),\n  2323→                root_scanned, root_indexed, root_permission_errors);\n  2324→            perf_log(format!(\n  2325→                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n  2326→                pass_label,\n  2327→                root.to_string_lossy(),\n  2328→                root_started.elapsed().as_millis(),\n  2329→                root_scanned,\n  2330→                root_indexed,\n  2331→                root_permission_errors,\n  2332→            ));\n  2333→        }\n  2334→\n  2335→        // Flush between passes\n  2336→        if !batch.is_empty() {\n  2337→            upsert_rows(conn, &batch)?;\n  2338→            batch.clear();\n  2339→        }\n  2340→        if !stamp_batch.is_empty() {\n  2341→            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2342→            stamp_batch.clear();\n  2343→        }\n  2344→\n  2345→        perf_log(format!(\n  2346→            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n  2347→            pass_label,\n  2348→            pass_started.elapsed().as_millis(),\n  2349→            pass_scanned,\n  2350→            pass_indexed,\n  2351→        ));\n  2352→\n  2353→        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n  2354→        // Fresh index uses per-root emit above instead.\n  2355→        if pass == 0 && !is_fresh {\n  2356→            let _ = refresh_and_emit_status_counts(app, state);\n  2357→            let _ = app.emit(\n  2358→                \"index_updated\",\n  2359→                IndexUpdatedEvent {\n  2360→                    entries_count: state.status.lock().entries_count,\n  2361→                    last_updated: now_epoch(),\n  2362→                    permission_errors,\n  2363→                },\n  2364→            );\n  2365→        }\n  2366→    }\n  2367→\n  2368→    if !batch.is_empty() {\n  2369→        upsert_rows(conn, &batch)?;\n  2370→    }\n  2371→\n  2372→    if !stamp_batch.is_empty() {\n  2373→        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2374→    }\n  2375→\n  2376→    set_progress(state, scanned, indexed, &current_path);\n  2377→    emit_index_progress(app, scanned, indexed, current_path.clone());\n  2378→\n  2379→    // Remove entries not seen in this run (deleted files)\n  2380→    // Fresh index: DB was empty before this run, no stale entries possible\n  2381→    let deleted_count: i64 = if is_fresh {\n  2382→        0\n  2383→    } else {\n  2384→        let count = conn\n  2385→            .query_row(\n  2386→                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n  2387→                params![current_run_id],\n  2388→                |row| row.get(0),\n  2389→            )\n  2390→            .unwrap_or(0);\n  2391→        conn.execute(\n  2392→            \"DELETE FROM entries WHERE run_id < ?1\",\n  2393→            params![current_run_id],\n  2394→        )\n  2395→        .map_err(|e| e.to_string())?;\n  2396→        count\n  2397→    };\n  2398→\n  2399→    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n  2400→\n  2401→    if deleted_count > 0 || indexed > 0 {\n  2402→        invalidate_search_caches(state);\n  2403→    }\n  2404→\n  2405→    let (entries_count, last_updated) = update_status_counts(state)?;\n  2406→    // Persist cached counts for instant startup next time\n  2407→    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n  2408→    if let Some(lu) = last_updated {\n  2409→        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n  2410→    }\n  2411→    let updated_at = last_updated.unwrap_or_else(now_epoch);\n  2412→\n  2413→    {\n  2414→        let mut status = state.status.lock();\n  2415→        status.state = IndexState::Ready;\n  2416→        status.permission_errors = permission_errors;\n  2417→        status.scanned = scanned;\n  2418→        status.indexed = indexed;\n  2419→        status.current_path = current_path.clone();\n  2420→        status.message = if permission_errors > 0 {\n  2421→            Some(format!(\n  2422→                \"{} permission/access error(s) occurred.\",\n  2423→                permission_errors\n  2424→            ))\n  2425→        } else {\n  2426→            None\n  2427→        };\n  2428→    }\n  2429→    emit_index_progress(app, scanned, indexed, current_path);\n  2430→    emit_index_updated(app, entries_count, updated_at, permission_errors);\n  2431→    emit_index_state(\n  2432→        app,\n  2433→        \"Ready\",\n  2434→        if permission_errors > 0 {\n  2435→            Some(format!(\"{} permission/access error(s)\", permission_errors))\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6fa31388-9f4f-451b-bb68-63f713dfc52e","timestamp":"2026-02-22T07:39:22.770Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))","numLines":300,"startLine":2136,"totalLines":5786}},"sourceToolAssistantUUID":"69315636-cae6-4c0f-aeb7-0e8afc29c3f3"}
{"parentUuid":"6fa31388-9f4f-451b-bb68-63f713dfc52e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01SVyX5KWoFaTxCRbeuCKsWU","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me understand the current indexing flow:\n\n1. For fresh index: single pass, no depth limit, uses `BATCH_SIZE * 5` = 50,000 for flush batch size\n2. For incremental: 2 passes (shallow depth <= 6, then deep)\n3. Uses jwalk for parallel scanning with `jwalk_num_threads()` = `(available_parallelism / 2).max(4).min(16)`\n4. Uses `preload_existing_entries` for each root during incremental scan\n\nThe user is seeing 1 minute 18 seconds for a reset + full index. Reset would wipe the DB and trigger a fresh index.\n\n\nNow I'm tracing through what happens when reset is called to understand where the time is being spent.","signature":"EskFCkYICxgCKkD6JddXpZlzdhG14IHHb6kDalmkGhFfni1Axt0MDZNqCnlazUNEACvy6ijpzjYudlV2Ag4yDo/TraOXl6YLexOnEgwUmrMuNsa1ABb3MSQaDERYJrlIqyjq0TAKWiIwo5XtRIzKC1FUsD6dC4bdyKv0l5ghgQlW4wge1C7QKA40I9EecuvnxkdjrnX7Rr9uKrAEqBqopbMMQ/KHZLWB3sTg5i/9X3YT2DBY5EjIdpWYMyPNT8Us7FCTGGViwOQIiMW6lHG8orBFSu+O75Am2Jxtf/8utsnfHzz19NtLf4wRVtlakh5HREQDsp3u+dI1v+02zO+DeObwEeuAs+Q8gmcjJZYGt5o8cWVWrnB9DFgMAZ8dtc0OKzsc4F1rVtBTBlU+odN3YjZsLc0HuKgmvdbRusCFT1xSwccYjiyP6QLUtE9YSnVnMG6BIrKVIvNpp4Cg9CS052NSNXDlez7zeeOIS8J0Jy8jg0uViL4U10IyioNHD3Y+7emAbczOyayIvpe/VZr17Kc3C79mAwII0eZqAWq+opibXaMotKmaLNkrOnP6wmtMcEfUR/v39YvLbnERHMItLNXgABQaEwgdIzGdRKHxhyZG52wvVVPbdnC8cVnDlv33/l5NKlZtA7D0DZUL1BDLcEyiGqE6HoT9CclBwtu9xksrC5HkupudZrXRS08Cn0x4GA8lykXnC3AMqXAyMpQj4H5s2heedFU7MFGMXQQoTCjyDXvt8vFvDZCAMZ8utbAIOua8jyubAoTaYeMvqzLLs7JNM0GvV7hMSNJF1d0jhmvO3bPv4hTbKPbOaR1/OrkggaQEeq6YvrhxnC41a+BAq8Spcexkv07DiVmjGpqxkZ9F//7rPprk9MwsKqmLtCUxHeSftJ0r01VgrMwuae/BKwuMAojdFfFnoorlqYNAIc8aN7r7IaMWNMZy1D0YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4431,"cache_read_input_tokens":43893,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4431},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj9YkyxuVtCdXhWrqUH","type":"assistant","uuid":"e968bde7-08e8-4535-8daa-70598ab971fa","timestamp":"2026-02-22T07:39:28.992Z"}
{"parentUuid":"e968bde7-08e8-4535-8daa-70598ab971fa","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01SVyX5KWoFaTxCRbeuCKsWU","type":"message","role":"assistant","content":[{"type":"text","text":"Let me look at what happens during reset and the DB init:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4431,"cache_read_input_tokens":43893,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4431},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj9YkyxuVtCdXhWrqUH","type":"assistant","uuid":"e838e356-01b4-414d-8bce-c3038ad265a5","timestamp":"2026-02-22T07:39:28.997Z"}
{"parentUuid":"e838e356-01b4-414d-8bce-c3038ad265a5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01SVyX5KWoFaTxCRbeuCKsWU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PApj1fwUtXWEjBi2WYVo6x","name":"Grep","input":{"pattern":"fn reset_index|fn init_db|set_indexing_pragmas|restore_normal_pragmas|PRAGMA|journal_mode|synchronous|cache_size","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4431,"cache_read_input_tokens":43893,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4431},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNj9YkyxuVtCdXhWrqUH","type":"assistant","uuid":"02174ab0-2c93-40be-bbca-551b5187106f","timestamp":"2026-02-22T07:39:31.148Z"}
{"parentUuid":"02174ab0-2c93-40be-bbca-551b5187106f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01PApj1fwUtXWEjBi2WYVo6x","toolUseID":"toolu_01PApj1fwUtXWEjBi2WYVo6x","timestamp":"2026-02-22T07:39:31.803Z","uuid":"6f8b1cce-f223-426f-a0c6-f8870c3b5393"}
{"parentUuid":"02174ab0-2c93-40be-bbca-551b5187106f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PApj1fwUtXWEjBi2WYVo6x","type":"tool_result","content":"384-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n385-    conn.execute_batch(&format!(\n386-        r#\"\n387:        PRAGMA journal_mode=WAL;\n388:        PRAGMA synchronous=NORMAL;\n389:        PRAGMA temp_store=MEMORY;\n390:        PRAGMA busy_timeout={busy_timeout_ms};\n391-        \"#,\n392-    ))\n393-    .map_err(|e| e.to_string())?;\n--\n401-fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n402-    let conn = db_connection_with_timeout(db_path, 500)?;\n403-    conn.execute_batch(\n404:        \"PRAGMA cache_size = -32768;\n405:         PRAGMA mmap_size = 268435456;\",\n406-    )\n407-    .map_err(|e| e.to_string())?;\n408-    Ok(conn)\n409-}\n410-\n411:pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n412-    conn.execute_batch(\n413-        r#\"\n414:        PRAGMA synchronous = OFF;\n415:        PRAGMA cache_size = -131072;\n416:        PRAGMA mmap_size = 536870912;\n417:        PRAGMA wal_autocheckpoint = 0;\n418-        \"#,\n419-    )\n420-    .map_err(|e| e.to_string())\n421-}\n422-\n423:pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n424-    conn.execute_batch(\n425-        r#\"\n426:        PRAGMA synchronous = NORMAL;\n427:        PRAGMA cache_size = -16384;\n428:        PRAGMA mmap_size = 268435456;\n429:        PRAGMA wal_autocheckpoint = 1000;\n430-        \"#,\n431-    )\n432-    .map_err(|e| e.to_string())?;\n433:    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n434-        .map_err(|e| e.to_string())?;\n435-    Ok(())\n436-}\n437-\n438:fn init_db(db_path: &Path) -> AppResult<()> {\n439-    let t = Instant::now();\n440-    let conn = db_connection(db_path)?;\n441-    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n442-\n443-    let current_version: i32 = conn\n444:        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n445-        .unwrap_or(0);\n446-    if current_version != DB_VERSION {\n447-        conn.execute_batch(\n--\n454-            \"#,\n455-        )\n456-        .map_err(|e| e.to_string())?;\n457:        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n458-            .map_err(|e| e.to_string())?;\n459-    }\n460-    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n--\n2007-    ));\n2008-\n2009-    let mut conn = db_connection(&state.db_path)?;\n2010:    set_indexing_pragmas(&conn)?;\n2011-\n2012-    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n2013-    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n--\n2037-    }\n2038-\n2039-    let _ = conn.execute_batch(\"ANALYZE\");\n2040:    let _ = restore_normal_pragmas(&conn);\n2041-\n2042-    match &result {\n2043-        Ok(_) => {\n--\n2963-}\n2964-\n2965-#[tauri::command]\n2966:async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n2967-    let state = state.inner().clone();\n2968-    tauri::async_runtime::spawn_blocking(move || {\n2969-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n--\n2982-        }\n2983-\n2984-        let conn = db_connection(&state.db_path)?;\n2985:        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n2986-        let _ = conn.execute_batch(\n2987:            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n2988-        );\n2989-        conn.execute(\"DELETE FROM entries\", [])\n2990-            .map_err(|e| e.to_string())?;"}]},"uuid":"5654ea74-f428-45fd-b797-a2e81dae2565","timestamp":"2026-02-22T07:39:31.802Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"384-    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n385-    conn.execute_batch(&format!(\n386-        r#\"\n387:        PRAGMA journal_mode=WAL;\n388:        PRAGMA synchronous=NORMAL;\n389:        PRAGMA temp_store=MEMORY;\n390:        PRAGMA busy_timeout={busy_timeout_ms};\n391-        \"#,\n392-    ))\n393-    .map_err(|e| e.to_string())?;\n--\n401-fn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n402-    let conn = db_connection_with_timeout(db_path, 500)?;\n403-    conn.execute_batch(\n404:        \"PRAGMA cache_size = -32768;\n405:         PRAGMA mmap_size = 268435456;\",\n406-    )\n407-    .map_err(|e| e.to_string())?;\n408-    Ok(conn)\n409-}\n410-\n411:pub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n412-    conn.execute_batch(\n413-        r#\"\n414:        PRAGMA synchronous = OFF;\n415:        PRAGMA cache_size = -131072;\n416:        PRAGMA mmap_size = 536870912;\n417:        PRAGMA wal_autocheckpoint = 0;\n418-        \"#,\n419-    )\n420-    .map_err(|e| e.to_string())\n421-}\n422-\n423:pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n424-    conn.execute_batch(\n425-        r#\"\n426:        PRAGMA synchronous = NORMAL;\n427:        PRAGMA cache_size = -16384;\n428:        PRAGMA mmap_size = 268435456;\n429:        PRAGMA wal_autocheckpoint = 1000;\n430-        \"#,\n431-    )\n432-    .map_err(|e| e.to_string())?;\n433:    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n434-        .map_err(|e| e.to_string())?;\n435-    Ok(())\n436-}\n437-\n438:fn init_db(db_path: &Path) -> AppResult<()> {\n439-    let t = Instant::now();\n440-    let conn = db_connection(db_path)?;\n441-    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n442-\n443-    let current_version: i32 = conn\n444:        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n445-        .unwrap_or(0);\n446-    if current_version != DB_VERSION {\n447-        conn.execute_batch(\n--\n454-            \"#,\n455-        )\n456-        .map_err(|e| e.to_string())?;\n457:        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n458-            .map_err(|e| e.to_string())?;\n459-    }\n460-    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n--\n2007-    ));\n2008-\n2009-    let mut conn = db_connection(&state.db_path)?;\n2010:    set_indexing_pragmas(&conn)?;\n2011-\n2012-    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n2013-    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n--\n2037-    }\n2038-\n2039-    let _ = conn.execute_batch(\"ANALYZE\");\n2040:    let _ = restore_normal_pragmas(&conn);\n2041-\n2042-    match &result {\n2043-        Ok(_) => {\n--\n2963-}\n2964-\n2965-#[tauri::command]\n2966:async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n2967-    let state = state.inner().clone();\n2968-    tauri::async_runtime::spawn_blocking(move || {\n2969-        if state.indexing_active.load(AtomicOrdering::Acquire) {\n--\n2982-        }\n2983-\n2984-        let conn = db_connection(&state.db_path)?;\n2985:        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n2986-        let _ = conn.execute_batch(\n2987:            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n2988-        );\n2989-        conn.execute(\"DELETE FROM entries\", [])\n2990-            .map_err(|e| e.to_string())?;","numLines":100},"sourceToolAssistantUUID":"02174ab0-2c93-40be-bbca-551b5187106f"}
{"parentUuid":"5654ea74-f428-45fd-b797-a2e81dae2565","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01HRqoA6XGPr6dc1WEiGLUy1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016gmtssRj7TKZnDD9dGXGqz","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2966,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1644,"cache_read_input_tokens":48324,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1644},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjACuumxgQJBp5d6GeN","type":"assistant","uuid":"d3a49659-cca9-4af1-995c-6a22a7f78aad","timestamp":"2026-02-22T07:39:33.949Z"}
{"parentUuid":"d3a49659-cca9-4af1-995c-6a22a7f78aad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_016gmtssRj7TKZnDD9dGXGqz","toolUseID":"toolu_016gmtssRj7TKZnDD9dGXGqz","timestamp":"2026-02-22T07:39:33.962Z","uuid":"c817d081-84de-4b33-9eb7-aa6af6efde53"}
{"parentUuid":"d3a49659-cca9-4af1-995c-6a22a7f78aad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016gmtssRj7TKZnDD9dGXGqz","type":"tool_result","content":"  2966→async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n  2967→    let state = state.inner().clone();\n  2968→    tauri::async_runtime::spawn_blocking(move || {\n  2969→        if state.indexing_active.load(AtomicOrdering::Acquire) {\n  2970→            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n  2971→        }\n  2972→\n  2973→        // Stop existing file watcher and wait for it to fully exit\n  2974→        state.watcher_stop.store(true, AtomicOrdering::Release);\n  2975→        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n  2976→        while state.watcher_active.load(AtomicOrdering::Acquire) {\n  2977→            if std::time::Instant::now() >= deadline {\n  2978→                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n  2979→                break;\n  2980→            }\n  2981→            std::thread::sleep(std::time::Duration::from_millis(50));\n  2982→        }\n  2983→\n  2984→        let conn = db_connection(&state.db_path)?;\n  2985→        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n  2986→        let _ = conn.execute_batch(\n  2987→            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n  2988→        );\n  2989→        conn.execute(\"DELETE FROM entries\", [])\n  2990→            .map_err(|e| e.to_string())?;\n  2991→        conn.execute(\"DELETE FROM meta\", [])\n  2992→            .map_err(|e| e.to_string())?;\n  2993→\n  2994→        {\n  2995→            let mut status = state.status.lock();\n  2996→            status.state = IndexState::Indexing;\n  2997→            status.entries_count = 0;\n  2998→            status.last_updated = None;\n  2999→            status.permission_errors = 0;\n  3000→            status.message = None;\n  3001→            status.scanned = 0;\n  3002→            status.indexed = 0;\n  3003→            status.current_path.clear();\n  3004→        }\n  3005→\n  3006→        invalidate_search_caches(&state);\n  3007→\n  3008→        emit_index_state(&app, \"Indexing\", None);\n  3009→        emit_index_updated(&app, 0, now_epoch(), 0);\n  3010→\n  3011→        // Allow new watcher to start\n  3012→        state.watcher_stop.store(false, AtomicOrdering::Release);\n  3013→\n  3014→        #[cfg(target_os = \"windows\")]\n  3015→        {\n  3016→            win::start_windows_indexing(app, state);\n  3017→            Ok(())\n  3018→        }\n  3019→        #[cfg(not(target_os = \"windows\"))]\n  3020→        {\n  3021→            start_full_index_worker(app, state)\n  3022→        }\n  3023→    })\n  3024→    .await\n  3025→    .map_err(|e| e.to_string())?\n  3026→}\n  3027→\n  3028→fn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n  3029→    if !search_log_enabled() {\n  3030→        return;\n  3031→    }\n  3032→\n  3033→    let log_path = db_path.with_file_name(\"search.log\");\n  3034→    let Ok(mut f) = fs::OpenOptions::new()\n  3035→        .create(true)\n  3036→        .append(true)\n  3037→        .open(&log_path)\n  3038→    else {\n  3039→        return;\n  3040→    };\n  3041→    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n  3042→    let _ = writeln!(\n  3043→        f,\n  3044→        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n  3045→        now_epoch(),\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6a31eee3-53b2-4764-99ca-931bc3dc1db3","timestamp":"2026-02-22T07:39:33.961Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"async fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),","numLines":80,"startLine":2966,"totalLines":5786}},"sourceToolAssistantUUID":"d3a49659-cca9-4af1-995c-6a22a7f78aad"}
{"parentUuid":"6a31eee3-53b2-4764-99ca-931bc3dc1db3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_014hf7aUA6hKkwu5qaZydYh2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me understand the current flow for fresh index:\n\n1. Reset: DELETE all entries, DELETE all meta, then call `start_full_index_worker`\n2. Fresh index: `is_fresh = true` (since `last_run_id = 0`)\n3. Fresh uses `BATCH_SIZE * 5 = 50,000` batch size\n4. Single unlimited-depth pass (no 2-pass)\n5. Uses jwalk with `jwalk_num_threads()` = `(n.get() / 2).max(4).min(16)`\n\nThe issue might be:\n\n\nThe reset flow waits for the watcher to stop, then deletes all entries and calls the full index worker. Even though it uses synchronous=OFF for speed, the DELETE operation itself could still be a bottleneck, and then there's the ANALYZE and index creation that happen after the bulk insert.\n\nFor a fresh index, `is_fresh` is determined by checking if `last_run_id` is 0, which gets reset when `DELETE FROM meta` is called. The real slowdown on macOS when scanning `$HOME` is likely coming from a combination of factors: the sheer number of files being traversed with unlimited depth, the string allocations happening during entry processing, the large batch SQL upserts, and then the ANALYZE plus index rebuild at the end. After the fresh scan completes, it does a final upsert with any remaining rows and stamps the run ID, though the stamp batch would be empty for a fresh index.\n\nThe main culprit is probably the index recreation—dropping 4 indexes at the start, doing a bulk insert of hundreds of thousands of rows, then recreating those 4 indexes on the large database. If there are 300,000+ files, the walking and inserting alone could take 30 seconds, and then rebuilding indexes on that volume would easily account for the remaining time to hit 78 seconds total.\n\nThe biggest win would be switching to multi-row VALUES inserts instead of executing one prepared statement per row, which would cut down the SQL parsing overhead significantly. Instead of N execute calls, we could batch 100 rows per statement. I should also skip ANALYZE after a fresh index build since it likely won't add much value. For parallelization, I could use a channel to send rows from the jwalk threads to a single database writer thread.\n\nActually, the real bottleneck is that with `BATCH_SIZE * 5 = 50,000` rows per transaction, we're making 50,000 individual `stmt.execute()` calls. Multi-row inserts using SQLite's `INSERT INTO ... VALUES (?, ?), (?, ?), ...` syntax could be 3-10x faster, supporting up to 500 rows per statement.\n\nThe prepared statement reuse within a transaction does help reduce overhead, but the per-execute call cost and SQLite's internal handling are still significant. Looking at the threading setup with `n/2` capped at 4-16 threads, an 8-core Mac would use 4 threads. For the 78-second runtime on 400k files, the bottleneck seems to be the stat() calls in `index_row_from_jwalk_entry` happening across parallel jwalk threads, combined with the individual insert overhead. Let me check what metadata the index functions are actually fetching.","signature":"Er4jCkYICxgCKkCMjXBCSF5vErg03xQ23DnbCAHnLr1LVWMVA3XpTCW5dQ0603RC9E0kticLza2MQX30RwJCZxaPaa54wyNaO+44Egw+SqsIV4vXhlJYM8saDBZcFnqRNx/GzYkAMCIwwEWLV3MndIJaqY9pm/z6L9eW1SXY3Yv6v5djapErHxnrZFYomzhRAQOWHnkZIgiOKqUi53NyJKiM36x5xBsARinejf/Yie3/T7Gvz1cSIts7UtC5hcGvQEIGDGlfgovsnE/lB9M5KEDkvtX7b4eIiD47aEfxYj3OPsQbFmW8H4R2E5SYMQjNOYW7Yzrj0bVVoUMTtkkxgJaqdtRYsHnOCwU2JCKFOe4By1ypVJOY8v5lfT5aPu70hfAl5UmGhv087iH4oBtuprhsXso1vryceIfvN2qLeWsDhPeDtg8sW45sjvIQutXjjqwhVDxpd4pVS8ff1HzslNCd3StHynnzepizhx4fOIVJjFPV5ljCbgRD51syC1IBb7moeCeLhxCjmK3krZmiaTb5J7jvYKISZ0mDNnrWnnycRPRJNM/3WYslMDMHnQeLQ9vSwYYze8XZBFLTPk0mlYzmLznO/6c9XpePMS3Rn1jTD7OzWIkLW9lsbF+VKXUq2JsfQ2s3mcQFxNeCjQ/RdKITb3eYRUJiN74QD6uTbLEXzrxixYlibxL9eBrDteyram4DS4/+KAewQwsBV3H6hKvT/OpvYFyLw+bvm4FdweLrGx1669HjhvgJk/ncUGAt9uk38kTviX2j9uAfxZz/T3rbEUDwFZ8f9U3PE5tsK5lG52iO8uZjb/NG5WSoLgd9piGg6hriHMUu0YD3S9XS04HxUwlb2kOhN9bDUVwyNj4JBRCRH7FSfPImoTNYdmoJWZo6D0tUh/lg7b/zbWM3sbmLJd6AjxSyX+LRdZQaJlowfFF25dUlSi9OC9avGUvT+7X/+qhebCJmhkXAJ64PJmP6XaPKqvCw9iia6oeG4xboew80HKvlYbqDXj/4kpvOUhBAL7yQfiSk0Ng5tFJyWO3ERKMXIgbheMeUuPllQg9M26ti2dumaCdOebwOptjgb0b4/keJxy+QoHsqyk8rBFaCsDO3Zjoq+cRq1TxqOPH9sU13LXgYuTHtxXQNkSOAMRQ7D29nKMNlxDCEqWixTormWK5tdIqs3Nnd29S+pMI8UMIX5kAsPq2sktR2QLJ6N22Tc2rDAj++s6hwFmKMK5pcNot1wJHw0k84IGXowmeIpXLJ+c8U3fVjaT0fVixKDc7Zt70I1Uu2zXqsAeWJFjiFUmR/BdPgeNzqcPbgLVfls+Vr0lZn3ncVCxOXrCTD95UrZEjI8EaN0vAIjKCf8mRvEjYXGcbYgEMpUc3FlkgfPL0CZAgUnA3YPwrSqEFMD5bZ+Ha/cENj4IVrYuzBaz25JqUqwBeS3szA5pLzt+RCT3tx79PV9VmnwyKHOCXd5iJuXUJdBIRcL/WZZTt5zPTvAaXqlHbrEBDCWhLbUhCe9S4LkCrD37R5dCNe6hPpcTb0ghq6X6HKtKZncNA3xJGVhze79lYcjjTEWONuPmXmdijXsF2ythFc0BJ4t/W6SfrLDDRyUdY2jyCRQmygDD2TNjWX1W4kk//JTDYUPO+VPKFZ+CuaSfn2CJoxKS20T+kSDerjGxqRuwdeofrhu/aHUGzINLDSW2vfW/e8DEQFllHDTyorm5ca35bbYj5tMENppVnMi26a8iRz55tXYHn1vfblOnGP7A/d8PpC/Njy/usuxYMDl/BgL1r7oWkp75yGU3oqrVfE+RuO9Z87wsxCQS1yblA/lQh2kdhxBvGlQ+OBUxK/4CRJ0WX33sL6iNU1qsGHybuXR0CRZH/i9Yboz+UkWiwUroOaN1t3u0buedmUBZLnQIuO6OuM/d6cyfnIpsyF+HJnpbOIL8DYFRj163voexS6BA/DhQSrjlf8JOIz6WDFwHurKa7Tt3H4LfNNCl0b9OKfdxuF5/FPhple/qsj1fjCYBpylTFA3wlFruIVBP95hJ9r2JBFEGbxlQ2APgzuKTng7aj16TfDfuJYQqI+XWqFkrwgvnAjc9SL1jG59uepXPoBcyTP7tOC/ZUltaKyQe0gaAu6zZ7PRqb9BgC7LaWJ60Buv6uqS7ZxRwNTt/wAdE7VzaSO0yHp8tb40O/RyIzIhDU3gdeUiU13spq3h9pHPkBVyIGHnJWphiBxTSSYFYoKnuhZzDoJxoXepX2+bqObjwGMeAP7bGOpAhpqAxDEuGUMIF1OKF0hgEJSt4u/0n0ARfFxKmN+Q4rYypVR7xbXYNi5X9MFm3+skvjwL+rQpAz52R2Mmd8Stk7b+4C4a9JXew5mQozENVAa+KM27PloB58NNkhApVjVH/bPvTv3dlvHD9m5dSk//c66HS/hfnZEQ1hTOOdxcTU9HbKzfRCVfZnnScOkLzj8ejljW/nv+2oMWtyaY8t8R31ZYedkj/Gws5SDAvzbCoTZibpyEndFBnWym8ZUCSAJs+2mc9jM4ZJx+2pf9mdZ72jSwBzDBp3XMfD636UpkCPP+MAbv/8nc4QsRaEdSZWaD9j+YuzO9OrQf0juUPdGzsAslDkUfVjw6a8XcphVZJOoQRRcM6yhA7T73ST6ghpnf840vUu6+NQpqkgBiajqQsMr2CdkWPQS4D0Hp1ZVNEWdV6lld30yd9vT6iIMOkz8DF7dEad5EN6h6lqD47SBz5gr2p5BvZOREdV1JPehclicMVK4CaAnFKWXlVGNzJ2RNoS4PNso+bbzxmYk88PILGGE8OlMKto3uYgBRECgF90l0JPxqyTa/Xkawa3VTEDJfE2muyg6iITG7z7P9JMGkuAieHkBb+sFY5Aw+LyKDe2VipNvZf4crH24/9x4jTLiDMJTLaqDqauFl4bzrLaMEqlGf9u1A4/5q71AZiea2W3wI9A9U7K7pJ4tmP6ubYfHdX06LQmB2tX4qUaSzZ+OhJo5q0s0N6a7sdceYBxqobGIaHJYMFZ3IMZrHyCRgOvOJs5Q+cA9kctiqtjIRiWj7By048JFJ11WHOfra+hHcql28pLXrCn9GqlkVGHWuScyZ9BZz0PLki6PKiIUyp6RA4g3iH8W6KrdvFjIhnEH1EeDWrNKNXHlPGH0cPrTcv1QBCnjXroxZrU950T2RTSfMH8PKn1N/uQY6wcGzLpi0oIEfG32nYBjCVPhawA9b1eKO3NTT6IbSxB3Twhq/3wA49Yl/e8vDEi6N5ujKCqU7BP06/Gjvmo+uVsGPMaUY45+Ft8kMBkk0deaHgnROcZj/cE+PKOnMOyWnH6J3gP2kZHgIhfjN1CKoy6Wi9tgdrgixjR5jZZLI4SAGDnX9Mvtj4nW/cKGMBsz3HeH3chNCbAvKUcO/oEWSITtPr+a9Fo0ulmySG1AmwNWA01ZmdEBiV91v/jQdThYLlfYBZfgxHV1OnTPK7eWjB39MpnPL8cA9dX0FBDmiZS1GMYdGW2s6fNA5i2nRgorFRyw2yX9AuoFSodDDd8twVlxwvm02W7uNCDgKbAI4zbMaW2Rd9YhlrKTgd1W6+MuWN1S4DNmgWDhceSsxHZATi6KGJcZ16DYn8eD6TjN62pg2nsO0gdpUmb1Be//dVHcTLeByo3P+O9oCnHEA7wdOjpA8iaNqFq1XWLInboNYXTZwjO+iZ78iDDUHbd9t1ND0HsB5ZnUA17VEcvkAAwy5/vi9wVlM7uqTGDqfWnAM31bkwx/lGdrr2a+8toaeECp9bMy7MJiX8IGk3cB5bW1G7C4qdBFDYx60vxRgbguj8VxiFOyt6nFoK7SQ0GX3/7Oa0K3TsJ6ltaHqYOxpafnjCsl2emKqx5mpjFRyupeEOOT43MDweEZHcKbcCOylbv6+KH2SatKIrOCdDDURoFWGT1NEJqNMXULdtRO3yj9Uuu3rKmB9C9hwcvbQM348sXUA4wEDvO4C+hMx6AiG+91Nef0evuJ4LbAv6Ty4SBJ2n+7bDPxTp1x7jnyAuz5Bop+1fwZgOX7d/IuFZ1fcR/+xwhR851iFrT7Dlmsie8RHhFpjT/uMJCmbrPXYbuH8o0W3o1V7nmrfY7LHysjtW2uM+b2szY3WLTwZ+cN8DRUa7xNXkmFkca19QxHDvWyqwtQDapMKavhhVv1LK0Ui+jRv+Jpn1fj4uuwsWFFya4uyZcvz9wXp2GoZsRnhGhLdSIlC/h8LHpTgdrD57qfi/C9YutrwDE50JCJRZ8FTvamXDhhzyFyQAqTe5DeuHaQA4ljkXceBj0+5VIwjALdpBuDw8yBqSUMR6Y0Vp6y0i+iXKenQYPeQjp2Qjkx1hGhrn6H81e7wb6BVcnEPiXamrcretSLXW/WjnNtgmoe2gUTEaAGjYIQv6Z+Y3QG3EHUaQPFrteWzbBV6Gx7ag/iTiRh+Qtp4krY9yg0wa4YQGTBibckkQOVY3zmdwBCYBUXqfAIAROhr6iIDJ/ltFkKEB41LXc/p6OW6wxXb+suNuzIHxjIGEh3G5qpvsvXu/eUURskuuLhYLT7oI6Z29S1yS4DBAxO5KgOSEtVI1oy3yZ/GYvQ5THKW+fXrwH6LchyFokhSNgsOnugbqdZVXBBDFxcAgDyEM/0/371luvcM4HO6SRJJ4Xrub8X2hzOmQQuJnGGKAM6Q+hV+hgyrk9BJbkzI8lshwKixewGePhJKMO0ytQwcLSuaZ/tRRKHLQX/1LJvLLDBzMgn2VpnsCVtz+TL+RfqaZvADiJ412yVTPHSVaKAOSaEb0AUgxZvNFGsxuKSXHDN4wVcDMtH0Ko4VeVpue9TLXP0rRMg9EZdNPhoIXaMPE0uAfxJvxRbbSnw+1j/dDeiJCLs9SIT/7aMgZJB+y7xQR3KOHany+qWoDZibOYbnJE2mwgEGKeoC80J2KvoOaTo1d4DWgaAYu3Idau1l1MLmZq0/tz8o8C+GGv8uARBgR6xwhZ+D0fj1ugWKNpWZ5ug14ecHCGaizZOwIQz5tsYlgg6zBJtA/b2yDOsNTK9slHiVKeWSk/Uxlu0iNG0aODQeFqWWvhGFeU0YGN/swRyovYOG6h68Pomdr6n4SRjHmU7vcibafrRWFFcrl5KmfxWrm4sqNSkMJQr/RZY1U1Erxsl/gDegcufhuMfyl4hyOmeOXN7g6Ok8psYoIFtQNei8Qc/odihd9sD9fo1yOMDJwK3yAIyQlX7KmRCnaubB2YTpQvH3mVvNfKXKUOpaLUcwUlaZclFrBbVpm2QddNoIxUaT5CUfWsc9F8ZVs0h3Kr66Mr+t8579csoipE+QK+Lpm+lxZ2ZYkUQPv+GtSwUHOFOl8jYkybcPLajYENhGsqeaherPwJgBqpkHK0pCt/Rmm2kVAQ5wrPCQtuH0Q4f6zqrtO4VFs3FLsSpYLhPEINCmWchfVE9tAnPfavnbkg3yqYe0OYdiv3/0FzpAxsvk1XxSDou6/4DIrO3SsPXYbYA1WzXi/X6+HtOF/sFwMsFaMvE+6/BedgnqLfRZvTDLsMw286sqivvu+VNz//g+Lv28rHVhILhrUmHt+y33GY+/5sfpeJweLz/37dfNK6S7FD05C/Zb2EhzU35bABZ0hujv9eJKMppA7auWGBUpNS3pYkhZdcFxlUTAMJCqg+5nDTOeyY8hUGW2GUT1I7DxjRQ+1b2StoWBoU8ulS+ntIpvHG56F5lsDk4VhHboL2ng5UaBXf/EzefehyZp1szx81ss6Nm203fHyrP4ra6WgKhtAEoilMve5ECy0P9seXe8k9k0g7ycuk5UCR0KXtCdyRHr34zvXWXYhSukveA6kRUGvAdYVNNKG7+YUXbGuTOTFfiUZW02Cz/KuMvoYyaUqvt7ooGiX/xuDezoMVGh0d1OefiyQKEOFlT+InymSJsjVs8UGDxEiyYiV1ThDDnv2pq5GE754gR/47XYKwMOT1N2jxywS1PH8luYXPyktFrDQpKZAsNBtgdmurk8RZmoDDHRGxdHnEVIH88vrX8HcOb4tq6xtNnMQ+gx2sauD8KyT6rh0+2J+usB0FS9ALZxjAYx/vqGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1384,"cache_read_input_tokens":49968,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1384},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjANDkMe83Lr2ccSkUD","type":"assistant","uuid":"0ab55372-4f07-4944-87af-c96ce5b976af","timestamp":"2026-02-22T07:40:06.363Z"}
{"parentUuid":"0ab55372-4f07-4944-87af-c96ce5b976af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_014hf7aUA6hKkwu5qaZydYh2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0147rvziJMGGuZ3FHyTnVPeB","name":"Grep","input":{"pattern":"fn index_row_from_jwalk_entry|fn index_row_from_path|fn collect_rows_recursive","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1384,"cache_read_input_tokens":49968,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1384},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjANDkMe83Lr2ccSkUD","type":"assistant","uuid":"75d7066e-fbb4-435c-bc4e-c7fc7ba80cf5","timestamp":"2026-02-22T07:40:06.414Z"}
{"parentUuid":"75d7066e-fbb4-435c-bc4e-c7fc7ba80cf5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_0147rvziJMGGuZ3FHyTnVPeB","toolUseID":"toolu_0147rvziJMGGuZ3FHyTnVPeB","timestamp":"2026-02-22T07:40:07.114Z","uuid":"b9156d69-0ddd-4e7b-a270-edd24a4e1da4"}
{"parentUuid":"75d7066e-fbb4-435c-bc4e-c7fc7ba80cf5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0147rvziJMGGuZ3FHyTnVPeB","type":"tool_result","content":"1273-        .iter()\n1274-        .any(|root| path == root || path.starts_with(root))\n1275-    {\n1276-        return true;\n1277-    }\n1278-    if ignored_patterns\n1279-        .iter()\n1280-        .any(|pattern| matches_ignore_pattern(&s, pattern))\n1281-    {\n1282-        return true;\n1283-    }\n1284-    if let Some(gi) = gitignore {\n1285-        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n1286-        if gi.is_ignored(path, is_dir) {\n1287-            return true;\n1288-        }\n1289-    }\n1290-    false\n1291-}\n1292-\n1293-fn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n1294-    if is_dir {\n1295-        return None;\n1296-    }\n1297-\n1298-    path.extension()\n1299-        .and_then(|ext| ext.to_str())\n1300-        .map(|ext| ext.to_lowercase())\n1301-}\n1302-\n1303:pub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n1304-    let is_dir = metadata.is_dir();\n1305-\n1306-    let name = path\n1307-        .file_name()\n1308-        .map(|v| v.to_string_lossy().to_string())\n1309-        .or_else(|| {\n1310-            if path == Path::new(\"/\") {\n1311-                Some(\"/\".to_string())\n1312-            } else {\n1313-                None\n1314-            }\n1315-        })?;\n1316-\n1317-    let dir = path\n1318-        .parent()\n1319-        .map(|p| p.to_string_lossy().to_string())\n1320-        .unwrap_or_else(|| \"/\".to_string());\n1321-\n1322-    let mtime = metadata\n1323-        .modified()\n1324-        .ok()\n1325-        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n1326-        .map(|d| d.as_secs() as i64);\n1327-\n1328-    let size = if metadata.is_file() {\n1329-        Some(metadata.len() as i64)\n1330-    } else {\n1331-        None\n1332-    };\n1333-\n1334-    Some(IndexRow {\n1335-        path: path.to_string_lossy().to_string(),\n1336-        name,\n1337-        dir,\n1338-        is_dir: if is_dir { 1 } else { 0 },\n1339-        ext: extension_for(path, is_dir),\n1340-        mtime,\n1341-        size,\n1342-        indexed_at: now_epoch(),\n1343-        run_id: 0,\n1344-    })\n1345-}\n1346-\n1347:fn index_row_from_path(path: &Path) -> Option<IndexRow> {\n1348-    let metadata = fs::symlink_metadata(path).ok()?;\n1349-    index_row_from_path_and_metadata(path, &metadata)\n1350-}\n1351-\n1352-fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n1353-    let metadata = entry.metadata().ok()?;\n1354-    index_row_from_path_and_metadata(entry.path(), &metadata)\n1355-}\n1356-\n1357:fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n1358-    let metadata = entry.metadata().ok()?;\n1359-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n1360-}\n1361-\n1362:fn collect_rows_recursive(\n1363-    root: &Path,\n1364-    ignored_roots: &[PathBuf],\n1365-    ignored_patterns: &[IgnorePattern],\n1366-) -> Vec<IndexRow> {\n1367-    let mut rows = Vec::new();\n1368-\n1369-    let iter = WalkDir::new(root)\n1370-        .follow_links(false)\n1371-        .into_iter()\n1372-        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n1373-\n1374-    for entry in iter.flatten() {\n1375-        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n1376-            rows.push(row);\n1377-        }\n1378-    }\n1379-\n1380-    rows\n1381-}\n1382-\n1383-fn entry_from_index_row(row: IndexRow) -> EntryDto {\n1384-    EntryDto {\n1385-        path: row.path,\n1386-        name: row.name,\n1387-        dir: row.dir,\n1388-        is_dir: row.is_dir == 1,\n1389-        ext: row.ext,\n1390-        size: row.size,\n1391-        mtime: row.mtime,\n1392-    }"}]},"uuid":"0fc9f118-fa89-47b4-9858-c4df5efb5723","timestamp":"2026-02-22T07:40:07.112Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"1273-        .iter()\n1274-        .any(|root| path == root || path.starts_with(root))\n1275-    {\n1276-        return true;\n1277-    }\n1278-    if ignored_patterns\n1279-        .iter()\n1280-        .any(|pattern| matches_ignore_pattern(&s, pattern))\n1281-    {\n1282-        return true;\n1283-    }\n1284-    if let Some(gi) = gitignore {\n1285-        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n1286-        if gi.is_ignored(path, is_dir) {\n1287-            return true;\n1288-        }\n1289-    }\n1290-    false\n1291-}\n1292-\n1293-fn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n1294-    if is_dir {\n1295-        return None;\n1296-    }\n1297-\n1298-    path.extension()\n1299-        .and_then(|ext| ext.to_str())\n1300-        .map(|ext| ext.to_lowercase())\n1301-}\n1302-\n1303:pub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n1304-    let is_dir = metadata.is_dir();\n1305-\n1306-    let name = path\n1307-        .file_name()\n1308-        .map(|v| v.to_string_lossy().to_string())\n1309-        .or_else(|| {\n1310-            if path == Path::new(\"/\") {\n1311-                Some(\"/\".to_string())\n1312-            } else {\n1313-                None\n1314-            }\n1315-        })?;\n1316-\n1317-    let dir = path\n1318-        .parent()\n1319-        .map(|p| p.to_string_lossy().to_string())\n1320-        .unwrap_or_else(|| \"/\".to_string());\n1321-\n1322-    let mtime = metadata\n1323-        .modified()\n1324-        .ok()\n1325-        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n1326-        .map(|d| d.as_secs() as i64);\n1327-\n1328-    let size = if metadata.is_file() {\n1329-        Some(metadata.len() as i64)\n1330-    } else {\n1331-        None\n1332-    };\n1333-\n1334-    Some(IndexRow {\n1335-        path: path.to_string_lossy().to_string(),\n1336-        name,\n1337-        dir,\n1338-        is_dir: if is_dir { 1 } else { 0 },\n1339-        ext: extension_for(path, is_dir),\n1340-        mtime,\n1341-        size,\n1342-        indexed_at: now_epoch(),\n1343-        run_id: 0,\n1344-    })\n1345-}\n1346-\n1347:fn index_row_from_path(path: &Path) -> Option<IndexRow> {\n1348-    let metadata = fs::symlink_metadata(path).ok()?;\n1349-    index_row_from_path_and_metadata(path, &metadata)\n1350-}\n1351-\n1352-fn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n1353-    let metadata = entry.metadata().ok()?;\n1354-    index_row_from_path_and_metadata(entry.path(), &metadata)\n1355-}\n1356-\n1357:fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n1358-    let metadata = entry.metadata().ok()?;\n1359-    index_row_from_path_and_metadata(&entry.path(), &metadata)\n1360-}\n1361-\n1362:fn collect_rows_recursive(\n1363-    root: &Path,\n1364-    ignored_roots: &[PathBuf],\n1365-    ignored_patterns: &[IgnorePattern],\n1366-) -> Vec<IndexRow> {\n1367-    let mut rows = Vec::new();\n1368-\n1369-    let iter = WalkDir::new(root)\n1370-        .follow_links(false)\n1371-        .into_iter()\n1372-        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n1373-\n1374-    for entry in iter.flatten() {\n1375-        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n1376-            rows.push(row);\n1377-        }\n1378-    }\n1379-\n1380-    rows\n1381-}\n1382-\n1383-fn entry_from_index_row(row: IndexRow) -> EntryDto {\n1384-    EntryDto {\n1385-        path: row.path,\n1386-        name: row.name,\n1387-        dir: row.dir,\n1388-        is_dir: row.is_dir == 1,\n1389-        ext: row.ext,\n1390-        size: row.size,\n1391-        mtime: row.mtime,\n1392-    }","numLines":120},"sourceToolAssistantUUID":"75d7066e-fbb4-435c-bc4e-c7fc7ba80cf5"}
{"parentUuid":"0fc9f118-fa89-47b4-9858-c4df5efb5723","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Qcje8XfdTTxhfDXmoaUuzh","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the full picture. Let me think about optimization opportunities:\n\n1. **Multi-row INSERT**: Instead of inserting rows one at a time in a loop, use batched multi-row VALUES. SQLite's `INSERT INTO ... VALUES (...), (...), ...` is much more efficient.\n\n2. **The `entry.metadata()` call**: In `index_row_from_jwalk_entry`, it calls `entry.metadata()` which may call `stat()`. jwalk should have the metadata already from the directory scan. Let me check what metadata jwalk provides.\n\n3. **jwalk thread count**: Currently `(n/2).max(4).min(16)`. For a 10-core Mac, that's 5 threads. Increasing to full parallelism might help if IO isn't the bottleneck.\n\n\n4. **ANALYZE and checkpoint overhead**: Running `ANALYZE` on large databases and the WAL checkpoint at the end can both be slow, so I should consider skipping them for fresh indexes.\n\nThe multi-row INSERT optimization seems like the biggest win here. Instead of executing individual statements in a loop, I can batch multiple rows into a single INSERT statement with multiple value sets, which eliminates the per-execute overhead even within a transaction.\n\nSQLite's parameter limit means I can fit about 111 rows per statement (999 parameters ÷ 9 columns), so I'd need to chunk the batch accordingly. For a fresh index where there are no conflicts, I can use a plain INSERT instead of INSERT OR IGNORE, which is simpler.\n\nNow I'm wondering whether the single-row execute calls are actually the bottleneck compared to the file I/O itself...\n\nWith 400k files in 50k batches, that's 8 transactions each containing 50k individual executes. Even accounting for parameter binding and B-tree updates, SQLite with WAL mode and synchronous=OFF can handle around 500k to 1M simple inserts per second, so 400k rows would only take 0.4-0.8 seconds. The real bottleneck is the file system walk traversing deep directories, which could easily take 20-40 seconds on a typical home directory.\n\nLooking at the actual code, I see that `entry.metadata()` is being called for each file, but jwalk already provides metadata from the directory read itself, so there shouldn't be additional stat calls happening there. The other culprits are likely the string allocations from repeated `to_string()` and `to_string_lossy()` calls, plus the index creation overhead at the end when building 4 indexes on a large table. shouldn't require an extra stat() syscall. Let me verify this...\n\nActually, jwalk's DirEntry does have cached metadata from the readdir operation. `entry.metadata()` should use cached data. But looking at the jwalk source, the metadata might require an additional stat if not yet fetched.\n\nWait, there's something important here. `entry.path()` allocates a new `PathBuf` every time! In the hot loop we're calling it multiple times and then converting to strings, which means we're doing a `PathBuf` allocation plus separate String allocations for the directory, filename, and extension. For 400k files, that's millions of allocations just for string conversions when we could be reusing the path data more efficiently.\n\nThe real issue is that jwalk's parallel directory traversal produces results that get consumed serially in the main loop. The rayon threads are doing the parallel work to read directories and filter children, but then we iterate through the results one at a time, process them, and write to the database serially. So we're not actually getting parallelism in the processing phase—we're just getting parallelism in the I/O phase of reading directories.\n\nThe bottleneck comes down to what happens per item: calling `entry.metadata()` might trigger an extra syscall since `readdir` only gives us the file type, not the full stat information. If we're calling stat for every entry to get mtime or other details, that's adding latency to the serial processing loop.\n\nBut jwalk parallelizes those stat calls across its thread pool, so with multiple threads the throughput is much better than doing it sequentially. The real constraint is probably the main thread collecting results from the channel and writing to the database sequentially. To speed things up, I should increase the jwalk thread count to maximize parallel stat throughput and batch more rows per database insert.\n\nLet me check the timing logs to see where the 78 seconds is actually going. The code already has instrumentation that logs elapsed time and counts for each pass, plus a final summary. I need to verify if the performance logging is enabled by default so I can see the breakdown.\n\nLooking at the perf log setup, it requires the `EVERYTHING_PERF_LOG` environment variable, but the `[timing]` logs use direct stderr output so they should always show up. The user should run this and check the console output to see where time is being spent, but since I can't run it interactively, I'll focus on the likely bottlenecks: thread count for fresh indexes, the ANALYZE step, and whether database writes are blocking the indexing process. The filesystem enumeration is probably the real bottleneck here, not the database writes. Let me think through some concrete optimizations: I could increase the thread count for jwalk when doing a fresh index since we're just doing I/O-bound stat calls, scaling it up to use more cores. For the database side, I could switch to multi-row INSERT statements for fresh indexes to reduce the overhead of individual execute() calls.\n\nWriting the implementation... ), (?,?,?,?,?,?,?,?,?), ...\n\nUp to 111 rows per statement, all within a larger transaction to eliminate individual statement preparation overhead.\n\nI could also use a producer-consumer pattern with jwalk results collected on a thread and DB writes on the main thread, though the current code already does this implicitly since jwalk is multi-threaded. Other options include reducing string allocations with `Cow<str>`, skipping ANALYZE on a fresh index, or skipping the WAL checkpoint which can be slow on large databases.\n\nFor a typical Mac with ~400k files, the file walk dominates at 20-50s, while DB inserts take 2-5s with batching, index creation takes 5-15s, ANALYZE takes 5-10s, and WAL checkpoint takes 1-5s. The real bottleneck is the file walk itself—with jwalk's parallel scanning, I'm limited by either kernel readdir and stat syscalls or thread synchronization overhead, and on macOS each stat() call is quite fast at 1-5μs in the kernel.\n\nIn practice though, on a cold SSD filesystem, stat() can take 50-200μs each, so with 400k files and 4 threads I'd expect around 10 seconds, but with 8 threads that drops to 5 seconds. Increasing thread count could cut the file walk time in half.\n\nFor the database side, I'm batching 50k rows per transaction across 8 transactions, and I can further optimize by packing multiple rows into a single INSERT statement—up to 111 rows per statement to avoid hitting SQLite's parameter limit—which eliminates individual statement preparation overhead.\n\nLooking at the full pipeline: file walk takes 20-40 seconds, database inserts around 2 seconds, index creation on 4 indexes maybe 5-12 seconds, plus ANALYZE and WAL checkpoint each adding a few seconds, so the total is probably dominated by the file walk time.\n\nTo get under 50 seconds from the current 78, I need to save at least 28 seconds—the biggest opportunities are increasing thread count for the file walk (could save 5-15 seconds), skipping ANALYZE since a fresh index is already optimal (3-5 seconds), and either skipping the WAL checkpoint or using a passive mode instead of truncate (2-5 seconds).\n\nLet me reconsider the fresh index flow more carefully—when it's a fresh run, the code drops the secondary indexes first.\n\nThen it runs the incremental indexing with the fresh flag set, followed by recreating those four indexes using CREATE INDEX IF NOT EXISTS statements. After that comes ANALYZE and finally the WAL checkpoint with TRUNCATE mode.\n\nLooking at the actual execution order in the code, the indexes are created while `synchronous=OFF` is still active from the earlier pragma setup, so that optimization is already in place. But then I'm noticing the indexes are created after the inner indexing function completes, which means there's a potential ordering issue to consider.\n\nThe real bottleneck appears to be the WAL checkpoint that happens during `restore_normal_pragmas`. With `synchronous=OFF` during all the inserts and `wal_autocheckpoint=0` disabled, the WAL file accumulates a massive amount of data—potentially 80MB or more from 400k rows. When the checkpoint finally runs, it has to flush all of that to disk at once, which is where the performance hit comes from.\n\nNow I need to figure out where the 78 seconds is actually going. The user reported the total time from reset to completion, so I should add more granular timing logs to track each phase and see which roots are taking the longest.\n\nLooking at what's typically in a macOS home directory, the priority roots like Documents and Downloads scan quickly, but the deferred ones like Library are where things get slow. Library itself gets deferred but still scanned, and even with the skip paths filtering out Caches, Developer/CoreSimulator, and Logs, there's still a lot left—Application Support, the remaining Developer directories, Preferences, Mobile Documents. That's probably where most of the time is going.\n\nFor actual performance gains, I could increase the jwalk thread count for fresh indexes to use more parallelism, skip the ANALYZE step initially since a fresh index doesn't have statistics anyway and could run it asynchronously later, or switch to a faster journal mode during the initial insert phase instead of WAL.\n\nBut thinking about this more strategically—the real bottleneck is likely the index creation itself. Running all four CREATE INDEX commands in parallel would be ideal, but SQLite doesn't support parallel writes even in WAL mode, so that's not viable. The most practical win would be deferring ANALYZE to run in the background after the index is marked ready, letting the user see results faster.\n\nI could also boost the scan thread count from `(n/2).max(4)` to `n.max(8)` to parallelize the file traversal more aggressively. And in the row indexing logic, I'm calling `entry.metadata()` which might trigger unnecessary stat calls—since jwalk already provides file type information from readdir, I only need to stat for mtime and size. The stamp_run_id_batch optimization is already handled since fresh indexes have an empty existing map.\n\nFor path building, instead of calling `entry.path()` which allocates a new PathBuf each time, I could combine `entry.parent_path` with `entry.file_name` directly. Looking at what jwalk exposes, `file_type` is already available from readdir without any syscall, so I don't need metadata just to check if something's a directory—but I'll still need it for mtime and size.\n\nThe real question is whether the metadata calls are happening in parallel or serially. The `process_read_dir` closure runs in the rayon thread pool, but `index_row_from_jwalk_entry` gets called in the main loop, which means any stat syscalls there would be serial and could become a bottleneck. The issue is that `entry.metadata()` calls are happening serially on the main thread when `index_row_from_jwalk_entry` runs, creating a bottleneck. I should move the metadata fetching into the `process_read_dir` closure where rayon threads can parallelize it instead. The closure currently filters entries based on path and file type, but I can pre-fetch metadata there while still in the parallel context. Looking at jwalk's API, the `DirEntry` type has a `metadata()` method that lazily fetches metadata on demand rather than pre-caching it. I could leverage the `process_read_dir` callback to pre-fetch metadata in parallel within the rayon thread pool, or use rayon's parallel iterators directly on the filtered children to batch the metadata calls. I could use `process_read_dir` to prefetch metadata while filtering entries, since that callback runs in a rayon thread and would parallelize the stat() calls across directories.\n\nPrefetching metadata in the callback... I'm checking whether jwalk caches metadata results—if the DirEntry stores a cloned Metadata field, calling it twice would be cheap, but if it always calls symlink_metadata, I'd be duplicating syscalls. Without being certain of the exact jwalk version behavior, I should focus on the most straightforward optimizations: increasing thread count could save 10-20 seconds, which is a safer bet than relying on metadata caching assumptions.\n\nLooking at the batch sizing, I'm realizing that with synchronous=OFF, commit overhead is already minimal at 50k rows per batch, so pushing to 200k might not yield much benefit—the real gains are likely from reducing the number of transactions themselves or from the simpler tuning knobs like thread count and skipping ANALYZE.\n\nNow I'm tracing through the actual indexing flow more carefully: for each root directory, it preloads existing entries (empty for a fresh index), then walks and inserts. The batch is shared across all roots, so it accumulates until hitting the flush threshold. For roots with many files like Library, the batch flushes multiple times within that root, which is fine. Let me check what else might be causing slowness—I should look at the path filtering logic.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2976,"cache_read_input_tokens":51352,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2976},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjCottwfaHNgWqVCFkX","type":"assistant","uuid":"c879fd28-b241-4b74-94bc-57be89cb65ed","timestamp":"2026-02-22T07:42:42.570Z"}
{"parentUuid":"c879fd28-b241-4b74-94bc-57be89cb65ed","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Qcje8XfdTTxhfDXmoaUuzh","type":"message","role":"assistant","content":[{"type":"text","text":"Let me look at the skip path functions and understand what might be slow:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2976,"cache_read_input_tokens":51352,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2976},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjCottwfaHNgWqVCFkX","type":"assistant","uuid":"c13dca10-4883-41a8-8be6-e0b9c8612d13","timestamp":"2026-02-22T07:42:42.581Z"}
{"parentUuid":"c13dca10-4883-41a8-8be6-e0b9c8612d13","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Qcje8XfdTTxhfDXmoaUuzh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KodYRASwPNHnt9J1eTYPzm","name":"Grep","input":{"pattern":"fn should_skip_path_ext|fn should_skip_path|gitignore|is_ignored","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":15},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2976,"cache_read_input_tokens":51352,"output_tokens":7966,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":2976,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNjCottwfaHNgWqVCFkX","type":"assistant","uuid":"9d2e64e4-ec72-4d6a-92a5-f988e42ff766","timestamp":"2026-02-22T07:42:43.416Z"}
{"parentUuid":"9d2e64e4-ec72-4d6a-92a5-f988e42ff766","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01KodYRASwPNHnt9J1eTYPzm","toolUseID":"toolu_01KodYRASwPNHnt9J1eTYPzm","timestamp":"2026-02-22T07:42:44.051Z","uuid":"d985f189-e731-4566-a141-0fda5b8134af"}
{"parentUuid":"9d2e64e4-ec72-4d6a-92a5-f988e42ff766","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KodYRASwPNHnt9J1eTYPzm","type":"tool_result","content":"14-    },\n15-    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n16-};\n17-\n18-use parking_lot::{Mutex, RwLock};\n19-use rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\n20-use serde::Serialize;\n21-use tauri::{AppHandle, Emitter, Manager, State};\n22-#[cfg(target_os = \"macos\")]\n23-use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n24-#[cfg(target_os = \"windows\")]\n25-use std::os::windows::process::CommandExt;\n26-use walkdir::WalkDir;\n27-\n28-mod fd_search;\n29:mod gitignore_filter;\n30-#[cfg(target_os = \"macos\")]\n31-mod mac;\n32-mod mem_search;\n33-mod query;\n34-#[cfg(target_os = \"windows\")]\n35-mod win;\n36-use fd_search::{FdSearchCache, FdSearchResultDto};\n37-use query::{escape_like, parse_query, SearchMode};\n38-\n39-const DEFAULT_LIMIT: u32 = 300;\n40-const SHORT_QUERY_LIMIT: u32 = 100;\n41-const MAX_LIMIT: u32 = 1000;\n42-pub(crate) const BATCH_SIZE: usize = 10_000;\n43-const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n44-pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n--\n278-    op_type: &'static str,\n279-    at: Instant,\n280-}\n281-\n282-#[derive(Debug, Clone, PartialEq, Eq)]\n283-pub(crate) enum IgnorePattern {\n284-    AnySegment(String),\n285-    Glob(String),\n286-}\n287-\n288-#[derive(Debug, Clone)]\n289-pub(crate) struct IgnoreRulesCache {\n290-    roots: Vec<PathBuf>,\n291-    patterns: Vec<IgnorePattern>,\n292-    pathignore_mtime: Option<SystemTime>,\n293:    gitignore_mtime: Option<SystemTime>,\n294-}\n295-\n296-#[derive(Debug, Clone)]\n297-pub(crate) struct AppState {\n298-    pub(crate) db_path: PathBuf,\n299-    pub(crate) home_dir: PathBuf,\n300-    pub(crate) scan_root: PathBuf,\n301-    pub(crate) cwd: PathBuf,\n302-    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n303-    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n304-    pub(crate) db_ready: Arc<AtomicBool>,\n305-    pub(crate) indexing_active: Arc<AtomicBool>,\n306-    pub(crate) status: Arc<Mutex<IndexStatus>>,\n307-    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n308-    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n309-    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n310-    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n311-    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n312:    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n313-    /// In-memory index for instant search while DB upsert runs in background.\n314-    /// Set by MFT scan, cleared after background DB upsert completes.\n315-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n316-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n317-    pub(crate) watcher_stop: Arc<AtomicBool>,\n318-    /// Set to true while a file watcher event loop is running.\n319-    pub(crate) watcher_active: Arc<AtomicBool>,\n320-    /// Set to true once frontend onMount has completed enough to accept user input.\n321-    pub(crate) frontend_ready: Arc<AtomicBool>,\n322-}\n323-\n324-#[derive(Debug, Clone)]\n325-pub(crate) struct NegativeNameEntry {\n326-    created_at: Instant,\n327-    fallback_checked: bool,\n--\n872-\n873-            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n874-                continue;\n875-            };\n876-\n877-            let key = path.to_string_lossy().to_string();\n878-            if seen_roots.insert(key) {\n879-                roots.push(path);\n880-            }\n881-        }\n882-    }\n883-\n884-    (roots, patterns)\n885-}\n886-\n887:fn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n888:    let gitignore = if let Some(root) = find_git_root(cwd) {\n889:        root.join(\".gitignore\")\n890:    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n891-        file\n892-    } else {\n893-        return Vec::new();\n894-    };\n895:    let contents = match fs::read_to_string(&gitignore) {\n896-        Ok(contents) => contents,\n897-        Err(_) => return Vec::new(),\n898-    };\n899-\n900-    let mut roots = Vec::new();\n901-    let mut seen = HashSet::new();\n902-\n903-    for line in contents.lines() {\n904-        let trimmed = line.trim();\n905-        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n906-            continue;\n907-        }\n908-        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n909-            continue;\n910-        }\n--\n1025-    cwd: &Path,\n1026-    base_roots: &[PathBuf],\n1027-    base_patterns: &[IgnorePattern],\n1028-) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n1029-    let mut roots = base_roots.to_vec();\n1030-    let mut patterns = base_patterns.to_vec();\n1031-    let mut seen: HashSet<String> = roots\n1032-        .iter()\n1033-        .map(|p| p.to_string_lossy().to_string())\n1034-        .collect();\n1035-    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n1036-\n1037-    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n1038-    for root in pathignore_roots\n1039-        .into_iter()\n1040:        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n1041-        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n1042-        .chain(windows_noisy_roots(home_dir).into_iter())\n1043-    {\n1044-        let key = root.to_string_lossy().to_string();\n1045-        if seen.insert(key) {\n1046-            roots.push(root);\n1047-        }\n1048-    }\n1049-\n1050-    for pattern in pathignore_patterns\n1051-        .into_iter()\n1052-        .chain(builtin_ignore_patterns(home_dir))\n1053-    {\n1054-        let key = ignore_pattern_key(&pattern);\n1055-        if seen_patterns.insert(key) {\n--\n1071-        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n1072-        // ~/.pyenv/versions/*/lib\n1073-        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n1074-    ]\n1075-}\n1076-\n1077-pub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n1078-    let home_dir = &state.home_dir;\n1079-    let cwd = &state.cwd;\n1080-\n1081-    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n1082-        .or_else(|| Some(home_dir.join(\".pathignore\")))\n1083-        .and_then(|p| fs::metadata(&p).ok())\n1084-        .and_then(|m| m.modified().ok());\n1085-\n1086:    let gitignore_mtime = find_git_root(cwd)\n1087:        .map(|root| root.join(\".gitignore\"))\n1088:        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n1089-        .and_then(|p| fs::metadata(&p).ok())\n1090-        .and_then(|m| m.modified().ok());\n1091-\n1092-    let mut cache = state.ignore_cache.lock();\n1093-    if let Some(ref cached) = *cache {\n1094:        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n1095-        {\n1096-            return (cached.roots.clone(), cached.patterns.clone());\n1097-        }\n1098-    }\n1099-\n1100-    let (roots, patterns) = effective_ignore_rules(\n1101-        home_dir,\n1102-        cwd,\n1103-        state.path_ignores.as_ref(),\n1104-        state.path_ignore_patterns.as_ref(),\n1105-    );\n1106-\n1107-    *cache = Some(IgnoreRulesCache {\n1108-        roots: roots.clone(),\n1109-        patterns: patterns.clone(),\n1110-        pathignore_mtime,\n1111:        gitignore_mtime,\n1112-    });\n1113-\n1114-    (roots, patterns)\n1115-}\n1116-\n1117-fn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n1118-    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n1119-    for root in roots {\n1120-        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n1121-    }\n1122-    for pattern in patterns {\n1123-        ignore_pattern_key(pattern).hash(&mut hasher);\n1124-    }\n1125-    hasher.finish()\n1126-}\n--\n1223-                if cur == \"/\" {\n1224-                    break;\n1225-                }\n1226-\n1227-                let Some(pos) = cur.rfind('/') else {\n1228-                    break;\n1229-                };\n1230-\n1231-                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n1232-            }\n1233-            false\n1234-        }\n1235-    }\n1236-}\n1237-\n1238:pub(crate) fn should_skip_path(\n1239-    path: &Path,\n1240-    ignored_roots: &[PathBuf],\n1241-    ignored_patterns: &[IgnorePattern],\n1242-) -> bool {\n1243-    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n1244-}\n1245-\n1246:pub(crate) fn should_skip_path_ext(\n1247-    path: &Path,\n1248-    ignored_roots: &[PathBuf],\n1249-    ignored_patterns: &[IgnorePattern],\n1250:    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n1251-    is_dir_hint: Option<bool>,\n1252-) -> bool {\n1253-    let s = normalize_slashes(path.to_string_lossy().to_string());\n1254-\n1255-    / Single-component builtin names: check path segments\n1256-    if s.split('/').any(|seg| {\n1257-        BUILTIN_SKIP_NAMES.contains(&seg)\n1258-            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n1259-    }) {\n1260-        return true;\n1261-    }\n1262-\n1263-    // Multi-component builtin paths\n1264-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n1265-        let infix = format!(\"/{pat}/\");\n--\n1269-        return true;\n1270-    }\n1271-\n1272-    if ignored_roots\n1273-        .iter()\n1274-        .any(|root| path == root || path.starts_with(root))\n1275-    {\n1276-        return true;\n1277-    }\n1278-    if ignored_patterns\n1279-        .iter()\n1280-        .any(|pattern| matches_ignore_pattern(&s, pattern))\n1281-    {\n1282-        return true;\n1283-    }\n1284:    if let Some(gi) = gitignore {\n1285-        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n1286:        if gi.is_ignored(path, is_dir) {\n1287-            return true;\n1288-        }\n1289-    }\n1290-    false\n1291-}\n1292-\n1293-fn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n1294-    if is_dir {\n1295-        return None;\n1296-    }\n1297-\n1298-    path.extension()\n1299-        .and_then(|ext| ext.to_str())\n1300-        .map(|ext| ext.to_lowercase())\n1301-}\n--\n2065-    result\n2066-}\n2067-\n2068-fn run_incremental_index_inner(\n2069-    app: &AppHandle,\n2070-    state: &AppState,\n2071-    conn: &mut Connection,\n2072-) -> AppResult<()> {\n2073-\n2074-    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n2075-        &state.home_dir,\n2076-        &state.cwd,\n2077-        state.path_ignores.as_ref(),\n2078-        state.path_ignore_patterns.as_ref(),\n2079-    );\n2080:    let gi_filter = state.gitignore.get();\n2081-\n2082-    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n2083-        .and_then(|v| v.parse().ok())\n2084-        .unwrap_or(0);\n2085-    let current_run_id = last_run_id + 1;\n2086-    / Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n2087-    let is_fresh = last_run_id == 0;\n2088-\n2089-    // Fresh index has no secondary indexes to maintain, so we can use larger\n2090-    // batches to reduce transaction overhead (fewer commits = faster).\n2091-    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n2092-\n2093-    let mut scanned: u64 = 0;\n2094-    let mut indexed: u64 = 0;\n2095-    let mut permission_errors: u64 = 0;\n--\n5022-        std::env::var(\"HOME\")\n5023-            .or_else(|_| std::env::var(\"USERPROFILE\"))\n5024-            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n5025-    );\n5026-    let scan_root = if cfg!(windows) {\n5027-        PathBuf::from(\"C:\\\\\")\n5028-    } else {\n5029-        home_dir.clone()\n5030-    };\n5031-    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n5032-    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n5033-    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n5034-    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n5035-        path_ignores.push(app_data_dir.clone());\n5036-    }\n5037:    for root in load_gitignore_roots(&home_dir, &cwd) {\n5038-        if !path_ignores.iter().any(|r| r == &root) {\n5039-            path_ignores.push(root);\n5040-        }\n5041-    }\n5042-    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n5043-\n5044:    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n5045-\n5046-    let state = AppState {\n5047-        db_path,\n5048-        home_dir,\n5049-        scan_root,\n5050-        cwd,\n5051-        path_ignores: Arc::new(path_ignores),\n5052-        path_ignore_patterns: Arc::new(path_ignore_patterns),\n5053-        db_ready: Arc::new(AtomicBool::new(false)),\n5054-        indexing_active: Arc::new(AtomicBool::new(false)),\n5055-        status: Arc::new(Mutex::new(IndexStatus::default())),\n5056-        recent_ops: Arc::new(Mutex::new(Vec::new())),\n5057-        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n5058-        fd_search_cache: Arc::new(Mutex::new(None)),\n5059-        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n5060-        ignore_cache: Arc::new(Mutex::new(None)),\n5061:        gitignore,\n5062-        mem_index: Arc::new(RwLock::new(None)),\n5063-        watcher_stop: Arc::new(AtomicBool::new(false)),\n5064-        watcher_active: Arc::new(AtomicBool::new(false)),\n5065-        frontend_ready: Arc::new(AtomicBool::new(false)),\n5066-    };\n5067-\n5068-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n5069-    app.manage(state.clone());\n5070-    if !bench_mode {\n5071-        register_global_shortcut(&app.handle())?;\n5072-    }\n5073-    // Context menu item IDs use the \"ctx_\" prefix by convention.\n5074-    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n5075-    #[cfg(target_os = \"macos\")]\n5076-    {\n--\n5352-        AppState {\n5353-            db_path,\n5354-            home_dir: home_dir.clone(),\n5355-            scan_root: home_dir.clone(),\n5356-            cwd,\n5357-            path_ignores: Arc::new(Vec::new()),\n5358-            path_ignore_patterns: Arc::new(Vec::new()),\n5359-            db_ready: Arc::new(AtomicBool::new(true)),\n5360-            indexing_active: Arc::new(AtomicBool::new(false)),\n5361-            status: Arc::new(Mutex::new(IndexStatus::default())),\n5362-            recent_ops: Arc::new(Mutex::new(Vec::new())),\n5363-            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n5364-            fd_search_cache: Arc::new(Mutex::new(None)),\n5365-            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n5366-            ignore_cache: Arc::new(Mutex::new(None)),\n5367:            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n5368-            mem_index: Arc::new(RwLock::new(None)),\n5369-            watcher_stop: Arc::new(AtomicBool::new(false)),\n5370-            watcher_active: Arc::new(AtomicBool::new(false)),\n5371-            frontend_ready: Arc::new(AtomicBool::new(true)),\n5372-        }\n5373-    }\n5374-\n5375-    #[test]\n5376:    fn should_skip_path_for_ignored_descendant() {\n5377-        let ignored = vec![PathBuf::from(\n5378-            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n5379-        )];\n5380-        let target = Path::new(\n5381-            \"REDACTED\",\n5382-        );\n5383-\n5384-        assert!(should_skip_path(target, &ignored, &[]));\n5385-    }\n5386-\n5387-    #[test]\n5388-    fn filter_ignored_entries_removes_pathignore_matches() {\n5389-        let ignored = vec![PathBuf::from(\n5390-            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n5391-        )];\n5392-        let entries = vec![\n5393-            mk_entry(\n5394-                \"REDACTED\",\n5395-                \"-Users-al02402336-a_desktop\",\n5396-            ),\n5397-            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n5398-        ];\n5399-\n5400-        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n5401-\n5402-        assert_eq!(filtered.len(), 1);\n5403-        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n5404-    }\n5405-\n5406-    #[test]\n5407:    fn should_skip_path_for_glob_any_segment_target() {\n5408-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n5409-\n5410-        assert!(should_skip_path(\n5411-            Path::new(\"/Users/al02402336/work/rust/target\"),\n5412-            &[],\n5413-            &patterns\n5414-        ));\n5415-        assert!(should_skip_path(\n5416-            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n5417-            &[],\n5418-            &patterns\n5419-        ));\n5420-        assert!(!should_skip_path(\n5421-            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n5422-            &[],"}]},"uuid":"643e17e4-57dd-45cd-ba32-5babc9d6ead1","timestamp":"2026-02-22T07:42:44.049Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"14-    },\n15-    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n16-};\n17-\n18-use parking_lot::{Mutex, RwLock};\n19-use rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\n20-use serde::Serialize;\n21-use tauri::{AppHandle, Emitter, Manager, State};\n22-#[cfg(target_os = \"macos\")]\n23-use tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n24-#[cfg(target_os = \"windows\")]\n25-use std::os::windows::process::CommandExt;\n26-use walkdir::WalkDir;\n27-\n28-mod fd_search;\n29:mod gitignore_filter;\n30-#[cfg(target_os = \"macos\")]\n31-mod mac;\n32-mod mem_search;\n33-mod query;\n34-#[cfg(target_os = \"windows\")]\n35-mod win;\n36-use fd_search::{FdSearchCache, FdSearchResultDto};\n37-use query::{escape_like, parse_query, SearchMode};\n38-\n39-const DEFAULT_LIMIT: u32 = 300;\n40-const SHORT_QUERY_LIMIT: u32 = 100;\n41-const MAX_LIMIT: u32 = 1000;\n42-pub(crate) const BATCH_SIZE: usize = 10_000;\n43-const RECENT_OP_TTL: Duration = Duration::from_secs(2);\n44-pub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\n--\n278-    op_type: &'static str,\n279-    at: Instant,\n280-}\n281-\n282-#[derive(Debug, Clone, PartialEq, Eq)]\n283-pub(crate) enum IgnorePattern {\n284-    AnySegment(String),\n285-    Glob(String),\n286-}\n287-\n288-#[derive(Debug, Clone)]\n289-pub(crate) struct IgnoreRulesCache {\n290-    roots: Vec<PathBuf>,\n291-    patterns: Vec<IgnorePattern>,\n292-    pathignore_mtime: Option<SystemTime>,\n293:    gitignore_mtime: Option<SystemTime>,\n294-}\n295-\n296-#[derive(Debug, Clone)]\n297-pub(crate) struct AppState {\n298-    pub(crate) db_path: PathBuf,\n299-    pub(crate) home_dir: PathBuf,\n300-    pub(crate) scan_root: PathBuf,\n301-    pub(crate) cwd: PathBuf,\n302-    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n303-    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n304-    pub(crate) db_ready: Arc<AtomicBool>,\n305-    pub(crate) indexing_active: Arc<AtomicBool>,\n306-    pub(crate) status: Arc<Mutex<IndexStatus>>,\n307-    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n308-    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n309-    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n310-    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n311-    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n312:    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n313-    /// In-memory index for instant search while DB upsert runs in background.\n314-    /// Set by MFT scan, cleared after background DB upsert completes.\n315-    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n316-    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n317-    pub(crate) watcher_stop: Arc<AtomicBool>,\n318-    /// Set to true while a file watcher event loop is running.\n319-    pub(crate) watcher_active: Arc<AtomicBool>,\n320-    /// Set to true once frontend onMount has completed enough to accept user input.\n321-    pub(crate) frontend_ready: Arc<AtomicBool>,\n322-}\n323-\n324-#[derive(Debug, Clone)]\n325-pub(crate) struct NegativeNameEntry {\n326-    created_at: Instant,\n327-    fallback_checked: bool,\n--\n872-\n873-            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n874-                continue;\n875-            };\n876-\n877-            let key = path.to_string_lossy().to_string();\n878-            if seen_roots.insert(key) {\n879-                roots.push(path);\n880-            }\n881-        }\n882-    }\n883-\n884-    (roots, patterns)\n885-}\n886-\n887:fn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n888:    let gitignore = if let Some(root) = find_git_root(cwd) {\n889:        root.join(\".gitignore\")\n890:    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n891-        file\n892-    } else {\n893-        return Vec::new();\n894-    };\n895:    let contents = match fs::read_to_string(&gitignore) {\n896-        Ok(contents) => contents,\n897-        Err(_) => return Vec::new(),\n898-    };\n899-\n900-    let mut roots = Vec::new();\n901-    let mut seen = HashSet::new();\n902-\n903-    for line in contents.lines() {\n904-        let trimmed = line.trim();\n905-        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n906-            continue;\n907-        }\n908-        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n909-            continue;\n910-        }\n--\n1025-    cwd: &Path,\n1026-    base_roots: &[PathBuf],\n1027-    base_patterns: &[IgnorePattern],\n1028-) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n1029-    let mut roots = base_roots.to_vec();\n1030-    let mut patterns = base_patterns.to_vec();\n1031-    let mut seen: HashSet<String> = roots\n1032-        .iter()\n1033-        .map(|p| p.to_string_lossy().to_string())\n1034-        .collect();\n1035-    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n1036-\n1037-    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n1038-    for root in pathignore_roots\n1039-        .into_iter()\n1040:        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n1041-        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n1042-        .chain(windows_noisy_roots(home_dir).into_iter())\n1043-    {\n1044-        let key = root.to_string_lossy().to_string();\n1045-        if seen.insert(key) {\n1046-            roots.push(root);\n1047-        }\n1048-    }\n1049-\n1050-    for pattern in pathignore_patterns\n1051-        .into_iter()\n1052-        .chain(builtin_ignore_patterns(home_dir))\n1053-    {\n1054-        let key = ignore_pattern_key(&pattern);\n1055-        if seen_patterns.insert(key) {\n--\n1071-        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n1072-        // ~/.pyenv/versions/*/lib\n1073-        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n1074-    ]\n1075-}\n1076-\n1077-pub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n1078-    let home_dir = &state.home_dir;\n1079-    let cwd = &state.cwd;\n1080-\n1081-    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n1082-        .or_else(|| Some(home_dir.join(\".pathignore\")))\n1083-        .and_then(|p| fs::metadata(&p).ok())\n1084-        .and_then(|m| m.modified().ok());\n1085-\n1086:    let gitignore_mtime = find_git_root(cwd)\n1087:        .map(|root| root.join(\".gitignore\"))\n1088:        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n1089-        .and_then(|p| fs::metadata(&p).ok())\n1090-        .and_then(|m| m.modified().ok());\n1091-\n1092-    let mut cache = state.ignore_cache.lock();\n1093-    if let Some(ref cached) = *cache {\n1094:        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n1095-        {\n1096-            return (cached.roots.clone(), cached.patterns.clone());\n1097-        }\n1098-    }\n1099-\n1100-    let (roots, patterns) = effective_ignore_rules(\n1101-        home_dir,\n1102-        cwd,\n1103-        state.path_ignores.as_ref(),\n1104-        state.path_ignore_patterns.as_ref(),\n1105-    );\n1106-\n1107-    *cache = Some(IgnoreRulesCache {\n1108-        roots: roots.clone(),\n1109-        patterns: patterns.clone(),\n1110-        pathignore_mtime,\n1111:        gitignore_mtime,\n1112-    });\n1113-\n1114-    (roots, patterns)\n1115-}\n1116-\n1117-fn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n1118-    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n1119-    for root in roots {\n1120-        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n1121-    }\n1122-    for pattern in patterns {\n1123-        ignore_pattern_key(pattern).hash(&mut hasher);\n1124-    }\n1125-    hasher.finish()\n1126-}\n--\n1223-                if cur == \"/\" {\n1224-                    break;\n1225-                }\n1226-\n1227-                let Some(pos) = cur.rfind('/') else {\n1228-                    break;\n1229-                };\n1230-\n1231-                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n1232-            }\n1233-            false\n1234-        }\n1235-    }\n1236-}\n1237-\n1238:pub(crate) fn should_skip_path(\n1239-    path: &Path,\n1240-    ignored_roots: &[PathBuf],\n1241-    ignored_patterns: &[IgnorePattern],\n1242-) -> bool {\n1243-    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n1244-}\n1245-\n1246:pub(crate) fn should_skip_path_ext(\n1247-    path: &Path,\n1248-    ignored_roots: &[PathBuf],\n1249-    ignored_patterns: &[IgnorePattern],\n1250:    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n1251-    is_dir_hint: Option<bool>,\n1252-) -> bool {\n1253-    let s = normalize_slashes(path.to_string_lossy().to_string());\n1254-\n1255-    / Single-component builtin names: check path segments\n1256-    if s.split('/').any(|seg| {\n1257-        BUILTIN_SKIP_NAMES.contains(&seg)\n1258-            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n1259-    }) {\n1260-        return true;\n1261-    }\n1262-\n1263-    // Multi-component builtin paths\n1264-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n1265-        let infix = format!(\"/{pat}/\");\n--\n1269-        return true;\n1270-    }\n1271-\n1272-    if ignored_roots\n1273-        .iter()\n1274-        .any(|root| path == root || path.starts_with(root))\n1275-    {\n1276-        return true;\n1277-    }\n1278-    if ignored_patterns\n1279-        .iter()\n1280-        .any(|pattern| matches_ignore_pattern(&s, pattern))\n1281-    {\n1282-        return true;\n1283-    }\n1284:    if let Some(gi) = gitignore {\n1285-        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n1286:        if gi.is_ignored(path, is_dir) {\n1287-            return true;\n1288-        }\n1289-    }\n1290-    false\n1291-}\n1292-\n1293-fn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n1294-    if is_dir {\n1295-        return None;\n1296-    }\n1297-\n1298-    path.extension()\n1299-        .and_then(|ext| ext.to_str())\n1300-        .map(|ext| ext.to_lowercase())\n1301-}\n--\n2065-    result\n2066-}\n2067-\n2068-fn run_incremental_index_inner(\n2069-    app: &AppHandle,\n2070-    state: &AppState,\n2071-    conn: &mut Connection,\n2072-) -> AppResult<()> {\n2073-\n2074-    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n2075-        &state.home_dir,\n2076-        &state.cwd,\n2077-        state.path_ignores.as_ref(),\n2078-        state.path_ignore_patterns.as_ref(),\n2079-    );\n2080:    let gi_filter = state.gitignore.get();\n2081-\n2082-    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n2083-        .and_then(|v| v.parse().ok())\n2084-        .unwrap_or(0);\n2085-    let current_run_id = last_run_id + 1;\n2086-    / Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n2087-    let is_fresh = last_run_id == 0;\n2088-\n2089-    // Fresh index has no secondary indexes to maintain, so we can use larger\n2090-    // batches to reduce transaction overhead (fewer commits = faster).\n2091-    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n2092-\n2093-    let mut scanned: u64 = 0;\n2094-    let mut indexed: u64 = 0;\n2095-    let mut permission_errors: u64 = 0;\n--\n5022-        std::env::var(\"HOME\")\n5023-            .or_else(|_| std::env::var(\"USERPROFILE\"))\n5024-            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n5025-    );\n5026-    let scan_root = if cfg!(windows) {\n5027-        PathBuf::from(\"C:\\\\\")\n5028-    } else {\n5029-        home_dir.clone()\n5030-    };\n5031-    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n5032-    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n5033-    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n5034-    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n5035-        path_ignores.push(app_data_dir.clone());\n5036-    }\n5037:    for root in load_gitignore_roots(&home_dir, &cwd) {\n5038-        if !path_ignores.iter().any(|r| r == &root) {\n5039-            path_ignores.push(root);\n5040-        }\n5041-    }\n5042-    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n5043-\n5044:    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n5045-\n5046-    let state = AppState {\n5047-        db_path,\n5048-        home_dir,\n5049-        scan_root,\n5050-        cwd,\n5051-        path_ignores: Arc::new(path_ignores),\n5052-        path_ignore_patterns: Arc::new(path_ignore_patterns),\n5053-        db_ready: Arc::new(AtomicBool::new(false)),\n5054-        indexing_active: Arc::new(AtomicBool::new(false)),\n5055-        status: Arc::new(Mutex::new(IndexStatus::default())),\n5056-        recent_ops: Arc::new(Mutex::new(Vec::new())),\n5057-        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n5058-        fd_search_cache: Arc::new(Mutex::new(None)),\n5059-        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n5060-        ignore_cache: Arc::new(Mutex::new(None)),\n5061:        gitignore,\n5062-        mem_index: Arc::new(RwLock::new(None)),\n5063-        watcher_stop: Arc::new(AtomicBool::new(false)),\n5064-        watcher_active: Arc::new(AtomicBool::new(false)),\n5065-        frontend_ready: Arc::new(AtomicBool::new(false)),\n5066-    };\n5067-\n5068-    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n5069-    app.manage(state.clone());\n5070-    if !bench_mode {\n5071-        register_global_shortcut(&app.handle())?;\n5072-    }\n5073-    // Context menu item IDs use the \"ctx_\" prefix by convention.\n5074-    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n5075-    #[cfg(target_os = \"macos\")]\n5076-    {\n--\n5352-        AppState {\n5353-            db_path,\n5354-            home_dir: home_dir.clone(),\n5355-            scan_root: home_dir.clone(),\n5356-            cwd,\n5357-            path_ignores: Arc::new(Vec::new()),\n5358-            path_ignore_patterns: Arc::new(Vec::new()),\n5359-            db_ready: Arc::new(AtomicBool::new(true)),\n5360-            indexing_active: Arc::new(AtomicBool::new(false)),\n5361-            status: Arc::new(Mutex::new(IndexStatus::default())),\n5362-            recent_ops: Arc::new(Mutex::new(Vec::new())),\n5363-            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n5364-            fd_search_cache: Arc::new(Mutex::new(None)),\n5365-            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n5366-            ignore_cache: Arc::new(Mutex::new(None)),\n5367:            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n5368-            mem_index: Arc::new(RwLock::new(None)),\n5369-            watcher_stop: Arc::new(AtomicBool::new(false)),\n5370-            watcher_active: Arc::new(AtomicBool::new(false)),\n5371-            frontend_ready: Arc::new(AtomicBool::new(true)),\n5372-        }\n5373-    }\n5374-\n5375-    #[test]\n5376:    fn should_skip_path_for_ignored_descendant() {\n5377-        let ignored = vec![PathBuf::from(\n5378-            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n5379-        )];\n5380-        let target = Path::new(\n5381-            \"REDACTED\",\n5382-        );\n5383-\n5384-        assert!(should_skip_path(target, &ignored, &[]));\n5385-    }\n5386-\n5387-    #[test]\n5388-    fn filter_ignored_entries_removes_pathignore_matches() {\n5389-        let ignored = vec![PathBuf::from(\n5390-            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n5391-        )];\n5392-        let entries = vec![\n5393-            mk_entry(\n5394-                \"REDACTED\",\n5395-                \"-Users-al02402336-a_desktop\",\n5396-            ),\n5397-            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n5398-        ];\n5399-\n5400-        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n5401-\n5402-        assert_eq!(filtered.len(), 1);\n5403-        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n5404-    }\n5405-\n5406-    #[test]\n5407:    fn should_skip_path_for_glob_any_segment_target() {\n5408-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n5409-\n5410-        assert!(should_skip_path(\n5411-            Path::new(\"/Users/al02402336/work/rust/target\"),\n5412-            &[],\n5413-            &patterns\n5414-        ));\n5415-        assert!(should_skip_path(\n5416-            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n5417-            &[],\n5418-            &patterns\n5419-        ));\n5420-        assert!(!should_skip_path(\n5421-            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n5422-            &[],","numLines":449},"sourceToolAssistantUUID":"9d2e64e4-ec72-4d6a-92a5-f988e42ff766"}
{"parentUuid":"643e17e4-57dd-45cd-ba32-5babc9d6ead1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01EBy9zoU17dQ5KJV3hDYnD5","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a better understanding of the code. Let me identify the key bottlenecks:\n\n1. `should_skip_path_ext` is called per entry in `process_read_dir` closure. It calls `normalize_slashes(path.to_string_lossy().to_string())` - that's a String allocation for every entry. Also `path.starts_with(root)` for each root. This runs in the rayon pool, so it's parallelized.\n\n2. The main loop processes jwalk entries serially: `index_row_from_jwalk_entry` calls `entry.metadata()` which may call `stat()`. This is serial.\n\n\n3. There are also multiple string conversions happening in `index_row_from_path_and_metadata`, and after the scan completes, we're creating 4 indexes, running analysis, and truncating the WAL checkpoint.\n\nLet me check if the gitignore filtering is contributing to the performance issues.","signature":"EqQHCkYICxgCKkAbjuDrhtBJszGMmkoXthRyRV5gxsdSWUuDVy70cPJK2/xHYGVx6GGC6dpVVYKMLEAjCvf8JIQ5qTHjiQnQVGYREgxcpavK3bNvqafKIEoaDDUR1lvDlnb9oMDWmCIwwjD+EzQlahmGBILLYQ/s4nby0z/eJMhfuYv+Ms6URCrzkkNdgFfTRI2qM0Xc84NOKosGGhwaCuFiqMSmjtWospsc7m5gxOdcbPysMkr23tPUWgg2seVwEo82nM5EoSA7yLZR7zFjUwojGRHcbZTwpMNThSzpG+h1V9Km9BaA6nLGtQZsWLJBVt1ywxMhCdfykH653Ge5fbGG2w7+VU5jWl6Kcqr16CarQk1WrES1mvGJ/Z1sXIAKPEkbHqgzI3EOxs6HNIg05JKwwQ8XS+BLRjtZMH38YgaJN0Ax7ecpfNVRpcfGhRlSqKBtcO6i0VIi/E4r5OR4NsuXTzOJ3hpaUQTa7uJSlH5gMW0QtbDM5uCiFbKbhQGnuUQdthxuRiCMjH2evmQLgJx0cDEd+h+kf9yMNH2EWdzM/uk813UA7LC0u9HGBcFflP7Tl/74AUG7siobfl/byBV1o936pBGrQTwGiAqoZKin4doErILMm0a25tqsBQJBbgYBlznu2av9UtigcY9lTN50DN+jJsnqgtphqzK0Aqa1iTcLVwrc2FvNHkC3gddDLXmvAqOpQDzxHaWT8an/wS3uXHi7YqwXKL+1qPtKdVDw+E96O62++tN2/uFAVPufoYQQFtvhdH/n3jP4FWNaw6npyq/sjH+DDLRKijixCi43XFBSfvrFGhKkhposvW7P0bg8+P7wgcOFJfiQTCo83r+njk/OATrf7b5WgxaKE/dSwEO+3AQ8TEwHKzTs3H4p72tRcIO6QefUiVYxeye84766Iz85KS2u/+FcqR5lROdOP+AQVb3BMiKh/myYwi/OnCsvObcZPMvz5d8pws01qYhP/PsiZzm3J9PpGVerVSMAaexiCUCTuLVkEng0Sx1lwOTiVGLoqnEyZRY7hPtJPc1E9dOg3dAewFVWRx6d91ia43Qwj1YL1VDNREWbg28sTJeDl8HQm70c5vd5dbzWpx53Ee7ev7ikD6iAf6B/BvKd6N77VVcUM6VI1bAky23kbkIW9cTMKZbIJUFcOR6qNMevE3BWfALnn6i8ENKT+M7y8uGyTMpLhYG1s5ZoNMaltjF8Ezn493WFJyGFk31RsTrIwA4aQwAYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":14233,"cache_read_input_tokens":54328,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":14233},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjQPCBEYZHGBJuAuW3v","type":"assistant","uuid":"23305084-3934-4a64-87d7-a307793a5811","timestamp":"2026-02-22T07:42:52.797Z"}
{"parentUuid":"23305084-3934-4a64-87d7-a307793a5811","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01EBy9zoU17dQ5KJV3hDYnD5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YRAQJDzNZfLo5EJ7vcHjmh","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/gitignore_filter.rs"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":14233,"cache_read_input_tokens":54328,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":14233},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjQPCBEYZHGBJuAuW3v","type":"assistant","uuid":"c074108f-dfbc-40ca-aa50-393972d6d912","timestamp":"2026-02-22T07:42:52.821Z"}
{"parentUuid":"c074108f-dfbc-40ca-aa50-393972d6d912","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01YRAQJDzNZfLo5EJ7vcHjmh","toolUseID":"toolu_01YRAQJDzNZfLo5EJ7vcHjmh","timestamp":"2026-02-22T07:42:52.839Z","uuid":"babd51d7-af47-4171-883d-4c78ee3af157"}
{"parentUuid":"c074108f-dfbc-40ca-aa50-393972d6d912","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YRAQJDzNZfLo5EJ7vcHjmh","type":"tool_result","content":"     1→use ignore::gitignore::{Gitignore, GitignoreBuilder};\n     2→use std::path::{Path, PathBuf};\n     3→use std::sync::{Arc, OnceLock};\n     4→\n     5→pub struct GitignoreFilter {\n     6→    matchers: Vec<Gitignore>,\n     7→}\n     8→\n     9→impl std::fmt::Debug for GitignoreFilter {\n    10→    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n    11→        f.debug_struct(\"GitignoreFilter\")\n    12→            .field(\"matchers_count\", &self.matchers.len())\n    13→            .finish()\n    14→    }\n    15→}\n    16→\n    17→impl GitignoreFilter {\n    18→    pub fn build(home_dir: &Path) -> Self {\n    19→        let matchers = discover_gitignores(home_dir);\n    20→        Self { matchers }\n    21→    }\n    22→\n    23→    pub fn root_paths(&self) -> Vec<&Path> {\n    24→        self.matchers.iter().map(|gi| gi.path()).collect()\n    25→    }\n    26→\n    27→    pub fn is_ignored(&self, path: &Path, is_dir: bool) -> bool {\n    28→        for gi in &self.matchers {\n    29→            match gi.matched(path, is_dir) {\n    30→                ignore::Match::Ignore(_) => return true,\n    31→                ignore::Match::Whitelist(_) => return false,\n    32→                ignore::Match::None => {}\n    33→            }\n    34→        }\n    35→        false\n    36→    }\n    37→}\n    38→\n    39→fn discover_gitignores(home_dir: &Path) -> Vec<Gitignore> {\n    40→    let mut result = Vec::new();\n    41→\n    42→    let Ok(entries) = std::fs::read_dir(home_dir) else {\n    43→        return result;\n    44→    };\n    45→\n    46→    for entry in entries.flatten() {\n    47→        let path = entry.path();\n    48→        if !path.is_dir() {\n    49→            continue;\n    50→        }\n    51→\n    52→        let name = entry.file_name();\n    53→        let name_str = name.to_string_lossy();\n    54→        if name_str.starts_with('.') || name_str == \"Library\" {\n    55→            continue;\n    56→        }\n    57→\n    58→        collect_gitignores_recursive(&path, 0, 3, &mut result);\n    59→    }\n    60→\n    61→    result\n    62→}\n    63→\n    64→fn collect_gitignores_recursive(\n    65→    dir: &Path,\n    66→    depth: usize,\n    67→    max_depth: usize,\n    68→    result: &mut Vec<Gitignore>,\n    69→) {\n    70→    if depth > max_depth {\n    71→        return;\n    72→    }\n    73→\n    74→    let git_dir = dir.join(\".git\");\n    75→    if git_dir.exists() {\n    76→        let gitignore_path = dir.join(\".gitignore\");\n    77→        if gitignore_path.is_file() {\n    78→            let mut builder = GitignoreBuilder::new(dir);\n    79→            if builder.add(&gitignore_path).is_none() {\n    80→                if let Ok(gi) = builder.build() {\n    81→                    result.push(gi);\n    82→                }\n    83→            }\n    84→        }\n    85→        return;\n    86→    }\n    87→\n    88→    let Ok(entries) = std::fs::read_dir(dir) else {\n    89→        return;\n    90→    };\n    91→\n    92→    for entry in entries.flatten() {\n    93→        let path = entry.path();\n    94→        if !path.is_dir() {\n    95→            continue;\n    96→        }\n    97→\n    98→        let name = entry.file_name();\n    99→        let name_str = name.to_string_lossy();\n   100→        if name_str.starts_with('.')\n   101→            || name_str == \"node_modules\"\n   102→            || name_str == \"Library\"\n   103→            || name_str == \"target\"\n   104→        {\n   105→            continue;\n   106→        }\n   107→\n   108→        collect_gitignores_recursive(&path, depth + 1, max_depth, result);\n   109→    }\n   110→}\n   111→\n   112→pub type SharedGitignoreFilter = Arc<GitignoreFilter>;\n   113→\n   114→pub fn build_shared_filter(home_dir: &Path) -> SharedGitignoreFilter {\n   115→    Arc::new(GitignoreFilter::build(home_dir))\n   116→}\n   117→\n   118→/// Lazy gitignore filter — defers expensive filesystem scan until first access.\n   119→pub struct LazyGitignoreFilter {\n   120→    home_dir: PathBuf,\n   121→    inner: OnceLock<SharedGitignoreFilter>,\n   122→}\n   123→\n   124→impl std::fmt::Debug for LazyGitignoreFilter {\n   125→    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n   126→        f.debug_struct(\"LazyGitignoreFilter\")\n   127→            .field(\"initialized\", &self.inner.get().is_some())\n   128→            .finish()\n   129→    }\n   130→}\n   131→\n   132→impl LazyGitignoreFilter {\n   133→    pub fn new(home_dir: PathBuf) -> Self {\n   134→        Self {\n   135→            home_dir,\n   136→            inner: OnceLock::new(),\n   137→        }\n   138→    }\n   139→\n   140→    pub fn get(&self) -> SharedGitignoreFilter {\n   141→        self.inner\n   142→            .get_or_init(|| {\n   143→                eprintln!(\"[gitignore] building filter (lazy init)...\");\n   144→                let started = std::time::Instant::now();\n   145→                let filter = build_shared_filter(&self.home_dir);\n   146→                eprintln!(\"[gitignore] filter built in {}ms\", started.elapsed().as_millis());\n   147→                filter\n   148→            })\n   149→            .clone()\n   150→    }\n   151→}\n   152→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d38a8bea-d76f-4f29-9d74-034afd701e60","timestamp":"2026-02-22T07:42:52.837Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/gitignore_filter.rs","content":"use ignore::gitignore::{Gitignore, GitignoreBuilder};\nuse std::path::{Path, PathBuf};\nuse std::sync::{Arc, OnceLock};\n\npub struct GitignoreFilter {\n    matchers: Vec<Gitignore>,\n}\n\nimpl std::fmt::Debug for GitignoreFilter {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"GitignoreFilter\")\n            .field(\"matchers_count\", &self.matchers.len())\n            .finish()\n    }\n}\n\nimpl GitignoreFilter {\n    pub fn build(home_dir: &Path) -> Self {\n        let matchers = discover_gitignores(home_dir);\n        Self { matchers }\n    }\n\n    pub fn root_paths(&self) -> Vec<&Path> {\n        self.matchers.iter().map(|gi| gi.path()).collect()\n    }\n\n    pub fn is_ignored(&self, path: &Path, is_dir: bool) -> bool {\n        for gi in &self.matchers {\n            match gi.matched(path, is_dir) {\n                ignore::Match::Ignore(_) => return true,\n                ignore::Match::Whitelist(_) => return false,\n                ignore::Match::None => {}\n            }\n        }\n        false\n    }\n}\n\nfn discover_gitignores(home_dir: &Path) -> Vec<Gitignore> {\n    let mut result = Vec::new();\n\n    let Ok(entries) = std::fs::read_dir(home_dir) else {\n        return result;\n    };\n\n    for entry in entries.flatten() {\n        let path = entry.path();\n        if !path.is_dir() {\n            continue;\n        }\n\n        let name = entry.file_name();\n        let name_str = name.to_string_lossy();\n        if name_str.starts_with('.') || name_str == \"Library\" {\n            continue;\n        }\n\n        collect_gitignores_recursive(&path, 0, 3, &mut result);\n    }\n\n    result\n}\n\nfn collect_gitignores_recursive(\n    dir: &Path,\n    depth: usize,\n    max_depth: usize,\n    result: &mut Vec<Gitignore>,\n) {\n    if depth > max_depth {\n        return;\n    }\n\n    let git_dir = dir.join(\".git\");\n    if git_dir.exists() {\n        let gitignore_path = dir.join(\".gitignore\");\n        if gitignore_path.is_file() {\n            let mut builder = GitignoreBuilder::new(dir);\n            if builder.add(&gitignore_path).is_none() {\n                if let Ok(gi) = builder.build() {\n                    result.push(gi);\n                }\n            }\n        }\n        return;\n    }\n\n    let Ok(entries) = std::fs::read_dir(dir) else {\n        return;\n    };\n\n    for entry in entries.flatten() {\n        let path = entry.path();\n        if !path.is_dir() {\n            continue;\n        }\n\n        let name = entry.file_name();\n        let name_str = name.to_string_lossy();\n        if name_str.starts_with('.')\n            || name_str == \"node_modules\"\n            || name_str == \"Library\"\n            || name_str == \"target\"\n        {\n            continue;\n        }\n\n        collect_gitignores_recursive(&path, depth + 1, max_depth, result);\n    }\n}\n\npub type SharedGitignoreFilter = Arc<GitignoreFilter>;\n\npub fn build_shared_filter(home_dir: &Path) -> SharedGitignoreFilter {\n    Arc::new(GitignoreFilter::build(home_dir))\n}\n\n/// Lazy gitignore filter — defers expensive filesystem scan until first access.\npub struct LazyGitignoreFilter {\n    home_dir: PathBuf,\n    inner: OnceLock<SharedGitignoreFilter>,\n}\n\nimpl std::fmt::Debug for LazyGitignoreFilter {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"LazyGitignoreFilter\")\n            .field(\"initialized\", &self.inner.get().is_some())\n            .finish()\n    }\n}\n\nimpl LazyGitignoreFilter {\n    pub fn new(home_dir: PathBuf) -> Self {\n        Self {\n            home_dir,\n            inner: OnceLock::new(),\n        }\n    }\n\n    pub fn get(&self) -> SharedGitignoreFilter {\n        self.inner\n            .get_or_init(|| {\n                eprintln!(\"[gitignore] building filter (lazy init)...\");\n                let started = std::time::Instant::now();\n                let filter = build_shared_filter(&self.home_dir);\n                eprintln!(\"[gitignore] filter built in {}ms\", started.elapsed().as_millis());\n                filter\n            })\n            .clone()\n    }\n}\n","numLines":152,"startLine":1,"totalLines":152}},"sourceToolAssistantUUID":"c074108f-dfbc-40ca-aa50-393972d6d912"}
{"parentUuid":"d38a8bea-d76f-4f29-9d74-034afd701e60","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01RTM6LefV5rM8uBh4MazTLC","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me check the Cargo.toml for the jwalk version:","signature":"Et4BCkYICxgCKkDpRoHZQ8ier0sYy1/f4vUKGLAnHVXDVtgMD0OYobD9/zqeNbFGoLJwMFn1OFNicu+UCgaks8FntyBBw8H1j/DREgztwZN1Fso9AbF06ioaDFpdMouo+cHIjQ/IByIweyY+ebRCSMY6UK8+ZPsgLeK1biVFKf1JNn5yAjUGcJq1hpbXOK5RygixbW3jad3GKkYv5zyP3WeBD+g1bTVAdKuIoP0GbfBPHI3bFDks+XHpw84phfbgrQgULmRSGlnwJeKQrk2dkEi72Qg20XIeMGhokGyBd0H8GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2169,"cache_read_input_tokens":68561,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2169},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjR2zmdshk5WKGDKJjU","type":"assistant","uuid":"cddc60bc-7d4e-487f-870b-cb41e9355d33","timestamp":"2026-02-22T07:42:54.959Z"}
{"parentUuid":"cddc60bc-7d4e-487f-870b-cb41e9355d33","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01RTM6LefV5rM8uBh4MazTLC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DDKpACWcnHbAtRWq1BNpcH","name":"Bash","input":{"command":"cat /Users/al02402336/everything/src-tauri/Cargo.toml | grep -E \"jwalk|rayon|rusqlite\"","description":"Check jwalk/rayon versions"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2169,"cache_read_input_tokens":68561,"output_tokens":141,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":2169,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNjR2zmdshk5WKGDKJjU","type":"assistant","uuid":"3c20192e-e1c6-4b9e-b45d-6a98690345c4","timestamp":"2026-02-22T07:42:56.230Z"}
{"parentUuid":"3c20192e-e1c6-4b9e-b45d-6a98690345c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DDKpACWcnHbAtRWq1BNpcH","type":"tool_result","content":"rusqlite = { version = \"0.32\", features = [\"bundled\", \"chrono\", \"hooks\"] }\njwalk = \"0.8\"\nrayon = \"1\"","is_error":false}]},"uuid":"556c3594-4af6-4bd5-a8b1-58f9e058653a","timestamp":"2026-02-22T07:42:56.396Z","toolUseResult":{"stdout":"rusqlite = { version = \"0.32\", features = [\"bundled\", \"chrono\", \"hooks\"] }\njwalk = \"0.8\"\nrayon = \"1\"","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"3c20192e-e1c6-4b9e-b45d-6a98690345c4"}
{"parentUuid":"556c3594-4af6-4bd5-a8b1-58f9e058653a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01XPxSu2mk16se6EtUyUNWqb","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"jwalk 0.8 - let me check what its DirEntry looks like. In jwalk 0.8, the `DirEntry` has:\n- `file_type` - file type from readdir (no extra syscall)\n- `path()` - allocates new PathBuf\n- `metadata()` - may call stat\n\nLooking at jwalk 0.8 source code, the key thing is whether metadata is cached. In jwalk 0.8, `DirEntry::metadata()` calls `entry.path().metadata()` if not yet cached. Since the path is built by joining parent_path + file_name, this triggers a stat() call.\n\n\nThe real bottleneck is those serial stat() calls happening in `index_row_from_jwalk_entry`. I can tackle this by using the file_type directly from DirEntry to avoid the metadata call, prefetching metadata in parallel within the rayon threads where `process_read_dir` runs, and potentially bumping up the jwalk thread count for more concurrent stat workers.\n\nFor the metadata prefetching approach, I need to dig into how jwalk 0.8 actually handles this. The `process_read_dir` closure gets mutable references to DirEntry objects, and while there's no guaranteed internal caching, I can still call metadata() on each entry while we're already in the rayon thread pool, which means the stats happen in parallel rather than serially later.\n\nThe tricky part is storing those results somewhere useful. Using jwalk's custom state mechanism would work but adds complexity. A simpler approach might be to buffer entries from jwalk into chunks, then use rayon to parallel-fetch metadata for that batch before processing, though that trades some memory for better parallelism.\n\nThe real bottleneck I'm seeing now is that while jwalk itself parallelizes the directory traversal, the main processing loop that calls `entry.metadata()` runs serially on the main thread. I'm wondering if we could use channels to let multiple threads fetch metadata in parallel as entries come through.\n\nActually, batching entries from jwalk and then processing each batch with rayon could work—collect maybe a thousand entries at a time, parallelize the metadata calls across them, then write to the database. Though adding another rayon layer on top of jwalk's existing parallelism might cause thread pool contention, so we'd probably need a separate thread pool.\n\nLet me step back and think about where the actual time is going. For a fresh macOS index of the home directory, I'm guessing the file walk and stat calls dominate at 40-60 seconds, with database writes taking maybe 2-5 seconds and index creation another 5-15 seconds.\n\nIf walk and stat are really the bottleneck, then increasing thread count and parallelizing stats are the main wins. But I'm also noticing that `should_skip_path_ext` is doing some expensive work per entry—it's allocating strings for path normalization, splitting paths into segments, and then creating a new format string for every builtin skip pattern it checks against. That's a lot of unnecessary allocations happening in a hot loop.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":195,"cache_read_input_tokens":70730,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":195},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjRJae7USY4LjeotxV9","type":"assistant","uuid":"ee628add-b932-41dc-9989-272542d16dad","timestamp":"2026-02-22T07:43:32.281Z"}
{"parentUuid":"ee628add-b932-41dc-9989-272542d16dad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01XPxSu2mk16se6EtUyUNWqb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011Kvxsx9fJDezjudCvY5fWf","name":"Grep","input":{"pattern":"fn normalize_slashes|fn matches_ignore_pattern","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":15},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":195,"cache_read_input_tokens":70730,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":195},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjRJae7USY4LjeotxV9","type":"assistant","uuid":"3b76f8f9-7413-49a8-b7f7-6156cf7ad57f","timestamp":"2026-02-22T07:43:33.037Z"}
{"parentUuid":"3b76f8f9-7413-49a8-b7f7-6156cf7ad57f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_011Kvxsx9fJDezjudCvY5fWf","toolUseID":"toolu_011Kvxsx9fJDezjudCvY5fWf","timestamp":"2026-02-22T07:43:33.705Z","uuid":"b9205874-1b9d-45f8-873e-64733fe0c412"}
{"parentUuid":"3b76f8f9-7413-49a8-b7f7-6156cf7ad57f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011Kvxsx9fJDezjudCvY5fWf","type":"tool_result","content":"732-        Err(_) => return Vec::new(),\n733-    };\n734-    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n735-        row.get::<_, String>(0)\n736-    }) {\n737-        Ok(r) => r,\n738-        Err(_) => return Vec::new(),\n739-    };\n740-    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n741-    if dirs.len() > RESOLVE_DIRS_MAX {\n742-        return Vec::new();\n743-    }\n744-    dirs\n745-}\n746-\n747:fn normalize_slashes(s: String) -> String {\n748-    s.replace('\\\\', \"/\")\n749-}\n750-\n751-fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n752-    let trimmed = raw.trim();\n753-    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n754-        return None;\n755-    }\n756-\n757-    let mut path = if trimmed == \"~\" {\n758-        home_dir.to_path_buf()\n759-    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n760-        home_dir.join(rest)\n761-    } else {\n762-        PathBuf::from(trimmed)\n--\n1194-                star_px + 1\n1195-            };\n1196-            tx = star_tx;\n1197-        } else {\n1198-            return false;\n1199-        }\n1200-    }\n1201-\n1202-    while px < pn && pat[px] == b'*' {\n1203-        px += 1;\n1204-    }\n1205-\n1206-    px == pn\n1207-}\n1208-\n1209:pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1210-    match pattern {\n1211-        IgnorePattern::AnySegment(segment) => {\n1212-            let suffix = format!(\"/{segment}\");\n1213-            let infix = format!(\"/{segment}/\");\n1214-            path.ends_with(&suffix) || path.contains(&infix)\n1215-        }\n1216-        IgnorePattern::Glob(glob) => {\n1217-            let mut cur = path;\n1218-            loop {\n1219-                if glob_match_path(glob, cur) {\n1220-                    return true;\n1221-                }\n1222-\n1223-                if cur == \"/\" {\n1224-                    break;"}]},"uuid":"23247808-9f01-4125-afc3-1f033f6e70e0","timestamp":"2026-02-22T07:43:33.704Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"732-        Err(_) => return Vec::new(),\n733-    };\n734-    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n735-        row.get::<_, String>(0)\n736-    }) {\n737-        Ok(r) => r,\n738-        Err(_) => return Vec::new(),\n739-    };\n740-    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n741-    if dirs.len() > RESOLVE_DIRS_MAX {\n742-        return Vec::new();\n743-    }\n744-    dirs\n745-}\n746-\n747:fn normalize_slashes(s: String) -> String {\n748-    s.replace('\\\\', \"/\")\n749-}\n750-\n751-fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n752-    let trimmed = raw.trim();\n753-    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n754-        return None;\n755-    }\n756-\n757-    let mut path = if trimmed == \"~\" {\n758-        home_dir.to_path_buf()\n759-    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n760-        home_dir.join(rest)\n761-    } else {\n762-        PathBuf::from(trimmed)\n--\n1194-                star_px + 1\n1195-            };\n1196-            tx = star_tx;\n1197-        } else {\n1198-            return false;\n1199-        }\n1200-    }\n1201-\n1202-    while px < pn && pat[px] == b'*' {\n1203-        px += 1;\n1204-    }\n1205-\n1206-    px == pn\n1207-}\n1208-\n1209:pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1210-    match pattern {\n1211-        IgnorePattern::AnySegment(segment) => {\n1212-            let suffix = format!(\"/{segment}\");\n1213-            let infix = format!(\"/{segment}/\");\n1214-            path.ends_with(&suffix) || path.contains(&infix)\n1215-        }\n1216-        IgnorePattern::Glob(glob) => {\n1217-            let mut cur = path;\n1218-            loop {\n1219-                if glob_match_path(glob, cur) {\n1220-                    return true;\n1221-                }\n1222-\n1223-                if cur == \"/\" {\n1224-                    break;","numLines":63},"sourceToolAssistantUUID":"3b76f8f9-7413-49a8-b7f7-6156cf7ad57f"}
{"parentUuid":"23247808-9f01-4125-afc3-1f033f6e70e0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01L5AWjAdBs6MXvtkCMAP3ys","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I see more inefficiencies:\n\n1. `normalize_slashes(path.to_string_lossy().to_string())` - on macOS, this is just `path.to_string_lossy().to_string()` since there are no backslashes. The replace() call is essentially a no-op but still allocates. On macOS paths (always forward slashes), this creates a String copy unnecessarily.\n\n2. `matches_ignore_pattern` creates two format strings per `AnySegment` pattern call:\n```rust\nlet suffix = format!(\"/{segment}\");\nlet infix = format!(\"/{segment}/\");\n\n\n```\nThese get allocated for every single entry we check. With 5 AnySegment patterns and 400k entries, that's millions of unnecessary allocations just for string formatting.\n\n3. `BUILTIN_SKIP_PATHS.iter().any(|pat| { let infix = format!(\"/{pat}/\"); ... })` - creates 8 strings per entry, and this runs in parallel across rayon threads during `process_read_dir` and the initial scan of priority/deferred roots. The format string creation is happening inside the hot path where it's called repeatedly.\n\nThe real bottleneck I should focus on is the serial `stat()` calls in the main loop. When we iterate through `walker`, each call to `index_row_from_jwalk_entry` triggers `entry.metadata()`, which blocks. I could pre-fetch metadata within the `process_read_dir` closure by iterating over the children and warming the OS cache before the main loop processes them.\n```\nOn macOS APFS, `readdir` gives us `d_type` for file type but not the full stat info—we need a separate `stat()` call to get `mtime` and `size`. Since we're doing a fresh index, we don't need to compare against existing entries, but we still have to store `mtime` and `size` in the database for display and future incremental scans. The second major issue is string allocations in the hot path across 400k entries.\n\nFor each entry, we're creating multiple strings: the full path, just the filename, the parent directory, a lowercased extension, and another normalized path string in the skip check. That's roughly 5 allocations per entry totaling 2 million allocations with malloc/free overhead. I can optimize this by building the path string once and reusing slices of it instead of repeatedly converting and allocating. I need to verify whether jwalk 0.8 exposes `parent_path` and `file_name` as public fields or methods, since that's the key to avoiding the PathBuf allocation that `entry.path()` would create.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2350,"cache_read_input_tokens":70925,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2350},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjU3VNcBemDWmWQRxgp","type":"assistant","uuid":"d1a826f9-82d8-46fe-864b-2f5893a98cd8","timestamp":"2026-02-22T07:43:59.222Z"}
{"parentUuid":"d1a826f9-82d8-46fe-864b-2f5893a98cd8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01L5AWjAdBs6MXvtkCMAP3ys","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0116AKvcCUgHibw3o9hqM2Tf","name":"Bash","input":{"command":"cargo metadata --format-version 1 2>/dev/null | python3 -c \"import json,sys; data=json.load(sys.stdin); [print(p['manifest_path']) for p in data['packages'] if p['name']=='jwalk']\"","description":"Find jwalk package location"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2350,"cache_read_input_tokens":70925,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2350},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjU3VNcBemDWmWQRxgp","type":"assistant","uuid":"e6d2428e-8376-4347-94aa-4bd10d1bfa83","timestamp":"2026-02-22T07:43:59.828Z"}
{"parentUuid":"e6d2428e-8376-4347-94aa-4bd10d1bfa83","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 1\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n    import json,sys; data=json.load(sys.stdin); [print(p['manifest_path']) for p in data['packages'] if p['name']=='jwalk']\n                          ~~~~~~~~~^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n        cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n    import json,sys; data=json.load(sys.stdin); [print(p['manifest_path']) for p in data['packages'] if p['name']=='jwalk']\n                          ~~~~~~~~~^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n        cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)","is_error":true,"tool_use_id":"toolu_0116AKvcCUgHibw3o9hqM2Tf"}]},"uuid":"f299ea3f-7624-4455-87cd-35a11df2e614","timestamp":"2026-02-22T07:44:02.247Z","toolUseResult":"Error: Exit code 1\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n    import json,sys; data=json.load(sys.stdin); [print(p['manifest_path']) for p in data['packages'] if p['name']=='jwalk']\n                          ~~~~~~~~~^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n        cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n    import json,sys; data=json.load(sys.stdin); [print(p['manifest_path']) for p in data['packages'] if p['name']=='jwalk']\n                          ~~~~~~~~~^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n        cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)","sourceToolAssistantUUID":"e6d2428e-8376-4347-94aa-4bd10d1bfa83"}
{"parentUuid":"f299ea3f-7624-4455-87cd-35a11df2e614","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01CFn6r4VChxd4KP38xtYzcm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01AXD8H1UGo5arQEe9rKzJWt","name":"Bash","input":{"command":"find ~/.cargo/registry/src -name \"*.rs\" -path \"*/jwalk*\" | head -5","description":"Find jwalk source files"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2277,"cache_read_input_tokens":73275,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2277},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjW9a3gRTGjxJrXWfEG","type":"assistant","uuid":"492ea712-194b-4e15-a937-3e64a52f6f6d","timestamp":"2026-02-22T07:44:04.488Z"}
{"parentUuid":"492ea712-194b-4e15-a937-3e64a52f6f6d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AXD8H1UGo5arQEe9rKzJWt","type":"tool_result","content":"/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/tests/util/mod.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/tests/detect_deadlock.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/tests/integration.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/examples/du.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/benches/walk_benchmark.rs","is_error":false}]},"uuid":"583752bb-dcb8-4128-97c0-5eb12b550933","timestamp":"2026-02-22T07:44:05.321Z","toolUseResult":{"stdout":"/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/tests/util/mod.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/tests/detect_deadlock.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/tests/integration.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/examples/du.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/benches/walk_benchmark.rs","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"492ea712-194b-4e15-a937-3e64a52f6f6d"}
{"parentUuid":"583752bb-dcb8-4128-97c0-5eb12b550933","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_013MdYVAMGoH2s4isMRggFEd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01W9M3nmaMpHWQHDbCqMVhFB","name":"Bash","input":{"command":"find ~/.cargo/registry/src -path \"*/jwalk-0.8*\" -name \"*.rs\" | grep -v test | grep -v bench | grep -v example | head -10","description":"Find jwalk source files"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":355,"cache_read_input_tokens":75552,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":355},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjWNkJfie59WDXzEKcE","type":"assistant","uuid":"dc901eb9-eaec-4338-a6f5-cfef1922ac2a","timestamp":"2026-02-22T07:44:07.503Z"}
{"parentUuid":"dc901eb9-eaec-4338-a6f5-cfef1922ac2a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01W9M3nmaMpHWQHDbCqMVhFB","type":"tool_result","content":"/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/dir_entry_iter.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/dir_entry.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/error.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/ordered_queue.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/mod.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir_iter.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/ordered.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir_spec.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/run_context.rs","is_error":false}]},"uuid":"f4a878af-9495-447f-83c9-46b980fd595c","timestamp":"2026-02-22T07:44:08.165Z","toolUseResult":{"stdout":"/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/dir_entry_iter.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/dir_entry.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/error.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/ordered_queue.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/mod.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir_iter.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/ordered.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir_spec.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir.rs\n/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/run_context.rs","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"dc901eb9-eaec-4338-a6f5-cfef1922ac2a"}
{"parentUuid":"f4a878af-9495-447f-83c9-46b980fd595c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01HBzPvFPi32jWno8vknAW4j","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011kf1MjNuaaF5zsR3Xx6Wyr","name":"Read","input":{"file_path":"/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/dir_entry.rs"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":646,"cache_read_input_tokens":75907,"output_tokens":103,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":646,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNjWbSJJmCGVUtSSeTMD","type":"assistant","uuid":"b8915d3d-d185-4a35-bf5b-b29a29622b62","timestamp":"2026-02-22T07:44:10.230Z"}
{"parentUuid":"b8915d3d-d185-4a35-bf5b-b29a29622b62","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_011kf1MjNuaaF5zsR3Xx6Wyr","toolUseID":"toolu_011kf1MjNuaaF5zsR3Xx6Wyr","timestamp":"2026-02-22T07:44:10.257Z","uuid":"51922292-7998-4aee-b913-0a1d19aeb359"}
{"parentUuid":"b8915d3d-d185-4a35-bf5b-b29a29622b62","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011kf1MjNuaaF5zsR3Xx6Wyr","type":"tool_result","content":"     1→use std::ffi::{OsStr, OsString};\n     2→use std::fmt;\n     3→use std::fs::{self, FileType};\n     4→use std::path::{Path, PathBuf};\n     5→use std::sync::Arc;\n     6→\n     7→use crate::{ClientState, Error, ReadDirSpec, Result};\n     8→\n     9→/// Representation of a file or directory.\n    10→///\n    11→/// This representation does not wrap a `std::fs::DirEntry`. Instead it copies\n    12→/// `file_name`, `file_type`, and optionally `metadata` out of the underlying\n    13→/// `std::fs::DirEntry`. This allows it to quickly drop the underlying file\n    14→/// descriptor.\n    15→pub struct DirEntry<C: ClientState> {\n    16→    /// Depth of this entry relative to the root directory where the walk\n    17→    /// started.\n    18→    pub depth: usize,\n    19→    /// File name of this entry without leading path component.\n    20→    pub file_name: OsString,\n    21→    /// File type for the file/directory that this entry points at.\n    22→    pub file_type: FileType,\n    23→    /// Field where clients can store state from within the The\n    24→    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n    25→    /// callback.\n    26→    pub client_state: C::DirEntryState,\n    27→    /// Path used by this entry's parent to read this entry.\n    28→    pub parent_path: Arc<Path>,\n    29→    /// Path that will be used to read child entries. This is automatically set\n    30→    /// for directories. The\n    31→    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir) callback\n    32→    /// may set this field to `None` to skip reading the contents of a\n    33→    /// particular directory.\n    34→    pub read_children_path: Option<Arc<Path>>,\n    35→    /// If `read_children_path` is set and resulting `fs::read_dir` generates an error\n    36→    /// then that error is stored here.\n    37→    pub read_children_error: Option<Error>,\n    38→    // True if [`follow_links`] is `true` AND was created from a symlink path.\n    39→    follow_link: bool,\n    40→    // Origins of symlinks followed to get to this entry.\n    41→    follow_link_ancestors: Arc<Vec<Arc<Path>>>,\n    42→}\n    43→\n    44→impl<C: ClientState> DirEntry<C> {\n    45→    pub(crate) fn from_entry(\n    46→        depth: usize,\n    47→        parent_path: Arc<Path>,\n    48→        fs_dir_entry: &fs::DirEntry,\n    49→        follow_link_ancestors: Arc<Vec<Arc<Path>>>,\n    50→    ) -> Result<Self> {\n    51→        let file_type = fs_dir_entry\n    52→            .file_type()\n    53→            .map_err(|err| Error::from_path(depth, fs_dir_entry.path(), err))?;\n    54→        let file_name = fs_dir_entry.file_name();\n    55→        let read_children_path: Option<Arc<Path>> = if file_type.is_dir() {\n    56→            Some(Arc::from(parent_path.join(&file_name)))\n    57→        } else {\n    58→            None\n    59→        };\n    60→\n    61→        Ok(DirEntry {\n    62→            depth,\n    63→            file_name,\n    64→            file_type,\n    65→            parent_path,\n    66→            read_children_path,\n    67→            read_children_error: None,\n    68→            client_state: C::DirEntryState::default(),\n    69→            follow_link: false,\n    70→            follow_link_ancestors,\n    71→        })\n    72→    }\n    73→\n    74→    // Only used for root and when following links.\n    75→    pub(crate) fn from_path(\n    76→        depth: usize,\n    77→        path: &Path,\n    78→        follow_link: bool,\n    79→        follow_link_ancestors: Arc<Vec<Arc<Path>>>,\n    80→    ) -> Result<Self> {\n    81→        let metadata = if follow_link {\n    82→            fs::metadata(path).map_err(|err| Error::from_path(depth, path.to_owned(), err))?\n    83→        } else {\n    84→            fs::symlink_metadata(path)\n    85→                .map_err(|err| Error::from_path(depth, path.to_owned(), err))?\n    86→        };\n    87→\n    88→        let root_name = path.file_name().unwrap_or(path.as_os_str());\n    89→\n    90→        let read_children_path: Option<Arc<Path>> = if metadata.file_type().is_dir() {\n    91→            Some(Arc::from(path))\n    92→        } else {\n    93→            None\n    94→        };\n    95→\n    96→        Ok(DirEntry {\n    97→            depth,\n    98→            file_name: root_name.to_owned(),\n    99→            file_type: metadata.file_type(),\n   100→            parent_path: Arc::from(path.parent().map(Path::to_path_buf).unwrap_or_default()),\n   101→            read_children_path,\n   102→            read_children_error: None,\n   103→            client_state: C::DirEntryState::default(),\n   104→            follow_link,\n   105→            follow_link_ancestors,\n   106→        })\n   107→    }\n   108→\n   109→    /// Return the file type for the file that this entry points to.\n   110→    ///\n   111→    /// If this is a symbolic link and [`follow_links`] is `true`, then this\n   112→    /// returns the type of the target.\n   113→    ///\n   114→    /// This never makes any system calls.\n   115→    ///\n   116→    /// [`follow_links`]: struct.WalkDir.html#method.follow_links\n   117→    pub fn file_type(&self) -> FileType {\n   118→        self.file_type\n   119→    }\n   120→\n   121→    /// Return the file name of this entry.\n   122→    ///\n   123→    /// If this entry has no file name (e.g., `/`), then the full path is\n   124→    /// returned.\n   125→    pub fn file_name(&self) -> &OsStr {\n   126→        &self.file_name\n   127→    }\n   128→\n   129→    /// Returns the depth at which this entry was created relative to the root.\n   130→    ///\n   131→    /// The smallest depth is `0` and always corresponds to the path given\n   132→    /// to the `new` function on `WalkDir`. Its direct descendants have depth\n   133→    /// `1`, and their descendants have depth `2`, and so on.\n   134→    pub fn depth(&self) -> usize {\n   135→        self.depth\n   136→    }\n   137→\n   138→    /// Path to the file/directory represented by this entry.\n   139→    ///\n   140→    /// The path is created by joining `parent_path` with `file_name`.\n   141→    pub fn path(&self) -> PathBuf {\n   142→        self.parent_path.join(&self.file_name)\n   143→    }\n   144→\n   145→    /// Returns `true` if and only if this entry was created from a symbolic\n   146→    /// link. This is unaffected by the [`follow_links`] setting.\n   147→    ///\n   148→    /// When `true`, the value returned by the [`path`] method is a\n   149→    /// symbolic link name. To get the full target path, you must call\n   150→    /// [`std::fs::read_link(entry.path())`].\n   151→    ///\n   152→    /// [`path`]: struct.DirEntry.html#method.path\n   153→    /// [`follow_links`]: struct.WalkDir.html#method.follow_links\n   154→    /// [`std::fs::read_link(entry.path())`]: https://doc.rust-lang.org/stable/std/fs/fn.read_link.html\n   155→    pub fn path_is_symlink(&self) -> bool {\n   156→        self.file_type.is_symlink() || self.follow_link\n   157→    }\n   158→\n   159→    /// Return the metadata for the file that this entry points to.\n   160→    ///\n   161→    /// This will follow symbolic links if and only if the [`WalkDir`] value\n   162→    /// has [`follow_links`] enabled.\n   163→    ///\n   164→    /// # Platform behavior\n   165→    ///\n   166→    /// This always calls [`std::fs::symlink_metadata`].\n   167→    ///\n   168→    /// If this entry is a symbolic link and [`follow_links`] is enabled, then\n   169→    /// [`std::fs::metadata`] is called instead.\n   170→    ///\n   171→    /// # Errors\n   172→    ///\n   173→    /// Similar to [`std::fs::metadata`], returns errors for path values that\n   174→    /// the program does not have permissions to access or if the path does not\n   175→    /// exist.\n   176→    ///\n   177→    /// [`WalkDir`]: struct.WalkDir.html\n   178→    /// [`follow_links`]: struct.WalkDir.html#method.follow_links\n   179→    /// [`std::fs::metadata`]: https://doc.rust-lang.org/std/fs/fn.metadata.html\n   180→    /// [`std::fs::symlink_metadata`]: https://doc.rust-lang.org/stable/std/fs/fn.symlink_metadata.html\n   181→    pub fn metadata(&self) -> Result<fs::Metadata> {\n   182→        if self.follow_link {\n   183→            fs::metadata(&self.path())\n   184→        } else {\n   185→            fs::symlink_metadata(&self.path())\n   186→        }\n   187→        .map_err(|err| Error::from_entry(self, err))\n   188→    }\n   189→\n   190→    /// Reference to the path of the directory containing this entry.\n   191→    pub fn parent_path(&self) -> &Path {\n   192→        &self.parent_path\n   193→    }\n   194→\n   195→    pub(crate) fn read_children_spec(\n   196→        &self,\n   197→        client_read_state: C::ReadDirState,\n   198→    ) -> Option<ReadDirSpec<C>> {\n   199→        self.read_children_path\n   200→            .as_ref()\n   201→            .map(|read_children_path| ReadDirSpec {\n   202→                depth: self.depth,\n   203→                client_read_state,\n   204→                path: read_children_path.clone(),\n   205→                follow_link_ancestors: self.follow_link_ancestors.clone(),\n   206→            })\n   207→    }\n   208→\n   209→    pub(crate) fn follow_symlink(&self) -> Result<Self> {\n   210→        let path = self.path();\n   211→        let origins = self.follow_link_ancestors.clone();\n   212→        let dir_entry = DirEntry::from_path(self.depth, &path, true, origins)?;\n   213→\n   214→        if dir_entry.file_type.is_dir() {\n   215→            let target = fs::read_link(&path).map_err(|err| Error::from_io(self.depth, err))?;\n   216→            for ancestor in self.follow_link_ancestors.iter().rev() {\n   217→                if target.as_path() == ancestor.as_ref() {\n   218→                    return Err(Error::from_loop(\n   219→                        self.depth,\n   220→                        ancestor.as_ref(),\n   221→                        path.as_ref(),\n   222→                    ));\n   223→                }\n   224→            }\n   225→        }\n   226→\n   227→        Ok(dir_entry)\n   228→    }\n   229→}\n   230→\n   231→impl<C: ClientState> fmt::Debug for DirEntry<C> {\n   232→    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n   233→        write!(f, \"DirEntry({:?})\", self.path())\n   234→    }\n   235→}\n   236→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"48e2531d-c063-4e76-9cdb-58d16995948c","timestamp":"2026-02-22T07:44:10.255Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/dir_entry.rs","content":"use std::ffi::{OsStr, OsString};\nuse std::fmt;\nuse std::fs::{self, FileType};\nuse std::path::{Path, PathBuf};\nuse std::sync::Arc;\n\nuse crate::{ClientState, Error, ReadDirSpec, Result};\n\n/// Representation of a file or directory.\n///\n/// This representation does not wrap a `std::fs::DirEntry`. Instead it copies\n/// `file_name`, `file_type`, and optionally `metadata` out of the underlying\n/// `std::fs::DirEntry`. This allows it to quickly drop the underlying file\n/// descriptor.\npub struct DirEntry<C: ClientState> {\n    /// Depth of this entry relative to the root directory where the walk\n    /// started.\n    pub depth: usize,\n    /// File name of this entry without leading path component.\n    pub file_name: OsString,\n    /// File type for the file/directory that this entry points at.\n    pub file_type: FileType,\n    /// Field where clients can store state from within the The\n    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n    /// callback.\n    pub client_state: C::DirEntryState,\n    /// Path used by this entry's parent to read this entry.\n    pub parent_path: Arc<Path>,\n    /// Path that will be used to read child entries. This is automatically set\n    /// for directories. The\n    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir) callback\n    /// may set this field to `None` to skip reading the contents of a\n    /// particular directory.\n    pub read_children_path: Option<Arc<Path>>,\n    /// If `read_children_path` is set and resulting `fs::read_dir` generates an error\n    /// then that error is stored here.\n    pub read_children_error: Option<Error>,\n    // True if [`follow_links`] is `true` AND was created from a symlink path.\n    follow_link: bool,\n    // Origins of symlinks followed to get to this entry.\n    follow_link_ancestors: Arc<Vec<Arc<Path>>>,\n}\n\nimpl<C: ClientState> DirEntry<C> {\n    pub(crate) fn from_entry(\n        depth: usize,\n        parent_path: Arc<Path>,\n        fs_dir_entry: &fs::DirEntry,\n        follow_link_ancestors: Arc<Vec<Arc<Path>>>,\n    ) -> Result<Self> {\n        let file_type = fs_dir_entry\n            .file_type()\n            .map_err(|err| Error::from_path(depth, fs_dir_entry.path(), err))?;\n        let file_name = fs_dir_entry.file_name();\n        let read_children_path: Option<Arc<Path>> = if file_type.is_dir() {\n            Some(Arc::from(parent_path.join(&file_name)))\n        } else {\n            None\n        };\n\n        Ok(DirEntry {\n            depth,\n            file_name,\n            file_type,\n            parent_path,\n            read_children_path,\n            read_children_error: None,\n            client_state: C::DirEntryState::default(),\n            follow_link: false,\n            follow_link_ancestors,\n        })\n    }\n\n    // Only used for root and when following links.\n    pub(crate) fn from_path(\n        depth: usize,\n        path: &Path,\n        follow_link: bool,\n        follow_link_ancestors: Arc<Vec<Arc<Path>>>,\n    ) -> Result<Self> {\n        let metadata = if follow_link {\n            fs::metadata(path).map_err(|err| Error::from_path(depth, path.to_owned(), err))?\n        } else {\n            fs::symlink_metadata(path)\n                .map_err(|err| Error::from_path(depth, path.to_owned(), err))?\n        };\n\n        let root_name = path.file_name().unwrap_or(path.as_os_str());\n\n        let read_children_path: Option<Arc<Path>> = if metadata.file_type().is_dir() {\n            Some(Arc::from(path))\n        } else {\n            None\n        };\n\n        Ok(DirEntry {\n            depth,\n            file_name: root_name.to_owned(),\n            file_type: metadata.file_type(),\n            parent_path: Arc::from(path.parent().map(Path::to_path_buf).unwrap_or_default()),\n            read_children_path,\n            read_children_error: None,\n            client_state: C::DirEntryState::default(),\n            follow_link,\n            follow_link_ancestors,\n        })\n    }\n\n    /// Return the file type for the file that this entry points to.\n    ///\n    /// If this is a symbolic link and [`follow_links`] is `true`, then this\n    /// returns the type of the target.\n    ///\n    /// This never makes any system calls.\n    ///\n    /// [`follow_links`]: struct.WalkDir.html#method.follow_links\n    pub fn file_type(&self) -> FileType {\n        self.file_type\n    }\n\n    /// Return the file name of this entry.\n    ///\n    /// If this entry has no file name (e.g., `/`), then the full path is\n    /// returned.\n    pub fn file_name(&self) -> &OsStr {\n        &self.file_name\n    }\n\n    /// Returns the depth at which this entry was created relative to the root.\n    ///\n    /// The smallest depth is `0` and always corresponds to the path given\n    /// to the `new` function on `WalkDir`. Its direct descendants have depth\n    /// `1`, and their descendants have depth `2`, and so on.\n    pub fn depth(&self) -> usize {\n        self.depth\n    }\n\n    /// Path to the file/directory represented by this entry.\n    ///\n    /// The path is created by joining `parent_path` with `file_name`.\n    pub fn path(&self) -> PathBuf {\n        self.parent_path.join(&self.file_name)\n    }\n\n    /// Returns `true` if and only if this entry was created from a symbolic\n    /// link. This is unaffected by the [`follow_links`] setting.\n    ///\n    /// When `true`, the value returned by the [`path`] method is a\n    /// symbolic link name. To get the full target path, you must call\n    /// [`std::fs::read_link(entry.path())`].\n    ///\n    /// [`path`]: struct.DirEntry.html#method.path\n    /// [`follow_links`]: struct.WalkDir.html#method.follow_links\n    /// [`std::fs::read_link(entry.path())`]: https://doc.rust-lang.org/stable/std/fs/fn.read_link.html\n    pub fn path_is_symlink(&self) -> bool {\n        self.file_type.is_symlink() || self.follow_link\n    }\n\n    /// Return the metadata for the file that this entry points to.\n    ///\n    /// This will follow symbolic links if and only if the [`WalkDir`] value\n    /// has [`follow_links`] enabled.\n    ///\n    /// # Platform behavior\n    ///\n    /// This always calls [`std::fs::symlink_metadata`].\n    ///\n    /// If this entry is a symbolic link and [`follow_links`] is enabled, then\n    /// [`std::fs::metadata`] is called instead.\n    ///\n    /// # Errors\n    ///\n    /// Similar to [`std::fs::metadata`], returns errors for path values that\n    /// the program does not have permissions to access or if the path does not\n    /// exist.\n    ///\n    /// [`WalkDir`]: struct.WalkDir.html\n    /// [`follow_links`]: struct.WalkDir.html#method.follow_links\n    /// [`std::fs::metadata`]: https://doc.rust-lang.org/std/fs/fn.metadata.html\n    /// [`std::fs::symlink_metadata`]: https://doc.rust-lang.org/stable/std/fs/fn.symlink_metadata.html\n    pub fn metadata(&self) -> Result<fs::Metadata> {\n        if self.follow_link {\n            fs::metadata(&self.path())\n        } else {\n            fs::symlink_metadata(&self.path())\n        }\n        .map_err(|err| Error::from_entry(self, err))\n    }\n\n    /// Reference to the path of the directory containing this entry.\n    pub fn parent_path(&self) -> &Path {\n        &self.parent_path\n    }\n\n    pub(crate) fn read_children_spec(\n        &self,\n        client_read_state: C::ReadDirState,\n    ) -> Option<ReadDirSpec<C>> {\n        self.read_children_path\n            .as_ref()\n            .map(|read_children_path| ReadDirSpec {\n                depth: self.depth,\n                client_read_state,\n                path: read_children_path.clone(),\n                follow_link_ancestors: self.follow_link_ancestors.clone(),\n            })\n    }\n\n    pub(crate) fn follow_symlink(&self) -> Result<Self> {\n        let path = self.path();\n        let origins = self.follow_link_ancestors.clone();\n        let dir_entry = DirEntry::from_path(self.depth, &path, true, origins)?;\n\n        if dir_entry.file_type.is_dir() {\n            let target = fs::read_link(&path).map_err(|err| Error::from_io(self.depth, err))?;\n            for ancestor in self.follow_link_ancestors.iter().rev() {\n                if target.as_path() == ancestor.as_ref() {\n                    return Err(Error::from_loop(\n                        self.depth,\n                        ancestor.as_ref(),\n                        path.as_ref(),\n                    ));\n                }\n            }\n        }\n\n        Ok(dir_entry)\n    }\n}\n\nimpl<C: ClientState> fmt::Debug for DirEntry<C> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"DirEntry({:?})\", self.path())\n    }\n}\n","numLines":236,"startLine":1,"totalLines":236}},"sourceToolAssistantUUID":"b8915d3d-d185-4a35-bf5b-b29a29622b62"}
{"parentUuid":"48e2531d-c063-4e76-9cdb-58d16995948c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01YEZJ6iGYsLBD7ZABRdskJ2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the jwalk DirEntry structure:\n\n1. `entry.path()` calls `self.parent_path.join(&self.file_name)` - allocates a new PathBuf each time!\n2. `entry.metadata()` calls `fs::symlink_metadata(&self.path())` - always calls `path()` first (allocates PathBuf), then does `stat()` syscall!\n3. `entry.file_type` is already available without syscall (from readdir)\n4. `entry.parent_path` is `Arc<Path>` - no allocation\n5. `entry.file_name` is `OsString` - no allocation to read\n\n\n6. The real problem: we're calling `path()` three separate times in the indexing pipeline - once in `index_row_from_jwalk_entry`, again inside `metadata()`, and a third time when passing to `index_row_from_path_and_metadata` - that's three PathBuf allocations plus redundant stat() syscalls per entry!\n\n7. Then inside `index_row_from_path_and_metadata`, we're converting the path to strings multiple times: the full path, the filename, and the parent directory, each with their own allocations. But since we already have the parent path and filename from jwalk, we could reconstruct the full path string without creating intermediate PathBufs.\n\n8. The key optimization is to refactor `index_row_from_jwalk_entry` to call `entry.path()` exactly once, cache that result, and pass it through the entire pipeline to avoid redundant allocations and syscalls. I see that `follow_link` is private, so I can't check it directly. Looking at the `metadata()` method implementation, since our walker has `follow_links` set to `false`, all entries will use `fs::symlink_metadata`. I can simplify the function to just call that directly and avoid the redundant path allocations.\n\nNow I'm looking at how to optimize the path string building in `index_row_from_path_and_metadata`. The function already receives a `&Path`, so I need to think about where the allocations are happening—it's in converting the path to a string and extracting the parent and filename components.\n\nThe real bottleneck though is that metadata fetching happens serially on the main thread. I could parallelize this using rayon to pre-fetch stats in worker threads before processing the directory entries.\n\njwalk actually supports custom client state through a type parameter, so I can define a custom state that caches metadata directly on each DirEntry. This way I can fetch metadata in parallel within the rayon threads and attach it to the entry for later use.\n\nDefining the custom state structure... Checking the jwalk API to understand how to configure the walker with custom client state—the generic parameter C determines what metadata gets attached to each directory entry, and I need to see if I can use that to store pre-fetched symlink metadata instead of computing it on-demand. state type.\n\nWe can definitely implement this! Let me design the solution by creating a custom client state that holds pre-fetched metadata, though this would require changing the type signature of `index_row_from_jwalk_entry` or making it generic.\n\nActually, let me reconsider the parallelism here. Since `process_read_dir` runs per-directory in a rayon thread, and within each directory all entries are processed sequentially in that same thread, the metadata pre-fetch would also happen serially for all entries in that directory. With 4 rayon threads scanning 4 directories in parallel, we'd have 4 stat() calls happening concurrently, which is the bottleneck anyway. The main thread's consumer loop should be fast enough to keep up since stat() is what's slow, so we could pre-fetch metadata within each directory's rayon task and then pick up the entries in the main thread without additional stat() calls. So the main thread ends up doing all the stat() calls serially when it accesses entry.metadata(). By pre-fetching metadata in process_read_dir—which runs in parallel rayon threads—I can move those stat() syscalls off the main thread entirely. This means multiple directories get their metadata fetched simultaneously, and the main thread just reads the cached results without blocking on syscalls.\n\nMy implementation approach is to create a custom ClientState that holds optional metadata for each entry, populate it during process_read_dir filtering, then have index_row_from_jwalk_entry pull from that cache instead of calling entry.metadata() again.\n\nFor thread count, I'm thinking the current formula (n/2).max(4).min(16) is too conservative for a fresh index where I want maximum throughput. I could use all available cores up to 16, which would double the thread count on typical machines and potentially halve the file walking time.\n\nI also want to defer the ANALYZE step until after the index is marked Ready, running it asynchronously in the background so users can start searching immediately while the analysis completes.\n\nPre-computing the skip path patterns... Now I'm prioritizing these optimizations by complexity versus impact. Calling `path()` once instead of multiple times would eliminate around 800k allocations and save half a second to a second. Increasing thread count for the fresh index could be 30-50% faster on systems with many cores, saving 10-20 seconds. Pre-fetching metadata in parallel would take more effort but could save 10-30 seconds by parallelizing stat calls. Pre-computing the skip path strings would reduce allocations significantly, though the gains depend on how often these patterns are matched.\n\nLooking at what's needed to get from 78 seconds down to under 50 seconds, I need to save at least 28 seconds. The thread count increase alone could give me 8-15 seconds on a multi-core system, parallel stats could add another 10-20 seconds, and async ANALYZE might save another 3-8 seconds. The smaller optimizations like fixing the double path calls and pre-computing strings would chip away at the remaining time.\n\nI should prioritize the safer, simpler changes first—fixing the redundant path calls and bumping up the thread count—then move into the more complex optimizations like parallel metadata fetching and async analysis. The metadata approach needs careful consideration since it involves modifying how the directory walker callback works.\n\nLooking at the jwalk callback signature, I can store metadata directly on each directory entry by setting the associated type to `Option<Metadata>`. This way the stat calls happen in the rayon worker threads where they belong, and the main thread just reads the cached results.\n\nImplementing the metadata caching... I'm constructing the IndexRow by extracting the file name and parent path directly from the entry to minimize allocations, then building the full path string, determining if it's a directory, extracting the file extension if applicable, and computing the modification time from the metadata. I'm working through how to handle ownership when extracting the metadata from the entry—since the entry is owned by value in the loop, I can move the client_state out directly, but then I need to be careful about accessing other fields like path and file_name from the same entry afterward. I'm verifying that `client_state` is publicly accessible on `DirEntry`, which it is. So my implementation plan is to define a `MetaState` struct implementing `ClientState` with `DirEntryState` as `Option<Metadata>`, update the walker to use it, fetch and store metadata during directory reading, and then use that stored metadata when building index rows.\n\nNow I'm thinking through the `process_read_dir` closure structure...\n\nImplementing the filtering and metadata fetching logic...\n\nStill writing the walker setup... We need the full path for most of the filtering checks—skipping names, paths, ignored roots, patterns, and gitignore all require it—so we can't really avoid that PathBuf allocation in the filter step.\n\nThe real question is whether we can consolidate the two allocations (one for filtering, one for the stat call) into a single one. The `retain` approach doesn't let us carry data through, but I could restructure this to iterate through entries once, building up the full paths and checking conditions in a single pass rather than filtering first and then looping again. I see the issue now—`retain` only gives immutable references, so I can't mutate `entry.client_state` while filtering. I'll need to do this in two passes: first filter with `retain` to check the skip conditions, then iterate mutably to populate the metadata. That means two PathBuf allocations per entry during processing, which is acceptable.\n\nActually, looking at the allocation breakdown more carefully—the old approach creates one PathBuf during filtering in the rayon thread and another during metadata collection in the main thread. The new approach still creates two PathBufs per entry, but now both the filtering and metadata work happen in parallel rayon threads instead of serializing the metadata step on the main thread. That's where the real performance gain comes from.\n\nNow I need to look at the PathBuf allocations happening inside `should_skip_path_ext`. The filter creates a full path by joining the directory with the entry name, then passes it to the skip check function which internally normalizes the path to a string...\n\nStill analyzing path allocations... I could optimize by checking the filename directly against `BUILTIN_SKIP_NAMES` without constructing the full path string, since that's a simple segment comparison—only the multi-segment path checks would need the complete path built.\n\nNow I'm looking at the actual performance bottlenecks: parallelizing stat() calls in the read directory process could save 10-30 seconds, increasing thread count for fresh operations might gain another 5-15 seconds on multi-core systems, running ANALYZE in the background after Ready would eliminate the perceived wait time, and switching to a passive WAL checkpoint mode instead of truncate could shave off a few seconds.\n\nThe biggest wins are the parallel stat() implementation and the thread count increase, so I'll focus there first. For the parallel stat() approach, I need to define how the client state metadata gets pre-fetched, update the walker builder to use it, and modify the index row function to leverage this pre-computed state—but I should verify this won't break the incremental index path since the same walker handles both fresh and incremental scans. Looking at the code flow, the walker is created in the incremental index function and reused, so the optimization should apply to both cases without issues.\n\nFor thread count, I can either increase the default in `jwalk_num_threads()` or create a separate function for fresh scans, since incremental scans shouldn't use too many threads while other operations are running. The async ANALYZE approach is straightforward—spawn a background thread after the index completes and emits \"Ready\", accepting that query planning might be suboptimal for the first few searches. For the checkpoint optimization, switching to `wal_checkpoint(PASSIVE)` avoids blocking writers while still doing a best-effort checkpoint.\n\nNow I'm ready to implement these changes. I'll start by defining a ClientState type for metadata pre-fetching in the rayon threads and increase the thread count for fresh index operations...\n\nActually, let me first verify that jwalk 0.8 has the ClientState trait I need to import.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3509,"cache_read_input_tokens":76553,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3509},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjWjdQyoBqzz2qHHUBC","type":"assistant","uuid":"82b11317-da7a-4ef8-81e2-e75954f25a75","timestamp":"2026-02-22T07:46:30.171Z"}
{"parentUuid":"82b11317-da7a-4ef8-81e2-e75954f25a75","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01YEZJ6iGYsLBD7ZABRdskJ2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HGFGeX2P1axBBx7FzpktNk","name":"Bash","input":{"command":"cat /Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/lib.rs | head -100","description":"Check jwalk 0.8 exports"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3509,"cache_read_input_tokens":76553,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3509},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjWjdQyoBqzz2qHHUBC","type":"assistant","uuid":"72b6320b-b51d-4fb0-9d50-cdc2dd803f19","timestamp":"2026-02-22T07:46:31.410Z"}
{"parentUuid":"72b6320b-b51d-4fb0-9d50-cdc2dd803f19","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HGFGeX2P1axBBx7FzpktNk","type":"tool_result","content":"#![warn(clippy::all)]\n\n//! Filesystem walk.\n//!\n//! - Performed in parallel using rayon\n//! - Entries streamed in sorted order\n//! - Custom sort/filter/skip/state\n//!\n//! # Example\n//!\n//! Recursively iterate over the \"foo\" directory sorting by name:\n//!\n//! ```no_run\n//! # use std::io::Error;\n//! use jwalk::{WalkDir};\n//!\n//! # fn try_main() -> Result<(), Error> {\n//! for entry in WalkDir::new(\"foo\").sort(true) {\n//!   println!(\"{}\", entry?.path().display());\n//! }\n//! # Ok(())\n//! # }\n//! ```\n//! # Extended Example\n//!\n//! This example uses the\n//! [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n//! callback for custom:\n//! 1. **Sort** Entries by name\n//! 2. **Filter** Errors and hidden files\n//! 3. **Skip** Content of directories at depth 2\n//! 4. **State** Track depth `read_dir_state`. Mark first entry in each\n//!    directory with [`client_state`](struct.DirEntry.html#field.client_state)\n//!    `= true`.\n//!\n//! ```no_run\n//! # use std::io::Error;\n//! use std::cmp::Ordering;\n//! use jwalk::{ WalkDirGeneric };\n//!\n//! # fn try_main() -> Result<(), Error> {\n//! let walk_dir = WalkDirGeneric::<((usize),(bool))>::new(\"foo\")\n//!     .process_read_dir(|depth, path, read_dir_state, children| {\n//!         // 1. Custom sort\n//!         children.sort_by(|a, b| match (a, b) {\n//!             (Ok(a), Ok(b)) => a.file_name.cmp(&b.file_name),\n//!             (Ok(_), Err(_)) => Ordering::Less,\n//!             (Err(_), Ok(_)) => Ordering::Greater,\n//!             (Err(_), Err(_)) => Ordering::Equal,\n//!         });\n//!         // 2. Custom filter\n//!         children.retain(|dir_entry_result| {\n//!             dir_entry_result.as_ref().map(|dir_entry| {\n//!                 dir_entry.file_name\n//!                     .to_str()\n//!                     .map(|s| s.starts_with('.'))\n//!                     .unwrap_or(false)\n//!             }).unwrap_or(false)\n//!         });\n//!         // 3. Custom skip\n//!         children.iter_mut().for_each(|dir_entry_result| {\n//!             if let Ok(dir_entry) = dir_entry_result {\n//!                 if dir_entry.depth == 2 {\n//!                     dir_entry.read_children_path = None;\n//!                 }\n//!             }\n//!         });\n//!         // 4. Custom state\n//!         *read_dir_state += 1;\n//!         children.first_mut().map(|dir_entry_result| {\n//!             if let Ok(dir_entry) = dir_entry_result {\n//!                 dir_entry.client_state = true;\n//!             }\n//!         });\n//!     });\n//!\n//! for entry in walk_dir {\n//!   println!(\"{}\", entry?.path().display());\n//! }\n//! # Ok(())\n//! # }\n//! ```\n//! # Inspiration\n//!\n//! This crate is inspired by both [`walkdir`](https://crates.io/crates/walkdir)\n//! and [`ignore`](https://crates.io/crates/ignore). It attempts to combine the\n//! parallelism of `ignore` with `walkdir`'s streaming iterator API. Some code,\n//! comments, and test are copied directly from `walkdir`.\n//!\n//! # Implementation\n//!\n//! The following structures are central to the implementation:\n//!\n//! ## `ReadDirSpec`\n//!\n//! Specification of a future `read_dir` operation. These are stored in the\n//! `read_dir_spec_queue` in depth first order. When a rayon thread is ready for\n//! work it pulls the first availible `ReadDirSpec` from this queue.\n//!\n//! ## `ReadDir`","is_error":false}]},"uuid":"ed89204a-ab7d-49ec-b4d6-5727600f4a91","timestamp":"2026-02-22T07:46:31.569Z","toolUseResult":{"stdout":"#![warn(clippy::all)]\n\n//! Filesystem walk.\n//!\n//! - Performed in parallel using rayon\n//! - Entries streamed in sorted order\n//! - Custom sort/filter/skip/state\n//!\n//! # Example\n//!\n//! Recursively iterate over the \"foo\" directory sorting by name:\n//!\n//! ```no_run\n//! # use std::io::Error;\n//! use jwalk::{WalkDir};\n//!\n//! # fn try_main() -> Result<(), Error> {\n//! for entry in WalkDir::new(\"foo\").sort(true) {\n//!   println!(\"{}\", entry?.path().display());\n//! }\n//! # Ok(())\n//! # }\n//! ```\n//! # Extended Example\n//!\n//! This example uses the\n//! [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n//! callback for custom:\n//! 1. **Sort** Entries by name\n//! 2. **Filter** Errors and hidden files\n//! 3. **Skip** Content of directories at depth 2\n//! 4. **State** Track depth `read_dir_state`. Mark first entry in each\n//!    directory with [`client_state`](struct.DirEntry.html#field.client_state)\n//!    `= true`.\n//!\n//! ```no_run\n//! # use std::io::Error;\n//! use std::cmp::Ordering;\n//! use jwalk::{ WalkDirGeneric };\n//!\n//! # fn try_main() -> Result<(), Error> {\n//! let walk_dir = WalkDirGeneric::<((usize),(bool))>::new(\"foo\")\n//!     .process_read_dir(|depth, path, read_dir_state, children| {\n//!         // 1. Custom sort\n//!         children.sort_by(|a, b| match (a, b) {\n//!             (Ok(a), Ok(b)) => a.file_name.cmp(&b.file_name),\n//!             (Ok(_), Err(_)) => Ordering::Less,\n//!             (Err(_), Ok(_)) => Ordering::Greater,\n//!             (Err(_), Err(_)) => Ordering::Equal,\n//!         });\n//!         // 2. Custom filter\n//!         children.retain(|dir_entry_result| {\n//!             dir_entry_result.as_ref().map(|dir_entry| {\n//!                 dir_entry.file_name\n//!                     .to_str()\n//!                     .map(|s| s.starts_with('.'))\n//!                     .unwrap_or(false)\n//!             }).unwrap_or(false)\n//!         });\n//!         // 3. Custom skip\n//!         children.iter_mut().for_each(|dir_entry_result| {\n//!             if let Ok(dir_entry) = dir_entry_result {\n//!                 if dir_entry.depth == 2 {\n//!                     dir_entry.read_children_path = None;\n//!                 }\n//!             }\n//!         });\n//!         // 4. Custom state\n//!         *read_dir_state += 1;\n//!         children.first_mut().map(|dir_entry_result| {\n//!             if let Ok(dir_entry) = dir_entry_result {\n//!                 dir_entry.client_state = true;\n//!             }\n//!         });\n//!     });\n//!\n//! for entry in walk_dir {\n//!   println!(\"{}\", entry?.path().display());\n//! }\n//! # Ok(())\n//! # }\n//! ```\n//! # Inspiration\n//!\n//! This crate is inspired by both [`walkdir`](https://crates.io/crates/walkdir)\n//! and [`ignore`](https://crates.io/crates/ignore). It attempts to combine the\n//! parallelism of `ignore` with `walkdir`'s streaming iterator API. Some code,\n//! comments, and test are copied directly from `walkdir`.\n//!\n//! # Implementation\n//!\n//! The following structures are central to the implementation:\n//!\n//! ## `ReadDirSpec`\n//!\n//! Specification of a future `read_dir` operation. These are stored in the\n//! `read_dir_spec_queue` in depth first order. When a rayon thread is ready for\n//! work it pulls the first availible `ReadDirSpec` from this queue.\n//!\n//! ## `ReadDir`","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"72b6320b-b51d-4fb0-9d50-cdc2dd803f19"}
{"parentUuid":"ed89204a-ab7d-49ec-b4d6-5727600f4a91","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_0177qaoNfSrjsGqT1ujf7xvN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WTkrFohW6B5suHwfinvZAd","name":"Bash","input":{"command":"grep -n \"pub use\\|pub trait\\|pub struct\\|WalkDirGeneric\\|ClientState\" /Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/lib.rs | head -30","description":"Check jwalk public API"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":9648,"cache_read_input_tokens":80062,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9648},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjh9oFHsATtHSF8FsFy","type":"assistant","uuid":"ab164f74-8c07-46ec-8e9a-5a8ace77131b","timestamp":"2026-02-22T07:46:36.513Z"}
{"parentUuid":"ab164f74-8c07-46ec-8e9a-5a8ace77131b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WTkrFohW6B5suHwfinvZAd","type":"tool_result","content":"27://! [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n39://! use jwalk::{ WalkDirGeneric };\n42://! let walk_dir = WalkDirGeneric::<((usize),(bool))>::new(\"foo\")\n128:pub use crate::core::{DirEntry, DirEntryIter, Error};\n129:pub use rayon;\n132:pub type WalkDir = WalkDirGeneric<((), ())>;\n143:/// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir) callback.\n144:/// The type of ClientState is determined by WalkDirGeneric type parameter.\n145:pub trait ClientState: Send + Default + Debug + 'static {\n152:/// [`ClientState`](trait.ClientState.html) type parameter allows you to specify\n154:/// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n159:pub struct WalkDirGeneric<C: ClientState> {\n164:type ProcessReadDirFunction<C> = dyn Fn(Option<usize>, &Path, &mut <C as ClientState>::ReadDirState, &mut Vec<Result<DirEntry<C>>>)\n201:struct WalkDirOptions<C: ClientState> {\n212:impl<C: ClientState> WalkDirGeneric<C> {\n219:    /// has to be infallible. Use [`try_into_iter()`][WalkDirGeneric::try_into_iter()]\n222:        WalkDirGeneric {\n255:    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir) for custom\n329:    /// Initial ClientState::ReadDirState that is passed to\n330:    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n331:    /// when processing root. Defaults to ClientState::ReadDirState::default().\n356:fn process_dir_entry_result<C: ClientState>(\n387:impl<C: ClientState> IntoIterator for WalkDirGeneric<C> {\n502:impl<C: ClientState> Clone for WalkDirOptions<C> {\n556:impl<B, E> ClientState for (B, E)","is_error":false}]},"uuid":"95064a9b-4771-4219-8897-3bba1f9fbefe","timestamp":"2026-02-22T07:46:36.671Z","toolUseResult":{"stdout":"27://! [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n39://! use jwalk::{ WalkDirGeneric };\n42://! let walk_dir = WalkDirGeneric::<((usize),(bool))>::new(\"foo\")\n128:pub use crate::core::{DirEntry, DirEntryIter, Error};\n129:pub use rayon;\n132:pub type WalkDir = WalkDirGeneric<((), ())>;\n143:/// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir) callback.\n144:/// The type of ClientState is determined by WalkDirGeneric type parameter.\n145:pub trait ClientState: Send + Default + Debug + 'static {\n152:/// [`ClientState`](trait.ClientState.html) type parameter allows you to specify\n154:/// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n159:pub struct WalkDirGeneric<C: ClientState> {\n164:type ProcessReadDirFunction<C> = dyn Fn(Option<usize>, &Path, &mut <C as ClientState>::ReadDirState, &mut Vec<Result<DirEntry<C>>>)\n201:struct WalkDirOptions<C: ClientState> {\n212:impl<C: ClientState> WalkDirGeneric<C> {\n219:    /// has to be infallible. Use [`try_into_iter()`][WalkDirGeneric::try_into_iter()]\n222:        WalkDirGeneric {\n255:    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir) for custom\n329:    /// Initial ClientState::ReadDirState that is passed to\n330:    /// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n331:    /// when processing root. Defaults to ClientState::ReadDirState::default().\n356:fn process_dir_entry_result<C: ClientState>(\n387:impl<C: ClientState> IntoIterator for WalkDirGeneric<C> {\n502:impl<C: ClientState> Clone for WalkDirOptions<C> {\n556:impl<B, E> ClientState for (B, E)","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"ab164f74-8c07-46ec-8e9a-5a8ace77131b"}
{"parentUuid":"95064a9b-4771-4219-8897-3bba1f9fbefe","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01MdATetneXbWf4h1KdETpVD","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see! `ClientState` is a trait in jwalk. For `((), ())`, it's implemented generically for `(B, E)`. Let me check what `ClientState` requires.\n\nLooking at the jwalk source: `pub trait ClientState: Send + Default + Debug + 'static`.\n\nThe `ClientState` trait has associated types:- `ReadDirState` \n- `DirEntryState`\n\nFor `(B, E)`, it implements: `ReadDirState = B`, `DirEntryState = E`.\n\nSo I can use `((), Option<std::fs::Metadata>)` as the client state! This would give:\n\n\n- `ReadDirState = ()`\n- `DirEntryState = Option<std::fs::Metadata>` stored in `entry.client_state`\n\nNow I need to verify that `Option<std::fs::Metadata>` satisfies the trait bounds. `Option<T>` implements `Default` with `None` as the default value, and `Metadata` should be `Debug` and `Send`, so this should work.\n\nSo I can use `((), Option<std::fs::Metadata>)` as the `ClientState` tuple directly—much simpler than defining a custom struct. I'll instantiate the walker with this type and access the metadata through `entry.client_state`.\n\nFor the implementation, I need to fetch symlink metadata for each entry after filtering in `process_read_dir`, then update `index_row_from_jwalk_entry` to extract and use that metadata...\n\nUpdating the function signature and logic...\n\nNow I'm realizing there's a constraint issue: the `process_read_dir` closure needs to be `Send + Sync + 'static`, but I need to verify that the captured variables like `gi_ref`, `skip_roots`, and `skip_patterns` actually satisfy those bounds.\n\nChecking the function signature for `process_read_dir` and how it constructs the full path from the entry's file name...\n\nThe key insight is that `path` passed to the closure is already the parent directory for all entries, so `path.join(&entry.file_name)` gives us the same result as `entry.path()`. The problem is I'd be computing this path twice—once during the retain step and again during the metadata pre-fetch—which is wasteful.\n\nI could combine both operations into a single pass using a manual loop instead of `retain()`, computing the full path once and using it for both the skip check and the metadata fetch.\n\nCombining filter and stat in one pass... Still writing the filter logic...","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":750,"cache_read_input_tokens":89710,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":750},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjhY5SedQptmsP52uyu","type":"assistant","uuid":"47b2fe5c-1373-4ab4-971e-64736cf59159","timestamp":"2026-02-22T07:47:07.978Z"}
{"parentUuid":"47b2fe5c-1373-4ab4-971e-64736cf59159","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01MdATetneXbWf4h1KdETpVD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DBFy1cV252pBoDfsv5EaE8","name":"Bash","input":{"command":"grep -E \"edition|rust-version\" /Users/al02402336/everything/src-tauri/Cargo.toml","description":"Check Rust edition"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":750,"cache_read_input_tokens":89710,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":750},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjhY5SedQptmsP52uyu","type":"assistant","uuid":"f5876845-b4e7-4625-bccc-910d6ec1fde3","timestamp":"2026-02-22T07:47:08.803Z"}
{"parentUuid":"f5876845-b4e7-4625-bccc-910d6ec1fde3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DBFy1cV252pBoDfsv5EaE8","type":"tool_result","content":"edition = \"2021\"","is_error":false}]},"uuid":"3fdc8c4d-f753-406f-b090-aff7e22e97ab","timestamp":"2026-02-22T07:47:08.955Z","toolUseResult":{"stdout":"edition = \"2021\"","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"f5876845-b4e7-4625-bccc-910d6ec1fde3"}
{"parentUuid":"3fdc8c4d-f753-406f-b090-aff7e22e97ab","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01MZ4MpZXcpr9piRLmMax197","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BWtJUhxQtziWpZSR76JKrM","name":"Bash","input":{"command":"rustc --version","description":"Check Rust version"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1954,"cache_read_input_tokens":90460,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1954},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjjuoTsSDj4P5oEJ6xY","type":"assistant","uuid":"5a080f55-1941-4fac-a111-5b940c1a9050","timestamp":"2026-02-22T07:47:10.668Z"}
{"parentUuid":"5a080f55-1941-4fac-a111-5b940c1a9050","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BWtJUhxQtziWpZSR76JKrM","type":"tool_result","content":"rustc 1.90.0 (1159e78c4 2025-09-14)","is_error":false}]},"uuid":"d2d81096-0e7b-493b-95b3-b4f57d30db6b","timestamp":"2026-02-22T07:47:11.656Z","toolUseResult":{"stdout":"rustc 1.90.0 (1159e78c4 2025-09-14)","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"5a080f55-1941-4fac-a111-5b940c1a9050"}
{"parentUuid":"d2d81096-0e7b-493b-95b3-b4f57d30db6b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01W5u4tRT1f3bdwFyRuLq8BZ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Rust 1.90.0 - `retain_mut` was stabilized in 1.61, so it's available. Edition 2021.\n\nNow let me check the `ClientState` trait definition more carefully to understand what I need:","signature":"EtkCCkYICxgCKkAqt7FboFe1/trWDy46o12jEBdsrMSrHMdO/Lmde2/4ffTdPrgF5/9SPApCjaaJ8YHtmfL8Akc/lxpEN0R7ssN/EgycgXXfmPOubvR6GmkaDEoUTyCHjOv4ozUCqiIwZPG1j0gY6NFUhwv4CHcTsb7i/6xY0p6RdXqNGz+K0pHbWAiIekrGU37U1jwpAa+EKsABlrqAPRzL6uOKLT0nnXOVp/BOWK/brhPHxrMmqL4fZ1fM67UJ5zan3b+XX1IZoYv59v89fUyU0zpf8spCPHi0+e2Mv78oaHC1GTMW+zcqQq9pDFOFSZAQS/Y/fvTU723+hETmf82LlHOsBshzdTmZhs7SCDzl3qcScv1q2lVhgMvjBn9XNokFsSY6yW860+7UntGqbTrDb5BVTYb0rKlJDaMCrVqxeYnqYlnqXRingUO+6+b/3zQWr3jHkGrVK6LPGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":110,"cache_read_input_tokens":92414,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":110},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjk7VRQEknyUP3qsaE9","type":"assistant","uuid":"cb547c80-2f70-443d-b976-8fc69809beff","timestamp":"2026-02-22T07:47:13.937Z"}
{"parentUuid":"cb547c80-2f70-443d-b976-8fc69809beff","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01W5u4tRT1f3bdwFyRuLq8BZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DPW5bodYEFgdNxmXrVnQ5P","name":"Bash","input":{"command":"grep -A 20 \"pub trait ClientState\" /Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/lib.rs","description":"Check ClientState trait definition"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":110,"cache_read_input_tokens":92414,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":110},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjk7VRQEknyUP3qsaE9","type":"assistant","uuid":"d0e15e59-035b-41c4-b1c8-4cb5ac18562e","timestamp":"2026-02-22T07:47:15.537Z"}
{"parentUuid":"d0e15e59-035b-41c4-b1c8-4cb5ac18562e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DPW5bodYEFgdNxmXrVnQ5P","type":"tool_result","content":"pub trait ClientState: Send + Default + Debug + 'static {\n    type ReadDirState: Clone + Send + Default + Debug + 'static;\n    type DirEntryState: Send + Default + Debug + 'static;\n}\n\n/// Generic builder for walking a directory.\n///\n/// [`ClientState`](trait.ClientState.html) type parameter allows you to specify\n/// state to be stored with each DirEntry from within the\n/// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n/// callback.\n///\n/// Use [`WalkDir`](type.WalkDir.html) if you don't need to store client state\n/// into yeilded DirEntries.\npub struct WalkDirGeneric<C: ClientState> {\n    root: PathBuf,\n    options: WalkDirOptions<C>,\n}\n\ntype ProcessReadDirFunction<C> = dyn Fn(Option<usize>, &Path, &mut <C as ClientState>::ReadDirState, &mut Vec<Result<DirEntry<C>>>)\n    + Send","is_error":false}]},"uuid":"b7abae8a-c807-46b9-bd29-40b0e95e9830","timestamp":"2026-02-22T07:47:15.694Z","toolUseResult":{"stdout":"pub trait ClientState: Send + Default + Debug + 'static {\n    type ReadDirState: Clone + Send + Default + Debug + 'static;\n    type DirEntryState: Send + Default + Debug + 'static;\n}\n\n/// Generic builder for walking a directory.\n///\n/// [`ClientState`](trait.ClientState.html) type parameter allows you to specify\n/// state to be stored with each DirEntry from within the\n/// [`process_read_dir`](struct.WalkDirGeneric.html#method.process_read_dir)\n/// callback.\n///\n/// Use [`WalkDir`](type.WalkDir.html) if you don't need to store client state\n/// into yeilded DirEntries.\npub struct WalkDirGeneric<C: ClientState> {\n    root: PathBuf,\n    options: WalkDirOptions<C>,\n}\n\ntype ProcessReadDirFunction<C> = dyn Fn(Option<usize>, &Path, &mut <C as ClientState>::ReadDirState, &mut Vec<Result<DirEntry<C>>>)\n    + Send","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"d0e15e59-035b-41c4-b1c8-4cb5ac18562e"}
{"parentUuid":"b7abae8a-c807-46b9-bd29-40b0e95e9830","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01DaR5H6yTm4eWsmdGKXQ95P","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"`DirEntryState` needs: `Send + Default + Debug + 'static`.\n\n`Option<std::fs::Metadata>` satisfies:\n- `Send`: yes, Metadata is Send\n- `Default`: `Option<T>` default is `None` - this requires `Default for Option<T>` which is always `None`. Yes, `Option<T>` implements `Default` regardless of T.\n- `Debug`: yes, `Metadata` implements `Debug`\n- `'static`: yes, Metadata has no lifetime parameters\n\nAnd for the outer `ClientState` (which is `((), Option<Metadata>)` in this case):\n\n\nThe tuple `(B, E)` implements `ClientState` when both B and E satisfy `Default + Send + Debug + 'static`, plus B needs `Clone`. Let me verify the exact trait bounds on the impl to make sure that's what's required.","signature":"EtEGCkYICxgCKkDwrowdH/TkY9i5x951b34h5BAAQLuX9tc2GkE/gtl4yxMISFNnc11EZmt7h/72YQkfZ9Ju3zZyvK+XCpqOySe6EgwGcAOuMpLIOxwCV2caDOOCfdCUIuZ8wOvjCSIwA9co4K047U1/B53Z3tkbqoT1A0fFLAqAieyqZdwnYrHD107uT/L6nB4YKPQKRJ7YKrgFOAD5EY1XN/nqg7pZTym4Z1s3y7QrlYNdY9Xnytn8j1GPaswITHUP6qIc/szdiVoYG191ZXne67tgLQvtyf5CCpID1Wl+xWJ5wevX/3xeTwICwtpuL2W128pk9zEwPD0qsdgF4L2688u8oocPpczufyW7fnd+BeAbU6q2fa7pd9pO6rhFi2vWNzb+Ld2+mGMdMXnTgnnY0UWh4u/x+1CrVoFcjycATZZ/ayHCbI1L/tQquqrud+mO5WRTYPfqt52Ptjt+JKylXMxg1yTCTNqP4/qdhmVbufGXUJSBbOsP2TPqcPSuEe+TaNmxAD5IU0e09HwtlBwltF7JT7+JJadwIIZ1Ll5PONKVWYIAm2pe2NiRZH/4/Ep/zb1fGH8Ht/wPTpasWKMFbHBw6h0VMxzfEAJupyv4JZAkhx5Ovb3PW7Rz2ao8wTIA5OYygWq/MOHwfK6M/elheqz6kbp5moCjahoAya5dAvj6zKSCmLphnSV5+eeASAm5u3bucDjLUmJRKHWhOjGFfIzKBcSKNl5DGgdo45mAFvMDzgMJP31iiH8ncSujjaXaUCBb2UriR/MKmGi0ZUS1SjMxV8Vro2hw09GeinvKnNxMM2OSi+rxNFkORQ81YmYJkL54jeRdga1dOup8YZQ9aMjRIoOhTpoqb+XHdpVtHfCtSJfspGxyW32H0PL4rN40e7o1mrSKIXNgUv92e/w+x/MCOIwqO5ug4+k2Dwmb0u7LQBJlB8KVdJQSoHZ0TyVxUvBMCmohmQvokqznsWgxHeqfz8Fg3Gi+rpdLF7eqES9XlWO88u/0PquB98pB/+jxs8E0dUmogoq9hqiDCzk9cRhFNYrNqFro8Qgbf/lnKhM4KasKTt5WeviIgdR6SoW+XBiGQCn87IA0CukwmCPMTJ1NWEBTIo1mlj01voMFas6OGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":92524,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":476},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjkQR9wtX8xgYtq4sMH","type":"assistant","uuid":"19196903-afb6-447b-a004-8815c8a37ee2","timestamp":"2026-02-22T07:47:23.169Z"}
{"parentUuid":"19196903-afb6-447b-a004-8815c8a37ee2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01DaR5H6yTm4eWsmdGKXQ95P","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TPdGDnoQgRPwi2TMLJ7mKh","name":"Bash","input":{"command":"grep -A 10 \"impl.*ClientState for\" /Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/lib.rs","description":"Check ClientState blanket impl"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":92524,"output_tokens":368,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":476,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNjkQR9wtX8xgYtq4sMH","type":"assistant","uuid":"a9a36486-f821-4bf0-8ca4-eaca3366e6af","timestamp":"2026-02-22T07:47:23.208Z"}
{"parentUuid":"a9a36486-f821-4bf0-8ca4-eaca3366e6af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TPdGDnoQgRPwi2TMLJ7mKh","type":"tool_result","content":"impl<B, E> ClientState for (B, E)\nwhere\n    B: Clone + Send + Default + Debug + 'static,\n    E: Send + Default + Debug + 'static,\n{\n    type ReadDirState = B;\n    type DirEntryState = E;\n}","is_error":false}]},"uuid":"ae8610ab-ee3f-4219-9af4-95c761e7a47f","timestamp":"2026-02-22T07:47:23.331Z","toolUseResult":{"stdout":"impl<B, E> ClientState for (B, E)\nwhere\n    B: Clone + Send + Default + Debug + 'static,\n    E: Send + Default + Debug + 'static,\n{\n    type ReadDirState = B;\n    type DirEntryState = E;\n}","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"a9a36486-f821-4bf0-8ca4-eaca3366e6af"}
{"parentUuid":"ae8610ab-ee3f-4219-9af4-95c761e7a47f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_014s2prPSmfMyN1k26sSfZ1g","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"So `((), Option<std::fs::Metadata>)` will work as ClientState since:- `()`: Clone + Send + Default + Debug + 'static ✓- `Option<std::fs::Metadata>`: Send + Default + Debug + 'staticLet me verify `std::fs::Metadata` implements `Debug`. Actually, I think it does. Let me verify.\n\n`std::fs::Metadata` implements `Debug` and `Clone` in std. Actually, wait - is `Metadata` `Clone`? Let me check. In modern Rust (1.90), `fs::Metadata` does implement `Clone`.\n\n\nActually, `DirEntryState` only requires `Send + Default + Debug + 'static`, not `Clone`, so `Option<std::fs::Metadata>` works fine regardless. `Metadata` implements `Debug` since Rust 1.16, and `Option<T>` gets `Default` automatically, so `WalkDirGeneric::<((), Option<std::fs::Metadata>)>::new(root)` should compile without issues.\n\nNow I'm checking how `Metadata` gets used in the main loop. Since the loop takes ownership of `entry`, I can move `entry.client_state` directly without cloning. But I need to verify that `entry` is still accessible for other operations like checking `entry.depth` after I extract the metadata.","signature":"EsINCkYICxgCKkBulsWKDWblcGca99SCCaPPom7j3WmM+V4/pLKKzxj3/A+kPUIvuP+M5/T/utoNgaajf3UyGXzI8d6MkYFzPEdAEgyMxeiGLDh2EQ/cXZwaDEYGk8rK8KQ7YGKNBSIwJv5R0VkZN2wlN1QyQBpYLBkPWI+hwB+neS1m4uNki7ZXtO8Fkuf/kw2bv09+dt8vKqkMwRpa6DZ4W42jtjkKeuGPSzB78ZgoY5aCNUW4SfJ7wwPtdiIUZrJDVKNlmdLqPCzUBMU9n8ZrwTbPyYzQV+wtG43ZunrRIRkNbF7O9pfNlV1HlN8aGjH7GTSU9tGAGkUL9rtQJE5gQDp7VR6oPdWscTYMQ0KKttKlya1Ykh/IGTkgoDfj1fCEjLscivU/ebbdRLSexp9y0bryiSgrQ0CXjmxFnFsFKnFKh4Rag9glWId0VDQBl1BrG40mIJUWKciXZjCxlqeyWbuB1TICBwVEPBgtFtsrzYmFtrVU4SEFGrbxAG9yLV0tvBai3X1dULRd0ab6PjksDqaXpoWQL6Q06AEzT5K6ZVqkL+YaMqD8Q/TNx8do1pfaLAFnzf4/hEAD9H2eXFqk2rSK+nNMuQ7ViA09cQOGRFlwBZe1MgTh04Rwg7cR+vucodAoLvDN6+cK74QbWQS4jmDJ0eX01QFPIeItWFtvhqd1tGSFfA5uB1EQhhGSLg/aEfpYeKvoC++5PGgKsHWoRQ6tnkpvUwSkcBCJTAAR8i58GXjx/9628KZ8frx2x8lE10BKg301qGWqbmOVjM3HBx7jrB97HxrplkdbZG2Ze3HpuelC1IxAhmJnqJLG1NcePYAGwj3fAnMyKjWsTPQPuQ2UH5zw5BeEpSojGLCc1e0mOo9b9XvWIXbkdwFrq1s7u6+7LN/WM12SpFGkllqH96AOAKBt7awVooNC8kTF4449Aq4udEfuzpPvOsatiIlTsHenQEcwjPGBy/kSQ85w85zJ+IoRJ3wYZvvHGzL+qI6PC8JT/M7vaDtUtvj04QGBGdJGxxH3Mq5dxUYC5SiaCvW4GWyyZsMQ97uYfltotGtfRAE1CUENgMfZe9V+TNTFTGNQwJhhjwbo8gDub8wroXPRxgsw43Dc7i2SpK8uWIpHira5wcktIEui73sp9zPFFhgpOIzfHFb2KjH8bB4ESJb4MDyFGoEJb/+2P9YBCm4TKcEYTviSUF3soc2L8om4d0xRSj4Plmv3vqbYchsL89Los40hF3FGSZwroouh6dFTFkw5QscGnQTGf2vn1+TTllahoqDqEovvOhBPp3Np/acyH2PF7l6G0qTwo4R4YgMhPMM+H8fEGxBnr7MYRmGua396wnHbiLITr25hRt8ggYrDrO5WWJGl/hFNrzaYbhlpSe4eOLW0Our53cYiWRTin6cKsxuxL7ql7rELesV9DsoHMbVbztFY72TY78aCgPcY/YRglKItAD5nqVJpMKFXouVFAol0cZD23BpCk5RT3y2K9A2xtmd8sXCskXCMMdIOjTcZRe2EaVuefDuYzTZT8u/qtljLiRwYjEyM5pGaQbfC/dVrm8yy9mGv/DprDTOjAP1Soj1SfxryXKlCqm8B2ERjHLorkpC32rAd1tSOYwrCU4UfGXquv39p59bQKkTSL32ezjtXSmR/qarYWCKkIwfeKOI+LvVn0qbbPq6dHLBhEvsrdpGoGUVPc4jBqUUfprmsAC8XdY8HtjRN12BlGm4yMULmsDsftNGzy2RumEWY9sye9YqwrY1G98iBgp0vSjd7QwHnwDbuRX4yUFjTtA4/ZzwzBf2LOFYyohBWgYOabz6CvjJ6b06CkymBuhnIvQD1DUomhbGXKsTxXkbp4yu5XQCSz3Rfeo3gRW2grNwSxQuNhMB0espasl0ydVPDYns37ATughEReUzP02Ci9qr1Rk7z+U8l0q1ZV6FQi6TEj740FdGNWmpwBrIURR1/T7Tb+b0SI0xZD3U+S/JMEnwRLVT4D4vhYdVoLwVCF/UEFU3BYgqy9Cp/0h/NBM0rHQX+LaOjgFJwRFxYy2DOPLlJKmw0Fh2NgH2dOv7j9PX/1r1QdBNPfRxMQGiBakY5kC0itGx6HdokYkaccmoqK4XutLBlDnUDzn8ak67FHYq8Ym40Ey7I+5M3eJLWCnB0figtWS++yscMtiMz1uhUmNn7fPSw/bDeMjLyathd2aWKr3HHKvBKzZUNZFevvRC79bsEgotWBovns4M3h2nsalSZszbarDppQbZtTcC124zUga06Be5CA95q4j9w73ws8RzwqypwRs2yiS+Qbx8+K+YYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":445,"cache_read_input_tokens":93000,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":445},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjky5SPJCKTMcc8QTWE","type":"assistant","uuid":"5ff8b689-b16a-47de-b954-f4fc83675028","timestamp":"2026-02-22T07:47:34.846Z"}
{"parentUuid":"5ff8b689-b16a-47de-b954-f4fc83675028","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_014s2prPSmfMyN1k26sSfZ1g","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017eUAk5qoFJNfwkwbHKRzmL","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2243,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":445,"cache_read_input_tokens":93000,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":445},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjky5SPJCKTMcc8QTWE","type":"assistant","uuid":"f2c43499-9474-4059-b5f6-3fa5a88ce030","timestamp":"2026-02-22T07:47:34.877Z"}
{"parentUuid":"f2c43499-9474-4059-b5f6-3fa5a88ce030","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_017eUAk5qoFJNfwkwbHKRzmL","toolUseID":"toolu_017eUAk5qoFJNfwkwbHKRzmL","timestamp":"2026-02-22T07:47:34.907Z","uuid":"7e9dac41-0da6-4761-a118-43f839507d94"}
{"parentUuid":"f2c43499-9474-4059-b5f6-3fa5a88ce030","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017eUAk5qoFJNfwkwbHKRzmL","type":"tool_result","content":"  2243→            for result in walker {\n  2244→                match result {\n  2245→                    Ok(entry) => {\n  2246→                        let path = entry.path();\n  2247→                        if path == root.as_path() {\n  2248→                            continue;\n  2249→                        }\n  2250→\n  2251→                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n  2252→                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n  2253→                            continue;\n  2254→                        }\n  2255→\n  2256→                        scanned += 1;\n  2257→                        root_scanned += 1;\n  2258→                        current_path = path.to_string_lossy().to_string();\n  2259→\n  2260→                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n  2261→                            row.run_id = current_run_id;\n  2262→                            if is_fresh {\n  2263→                                // Fresh index: all entries are new, skip existing check\n  2264→                                indexed += 1;\n  2265→                                root_indexed += 1;\n  2266→                                batch.push(row);\n  2267→                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n  2268→                                if *old_mtime == row.mtime && *old_size == row.size {\n  2269→                                    stamp_batch.push(row.path);\n  2270→                                } else {\n  2271→                                    indexed += 1;\n  2272→                                    root_indexed += 1;\n  2273→                                    batch.push(row);\n  2274→                                }\n  2275→                            } else {\n  2276→                                indexed += 1;\n  2277→                                root_indexed += 1;\n  2278→                                batch.push(row);\n  2279→                            }\n  2280→                        }\n  2281→\n  2282→                        if batch.len() >= flush_batch_size {\n  2283→                            upsert_rows(conn, &batch)?;\n  2284→                            batch.clear();\n  2285→                        }\n  2286→\n  2287→                        if stamp_batch.len() >= flush_batch_size {\n  2288→                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2289→                            stamp_batch.clear();\n  2290→                        }\n  2291→\n  2292→                        if last_emit.elapsed() >= Duration::from_millis(200) {\n  2293→                            set_progress(state, scanned, indexed, &current_path);\n  2294→                            emit_index_progress(app, scanned, indexed, current_path.clone());\n  2295→                            last_emit = Instant::now();\n  2296→                        }\n  2297→                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n  2298→                        {\n  2299→                            perf_log(format!(\n  2300→                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n  2301→                                pass_label, scanned, indexed, current_path\n  2302→                            ));\n  2303→                            last_perf_emit = Instant::now();\n  2304→                        }\n  2305→                    }\n  2306→                    Err(err) => {\n  2307→                        scanned += 1;\n  2308→                        root_scanned += 1;\n  2309→                        permission_errors += 1;\n  2310→                        root_permission_errors += 1;\n  2311→                        if permission_errors <= 20 || perf_log_enabled() {\n  2312→                            eprintln!(\"[index] permission error: {}\", err);\n  2313→                        }\n  2314→                    }\n  2315→                }\n  2316→            }\n  2317→\n  2318→            pass_scanned += root_scanned;\n  2319→            pass_indexed += root_indexed;\n  2320→\n  2321→            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n  2322→                pass_label, root_str, root_started.elapsed().as_millis(),\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d5d8836d-0287-41fe-8b25-4d1086075dca","timestamp":"2026-02-22T07:47:34.903Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),","numLines":80,"startLine":2243,"totalLines":5786}},"sourceToolAssistantUUID":"f2c43499-9474-4059-b5f6-3fa5a88ce030"}
{"parentUuid":"d5d8836d-0287-41fe-8b25-4d1086075dca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Fxnms5fPXv447LnexAtN23","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"OK so in the main loop, the `entry` is used for:1. `entry.path()` - line 2246: builds PathBuf2. `entry.depth` - line 2252: checks depth3. `index_row_from_jwalk_entry(&entry)` - line 2260: fetches metadata and builds rowAfter my change, the updated version would be:- `entry.path()` on line 2246 - this allocates PathBuf ONCE\n- `entry.depth` - no cost- `index_row_from_jwalk_entry(entry)` - now takes owned entry, uses pre-fetched metadata from `client_state`But we can't use `entry` after passing it to `index_row_from_jwalk_entry` if we take ownership. Let me restructure:```rust\n\n\nfor result in walker {\n    match result {\n        Ok(entry) => {\n            // Access fields before moving entry\n            let depth = entry.depth;\n            let path = entry.path(); // PathBuf allocation\n            \n            if path == root.as_path() {\n                continue;\n            }\n\n            // Pass 1 check\n            if pass == 1 && depth <= SHALLOW_SCAN_DEPTH {\n                continue;\n            }\n\n            scanned += 1;\n            root_scanned += 1;\n            current_path = path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index\n```\n\nI need to extract the depth and path before moving the entry, then check those values against the root and pass conditions before proceeding with the row indexing.\n\nNow I'm running into a borrow issue where I'm trying to use `entry.path()` after moving `entry.client_state` out of it. The solution is to extract the path upfront before any moves happen, so I have the data I need without running into partial move conflicts. I'm realizing that in Rust, moving `client_state` out of `entry` only partially moves the struct, so I can still access other fields like `parent_path` and `file_name` afterward—I just can't use the entire `entry` struct as a whole. I need to verify whether Rust actually allows partial moves from struct fields—since `entry` is owned and `client_state` is a direct field, moving it out should work fine, leaving the other fields like `parent_path` and `file_name` still accessible. But I'm realizing `DirEntry` is defined in the jwalk crate, so I need to check its actual structure to confirm this approach is valid. our crate. Partial moves work on structs defined in any crate as long as you have access to the fields (which we do since `client_state` is `pub`). \n\nBut there might be an issue with `Drop` - if `DirEntry` has a `Drop` impl, you can't partially move fields out of it. Let me check if DirEntry implements Drop.\n\nLooking at the DirEntry source, there's no `Drop` impl. So partial moves should work.\n\nActually, I should double-check this. Let me think again... In Rust, you can move a field out of a struct if the struct is owned, the field isn't behind a reference, the struct doesn't implement `Drop`, and the field itself is movable. `Option<T>` isn't Copy unless T is Copy, and `Metadata` definitely isn't Copy, so moving `entry.client_state` out counts as a partial move.\n\nAfter that partial move, I can still access the other fields like `parent_path`, `file_name`, `depth`, and `file_type`. Let me verify the main loop doesn't use `entry` after the partial move - I'm extracting the depth as a copy, building the path, and then passing the entry to `index_row_from_jwalk_entry`, which should consume it properly.\n\nFor the path building, I have two options: either call `entry.path()` before the function and pass it separately, or build the path inside `index_row_from_jwalk_entry` using the parent path and file name. The second approach is cleaner since it only allocates the path string once.\n\nBut looking at the main loop, it already calls `entry.path()` to compare against the root, so we'd end up building the path twice anyway—once in the main loop and once inside the function. That's the same number of allocations as the current approach, so there's no real win here.\n\nActually, wait—I'm counting wrong. Right now we're doing three separate path allocations per entry: one in the main loop with `entry.path()`, another inside `index_row_from_jwalk_entry` when it calls `entry.metadata()`, and a third when we pass `entry.path()` to `index_row_from_path_and_metadata`. With my proposed change, I'd reduce that to just one PathBuf in the main loop plus one String allocation inside the function by using `entry.parent_path` and `entry.file_name` instead. So we'd go from three allocations down to two.\n\nLooking at how that PathBuf is actually used though—it's only needed for the root check and converting to a string for `current_path`—I could potentially avoid the PathBuf allocation entirely by working with string representations from the start. I could pass the already-built path string directly to the function instead of reconstructing it, which would avoid the double allocation—though cloning for `current_path` tracking still creates an extra copy that I'd need to think through.\n\nDefining the helper function... I'm setting `current_path` to the string representation of the path, then passing it to the `index_row_from_jwalk_entry` function which extracts metadata and builds an `IndexRow` with the file information.\n\nLooking at the allocations per entry, I'm creating a PathBuf from `entry.path()`, converting it to a string for `current_path`, then copying that string again inside the function for the `IndexRow.path` field, plus separate string allocations for the file name and parent directory—that's adding up to a PathBuf and at least four String allocations per entry, which seems wasteful since I'm essentially duplicating the path data.\n\nThe real bottleneck though isn't the allocation count itself—it's that I'm calling `stat()` on the main thread for every entry. The key optimization is moving those metadata fetches into `process_read_dir` where rayon can parallelize them, so the main loop just uses pre-fetched data without blocking on syscalls.\n\nNow I need to think about thread count configuration...\n\nDetermining thread pool size...\n\nIf I use the full core count instead of halving it, I could roughly halve the stat() time since those calls are happening in parallel within `process_read_dir`. But I need to balance that against the overhead of spawning too many threads.\n\nFor a fresh index build, I can be more aggressive with thread allocation since there's no other work competing for resources. So my plan is to increase threads to the full core count (capped at 16) for fresh builds, while keeping the current conservative approach for incremental updates.\n\nI'm also thinking about three other optimizations: pre-fetching metadata directly in the walker to avoid redundant stat calls, running ANALYZE in the background after the index is ready, and switching to a PASSIVE checkpoint mode instead of TRUNCATE to reduce I/O overhead.\n\nThere's also the `normalize_slashes` function that's doing unnecessary allocations on macOS—I can optimize it to only create a new String if backslashes are actually present, otherwise just return the original String. I'm realizing the real bottleneck is the initial `to_string_lossy().to_string()` call, but I can optimize `normalize_slashes` to avoid a second allocation on macOS by checking if the string contains backslashes before doing the replacement. Now I'm ready to implement the actual changes, prioritizing parallel metadata fetching, increasing thread count for fresh builds, async ANALYZE, passive checkpoints, and this slash normalization optimization.\n\nI need to check how `extension_for` works with the new approach—I'll be creating a variant that takes an `OsStr` directly from the directory entry's file name, converting it to a path to extract the extension and lowercase it.\n\nNow I'm mapping out all the places that need updates: the walker creation in `run_incremental_index_inner`, the main loop that processes entries, and the `index_row_from_jwalk_entry` function signature itself. The key change is switching from `WalkDirGeneric<((), ())>` to include metadata in the type parameter so I can access file information without additional system calls.\n\nI need to verify that `WalkDirGeneric` is publicly exported from jwalk at the crate root, which it is based on the lib.rs definition. For error entries from the walker, they won't have client state attached anyway, so handling them as permission errors remains straightforward.\n\nIn the metadata pre-fetch logic, if `stat()` fails for an entry, the client state gets set to `None`, and then `entry.client_state?` in `index_row_from_jwalk_entry` will skip that entry—which matches the current behavior where metadata failures cause skips. I'm checking the current implementation to make sure the error handling aligns correctly.\n\nNow I need to think through the actual implementation changes. The walker's type signature is changing from returning `DirEntry<((), ())>` to `DirEntry<((), Option<fs::Metadata>)>`, which will affect type inference downstream.\n\nThe `entry` variable will have a different client state type, but methods like `depth()` and `path()` should continue working fine. The key change is updating `index_row_from_jwalk_entry` to handle the new metadata-carrying type.\n\nI'll need to make two main edits: first, update the function signature and add the necessary imports, then modify the walker builder to use `retain_mut` and pass the metadata through the client state.\n\nBefore I write these changes, I need to verify that when I pre-fetch metadata in the processing thread, it gets correctly paired with each entry so that the comparison logic in `index_row_from_jwalk_entry` still works as expected.\n\nThere's a potential race condition where the file could change between the stat call in the worker thread and when the main thread processes it, but that's the same window that already exists in the current code, so it's acceptable.\n\nNow I'll implement the modifications carefully, starting with updating the function signature and logic to accept the pre-fetched metadata. I'm running into a complication with the conditional builder setup—since the walker type changes based on whether I use the generic version, I need to figure out how to handle the `max_depth` call that only applies on the first pass, which means the builder's type signature would differ between branches.\n\nFor the thread count optimization, I'm thinking I should create a separate function for the fresh index case rather than adding parameters everywhere, since that keeps the changes localized and the intent clearer.\n\nNow I need to handle the async ANALYZE operation...\n\nSpawning background thread for ANALYZE...\n\nI need to separate the pragma restoration from the checkpoint operation since the checkpoint acquires a write lock and could block the main thread. I'm creating a faster version of pragma restoration that skips the checkpoint, then moving both the checkpoint and ANALYZE to run asynchronously in the background.\n\nThe key insight is that `wal_checkpoint` can run from any connection, and I can use PASSIVE mode instead of TRUNCATE to avoid needing an exclusive lock, which lets the main thread continue without blocking.\n\nModifying the pragma restoration function...\n\nActually, with autocheckpoint set to 1000 pages, SQLite will handle the checkpoint automatically, so I might not need to explicitly call it at all.\n\nBut the WAL size does impact read performance since queries have to check both the main database file and the WAL for each page lookup. After inserting 400k rows, the WAL could grow quite large and slow down searches. Running a PASSIVE checkpoint starts the process without blocking other readers, which should be fast if there's no concurrent access.\n\nFor the ANALYZE step, instead of running it synchronously and blocking completion, I should run it after the \"Ready\" state is emitted so it doesn't delay the response.\n\nLooking at the flow more carefully, ANALYZE needs to happen after the indexes are built and after marking the index run as complete. I need to restructure this so the synchronous ANALYZE call gets moved out of the critical path. I see the issue now—the \"Ready\" state gets emitted from inside `run_incremental_index_inner` before that function returns, but then the outer `run_incremental_index` continues with ANALYZE, checkpoint, and metadata updates. So the user sees \"Ready\" while expensive operations are still happening in the background, and the file watcher doesn't actually start until `index_complete` is set after all those operations finish. The `indexing_active` flag gets cleared after `run_incremental_index` finishes, which includes the ANALYZE step, so the user's 78-second measurement captures the entire process from reset through completion. When the frontend receives the \"Ready\" event, searches should work immediately since the entries are already in the database—ANALYZE just optimizes query statistics afterward.\n\nLet me trace through the actual flow: \"Ready\" is emitted inside `run_incremental_index_inner`, but that's before ANALYZE and index creation happen in the outer `run_incremental_index` function. So the user sees \"Ready\" before the background work actually finishes. Looking at the code flow more carefully, I see that \"Ready\" gets emitted while the inner function is still running, but then ANALYZE and index creation happen afterward in the outer function. So when the user measures completion time, they're likely timing from when the UI shows \"Ready\" — but the actual indexing work continues in the background. For a fresh index run, the sequence is different: indexes get dropped first, then the inner function runs and emits \"Ready\", then indexes are recreated and ANALYZE runs. I see the issue now—\"Ready\" gets emitted before indexes are created, which would leave the database searchable but unindexed for several seconds. Let me trace through the actual execution order in `run_incremental_index` to confirm whether this is really a bug or if there's something I'm missing about the timing. I see the issue now—\"Ready\" gets emitted inside `run_incremental_index_inner` before the indexes are actually created, so on a fresh run users see the ready signal but searches will be slow since there are no indexes yet. I need to figure out where exactly this is happening and whether the signal should be delayed until after index creation completes.\n\nThe user's 78-second measurement from reset to completion likely includes everything after \"Ready\" appears, so the actual index creation is happening in the background while the UI already shows ready. Let me check what \"완료\" (completion) means in their context—whether they're measuring until the UI shows ready or until the entire process finishes. the 78 seconds includes the entire process from start to finish. The real bottleneck could be the filesystem walk and insertion, index creation, ANALYZE, or the checkpoint operation. Since I can't run the app directly to see the timing breakdown, I'll add instrumentation around index creation and ANALYZE, implement parallel metadata fetching, increase the thread pool size, and move index creation to happen before the \"Ready\" signal so the user can identify where the time is actually going.\n\nNow I'm weighing the tradeoff between emitting \"Ready\" quickly versus having indexes ready for immediate searching. If I create indexes before signaling \"Ready\", users will see a longer wait but get fast search results immediately. The current approach does the opposite—quick \"Ready\" signal but slow searches initially. I think the better experience is having indexes ready first, even if it delays the \"Ready\" message slightly.\n\nBut actually, the user's metric is about total time to completion after reset, which probably means when the app is fully functional with indexes created. So I should focus on what's actually in the critical path—the reset operation itself and then the full indexing worker that runs afterward. I need to trace through the exact timing of when \"Ready\" gets emitted versus when the user perceives the operation as complete—the \"Ready\" signal fires after the inner function finishes scanning and inserting rows, but the background thread keeps working on index creation and ANALYZE, and there's likely a flag preventing searches until indexing_active becomes false.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1862,"cache_read_input_tokens":93445,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1862},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjmpnPkQDL18wcLKhhV","type":"assistant","uuid":"02bfdb6c-ec2e-4225-a871-a40e54665f47","timestamp":"2026-02-22T07:51:02.159Z"}
{"parentUuid":"02bfdb6c-ec2e-4225-a871-a40e54665f47","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Fxnms5fPXv447LnexAtN23","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check if search is blocked during indexing and understand the full flow:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1862,"cache_read_input_tokens":93445,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1862},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjmpnPkQDL18wcLKhhV","type":"assistant","uuid":"7eba026e-2095-40fc-8e57-db6f33a1ece2","timestamp":"2026-02-22T07:51:02.159Z"}
{"parentUuid":"7eba026e-2095-40fc-8e57-db6f33a1ece2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Fxnms5fPXv447LnexAtN23","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Jh8vQ2U31NnhEaGSrfueex","name":"Grep","input":{"pattern":"indexing_active.*search|search.*indexing_active|fn search\\b","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1862,"cache_read_input_tokens":93445,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1862},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNjmpnPkQDL18wcLKhhV","type":"assistant","uuid":"1933d6cc-83b4-4507-b65d-f90052c1423a","timestamp":"2026-02-22T07:51:03.352Z"}
{"parentUuid":"1933d6cc-83b4-4507-b65d-f90052c1423a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01Jh8vQ2U31NnhEaGSrfueex","toolUseID":"toolu_01Jh8vQ2U31NnhEaGSrfueex","timestamp":"2026-02-22T07:51:04.070Z","uuid":"06bc6ab8-b8af-41e4-bfc7-94c675f9336e"}
{"parentUuid":"1933d6cc-83b4-4507-b65d-f90052c1423a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Jh8vQ2U31NnhEaGSrfueex","type":"tool_result","content":"3855-}\n3856-\n3857-#[tauri::command]\n3858:async fn search(\n3859-    _app: AppHandle,\n3860-    query: String,\n3861-    limit: Option<u32>,\n--\n3921-            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n3922-            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n3923-            eprintln!(\n3924:                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n3925-                rpc_elapsed_ms,\n3926-                execute_elapsed_ms,\n3927-                count_elapsed_ms,"}]},"uuid":"5a7c3635-b6ff-42b1-b140-9d357f46a75a","timestamp":"2026-02-22T07:51:04.068Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"3855-}\n3856-\n3857-#[tauri::command]\n3858:async fn search(\n3859-    _app: AppHandle,\n3860-    query: String,\n3861-    limit: Option<u32>,\n--\n3921-            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n3922-            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n3923-            eprintln!(\n3924:                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n3925-                rpc_elapsed_ms,\n3926-                execute_elapsed_ms,\n3927-                count_elapsed_ms,","numLines":15},"sourceToolAssistantUUID":"1933d6cc-83b4-4507-b65d-f90052c1423a"}
{"parentUuid":"5a7c3635-b6ff-42b1-b140-9d357f46a75a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01UzpdihhNQ7maG8AKgExkKM","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Search is not blocked during indexing - it can be called at any time. The `indexing_active` flag is logged but doesn't prevent search. So the user can search even while indexing, and after \"Ready\" is emitted (but before indexes are created), searches would be full table scans.\n\nOK, since I can't determine the exact timing breakdown without running the app, let me just implement the optimizations and add detailed timing logs. The user will then run the app and provide feedback.\n\nLet me now implement the changes:\n\n**Summary of changes:**\n\n1. **Parallel stat() in rayon threads**: Use `WalkDirGeneric<((), Option<fs::Metadata>)>` and pre-fetch metadata in `process_read_dir` closure. This parallelizes stat() calls across directories.\n\n\n2. **Increase thread count for fresh indexes**: Use a higher thread count formula that scales better than the current approach.\n3. **Create indexes before emitting \"Ready\"**: Move index creation into the incremental indexing flow so \"Ready\" actually means the indexes are ready to use.\n4. **Run ANALYZE asynchronously**: Spawn a separate thread to handle ANALYZE after marking the database ready.\n5. **Switch to PASSIVE checkpoint mode**: Change the checkpoint strategy to be less aggressive.\n6. **Skip path normalization on macOS**: Avoid the replace() call on that platform.\n7. **Add timing logs**: Instrument the index creation and ANALYZE steps with timing markers.\n\nNow I'm thinking through the implementation. Point 3 is trickier than it seems—moving index creation into `run_incremental_index_inner` means I need to thread the `is_fresh_run` flag through to that function, which requires adjusting its signature. Let me trace through the current function structure to see how to pass that information cleanly.\n\nActually, I realize the function already has what it needs—I can detect a fresh run by checking if `last_run_id == 0` inside `run_incremental_index_inner`. So I can conditionally create indexes at the end of that function, wrapping the creation in a timing block that only executes on fresh runs.\n\nRefactoring index creation...\n\nBut wait, moving index creation before the \"Ready\" signal would delay when users see completion, which defeats the optimization goal. The user is measuring time to \"완료\", and if that includes index creation, I'm making things worse. Instead, I should focus on speeding up the scan itself through parallelization and more worker threads, since the index creation likely happens after the \"Ready\" signal anyway.\n\nNow I'm clarifying what the user actually means by completion—they said \"reset 후 완료까지\", which is from reset to when the UI shows \"완료\" or \"준비됨\". That's when `emit_index_state` fires with \"Ready\", which happens inside `run_incremental_index_inner`. So the 78 seconds includes the DELETE operation, thread spawning, and then the full index creation: directory scan partition, filesystem walk (the dominant 40-60 second chunk), and SQL inserts.\n\nThe CREATE INDEX, ANALYZE, and checkpoint operations that follow the \"Ready\" emission aren't part of the user's measurement, so I should focus on optimizing the filesystem walk and insert operations. Let me check where exactly `run_incremental_index_inner` emits that \"Ready\" state to confirm whether it's before or after all the work completes. Now I'm zeroing in on what actually needs optimization: the filesystem walk and database inserts are where the 78 seconds is going. I could parallelize the stat() calls during directory traversal and increase thread count for initial indexing, but the bigger win is probably in how I'm inserting rows—switching from individual inserts to multi-row batches would reduce transaction overhead significantly.\n\nLooking at the actual mechanics of each insert operation, they're pretty fast in memory since I've disabled synchronous mode and dropped secondary indexes. At 500k-1M operations per second, 400k rows should only take 0.4-0.8 seconds, so the database isn't the real bottleneck here. The filesystem walk itself—all those readdir calls and stat syscalls—is what's actually eating up the time.\n\nOn an APFS SSD, each stat call could range from 50-200 microseconds depending on whether the OS metadata cache is warm or cold. With 4 rayon threads handling the stat calls across 400k files, I'm looking at somewhere between 10-20 seconds just for that phase. Bumping to 8 threads would cut that roughly in half. The total scan and insert time is probably dominated by that walk and stat overhead.\n\nLooking at the breakdown: single-threaded stat takes 40-70 seconds, database inserts add 2-5 seconds, and the COUNT/MAX queries another 1-3 seconds, which tracks with the observed 78 seconds. If I parallelize the stat calls across 8 threads instead of doing them serially on the main thread, I could get the walk and stat phase down to 20-35 seconds, bringing the total under 50 seconds. The current implementation has rayon threads doing readdir in parallel, but the actual stat calls still happen serially on the main thread—my change would move those stat calls into the rayon threads themselves.\n\nNow I'm implementing the fix by using `process_read_dir` with metadata pre-fetching in the rayon thread pool, doubling the thread count for the fresh index, and adding timing logs around the key phases. The rayon pool will handle the stat calls in parallel while the main thread consumes the results.\n\nI'm noticing that when metadata pre-fetch fails for an entry, it gets skipped in `index_row_from_jwalk_entry`, which mirrors the current behavior where `entry.metadata().ok()?` would fail. But there's a potential inefficiency: in the incremental pass, we're pre-fetching metadata for shallow entries that we'll skip anyway, wasting stat() calls. For a fresh index though, there's no second pass, so this isn't an issue there.\n\nThe solution would be to pass the current pass number into the closure so we can filter out shallow entries before pre-fetching their metadata, rather than doing the expensive stat() call upfront.\n\nNow I'm realizing there's a question about what depth value the entries actually have when they're being processed in the callback—the `_depth` parameter represents the parent directory's depth, so the children would be one level deeper, but I need to verify how that maps to the SHALLOW_SCAN_DEPTH threshold. So when jwalk reads a directory at depth D, it assigns depth D+1 to all the child entries, and this depth is already set by the time `process_read_dir` processes them. Let me trace through the read_dir code to confirm how this depth assignment actually works.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":12425,"cache_read_input_tokens":95307,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12425},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNk3FLgcWNYs4WxKnxV7","type":"assistant","uuid":"6d15505b-84bd-4028-9ffd-b26703edcf33","timestamp":"2026-02-22T07:52:17.973Z"}
{"parentUuid":"6d15505b-84bd-4028-9ffd-b26703edcf33","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01UzpdihhNQ7maG8AKgExkKM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01L8XjT5HGqALdY5xc2AFmaD","name":"Bash","input":{"command":"grep -n \"depth\\|process_read_dir\\|DirEntry::from_entry\" /Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir.rs | head -40","description":"Check how depth is set in jwalk entries"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":12425,"cache_read_input_tokens":95307,"output_tokens":3625,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":12425,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNk3FLgcWNYs4WxKnxV7","type":"assistant","uuid":"c6da4f66-8ffe-4e0c-a367-c26d0dadaeef","timestamp":"2026-02-22T07:52:18.611Z"}
{"parentUuid":"c6da4f66-8ffe-4e0c-a367-c26d0dadaeef","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01L8XjT5HGqALdY5xc2AFmaD","type":"tool_result","content":"","is_error":false}]},"uuid":"15b40fb2-f0f1-40a9-a68f-6e63acaa12ee","timestamp":"2026-02-22T07:52:18.762Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"c6da4f66-8ffe-4e0c-a367-c26d0dadaeef"}
{"parentUuid":"15b40fb2-f0f1-40a9-a68f-6e63acaa12ee","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01DSfV7DxhDVcrcBvJ85tmiC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CDetf1DDfCQidiTTeFZXqY","name":"Bash","input":{"command":"cat /Users/al02402336/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/jwalk-0.8.1/src/core/read_dir.rs | head -80","description":"Check read_dir implementation"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3591,"cache_read_input_tokens":107732,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3591},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNk8kXkH7KDPNXu5YtDP","type":"assistant","uuid":"4641cad1-bf9b-47f0-a829-bcc78ac6d21b","timestamp":"2026-02-22T07:52:20.992Z"}
{"parentUuid":"4641cad1-bf9b-47f0-a829-bcc78ac6d21b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CDetf1DDfCQidiTTeFZXqY","type":"tool_result","content":"use super::{ClientState, DirEntry, IndexPath, Ordered, ReadDirSpec};\nuse crate::Result;\n\n/// Results of successfully reading a directory.\n#[derive(Debug)]\npub struct ReadDir<C: ClientState> {\n    pub(crate) read_dir_state: C::ReadDirState,\n    pub(crate) results_list: Vec<Result<DirEntry<C>>>,\n}\n\nimpl<C: ClientState> ReadDir<C> {\n    pub fn new(\n        read_dir_state: C::ReadDirState,\n        results_list: Vec<Result<DirEntry<C>>>,\n    ) -> ReadDir<C> {\n        ReadDir {\n            read_dir_state,\n            results_list,\n        }\n    }\n\n    pub fn read_children_specs(&self) -> impl Iterator<Item = ReadDirSpec<C>> + '_ {\n        self.results_list.iter().filter_map(move |each| {\n            each.as_ref()\n                .ok()?\n                .read_children_spec(self.read_dir_state.clone())\n        })\n    }\n\n    pub fn ordered_read_children_specs(\n        &self,\n        index_path: &IndexPath,\n    ) -> Vec<Ordered<ReadDirSpec<C>>> {\n        self.read_children_specs()\n            .enumerate()\n            .map(|(i, spec)| Ordered::new(spec, index_path.adding(i), 0))\n            .collect()\n    }\n}","is_error":false}]},"uuid":"0645820b-020e-465c-9d98-edc0666a7cfb","timestamp":"2026-02-22T07:52:21.104Z","toolUseResult":{"stdout":"use super::{ClientState, DirEntry, IndexPath, Ordered, ReadDirSpec};\nuse crate::Result;\n\n/// Results of successfully reading a directory.\n#[derive(Debug)]\npub struct ReadDir<C: ClientState> {\n    pub(crate) read_dir_state: C::ReadDirState,\n    pub(crate) results_list: Vec<Result<DirEntry<C>>>,\n}\n\nimpl<C: ClientState> ReadDir<C> {\n    pub fn new(\n        read_dir_state: C::ReadDirState,\n        results_list: Vec<Result<DirEntry<C>>>,\n    ) -> ReadDir<C> {\n        ReadDir {\n            read_dir_state,\n            results_list,\n        }\n    }\n\n    pub fn read_children_specs(&self) -> impl Iterator<Item = ReadDirSpec<C>> + '_ {\n        self.results_list.iter().filter_map(move |each| {\n            each.as_ref()\n                .ok()?\n                .read_children_spec(self.read_dir_state.clone())\n        })\n    }\n\n    pub fn ordered_read_children_specs(\n        &self,\n        index_path: &IndexPath,\n    ) -> Vec<Ordered<ReadDirSpec<C>>> {\n        self.read_children_specs()\n            .enumerate()\n            .map(|(i, spec)| Ordered::new(spec, index_path.adding(i), 0))\n            .collect()\n    }\n}","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"4641cad1-bf9b-47f0-a829-bcc78ac6d21b"}
{"parentUuid":"0645820b-020e-465c-9d98-edc0666a7cfb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01TBuhSz1oqutpksnaPVrCkE","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have enough understanding. Let me design the implementation.\n\nKey insight: The `process_read_dir` closure receives children that already have their `depth` field set. The depth in `entry.depth` for children would be `parent_depth + 1`.\n\nFor pass 1 incremental (skip shallow entries where depth <= SHALLOW_SCAN_DEPTH):\n- We shouldn't pre-fetch metadata for entries with `entry.depth <= SHALLOW_SCAN_DEPTH`\n- This saves stat() calls for shallow entries in pass 1\n\nFor fresh index (pass=0, is_fresh=true) and incremental pass 0:\n\n\n- Pre-fetch all surviving entries' metadata\n\nSetting up the walker with closures that capture the current pass and freshness state...\n\nNow I'm checking the `retain_mut` signature to make sure I'm using it correctly—it takes a mutable reference and returns a bool to determine which elements to keep. Finishing the closure logic and checking for lifetime issues with the captured `path` reference—it should work fine since `full_path` is a local PathBuf that gets dropped each iteration, and the closure's `FnMut` requirement is satisfied by the mutable borrow of the vector elements.\n\nNow looking at how error entries are handled: the current code removes them via `unwrap_or(false)`, and my new version does the same with the `Err(_) => false` branch, so the behavior is consistent.\n\nMoving into the main walker loop...\n\nRefactoring the function call...\n\nInstead of changing the function signature, I'll handle the metadata extraction directly in the loop. The entry now carries pre-fetched metadata in its client state, so I can use that first and fall back to a stat call if needed for shallow entries or if the pre-fetch failed.\n\nActually, I realize I can move the client_state directly out of the entry since I own it from the channel, avoiding the clone overhead.\n\nBut wait—once I move a field out of the struct, I can't call methods on it anymore because methods take `&self`, which would require all fields to be accessible. So calling `entry.path()` after moving `entry.client_state` won't work, even though `path()` doesn't actually need that field.\n\nThe fix is to extract both `depth` and the path before moving anything out of `entry`. That way I can grab the values I need, then safely move `client_state` afterward without running into borrow checker issues.\n\nRestructuring the match arm... Finishing up the row handling logic where I check if metadata has changed compared to what's already indexed, and then I'm verifying that the entry goes out of scope properly since we only need the path and metadata going forward.\n\nNow I need to think through how `is_fresh` gets captured by the closure that processes the directory read results.\n\nSince `is_fresh` is derived from `last_run_id == 0` and `current_pass` needs to be available inside the closure, both can be captured from the enclosing scope. I'm setting up the walker with the appropriate thread pool size based on whether this is a fresh scan, and adjusting the max depth for shallow scans on the first pass when it's not a fresh run.\n\nSetting up the directory traversal logic...\n\nActually, I need to reconsider how the depth field works in this context. The entry's depth is determined when it's created, and for directories at depth D, their children would be at depth D+1. So when I'm checking `entry.depth > SHALLOW_SCAN_DEPTH` in pass 1, I'm filtering based on whether we've already descended past the shallow scan threshold, which means deeper entries get their metadata cached while shallower ones are deferred. So entries at depth ≤6 get skipped in pass 1, which means we only stat entries deeper than that. The logic checks whether we're in pass 1 and the entry is shallow enough to skip—if so, we don't call symlink_metadata, otherwise we do.\n\nThe key thing I'm realizing is that `entry.depth` is measured from the root of the walk, not from scan_root, so depth 6 means six levels down from the actual root directory. Since SHALLOW_SCAN_DEPTH is 6, this correctly aligns with what the main loop already processed in pass 0.\n\nLet me think through another aspect of this optimization.\n\nIn `process_read_dir`, we're building a full path by joining the parent path with the file name, then using that for both the skip check and the metadata call. But I'm wondering whether `symlink_metadata` is giving us the right information for symlinks, and how that feeds into the indexing logic.\n\nLooking at `index_row_from_path_and_metadata`, it uses `metadata.is_dir()` to determine if something's a directory. With `symlink_metadata`, a symlink pointing to a directory will report `is_symlink() == true` but NOT `is_dir() == true`, so those symlinks get stored as files instead of directories. This is actually the current behavior already since the old code also uses `symlink_metadata` through `entry.metadata()`, so we're not changing anything there.\n\nNow I need to plan out the code changes. I want to add a `jwalk_num_threads_fresh()` function and use it specifically for fresh index operations. Let me find where `jwalk_num_threads()` is currently being called so I can add this new variant in the right place.\n\nDefining a new function that calculates thread count for fresh indexing...\n\nNow I need to remove `index_row_from_jwalk_entry` since we're handling metadata directly in the main loop instead. We're already calling `index_row_from_path_and_metadata` with the path and metadata separately, so that helper function becomes redundant.\n\nUpdating the walker in the incremental index function...\n\nUpdating the main loop to use pre-fetched metadata...\n\nI need to handle the case where `client_state` is None differently depending on whether we're in pass 1 with shallow entries or if the stat actually failed. Since shallow entries get skipped before we try to access metadata, any None at that point means the stat failed and I should fall back to doing it here. Refining the error handling logic...\n\nI need to make sure the scanned counter increments for all entries, including those where the stat failed during the pre-fetch phase. The key insight is that when metadata wasn't pre-fetched (because stat failed in the rayon thread), I should count it as a permission error but still track it in the scanned count, then skip processing that entry. I need to trace through the logic more carefully for pass 1 shallow entries. In `process_read_dir`, if we're in pass 1 with depth <= SHALLOW_SCAN_DEPTH, we don't pre-fetch the stat, so the entry reaches the main loop without metadata. Then in the main loop, we skip it before even checking `client_state`, which means those shallow entries never get processed—they're filtered out early. So the only entries that make it through to the stat-checking logic are either pass 0 entries (which have pre-fetched stats) or pass 1 deep entries (which also have pre-fetched stats). Setting up the walker configuration... Finishing the parallelism configuration with the thread pool size, then I need to make sure `fs::Metadata` is properly accessible in the type annotation—since `fs` is already imported from `std`, I can use it directly in the generic type parameter.\n\nFor the `normalize_slashes` function, I'm adding a check to avoid unnecessary allocations on systems like macOS where backslashes never appear in paths, only doing the replacement when it's actually needed.\n\nNow I'm looking at the `BUILTIN_SKIP_PATHS` logic to see if there's a similar optimization opportunity there.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":623,"cache_read_input_tokens":111323,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":623},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNk8vWmHMnSMmsXzPoaY","type":"assistant","uuid":"87e1fcef-3fcc-4d90-9825-cb1b5933bf3b","timestamp":"2026-02-22T07:54:09.820Z"}
{"parentUuid":"87e1fcef-3fcc-4d90-9825-cb1b5933bf3b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01TBuhSz1oqutpksnaPVrCkE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014ikrfCYSkwjp746tvsCPaZ","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":1246,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":623,"cache_read_input_tokens":111323,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":623},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNk8vWmHMnSMmsXzPoaY","type":"assistant","uuid":"b5fa4f8a-0df6-489d-afca-5dd99cae23e2","timestamp":"2026-02-22T07:54:10.130Z"}
{"parentUuid":"b5fa4f8a-0df6-489d-afca-5dd99cae23e2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_014ikrfCYSkwjp746tvsCPaZ","toolUseID":"toolu_014ikrfCYSkwjp746tvsCPaZ","timestamp":"2026-02-22T07:54:10.146Z","uuid":"dd39a494-dd84-4b5b-98f5-bae2663d6bf4"}
{"parentUuid":"b5fa4f8a-0df6-489d-afca-5dd99cae23e2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014ikrfCYSkwjp746tvsCPaZ","type":"tool_result","content":"  1246→pub(crate) fn should_skip_path_ext(\n  1247→    path: &Path,\n  1248→    ignored_roots: &[PathBuf],\n  1249→    ignored_patterns: &[IgnorePattern],\n  1250→    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n  1251→    is_dir_hint: Option<bool>,\n  1252→) -> bool {\n  1253→    let s = normalize_slashes(path.to_string_lossy().to_string());\n  1254→\n  1255→    // Single-component builtin names: check path segments\n  1256→    if s.split('/').any(|seg| {\n  1257→        BUILTIN_SKIP_NAMES.contains(&seg)\n  1258→            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n  1259→    }) {\n  1260→        return true;\n  1261→    }\n  1262→\n  1263→    // Multi-component builtin paths\n  1264→    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n  1265→        let infix = format!(\"/{pat}/\");\n  1266→        let suffix = format!(\"/{pat}\");\n  1267→        s.contains(&infix) || s.ends_with(&suffix)\n  1268→    }) {\n  1269→        return true;\n  1270→    }\n  1271→\n  1272→    if ignored_roots\n  1273→        .iter()\n  1274→        .any(|root| path == root || path.starts_with(root))\n  1275→    {\n  1276→        return true;\n  1277→    }\n  1278→    if ignored_patterns\n  1279→        .iter()\n  1280→        .any(|pattern| matches_ignore_pattern(&s, pattern))\n  1281→    {\n  1282→        return true;\n  1283→    }\n  1284→    if let Some(gi) = gitignore {\n  1285→        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n  1286→        if gi.is_ignored(path, is_dir) {\n  1287→            return true;\n  1288→        }\n  1289→    }\n  1290→    false\n  1291→}\n  1292→\n  1293→fn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n  1294→    if is_dir {\n  1295→        return None;\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"deb01c5c-5d7a-42fe-bf08-f53c4fae1b1f","timestamp":"2026-02-22T07:54:10.145Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"pub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;","numLines":50,"startLine":1246,"totalLines":5786}},"sourceToolAssistantUUID":"b5fa4f8a-0df6-489d-afca-5dd99cae23e2"}
{"parentUuid":"deb01c5c-5d7a-42fe-bf08-f53c4fae1b1f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01PzkXbUdK77nf8LHeLJ13Di","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I see the issue: `BUILTIN_SKIP_PATHS.iter().any(|pat| { let infix = format!(\"/{pat}/\"); let suffix = format!(\"/{pat}\"); ... })` - this creates 2 format strings per pattern per call. With 8 patterns and 400k entries × 2 passes (process_read_dir + main loop for incremental), that's potentially millions of String allocations.\n\nLet me add a static lazy initialization for pre-computed skip path strings. I'll use `std::sync::OnceLock` to initialize them once.\n\nActually, looking at the code again: `should_skip_path_ext` is called in `process_read_dir` (rayon threads) and possibly elsewhere. \n\nThe `any` iterator short-circuits on the first match, so entries that don't hit the early BUILTIN_SKIP_NAMES check will still allocate up to 16 String objects (8 patterns × 2 format strings each) before finding a match or exhausting all patterns. Pre-computing these strings once at startup would eliminate this repeated allocation overhead entirely. Still writing optimization code...\n\nWith N patterns and 400k entries, that's millions of unnecessary allocations happening per scan. I can fix this by pre-computing the suffix and infix strings directly in the enum variant, so they're only created once during pattern initialization rather than repeatedly during matching. This eliminates the allocation overhead entirely for builtin patterns like `target` and `__pycache__`.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7628,"cache_read_input_tokens":111946,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7628},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkGxpPrwCnuqqfEUTFN","type":"assistant","uuid":"77951019-0999-4aba-bcfe-a5bbb9e0bedb","timestamp":"2026-02-22T07:54:27.949Z"}
{"parentUuid":"77951019-0999-4aba-bcfe-a5bbb9e0bedb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01PzkXbUdK77nf8LHeLJ13Di","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01USvhGmvC6wbeqJJdvvSqSD","name":"Grep","input":{"pattern":"AnySegment|IgnorePattern::Glob|parse_pattern_line|builtin_ignore_patterns","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":5},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7628,"cache_read_input_tokens":111946,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7628},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkGxpPrwCnuqqfEUTFN","type":"assistant","uuid":"29e28e8c-4838-4d83-a0c4-3adbe4655bb6","timestamp":"2026-02-22T07:54:28.293Z"}
{"parentUuid":"29e28e8c-4838-4d83-a0c4-3adbe4655bb6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01USvhGmvC6wbeqJJdvvSqSD","toolUseID":"toolu_01USvhGmvC6wbeqJJdvvSqSD","timestamp":"2026-02-22T07:54:29.050Z","uuid":"f3916b92-7f79-4aa3-a966-b8388fca4033"}
{"parentUuid":"29e28e8c-4838-4d83-a0c4-3adbe4655bb6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01USvhGmvC6wbeqJJdvvSqSD","type":"tool_result","content":"279-    at: Instant,\n280-}\n281-\n282-#[derive(Debug, Clone, PartialEq, Eq)]\n283-pub(crate) enum IgnorePattern {\n284:    AnySegment(String),\n285-    Glob(String),\n286-}\n287-\n288-#[derive(Debug, Clone)]\n289-pub(crate) struct IgnoreRulesCache {\n--\n789-        return None;\n790-    }\n791-\n792-    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n793-        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n794:            return Some(IgnorePattern::AnySegment(segment.to_string()));\n795-        }\n796-    }\n797-\n798:    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n799-        trimmed, base_dir, home_dir,\n800-    )))\n801-}\n802-\n803-fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n804-    match pattern {\n805:        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n806:        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n807-    }\n808-}\n809-\n810-fn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n811-    let mut current = Some(start);\n--\n1047-        }\n1048-    }\n1049-\n1050-    for pattern in pathignore_patterns\n1051-        .into_iter()\n1052:        .chain(builtin_ignore_patterns(home_dir))\n1053-    {\n1054-        let key = ignore_pattern_key(&pattern);\n1055-        if seen_patterns.insert(key) {\n1056-            patterns.push(pattern);\n1057-        }\n1058-    }\n1059-\n1060-    (roots, patterns)\n1061-}\n1062-\n1063:fn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n1064-    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n1065-    vec![\n1066-        // ~/Library/Application Support/*/Cache*\n1067:        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n1068-        // ~/Library/Application Support/*/Code Cache\n1069:        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n1070-        // ~/.rustup/toolchains/*/share/doc\n1071:        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n1072-        // ~/.pyenv/versions/*/lib\n1073:        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n1074-    ]\n1075-}\n1076-\n1077-pub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n1078-    let home_dir = &state.home_dir;\n--\n1206-    px == pn\n1207-}\n1208-\n1209-pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1210-    match pattern {\n1211:        IgnorePattern::AnySegment(segment) => {\n1212-            let suffix = format!(\"/{segment}\");\n1213-            let infix = format!(\"/{segment}/\");\n1214-            path.ends_with(&suffix) || path.contains(&infix)\n1215-        }\n1216:        IgnorePattern::Glob(glob) => {\n1217-            let mut cur = path;\n1218-            loop {\n1219-                if glob_match_path(glob, cur) {\n1220-                    return true;\n1221-                }\n--\n5403-        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n5404-    }\n5405-\n5406-    #[test]\n5407-    fn should_skip_path_for_glob_any_segment_target() {\n5408:        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n5409-\n5410-        assert!(should_skip_path(\n5411-            Path::new(\"/Users/al02402336/work/rust/target\"),\n5412-            &[],\n5413-            &patterns"}]},"uuid":"c243696d-bc9e-4ce9-8f45-47e5bde4ddff","timestamp":"2026-02-22T07:54:29.048Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"279-    at: Instant,\n280-}\n281-\n282-#[derive(Debug, Clone, PartialEq, Eq)]\n283-pub(crate) enum IgnorePattern {\n284:    AnySegment(String),\n285-    Glob(String),\n286-}\n287-\n288-#[derive(Debug, Clone)]\n289-pub(crate) struct IgnoreRulesCache {\n--\n789-        return None;\n790-    }\n791-\n792-    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n793-        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n794:            return Some(IgnorePattern::AnySegment(segment.to_string()));\n795-        }\n796-    }\n797-\n798:    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n799-        trimmed, base_dir, home_dir,\n800-    )))\n801-}\n802-\n803-fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n804-    match pattern {\n805:        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n806:        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n807-    }\n808-}\n809-\n810-fn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n811-    let mut current = Some(start);\n--\n1047-        }\n1048-    }\n1049-\n1050-    for pattern in pathignore_patterns\n1051-        .into_iter()\n1052:        .chain(builtin_ignore_patterns(home_dir))\n1053-    {\n1054-        let key = ignore_pattern_key(&pattern);\n1055-        if seen_patterns.insert(key) {\n1056-            patterns.push(pattern);\n1057-        }\n1058-    }\n1059-\n1060-    (roots, patterns)\n1061-}\n1062-\n1063:fn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n1064-    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n1065-    vec![\n1066-        // ~/Library/Application Support/*/Cache*\n1067:        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n1068-        // ~/Library/Application Support/*/Code Cache\n1069:        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n1070-        // ~/.rustup/toolchains/*/share/doc\n1071:        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n1072-        // ~/.pyenv/versions/*/lib\n1073:        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n1074-    ]\n1075-}\n1076-\n1077-pub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n1078-    let home_dir = &state.home_dir;\n--\n1206-    px == pn\n1207-}\n1208-\n1209-pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1210-    match pattern {\n1211:        IgnorePattern::AnySegment(segment) => {\n1212-            let suffix = format!(\"/{segment}\");\n1213-            let infix = format!(\"/{segment}/\");\n1214-            path.ends_with(&suffix) || path.contains(&infix)\n1215-        }\n1216:        IgnorePattern::Glob(glob) => {\n1217-            let mut cur = path;\n1218-            loop {\n1219-                if glob_match_path(glob, cur) {\n1220-                    return true;\n1221-                }\n--\n5403-        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n5404-    }\n5405-\n5406-    #[test]\n5407-    fn should_skip_path_for_glob_any_segment_target() {\n5408:        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n5409-\n5410-        assert!(should_skip_path(\n5411-            Path::new(\"/Users/al02402336/work/rust/target\"),\n5412-            &[],\n5413-            &patterns","numLines":97},"sourceToolAssistantUUID":"29e28e8c-4838-4d83-a0c4-3adbe4655bb6"}
{"parentUuid":"c243696d-bc9e-4ce9-8f45-47e5bde4ddff","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Ck4cWHMBrhVF5bMVwSEsuK","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have the full picture. Here are the changes I'll make:\n\n**Summary of optimizations:**\n\n1. **Parallel stat()**: Use `WalkDirGeneric<((), Option<fs::Metadata>)>` and pre-fetch metadata in `process_read_dir` via `retain_mut` (combines filter + stat in one pass, 1 PathBuf per entry).\n\n2. **More threads for fresh**: New `jwalk_num_threads_fresh()` = `n.max(4).min(16)` (doubles from current `n/2`).\n\n3. **Pre-compute BUILTIN_SKIP_PATHS strings**: Use `OnceLock<Vec<(String, String)>>` to avoid format! allocations in hot path.\n\n\n4. **Pre-compute AnySegment strings**: Store suffix and infix strings directly in the IgnorePattern enum to avoid runtime string operations.\n\n5. **normalize_slashes no-alloc on macOS**: Skip the replace call if there are no backslashes present.\n\n6. **PASSIVE checkpoint**: Switch from `wal_checkpoint(TRUNCATE)` to `wal_checkpoint(PASSIVE)`.\n\n7. **Add timing logs**: Instrument the index creation and ANALYZE phases to track performance.\n\nThe AnySegment pre-computation is going to require restructuring the IgnorePattern enum itself, so I'll need to be careful with that refactor.\n\nLooking at where AnySegment gets used, I can see it's constructed in `parse_pattern_line` and test cases, and matched in `matches_ignore_pattern` and `ignore_pattern_key`. That's a manageable scope for the change. Let me update the enum definition...\n\nUpdating the enum structure... Updating the pattern key generation and test cases...\n\nI need to make sure the test at line 5408 uses the constructor function instead of the direct struct syntax, and since `IgnorePattern` derives `PartialEq`, the comparison will work correctly. The patterns are actually deduplicated through `ignore_pattern_key` rather than direct equality checks, so this approach should be consistent with how the cache handles them. So removing the `PartialEq` derive would be breaking. But since we're adding fields, the struct variant will still work with PartialEq derived.\n\nLet me also check if `PartialEq` is derived and needed:\n\nWith struct variant:\n```rust\nIgnorePattern::AnySegment { segment: String, suffix: String, infix: String }\n```\n\nPartialEq would compare all three fields. The `suffix` and `infix` are derived from `segment`, so if `segment` equals, the other two also equal. We could implement PartialEq manually to just compare `segment`, but that's extra work. The auto-derived PartialEq is fine for correctness.\n\nNow I need to map out the concrete changes: normalizing slashes first, adding a static for builtin skip paths with a helper function, updating the skip path logic to use pre-computed strings, converting `AnySegment` to a struct variant with those pre-computed values, creating a helper to construct the pattern, updating all the places that create this variant, adding a fresh thread count function, and modifying the walker in the incremental index to use the right type and thread count based on whether it's a fresh index.\n\nThen in the main loop I'll use the pre-fetched metadata, switch `restore_normal_pragmas` to use a PASSIVE checkpoint, and check where `index_row_from_jwalk_entry` is called to make sure the changes work everywhere.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2275,"cache_read_input_tokens":119574,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2275},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkJMfMYWvf1pWSQYt7G","type":"assistant","uuid":"ae5c37d2-98b0-480f-baad-b3da142c8209","timestamp":"2026-02-22T07:54:58.990Z"}
{"parentUuid":"ae5c37d2-98b0-480f-baad-b3da142c8209","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Ck4cWHMBrhVF5bMVwSEsuK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PgugJKbbpNMyhv4FNJzrNH","name":"Grep","input":{"pattern":"index_row_from_jwalk_entry","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2275,"cache_read_input_tokens":119574,"output_tokens":1529,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":2275,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkJMfMYWvf1pWSQYt7G","type":"assistant","uuid":"e0f56319-29ce-4b9a-8bea-c68a7e9cbc71","timestamp":"2026-02-22T07:54:59.012Z"}
{"parentUuid":"e0f56319-29ce-4b9a-8bea-c68a7e9cbc71","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01PgugJKbbpNMyhv4FNJzrNH","toolUseID":"toolu_01PgugJKbbpNMyhv4FNJzrNH","timestamp":"2026-02-22T07:54:59.666Z","uuid":"b63a7028-fe4f-4169-9742-bc4fa3958ad8"}
{"parentUuid":"e0f56319-29ce-4b9a-8bea-c68a7e9cbc71","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PgugJKbbpNMyhv4FNJzrNH","type":"tool_result","content":"1357:fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n2260:                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {"}]},"uuid":"583aacb6-d301-4327-9746-1f7340ccb01d","timestamp":"2026-02-22T07:54:59.664Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"1357:fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n2260:                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {","numLines":2},"sourceToolAssistantUUID":"e0f56319-29ce-4b9a-8bea-c68a7e9cbc71"}
{"parentUuid":"583aacb6-d301-4327-9746-1f7340ccb01d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_015YqJbcfhxkwqjUtEYVfEMR","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"`index_row_from_jwalk_entry` is only called from one place. I'll remove this function and inline the logic.\n\nNow let me check what other files use the jwalk types:","signature":"EsoCCkYICxgCKkDxXT558xw0OYyu5HYU4GfdglCaTSFy1zdTAl86kahb3iGa7aoeC+SBx903EAK5UXH5zbCFsp7O2KyUlcHQzCv3EgxmodOnk0U9xMVr84MaDOXfiXki6vPtoVCERiIwtcSZw75lRzdn6aJubolsMwXBDVxD5rzKY4xtAI1/MGu7TyKqBfxfjCThGIAT6CNIKrEBe3cYVB3kS+Gh2IprR1HC2K1ikuQyRO/wd957fq7V3TjMuWguZveVYu28jhUKx4UzaP23WrVKhr/J40c3/T5x7G/oaCOh2ZjUVRSke3VWfYIobB9OfrSKVAiHTomCZalvTSW2jvxbXu0/1F/DrcbviqT2rNJNzLkz+zPyGodiBRzzxevPl6E4onbNehWwZcVdezEYMFL8XIQMa2o69KFUqyeHsYchUPz5BsT1KY/BSYJxGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1582,"cache_read_input_tokens":121849,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1582},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkLcYcWmqaFZW3egVWz","type":"assistant","uuid":"e614a04b-5d8c-4cf4-af52-a806618bf352","timestamp":"2026-02-22T07:55:02.731Z"}
{"parentUuid":"e614a04b-5d8c-4cf4-af52-a806618bf352","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_015YqJbcfhxkwqjUtEYVfEMR","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01F6h7WVVSn78ndfaA89b34N","name":"Grep","input":{"pattern":"jwalk|WalkDir\\b","path":"/Users/al02402336/everything/src-tauri/src","output_mode":"files_with_matches"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1582,"cache_read_input_tokens":121849,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1582},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkLcYcWmqaFZW3egVWz","type":"assistant","uuid":"442b51d0-e05b-4297-91e0-dcdd8a21841f","timestamp":"2026-02-22T07:55:03.721Z"}
{"parentUuid":"442b51d0-e05b-4297-91e0-dcdd8a21841f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01F6h7WVVSn78ndfaA89b34N","toolUseID":"toolu_01F6h7WVVSn78ndfaA89b34N","timestamp":"2026-02-22T07:55:04.363Z","uuid":"28e422bf-d64f-45fc-adb5-042b2f4127e7"}
{"parentUuid":"442b51d0-e05b-4297-91e0-dcdd8a21841f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01F6h7WVVSn78ndfaA89b34N","type":"tool_result","content":"Found 5 files\nsrc-tauri/src/main.rs\nsrc-tauri/src/win/nonadmin_indexer.rs\nsrc-tauri/src/win/mod.rs\nsrc-tauri/src/fd_search.rs\nsrc-tauri/src/win/search_catchup.rs"}]},"uuid":"b25801ae-d6be-494e-8361-d827bc3973b9","timestamp":"2026-02-22T07:55:04.361Z","toolUseResult":{"mode":"files_with_matches","filenames":["src-tauri/src/main.rs","src-tauri/src/win/nonadmin_indexer.rs","src-tauri/src/win/mod.rs","src-tauri/src/fd_search.rs","src-tauri/src/win/search_catchup.rs"],"numFiles":5},"sourceToolAssistantUUID":"442b51d0-e05b-4297-91e0-dcdd8a21841f"}
{"parentUuid":"b25801ae-d6be-494e-8361-d827bc3973b9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01NnDoFVQ8RCtLrzLh1oHPZM","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Other files use jwalk too. Let me check the mac module to see if it uses jwalk:","signature":"EvcBCkYICxgCKkC0FplJ3djMEURbWcVVUgtIG0SGOSHU41M83BoTKtfjlw8q2lzieQiZgM1HgBM5DYq6YAPTqo786usnnwfJyWClEgxlg8MQ3WE6CeCD8EQaDCucqMBxbA4+RhRb9SIwmzz/h/Qh+zwbiL2rTpi87xTQWQxUmA51UK1X/faAxwdkR9minLFBhmGGUtRfOMM2Kl/RqP6r4hdV+g15DukHmtGH3AqykhEK9nO68e/AszvsgSL3z4YpavFrTxh1uGxVUktcyHvmeg3w8aRRifIs7QplZWyKQ1ORe6qY6ALwPmufRsSa+vD5k89XUZyq1C59gxgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":259,"cache_read_input_tokens":123431,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":259},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkLxgKhSmLRJNyafB2D","type":"assistant","uuid":"05d3071f-9529-4fb7-9526-b27ed52aa393","timestamp":"2026-02-22T07:55:06.117Z"}
{"parentUuid":"05d3071f-9529-4fb7-9526-b27ed52aa393","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01NnDoFVQ8RCtLrzLh1oHPZM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011UHstPgqv8BViuwHY2FzJj","name":"Bash","input":{"command":"grep -n \"jwalk\\|index_row_from_jwalk\" /Users/al02402336/everything/src-tauri/src/mac/*.rs 2>/dev/null | head -20","description":"Check mac module for jwalk usage"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":259,"cache_read_input_tokens":123431,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":259},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkLxgKhSmLRJNyafB2D","type":"assistant","uuid":"1681ff23-10c5-4f11-8e09-d775bf58313e","timestamp":"2026-02-22T07:55:06.996Z"}
{"parentUuid":"1681ff23-10c5-4f11-8e09-d775bf58313e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011UHstPgqv8BViuwHY2FzJj","type":"tool_result","content":"","is_error":false}]},"uuid":"b7cfcd90-8882-4607-9322-f9b9a7c42047","timestamp":"2026-02-22T07:55:08.267Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"1681ff23-10c5-4f11-8e09-d775bf58313e"}
{"parentUuid":"b7cfcd90-8882-4607-9322-f9b9a7c42047","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_016vdyKjeV7iq2MRMhtbk9rY","type":"message","role":"assistant","content":[{"type":"text","text":"Good. Now let me make all the changes. I'll do them in the right order to avoid breaking things:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":183,"cache_read_input_tokens":123690,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":183},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkMFAmQo1TJ3TfBUrJw","type":"assistant","uuid":"f610d5e9-314e-49c2-8fc8-172dc2a24993","timestamp":"2026-02-22T07:55:10.273Z"}
{"parentUuid":"f610d5e9-314e-49c2-8fc8-172dc2a24993","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_016vdyKjeV7iq2MRMhtbk9rY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TzKRP6YEDkWtjW4696Yzsk","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":55,"limit":5},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":183,"cache_read_input_tokens":123690,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":183},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkMFAmQo1TJ3TfBUrJw","type":"assistant","uuid":"b07bd98b-555d-4a9c-9533-f2776c6ef75d","timestamp":"2026-02-22T07:55:11.046Z"}
{"parentUuid":"b07bd98b-555d-4a9c-9533-f2776c6ef75d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01TzKRP6YEDkWtjW4696Yzsk","toolUseID":"toolu_01TzKRP6YEDkWtjW4696Yzsk","timestamp":"2026-02-22T07:55:11.072Z","uuid":"cf99f2c3-39b0-4028-8902-63381acc7aaa"}
{"parentUuid":"b07bd98b-555d-4a9c-9533-f2776c6ef75d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TzKRP6YEDkWtjW4696Yzsk","type":"tool_result","content":"    55→fn jwalk_num_threads() -> usize {\n    56→    std::thread::available_parallelism()\n    57→        .map(|n| (n.get() / 2).max(4).min(16))\n    58→        .unwrap_or(8)\n    59→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e9a846e4-aab6-492f-832c-35fb34847fff","timestamp":"2026-02-22T07:55:11.070Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"fn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}","numLines":5,"startLine":55,"totalLines":5786}},"sourceToolAssistantUUID":"b07bd98b-555d-4a9c-9533-f2776c6ef75d"}
{"parentUuid":"e9a846e4-aab6-492f-832c-35fb34847fff","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_018cdESXJDkMxUEsmrw1cM27","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll make all the changes:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":298,"cache_read_input_tokens":123873,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":298},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkMTNyvy7CB3LiFsos1","type":"assistant","uuid":"644eef1d-2698-43f8-ba92-cda191b62aab","timestamp":"2026-02-22T07:55:12.698Z"}
{"type":"file-history-snapshot","messageId":"bac89353-9a3b-40ae-989f-866305dafcfb","snapshot":{"messageId":"192713d9-061f-43d9-b09d-c33b1dc64725","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v1","version":1,"backupTime":"2026-02-22T07:55:14.790Z"}},"timestamp":"2026-02-22T07:39:06.444Z"},"isSnapshotUpdate":true}
{"parentUuid":"644eef1d-2698-43f8-ba92-cda191b62aab","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_018cdESXJDkMxUEsmrw1cM27","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013TpyB34nYFofVmqmXfaMHJ","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"fn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}","new_string":"fn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":298,"cache_read_input_tokens":123873,"output_tokens":296,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":298,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkMTNyvy7CB3LiFsos1","type":"assistant","uuid":"bac89353-9a3b-40ae-989f-866305dafcfb","timestamp":"2026-02-22T07:55:14.785Z"}
{"parentUuid":"bac89353-9a3b-40ae-989f-866305dafcfb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_013TpyB34nYFofVmqmXfaMHJ","toolUseID":"toolu_013TpyB34nYFofVmqmXfaMHJ","timestamp":"2026-02-22T07:55:14.797Z","uuid":"4eec7cec-7a14-4e90-aeb0-2c97d9ab2f65"}
{"parentUuid":"bac89353-9a3b-40ae-989f-866305dafcfb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013TpyB34nYFofVmqmXfaMHJ","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"cb125d04-25e7-48db-ba61-2bd15ba0a652","timestamp":"2026-02-22T07:55:14.796Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"fn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}","newString":"fn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":58,"oldLines":6,"newStart":58,"newLines":12,"lines":["         .unwrap_or(8)"," }"," ","+fn jwalk_num_threads_fresh() -> usize {","+    std::thread::available_parallelism()","+        .map(|n| n.get().max(4).min(16))","+        .unwrap_or(8)","+}","+"," pub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[","     \".git\",","     \"node_modules\","]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"bac89353-9a3b-40ae-989f-866305dafcfb"}
{"parentUuid":"cb125d04-25e7-48db-ba61-2bd15ba0a652","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01PvfjPg5QFgGqbs9x7eRSdj","type":"message","role":"assistant","content":[{"type":"text","text":"Now change `normalize_slashes` to avoid the secondary allocation:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":353,"cache_read_input_tokens":124171,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":353},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkMjHhGPGM6Fwg1AzgX","type":"assistant","uuid":"1bda5f23-4302-433f-b2e8-0b8bf7152d99","timestamp":"2026-02-22T07:55:16.859Z"}
{"parentUuid":"1bda5f23-4302-433f-b2e8-0b8bf7152d99","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01PvfjPg5QFgGqbs9x7eRSdj","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Uzz357VcSHcNKzWAaUnxvM","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"fn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}","new_string":"fn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":353,"cache_read_input_tokens":124171,"output_tokens":184,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":353,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkMjHhGPGM6Fwg1AzgX","type":"assistant","uuid":"2ea400d0-1912-41dd-9003-b7a733fa82ce","timestamp":"2026-02-22T07:55:18.197Z"}
{"parentUuid":"2ea400d0-1912-41dd-9003-b7a733fa82ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01Uzz357VcSHcNKzWAaUnxvM","toolUseID":"toolu_01Uzz357VcSHcNKzWAaUnxvM","timestamp":"2026-02-22T07:55:18.206Z","uuid":"80a8cdc7-873b-4bf7-a09a-36413b087ee4"}
{"parentUuid":"2ea400d0-1912-41dd-9003-b7a733fa82ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Uzz357VcSHcNKzWAaUnxvM","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"55e71069-efb8-450a-b937-c96bacd9b82d","timestamp":"2026-02-22T07:55:18.205Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"fn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}","newString":"fn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    s.replace('\\\\', \"/\")\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":751,"oldLines":7,"newStart":751,"newLines":7,"lines":[" }"," "," fn normalize_slashes(s: String) -> String {","-    s.replace('\\\\', \"/\")","+    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }"," }"," "," fn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"2ea400d0-1912-41dd-9003-b7a733fa82ce"}
{"parentUuid":"55e71069-efb8-450a-b937-c96bacd9b82d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_013N8T7zFXmRcfxbf4hPcXox","type":"message","role":"assistant","content":[{"type":"text","text":"Now add the pre-computed BUILTIN_SKIP_PATHS check using OnceLock:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":352,"cache_read_input_tokens":124524,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":352},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkMyfPZKZBpr1R6Tb6x","type":"assistant","uuid":"b23d5738-b237-4d6d-b2a6-c74e196f5ec4","timestamp":"2026-02-22T07:55:20.076Z"}
{"parentUuid":"b23d5738-b237-4d6d-b2a6-c74e196f5ec4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_013N8T7zFXmRcfxbf4hPcXox","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017MLhcxFEx56SGDQf8iLNb5","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":95,"limit":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":352,"cache_read_input_tokens":124524,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":352},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkMyfPZKZBpr1R6Tb6x","type":"assistant","uuid":"04bf34d6-f888-4148-9ce8-667d5cf6fbff","timestamp":"2026-02-22T07:55:20.682Z"}
{"parentUuid":"04bf34d6-f888-4148-9ce8-667d5cf6fbff","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_017MLhcxFEx56SGDQf8iLNb5","toolUseID":"toolu_017MLhcxFEx56SGDQf8iLNb5","timestamp":"2026-02-22T07:55:20.725Z","uuid":"dae69fb1-d885-48af-a6f1-6e636b79268f"}
{"parentUuid":"04bf34d6-f888-4148-9ce8-667d5cf6fbff","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017MLhcxFEx56SGDQf8iLNb5","type":"tool_result","content":"    95→    \"AppData/Local/Temp\",\n    96→    \"AppData/Local/Microsoft\",\n    97→    \"AppData/Local/Google\",\n    98→    \"AppData/Local/Packages\",\n    99→];\n   100→\n   101→type AppResult<T> = Result<T, String>;\n   102→static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n   103→static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\n   104→static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"be18257f-57d2-482f-8e2e-4eb1388c4bc5","timestamp":"2026-02-22T07:55:20.723Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();","numLines":10,"startLine":95,"totalLines":5792}},"sourceToolAssistantUUID":"04bf34d6-f888-4148-9ce8-667d5cf6fbff"}
{"parentUuid":"be18257f-57d2-482f-8e2e-4eb1388c4bc5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_0132gXU22uGd1SJ9RiiFKgso","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013MN3s1juDzcJV567c117yB","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"type AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();","new_string":"type AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":385,"cache_read_input_tokens":124876,"output_tokens":339,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":385,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkNAVWA9aRfbFJFaQe1","type":"assistant","uuid":"0c2f8bb2-993e-481a-8868-e474a66bb2ce","timestamp":"2026-02-22T07:55:25.522Z"}
{"parentUuid":"0c2f8bb2-993e-481a-8868-e474a66bb2ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_013MN3s1juDzcJV567c117yB","toolUseID":"toolu_013MN3s1juDzcJV567c117yB","timestamp":"2026-02-22T07:55:25.537Z","uuid":"b23776fe-c15a-4813-a1fe-0141c3f7c24a"}
{"parentUuid":"0c2f8bb2-993e-481a-8868-e474a66bb2ce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013MN3s1juDzcJV567c117yB","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"32406dd1-5cf2-40be-bb32-29b6fc7cba9d","timestamp":"2026-02-22T07:55:25.533Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"type AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();","newString":"type AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":99,"oldLines":6,"newStart":99,"newLines":18,"lines":[" ];"," "," type AppResult<T> = Result<T, String>;","+","+// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.","+static BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();","+fn builtin_skip_path_checks() -> &'static [(String, String)] {","+    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {","+        BUILTIN_SKIP_PATHS","+            .iter()","+            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))","+            .collect()","+    })","+}","+"," static SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();"," static PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();"," static BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"0c2f8bb2-993e-481a-8868-e474a66bb2ce"}
{"parentUuid":"32406dd1-5cf2-40be-bb32-29b6fc7cba9d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01DBajymQn5mQk8G3VUkUeLt","type":"message","role":"assistant","content":[{"type":"text","text":"Now update `should_skip_path_ext` to use the pre-computed strings:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":396,"cache_read_input_tokens":125261,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":396},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkNXgDxGifrMaHp3SnN","type":"assistant","uuid":"527f1775-df32-4757-8a52-f2dd5cffb7e7","timestamp":"2026-02-22T07:55:27.295Z"}
{"parentUuid":"527f1775-df32-4757-8a52-f2dd5cffb7e7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01DBajymQn5mQk8G3VUkUeLt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UUB6q9SNhJU1RAu24XX3vQ","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }","new_string":"    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":396,"cache_read_input_tokens":125261,"output_tokens":303,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":396,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkNXgDxGifrMaHp3SnN","type":"assistant","uuid":"05f08894-0c05-43e1-a43f-8806e749c7ed","timestamp":"2026-02-22T07:55:29.802Z"}
{"parentUuid":"05f08894-0c05-43e1-a43f-8806e749c7ed","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01UUB6q9SNhJU1RAu24XX3vQ","toolUseID":"toolu_01UUB6q9SNhJU1RAu24XX3vQ","timestamp":"2026-02-22T07:55:29.813Z","uuid":"8e40e9ea-ec46-4f1a-92fd-b833770962ee"}
{"parentUuid":"05f08894-0c05-43e1-a43f-8806e749c7ed","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UUB6q9SNhJU1RAu24XX3vQ","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"85f28335-51a9-4767-af96-c45c7aed0dd0","timestamp":"2026-02-22T07:55:29.813Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }","newString":"    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if BUILTIN_SKIP_PATHS.iter().any(|pat| {\n        let infix = format!(\"/{pat}/\");\n        let suffix = format!(\"/{pat}\");\n        s.contains(&infix) || s.ends_with(&suffix)\n    }) {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":1279,"oldLines":11,"newStart":1279,"newLines":10,"lines":["     }"," ","     // Multi-component builtin paths","-    if BUILTIN_SKIP_PATHS.iter().any(|pat| {","-        let infix = format!(\"/{pat}/\");","-        let suffix = format!(\"/{pat}\");","-        s.contains(&infix) || s.ends_with(&suffix)","-    }) {","+    if builtin_skip_path_checks()","+        .iter()","+        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))","+    {","         return true;","     }"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"05f08894-0c05-43e1-a43f-8806e749c7ed"}
{"parentUuid":"85f28335-51a9-4767-af96-c45c7aed0dd0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01MbexMrCcP6bchodKUmdxRG","type":"message","role":"assistant","content":[{"type":"text","text":"Now update `IgnorePattern` to pre-compute suffix/infix strings:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":341,"cache_read_input_tokens":125657,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":341},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkNqVHhcQc2YxhzqNUS","type":"assistant","uuid":"d7b7b634-8590-4b80-baee-741f87b2a6bd","timestamp":"2026-02-22T07:55:31.571Z"}
{"parentUuid":"d7b7b634-8590-4b80-baee-741f87b2a6bd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01MbexMrCcP6bchodKUmdxRG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Eptg3sVywUjX8JAFXJkZPb","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}","new_string":"#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":341,"cache_read_input_tokens":125657,"output_tokens":397,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":341,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkNqVHhcQc2YxhzqNUS","type":"assistant","uuid":"08bd65da-e8f4-454c-b1a8-8b680b758ee5","timestamp":"2026-02-22T07:55:35.699Z"}
{"parentUuid":"08bd65da-e8f4-454c-b1a8-8b680b758ee5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01Eptg3sVywUjX8JAFXJkZPb","toolUseID":"toolu_01Eptg3sVywUjX8JAFXJkZPb","timestamp":"2026-02-22T07:55:35.708Z","uuid":"f3d2ca22-6faf-4c2b-ad4b-705a14fb5de2"}
{"parentUuid":"08bd65da-e8f4-454c-b1a8-8b680b758ee5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Eptg3sVywUjX8JAFXJkZPb","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"7ef30843-7b63-43b9-a84a-dd3c38be994a","timestamp":"2026-02-22T07:55:35.707Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}","newString":"#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    AnySegment(String),\n    Glob(String),\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":299,"oldLines":10,"newStart":299,"newLines":27,"lines":[" "," #[derive(Debug, Clone, PartialEq, Eq)]"," pub(crate) enum IgnorePattern {","-    AnySegment(String),","+    /// Matches any path segment equal to `segment`.","+    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid","+    /// per-call format! allocations in the hot path.","+    AnySegment {","+        segment: String,","+        suffix: String,","+        infix: String,","+    },","     Glob(String),"," }"," ","+impl IgnorePattern {","+    pub(crate) fn any_segment(segment: &str) -> Self {","+        IgnorePattern::AnySegment {","+            suffix: format!(\"/{segment}\"),","+            infix: format!(\"/{segment}/\"),","+            segment: segment.to_string(),","+        }","+    }","+}","+"," #[derive(Debug, Clone)]"," pub(crate) struct IgnoreRulesCache {","     roots: Vec<PathBuf>,"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"08bd65da-e8f4-454c-b1a8-8b680b758ee5"}
{"parentUuid":"7ef30843-7b63-43b9-a84a-dd3c38be994a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_011rnv8shdEBYmoREHr1PNNv","type":"message","role":"assistant","content":[{"type":"text","text":"Now update all usages of `IgnorePattern::AnySegment`. First, `parse_pattern_line`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":435,"cache_read_input_tokens":125998,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":435},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkPGVwXwpbAXuzw66rA","type":"assistant","uuid":"134e0963-2756-4310-828b-40d35511af55","timestamp":"2026-02-22T07:55:37.800Z"}
{"parentUuid":"134e0963-2756-4310-828b-40d35511af55","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_011rnv8shdEBYmoREHr1PNNv","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01U6V99taZd6S9J739whQrJV","name":"Grep","input":{"pattern":"IgnorePattern::AnySegment","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":435,"cache_read_input_tokens":125998,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":435},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkPGVwXwpbAXuzw66rA","type":"assistant","uuid":"3c0676df-0bd1-4e3b-9108-b9355659d825","timestamp":"2026-02-22T07:55:38.841Z"}
{"parentUuid":"3c0676df-0bd1-4e3b-9108-b9355659d825","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01U6V99taZd6S9J739whQrJV","toolUseID":"toolu_01U6V99taZd6S9J739whQrJV","timestamp":"2026-02-22T07:55:39.477Z","uuid":"6d91d652-0871-44c3-9be8-5ee7a71ae63c"}
{"parentUuid":"3c0676df-0bd1-4e3b-9108-b9355659d825","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01U6V99taZd6S9J739whQrJV","type":"tool_result","content":"312-\n313-impl IgnorePattern {\n314-    pub(crate) fn any_segment(segment: &str) -> Self {\n315:        IgnorePattern::AnySegment {\n316-            suffix: format!(\"/{segment}\"),\n317-            infix: format!(\"/{segment}/\"),\n318-            segment: segment.to_string(),\n--\n826-\n827-    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n828-        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n829:            return Some(IgnorePattern::AnySegment(segment.to_string()));\n830-        }\n831-    }\n832-\n--\n837-\n838-fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n839-    match pattern {\n840:        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n841-        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n842-    }\n843-}\n--\n1243-\n1244-pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1245-    match pattern {\n1246:        IgnorePattern::AnySegment(segment) => {\n1247-            let suffix = format!(\"/{segment}\");\n1248-            let infix = format!(\"/{segment}/\");\n1249-            path.ends_with(&suffix) || path.contains(&infix)\n--\n5439-\n5440-    #[test]\n5441-    fn should_skip_path_for_glob_any_segment_target() {\n5442:        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n5443-\n5444-        assert!(should_skip_path(\n5445-            Path::new(\"/Users/al02402336/work/rust/target\"),"}]},"uuid":"293de4b9-aa75-4189-acd2-9d496566cbf7","timestamp":"2026-02-22T07:55:39.475Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"312-\n313-impl IgnorePattern {\n314-    pub(crate) fn any_segment(segment: &str) -> Self {\n315:        IgnorePattern::AnySegment {\n316-            suffix: format!(\"/{segment}\"),\n317-            infix: format!(\"/{segment}/\"),\n318-            segment: segment.to_string(),\n--\n826-\n827-    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n828-        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n829:            return Some(IgnorePattern::AnySegment(segment.to_string()));\n830-        }\n831-    }\n832-\n--\n837-\n838-fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n839-    match pattern {\n840:        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n841-        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n842-    }\n843-}\n--\n1243-\n1244-pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1245-    match pattern {\n1246:        IgnorePattern::AnySegment(segment) => {\n1247-            let suffix = format!(\"/{segment}\");\n1248-            let infix = format!(\"/{segment}/\");\n1249-            path.ends_with(&suffix) || path.contains(&infix)\n--\n5439-\n5440-    #[test]\n5441-    fn should_skip_path_for_glob_any_segment_target() {\n5442:        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n5443-\n5444-        assert!(should_skip_path(\n5445-            Path::new(\"/Users/al02402336/work/rust/target\"),","numLines":39},"sourceToolAssistantUUID":"3c0676df-0bd1-4e3b-9108-b9355659d825"}
{"parentUuid":"293de4b9-aa75-4189-acd2-9d496566cbf7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01D5onsX31vBzyoVBbmLSftE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01REcF69hUb9Uo4JttvHbkg2","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"            return Some(IgnorePattern::AnySegment(segment.to_string()));","new_string":"            return Some(IgnorePattern::any_segment(segment));"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":661,"cache_read_input_tokens":126433,"output_tokens":162,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":661,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkPYoiMN7YQ2VTch3kZ","type":"assistant","uuid":"a9577769-9093-4a5e-9ea6-d08d9182b8ae","timestamp":"2026-02-22T07:55:42.085Z"}
{"parentUuid":"a9577769-9093-4a5e-9ea6-d08d9182b8ae","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01REcF69hUb9Uo4JttvHbkg2","toolUseID":"toolu_01REcF69hUb9Uo4JttvHbkg2","timestamp":"2026-02-22T07:55:42.096Z","uuid":"836cf520-3bf4-46c4-b832-0317dcbfb3ee"}
{"parentUuid":"a9577769-9093-4a5e-9ea6-d08d9182b8ae","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01REcF69hUb9Uo4JttvHbkg2","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"d25c2854-ef9a-411c-a1ae-3016ce566d7d","timestamp":"2026-02-22T07:55:42.095Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"            return Some(IgnorePattern::AnySegment(segment.to_string()));","newString":"            return Some(IgnorePattern::any_segment(segment));","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::AnySegment(segment.to_string()));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":826,"oldLines":7,"newStart":826,"newLines":7,"lines":[" ","     if let Some(segment) = trimmed.strip_prefix(\"**/\") {","         if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {","-            return Some(IgnorePattern::AnySegment(segment.to_string()));","+            return Some(IgnorePattern::any_segment(segment));","         }","     }"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"a9577769-9093-4a5e-9ea6-d08d9182b8ae"}
{"parentUuid":"d25c2854-ef9a-411c-a1ae-3016ce566d7d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01G6SdJf8ZtKXT48WfzZ5pq5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015Y8qm1QdLmEzVHwNw5HfEp","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}","new_string":"fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":311,"cache_read_input_tokens":127094,"output_tokens":271,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":311,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkPjzv8zE2NAucRLNEJ","type":"assistant","uuid":"aa3ffe4d-3c94-4e1b-9b96-72d75c12474d","timestamp":"2026-02-22T07:55:45.357Z"}
{"parentUuid":"aa3ffe4d-3c94-4e1b-9b96-72d75c12474d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_015Y8qm1QdLmEzVHwNw5HfEp","toolUseID":"toolu_015Y8qm1QdLmEzVHwNw5HfEp","timestamp":"2026-02-22T07:55:45.369Z","uuid":"1dfd6c0c-b22c-40df-8d55-359e8e612409"}
{"parentUuid":"aa3ffe4d-3c94-4e1b-9b96-72d75c12474d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015Y8qm1QdLmEzVHwNw5HfEp","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"d1c45db2-d752-4530-8df7-b9c2e6124ea0","timestamp":"2026-02-22T07:55:45.367Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}","newString":"fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":837,"oldLines":7,"newStart":837,"newLines":7,"lines":[" "," fn ignore_pattern_key(pattern: &IgnorePattern) -> String {","     match pattern {","-        IgnorePattern::AnySegment(segment) => format!(\"seg:{segment}\"),","+        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),","         IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),","     }"," }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"aa3ffe4d-3c94-4e1b-9b96-72d75c12474d"}
{"parentUuid":"d1c45db2-d752-4530-8df7-b9c2e6124ea0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_014TKjYry7ruDR6bSQco9nQZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01X4hs2EmSScWQpMnKxnfcK8","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }","new_string":"        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":309,"cache_read_input_tokens":127405,"output_tokens":237,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":309,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkPyqN19TjfBUtg92xT","type":"assistant","uuid":"86ffbd85-11c2-4636-a778-7310145d86f9","timestamp":"2026-02-22T07:55:48.711Z"}
{"parentUuid":"86ffbd85-11c2-4636-a778-7310145d86f9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01X4hs2EmSScWQpMnKxnfcK8","toolUseID":"toolu_01X4hs2EmSScWQpMnKxnfcK8","timestamp":"2026-02-22T07:55:48.725Z","uuid":"917cb0a7-4b2f-4a5c-b861-1bab9b64350c"}
{"parentUuid":"86ffbd85-11c2-4636-a778-7310145d86f9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01X4hs2EmSScWQpMnKxnfcK8","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"5041f287-eb01-4c93-8293-dc7e6c46e783","timestamp":"2026-02-22T07:55:48.724Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }","newString":"        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment(segment) => {\n            let suffix = format!(\"/{segment}\");\n            let infix = format!(\"/{segment}/\");\n            path.ends_with(&suffix) || path.contains(&infix)\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":1243,"oldLines":10,"newStart":1243,"newLines":8,"lines":[" "," pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {","     match pattern {","-        IgnorePattern::AnySegment(segment) => {","-            let suffix = format!(\"/{segment}\");","-            let infix = format!(\"/{segment}/\");","-            path.ends_with(&suffix) || path.contains(&infix)","+        IgnorePattern::AnySegment { suffix, infix, .. } => {","+            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())","         }","         IgnorePattern::Glob(glob) => {","             let mut cur = path;"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"86ffbd85-11c2-4636-a778-7310145d86f9"}
{"parentUuid":"5041f287-eb01-4c93-8293-dc7e6c46e783","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01AL6j2nTeBCSAbfkwkoeZZY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SUzHedXgjw6ouUVu2MRJhk","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];","new_string":"        let patterns = vec![IgnorePattern::any_segment(\"target\")];"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":275,"cache_read_input_tokens":127714,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":275},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkQEKVq7rjvcC9BXF7A","type":"assistant","uuid":"fb62d638-2960-4a96-aaf2-0297d7ef30e5","timestamp":"2026-02-22T07:55:52.058Z"}
{"parentUuid":"fb62d638-2960-4a96-aaf2-0297d7ef30e5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01SUzHedXgjw6ouUVu2MRJhk","toolUseID":"toolu_01SUzHedXgjw6ouUVu2MRJhk","timestamp":"2026-02-22T07:55:52.067Z","uuid":"712d10b8-b5d5-4719-8b39-847a58201ddc"}
{"parentUuid":"fb62d638-2960-4a96-aaf2-0297d7ef30e5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SUzHedXgjw6ouUVu2MRJhk","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"a46e6711-bdb8-4798-b265-471d42b4b34f","timestamp":"2026-02-22T07:55:52.066Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];","newString":"        let patterns = vec![IgnorePattern::any_segment(\"target\")];","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":5437,"oldLines":7,"newStart":5437,"newLines":7,"lines":[" ","     #[test]","     fn should_skip_path_for_glob_any_segment_target() {","-        let patterns = vec![IgnorePattern::AnySegment(\"target\".to_string())];","+        let patterns = vec![IgnorePattern::any_segment(\"target\")];"," ","         assert!(should_skip_path(","             Path::new(\"/Users/al02402336/work/rust/target\"),"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"fb62d638-2960-4a96-aaf2-0297d7ef30e5"}
{"parentUuid":"a46e6711-bdb8-4798-b265-471d42b4b34f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01R8rwceUyR8imV2VHxPszMG","type":"message","role":"assistant","content":[{"type":"text","text":"Now check if there are more AnySegment usages:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":205,"cache_read_input_tokens":127989,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":205},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkQUiRnGWAjH14tVr9c","type":"assistant","uuid":"70993e0c-0498-4cfd-97f6-b85cf9644967","timestamp":"2026-02-22T07:55:53.910Z"}
{"parentUuid":"70993e0c-0498-4cfd-97f6-b85cf9644967","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01R8rwceUyR8imV2VHxPszMG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016zVodCG23W49iSb66HCFaj","name":"Grep","input":{"pattern":"AnySegment","path":"/Users/al02402336/everything/src-tauri/src/main.rs","output_mode":"content","context":2},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":205,"cache_read_input_tokens":127989,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":205},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkQUiRnGWAjH14tVr9c","type":"assistant","uuid":"b6bf20b6-79a0-440b-84c3-cd17accec3d4","timestamp":"2026-02-22T07:55:54.989Z"}
{"parentUuid":"b6bf20b6-79a0-440b-84c3-cd17accec3d4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_016zVodCG23W49iSb66HCFaj","toolUseID":"toolu_016zVodCG23W49iSb66HCFaj","timestamp":"2026-02-22T07:55:55.642Z","uuid":"2ba7c305-0c9d-4c9d-8a06-34811c5f47fc"}
{"parentUuid":"b6bf20b6-79a0-440b-84c3-cd17accec3d4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016zVodCG23W49iSb66HCFaj","type":"tool_result","content":"303-    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n304-    /// per-call format! allocations in the hot path.\n305:    AnySegment {\n306-        segment: String,\n307-        suffix: String,\n--\n313-impl IgnorePattern {\n314-    pub(crate) fn any_segment(segment: &str) -> Self {\n315:        IgnorePattern::AnySegment {\n316-            suffix: format!(\"/{segment}\"),\n317-            infix: format!(\"/{segment}/\"),\n--\n838-fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n839-    match pattern {\n840:        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n841-        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n842-    }\n--\n1244-pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1245-    match pattern {\n1246:        IgnorePattern::AnySegment { suffix, infix, .. } => {\n1247-            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n1248-        }"}]},"uuid":"d01b7ec8-3be6-4671-a3dc-d07a4ad8726c","timestamp":"2026-02-22T07:55:55.640Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"303-    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n304-    /// per-call format! allocations in the hot path.\n305:    AnySegment {\n306-        segment: String,\n307-        suffix: String,\n--\n313-impl IgnorePattern {\n314-    pub(crate) fn any_segment(segment: &str) -> Self {\n315:        IgnorePattern::AnySegment {\n316-            suffix: format!(\"/{segment}\"),\n317-            infix: format!(\"/{segment}/\"),\n--\n838-fn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n839-    match pattern {\n840:        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n841-        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n842-    }\n--\n1244-pub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n1245-    match pattern {\n1246:        IgnorePattern::AnySegment { suffix, infix, .. } => {\n1247-            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n1248-        }","numLines":23},"sourceToolAssistantUUID":"b6bf20b6-79a0-440b-84c3-cd17accec3d4"}
{"parentUuid":"d01b7ec8-3be6-4671-a3dc-d07a4ad8726c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01CHHH4AnB5GEFvFMuQSkXRk","type":"message","role":"assistant","content":[{"type":"text","text":"Good. Now check other files that use `IgnorePattern::AnySegment`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":487,"cache_read_input_tokens":128194,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":487},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkQjujUmMcvgcpv8fBU","type":"assistant","uuid":"0c4b2f63-3243-4c6c-b3f4-0b0155a044ff","timestamp":"2026-02-22T07:55:57.735Z"}
{"parentUuid":"0c4b2f63-3243-4c6c-b3f4-0b0155a044ff","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01CHHH4AnB5GEFvFMuQSkXRk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Rj2zMVPY4UH5QhgHtoFaik","name":"Grep","input":{"pattern":"AnySegment","path":"/Users/al02402336/everything/src-tauri/src","output_mode":"files_with_matches"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":487,"cache_read_input_tokens":128194,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":487},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkQjujUmMcvgcpv8fBU","type":"assistant","uuid":"1ab10aa1-db93-445b-9fa9-a9324e5374ad","timestamp":"2026-02-22T07:55:58.651Z"}
{"parentUuid":"1ab10aa1-db93-445b-9fa9-a9324e5374ad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01Rj2zMVPY4UH5QhgHtoFaik","toolUseID":"toolu_01Rj2zMVPY4UH5QhgHtoFaik","timestamp":"2026-02-22T07:55:59.283Z","uuid":"e465ff06-043a-4b7e-a81d-87345857aba2"}
{"parentUuid":"1ab10aa1-db93-445b-9fa9-a9324e5374ad","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Rj2zMVPY4UH5QhgHtoFaik","type":"tool_result","content":"Found 2 files\nsrc-tauri/src/main.rs\nsrc-tauri/src/win/mft_indexer.rs"}]},"uuid":"aad7b292-79a4-42ff-8dc3-1f235d7a6fb6","timestamp":"2026-02-22T07:55:59.281Z","toolUseResult":{"mode":"files_with_matches","filenames":["src-tauri/src/main.rs","src-tauri/src/win/mft_indexer.rs"],"numFiles":2},"sourceToolAssistantUUID":"1ab10aa1-db93-445b-9fa9-a9324e5374ad"}
{"parentUuid":"aad7b292-79a4-42ff-8dc3-1f235d7a6fb6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01EGZ5qYKgrPBviMFQXAYshE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Gc1xXqPDhrc1zDVM45XEvn","name":"Grep","input":{"pattern":"AnySegment","path":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs","output_mode":"content","context":3},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":175,"cache_read_input_tokens":128681,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":175},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkR1PQLWqv6Q4FAULig","type":"assistant","uuid":"61e45636-752f-4e8f-a504-58045edc447c","timestamp":"2026-02-22T07:56:01.941Z"}
{"parentUuid":"61e45636-752f-4e8f-a504-58045edc447c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01Gc1xXqPDhrc1zDVM45XEvn","toolUseID":"toolu_01Gc1xXqPDhrc1zDVM45XEvn","timestamp":"2026-02-22T07:56:02.600Z","uuid":"91e2433c-30fa-4e9e-9970-55ffa0aa0d8a"}
{"parentUuid":"61e45636-752f-4e8f-a504-58045edc447c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Gc1xXqPDhrc1zDVM45XEvn","type":"tool_result","content":"142-    let _ = gi_thread.join();\n143-    let gi_filter = state.gitignore.get();\n144-\n145:    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\n146-    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\n147:        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }\n148-    }).collect();\n149-    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n150-    for name in &extra_segment_names {\n--\n698-\n699-/// Lightweight skip check for directories already in the pruned subtree.\n700-/// Subtree pruning already handles BUILTIN_SKIP_NAMES, ignored_roots, and\n701:/// AnySegment patterns. This only checks BUILTIN_SKIP_PATHS (multi-segment),\n702-/// BUILTIN_SKIP_SUFFIXES, gitignore, and Glob patterns — with zero heap allocations.\n703-fn should_skip_dir_in_pruned_subtree(\n704-    full_path: &str,\n--\n747-\n748-/// Lightweight skip check for files whose parent directory is already in the\n749-/// pruned subtree. Since subtree pruning already eliminates BUILTIN_SKIP_NAMES,\n750:/// BUILTIN_SKIP_PATHS, ignored_roots, and AnySegment patterns, this only needs\n751-/// to check gitignore rules and Glob patterns.\n752-fn should_skip_file_in_pruned_subtree(\n753-    parent_path: &str,\n--\n772-            return true;\n773-        }\n774-\n775:        // Check Glob patterns only (AnySegment handled by subtree pruning)\n776-        if !glob_patterns.is_empty() {\n777-            / SAFETY: replacing ASCII '\\' (0x5C) with '/' (0x2F) preserves UTF-8 validity.\n778-            unsafe { buf.as_bytes_mut().iter_mut().for_each(|b| if *b == b'\\\\' { *b = b'/'; }); }"}]},"uuid":"e677ab7a-5adc-49b2-97ed-c60604e10ead","timestamp":"2026-02-22T07:56:02.596Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"142-    let _ = gi_thread.join();\n143-    let gi_filter = state.gitignore.get();\n144-\n145:    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\n146-    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\n147:        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }\n148-    }).collect();\n149-    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n150-    for name in &extra_segment_names {\n--\n698-\n699-/// Lightweight skip check for directories already in the pruned subtree.\n700-/// Subtree pruning already handles BUILTIN_SKIP_NAMES, ignored_roots, and\n701:/// AnySegment patterns. This only checks BUILTIN_SKIP_PATHS (multi-segment),\n702-/// BUILTIN_SKIP_SUFFIXES, gitignore, and Glob patterns — with zero heap allocations.\n703-fn should_skip_dir_in_pruned_subtree(\n704-    full_path: &str,\n--\n747-\n748-/// Lightweight skip check for files whose parent directory is already in the\n749-/// pruned subtree. Since subtree pruning already eliminates BUILTIN_SKIP_NAMES,\n750:/// BUILTIN_SKIP_PATHS, ignored_roots, and AnySegment patterns, this only needs\n751-/// to check gitignore rules and Glob patterns.\n752-fn should_skip_file_in_pruned_subtree(\n753-    parent_path: &str,\n--\n772-            return true;\n773-        }\n774-\n775:        // Check Glob patterns only (AnySegment handled by subtree pruning)\n776-        if !glob_patterns.is_empty() {\n777-            / SAFETY: replacing ASCII '\\' (0x5C) with '/' (0x2F) preserves UTF-8 validity.\n778-            unsafe { buf.as_bytes_mut().iter_mut().for_each(|b| if *b == b'\\\\' { *b = b'/'; }); }","numLines":33},"sourceToolAssistantUUID":"61e45636-752f-4e8f-a504-58045edc447c"}
{"parentUuid":"e677ab7a-5adc-49b2-97ed-c60604e10ead","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Qffm3ZEmgdizVtpRzSRUhf","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VLsKiPsotHcz5QX3yyiHXG","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs","old_string":"        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }","new_string":"        if let IgnorePattern::AnySegment { segment, .. } = p { Some(segment.clone()) } else { None }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":709,"cache_read_input_tokens":128856,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":709},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkRFh8QpjioqC9ZiBvR","type":"assistant","uuid":"bc8a4fd6-e447-4de6-a8d0-566468e89232","timestamp":"2026-02-22T07:56:06.089Z"}
{"parentUuid":"bc8a4fd6-e447-4de6-a8d0-566468e89232","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>File has not been read yet. Read it first before writing to it.</tool_use_error>","is_error":true,"tool_use_id":"toolu_01VLsKiPsotHcz5QX3yyiHXG"}]},"uuid":"9230fb60-cc84-45a8-ba00-5970144e1b8e","timestamp":"2026-02-22T07:56:06.090Z","toolUseResult":"Error: File has not been read yet. Read it first before writing to it.","sourceToolAssistantUUID":"bc8a4fd6-e447-4de6-a8d0-566468e89232"}
{"parentUuid":"9230fb60-cc84-45a8-ba00-5970144e1b8e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_019BX7beJHxgtfuz6JEco2Ka","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VPSTqpC3CCzSQAgJkkMfNf","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs","offset":143,"limit":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":239,"cache_read_input_tokens":129565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":239},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkRWcozHJj94xCZUmte","type":"assistant","uuid":"603e634e-5a75-4c08-9859-873bbda4654a","timestamp":"2026-02-22T07:56:08.181Z"}
{"parentUuid":"603e634e-5a75-4c08-9859-873bbda4654a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01VPSTqpC3CCzSQAgJkkMfNf","toolUseID":"toolu_01VPSTqpC3CCzSQAgJkkMfNf","timestamp":"2026-02-22T07:56:08.207Z","uuid":"751dc258-4ac8-4566-af06-1dc9fd4450ba"}
{"parentUuid":"603e634e-5a75-4c08-9859-873bbda4654a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VPSTqpC3CCzSQAgJkkMfNf","type":"tool_result","content":"   143→    let gi_filter = state.gitignore.get();\n   144→\n   145→    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\n   146→    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\n   147→        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }\n   148→    }).collect();\n   149→    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n   150→    for name in &extra_segment_names {\n   151→        all_skip_names.push(name.as_str());\n   152→    }\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e903deea-a58d-428f-8757-8fe5d4b76af2","timestamp":"2026-02-22T07:56:08.206Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs","content":"    let gi_filter = state.gitignore.get();\n\n    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\n    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\n        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }\n    }).collect();\n    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n    for name in &extra_segment_names {\n        all_skip_names.push(name.as_str());\n    }","numLines":10,"startLine":143,"totalLines":908}},"sourceToolAssistantUUID":"603e634e-5a75-4c08-9859-873bbda4654a"}
{"type":"file-history-snapshot","messageId":"72a35504-91b0-46de-98e7-cfa44ffbdd87","snapshot":{"messageId":"192713d9-061f-43d9-b09d-c33b1dc64725","trackedFileBackups":{"src-tauri/src/main.rs":{"backupFileName":"d5d8131157dfe6bc@v1","version":1,"backupTime":"2026-02-22T07:55:14.790Z"},"src-tauri/src/win/mft_indexer.rs":{"backupFileName":"edf2453270568dde@v1","version":1,"backupTime":"2026-02-22T07:56:10.858Z"}},"timestamp":"2026-02-22T07:39:06.444Z"},"isSnapshotUpdate":true}
{"parentUuid":"e903deea-a58d-428f-8757-8fe5d4b76af2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01WQ6k9QmfXBrHXu61d5yoAg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JWvZfZvqnN6Jc1SvFzT4JL","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs","old_string":"        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }","new_string":"        if let IgnorePattern::AnySegment { segment, .. } = p { Some(segment.clone()) } else { None }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":508,"cache_read_input_tokens":129804,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":508},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkRfcJCY7JKY4LDddwp","type":"assistant","uuid":"72a35504-91b0-46de-98e7-cfa44ffbdd87","timestamp":"2026-02-22T07:56:10.853Z"}
{"parentUuid":"72a35504-91b0-46de-98e7-cfa44ffbdd87","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01JWvZfZvqnN6Jc1SvFzT4JL","toolUseID":"toolu_01JWvZfZvqnN6Jc1SvFzT4JL","timestamp":"2026-02-22T07:56:10.862Z","uuid":"9d0c4559-7ef8-431f-a5d5-ae413fe7706f"}
{"parentUuid":"72a35504-91b0-46de-98e7-cfa44ffbdd87","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JWvZfZvqnN6Jc1SvFzT4JL","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs has been updated successfully."}]},"uuid":"a90d7602-f0f5-4732-95ef-61eafc953a6c","timestamp":"2026-02-22T07:56:10.861Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs","oldString":"        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }","newString":"        if let IgnorePattern::AnySegment { segment, .. } = p { Some(segment.clone()) } else { None }","originalFile":"use std::cell::RefCell;\nuse std::collections::{HashMap, HashSet};\nuse std::mem;\nuse std::path::Path;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\n\nuse rayon::prelude::*;\n\nuse rusqlite::params;\nuse tauri::AppHandle;\n\nuse super::path_resolver::PathResolver;\nuse super::volume;\nuse crate::{\n    cached_effective_ignore_rules,\n    db_connection, emit_index_progress, emit_index_state, emit_index_updated,\n    get_meta, gitignore_filter, invalidate_search_caches, matches_ignore_pattern, now_epoch,\n    mem_search::CompactEntry,\n    refresh_and_emit_status_counts,\n    restore_normal_pragmas, set_indexing_pragmas, set_meta, set_progress,\n    update_status_counts, upsert_rows,\n    AppState, IgnorePattern, IndexRow, IndexState, BUILTIN_SKIP_NAMES,\n};\n\nuse windows::Win32::Foundation::HANDLE;\nuse windows::Win32::System::IO::DeviceIoControl;\nuse windows::Win32::System::Ioctl::FSCTL_ENUM_USN_DATA;\n\nconst MFT_BATCH_SIZE: usize = 50_000;\nconst EMIT_INTERVAL: Duration = Duration::from_millis(200);\nconst FILE_ATTRIBUTE_DIRECTORY: u32 = 0x10;\n\npub struct MftScanResult {\n    pub scanned: u64,\n    pub indexed: u64,\n    pub permission_errors: u64,\n}\n\n#[repr(C)]\nstruct MftEnumDataV0 {\n    start_file_reference_number: u64,\n    low_usn: i64,\n    high_usn: i64,\n}\n\nstruct MftRecord {\n    frn: u64,\n    parent_frn: u64,\n    name: String,\n    attributes: u32,\n    timestamp: Option<i64>,\n}\n\n/// Lightweight file entry — directories go into PathResolver instead.\nstruct MftFileEntry {\n    parent_frn: u64,\n    name: String,\n    timestamp: Option<i64>,\n}\n\npub fn scan_mft(state: &AppState, app: &AppHandle) -> Result<MftScanResult, String> {\n    use std::sync::atomic::Ordering as AtomicOrdering;\n\n    let started = Instant::now();\n    let ts = || format!(\"{:.1}s\", started.elapsed().as_secs_f32());\n    eprintln!(\"[win/mft +{}] starting MFT scan\", ts());\n\n    // Open volume FIRST — requires admin privileges.\n    // Do NOT modify state/DB before this succeeds, so a failed open_volume\n    // leaves index_complete and status untouched.\n    let vol = volume::open_volume('C')?;\n    eprintln!(\"[win/mft +{}] volume opened\", ts());\n\n    state\n        .indexing_active\n        .store(true, AtomicOrdering::Release);\n\n    // Mark index as incomplete — cleared when background DB finalize succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Indexing;\n        status.message = None;\n        status.scanned = 0;\n        status.indexed = 0;\n        status.current_path.clear();\n    }\n    emit_index_state(app, \"Indexing\", None);\n\n    // Pre-trigger gitignore filter build in background (overlaps with MFT enum)\n    let gi_arc = Arc::clone(&state.gitignore);\n    let gi_thread = std::thread::spawn(move || { gi_arc.get(); });\n\n    // ── Pass 1: Enumerate MFT — dirs into resolver, files into Vec ──\n    let pass1_started = Instant::now();\n    let mut resolver = PathResolver::with_capacity(\"C:\", 300_000);\n    let mut total_records: u64 = 0;\n    let mut total_dirs: u64 = 0;\n    let mut dir_entries: Vec<(u64, Option<i64>)> = Vec::with_capacity(300_000);\n    let mut file_entries: Vec<MftFileEntry> = Vec::with_capacity(2_500_000);\n    let mut pass1_last_emit = Instant::now();\n\n    enumerate_mft(vol.raw(), |record| {\n        total_records += 1;\n        let is_dir = (record.attributes & FILE_ATTRIBUTE_DIRECTORY) != 0;\n\n        if is_dir {\n            total_dirs += 1;\n            dir_entries.push((record.frn, record.timestamp));\n            resolver.add_record(record.frn, record.parent_frn, record.name);\n        } else {\n            file_entries.push(MftFileEntry {\n                parent_frn: record.parent_frn,\n                name: record.name,\n                timestamp: record.timestamp,\n            });\n        }\n\n        if pass1_last_emit.elapsed() >= EMIT_INTERVAL {\n            let msg = format!(\"Reading MFT... ({total_records} records)\");\n            set_progress(state, 0, 0, &msg);\n            emit_index_progress(app, 0, 0, msg);\n            pass1_last_emit = Instant::now();\n        }\n    })?;\n\n    eprintln!(\n        \"[win/mft +{}] pass1 done: {} records ({} dirs + {} files) in {}ms\",\n        ts(), total_records, total_dirs, file_entries.len(),\n        pass1_started.elapsed().as_millis()\n    );\n\n    // ── Pass 1.5: Compute effective ignore rules + collect home subtree dirs ──\n    let subtree_started = Instant::now();\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n\n    // Wait for gitignore filter (built in parallel with pass1, should already be done)\n    let _ = gi_thread.join();\n    let gi_filter = state.gitignore.get();\n\n    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\n    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\n        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }\n    }).collect();\n    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n    for name in &extra_segment_names {\n        all_skip_names.push(name.as_str());\n    }\n\n    // Find FRNs for pathignore root directories to prune entire subtrees\n    let mut skip_frns: HashSet<u64> = HashSet::new();\n    for root in &ignored_roots {\n        let root_win = root.to_string_lossy().replace('/', \"\\\\\");\n        if let Some(frn) = resolver.find_frn_by_path(&root_win) {\n            skip_frns.insert(frn);\n        }\n    }\n\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let scan_path_win = scan_str.replace('/', \"\\\\\");\n\n    let scan_frn = resolver.find_frn_by_path(&scan_path_win);\n    let dir_subtree = match scan_frn {\n        Some(frn) => {\n            let subtree = resolver.collect_subtree_pruned(frn, &all_skip_names, &skip_frns);\n            eprintln!(\n                \"[win/mft +{}] pass1.5: scan_root FRN={} dir_subtree={} dirs \\\n                 (pruned from {} total dirs) skip_names={} skip_frns={} in {}ms\",\n                ts(), frn, subtree.len(), total_dirs,\n                all_skip_names.len(), skip_frns.len(),\n                subtree_started.elapsed().as_millis()\n            );\n            subtree\n        }\n        None => {\n            eprintln!(\n                \"[win/mft +{}] pass1.5: scan_root not found in MFT ({}), using all dirs\",\n                ts(), scan_path_win\n            );\n            dir_entries.iter().map(|(frn, _)| *frn).collect()\n        }\n    };\n\n    resolver.drop_children_map();\n\n    // Pre-resolve all directory paths in subtree (so file lookups are cache hits)\n    let preresolve_started = Instant::now();\n    for &dir_frn in &dir_subtree {\n        let _ = resolver.resolve(dir_frn);\n    }\n    eprintln!(\n        \"[win/mft +{}] pre-resolved {} dir paths in {}ms\",\n        ts(), dir_subtree.len(), preresolve_started.elapsed().as_millis()\n    );\n\n    // All subtree dirs are now in path_cache — frn_map no longer needed\n    resolver.drop_frn_map();\n\n    // ── Pass 2: Resolve paths, filter, stat → collect into memory ──\n    let pass2_started = Instant::now();\n\n    // Get path_cache early — all subtree dirs pre-resolved in pass 1.5\n    let path_cache = resolver.path_cache();\n\n    // Pre-compute which dirs are under any gitignore root scope.\n    // Dirs/files outside all gitignore roots skip is_ignored() entirely.\n    let gi_roots: Vec<String> = gi_filter.root_paths().iter()\n        .map(|p| p.to_string_lossy().replace('/', \"\\\\\"))\n        .collect();\n    let dirs_under_gi: HashSet<u64> = if gi_roots.is_empty() {\n        HashSet::new()\n    } else {\n        path_cache.iter()\n            .filter(|(_, dir_path)| {\n                gi_roots.iter().any(|root| dir_path.starts_with(root.as_str()))\n            })\n            .map(|(&frn, _)| frn)\n            .collect()\n    };\n    eprintln!(\n        \"[win/mft +{}] gitignore scope: {} roots, {}/{} dirs under gitignore\",\n        ts(), gi_roots.len(), dirs_under_gi.len(), path_cache.len()\n    );\n\n    // Pre-extract Glob patterns for pruned-subtree skip checks\n    let glob_patterns: Vec<&IgnorePattern> = ignored_patterns\n        .iter()\n        .filter(|p| matches!(p, IgnorePattern::Glob(_)))\n        .collect();\n\n    // Pre-compute backslash versions of BUILTIN_SKIP_PATHS for Windows path matching\n    let skip_path_infixes: Vec<String> = crate::BUILTIN_SKIP_PATHS.iter()\n        .map(|p| format!(\"\\\\{}\\\\\", p.replace('/', \"\\\\\")))\n        .collect();\n    let skip_path_suffixes: Vec<String> = crate::BUILTIN_SKIP_PATHS.iter()\n        .map(|p| format!(\"\\\\{}\", p.replace('/', \"\\\\\")))\n        .collect();\n\n    // --- Process directories (parallel, mtime from USN timestamp) ---\n    let dir_results: Vec<CompactEntry> = dir_entries\n        .par_iter()\n        .filter(|(frn, _)| dir_subtree.contains(frn))\n        .filter_map(|(frn, timestamp)| {\n            let full_path = path_cache.get(frn)?;\n            let in_gi_scope = dirs_under_gi.contains(frn);\n            if should_skip_dir_in_pruned_subtree(\n                full_path, &gi_filter, &glob_patterns,\n                &skip_path_infixes, &skip_path_suffixes,\n                in_gi_scope,\n            ) {\n                return None;\n            }\n            // Extract name/dir from Windows path directly (avoid Path allocations)\n            let (dir, name) = match full_path.rfind('\\\\') {\n                Some(pos) => (&full_path[..pos], &full_path[pos + 1..]),\n                None => (\"\", full_path.as_str()),\n            };\n            if name.is_empty() { return None; }\n            Some(CompactEntry {\n                name: name.to_string(), dir: dir.to_string(),\n                is_dir: true, ext: None, mtime: *timestamp, size: None,\n            })\n        })\n        .collect();\n\n    let dirs_in_subtree = dir_entries.iter().filter(|(frn, _)| dir_subtree.contains(frn)).count() as u64;\n    let dir_indexed = dir_results.len() as u64;\n    let mut scanned: u64 = dirs_in_subtree;\n    let mut indexed: u64 = dir_indexed;\n    let mut filtered_skip: u64 = dirs_in_subtree - dir_indexed;\n\n    eprintln!(\n        \"[win/mft +{}] dirs done: scanned={scanned} indexed={indexed} \\\n         skip={filtered_skip} resolve_fail=0 in {}ms\",\n        ts(), pass2_started.elapsed().as_millis()\n    );\n\n    // ── Progressive Ready: build partial MemIndex from dirs only ──\n    let early_cap = super::EARLY_MEM_INDEX_LIMIT.min(dir_results.len());\n    eprintln!(\n        \"[win/mft +{}] building partial MemIndex ({} of {} dirs)...\",\n        ts(),\n        early_cap,\n        dir_results.len()\n    );\n    let early_entries: Vec<CompactEntry> = dir_results.iter().take(early_cap).cloned().collect();\n    let early_idx = Arc::new(crate::mem_search::MemIndex::build(early_entries));\n    eprintln!(\"[win/mft +{}] partial MemIndex built\", ts());\n    *state.mem_index.write() = Some(Arc::clone(&early_idx));\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = 0;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.message = None;\n        status.entries_count = indexed;\n        status.last_updated = Some(now_epoch());\n    }\n    emit_index_progress(app, scanned, indexed, String::new());\n    emit_index_updated(app, indexed, now_epoch(), 0);\n    emit_index_state(app, \"Ready\", None);\n    eprintln!(\n        \"[win/mft +{}] progressive Ready emitted ({indexed} dirs)\",\n        ts()\n    );\n\n    let mut mem_entries: Vec<CompactEntry> = Vec::with_capacity(dir_subtree.len() + file_entries.len());\n    mem_entries.extend(dir_results);\n\n    // --- Process files (parallel + stat) ---\n    let pass2_files_started = Instant::now();\n\n    let file_results: Vec<CompactEntry> = file_entries\n        .par_iter()\n        .filter(|entry| dir_subtree.contains(&entry.parent_frn))\n        .filter_map(|entry| {\n            let parent_path = path_cache.get(&entry.parent_frn)?;\n            let in_gi_scope = dirs_under_gi.contains(&entry.parent_frn);\n\n            if should_skip_file_in_pruned_subtree(\n                parent_path, &entry.name, &gi_filter, &glob_patterns,\n                in_gi_scope,\n            ) {\n                return None;\n            }\n\n            let ext = entry.name.rfind('.').and_then(|pos| {\n                if pos > 0 && pos < entry.name.len() - 1 {\n                    Some(entry.name[pos + 1..].to_lowercase())\n                } else {\n                    None\n                }\n            });\n\n            Some(CompactEntry {\n                name: entry.name.clone(),\n                dir: parent_path.clone(),\n                is_dir: false,\n                ext,\n                mtime: entry.timestamp,\n                size: None,\n            })\n        })\n        .collect();\n\n    let files_in_subtree = file_entries\n        .iter()\n        .filter(|e| dir_subtree.contains(&e.parent_frn))\n        .count() as u64;\n    let file_indexed = file_results.len() as u64;\n    scanned += files_in_subtree;\n    indexed += file_indexed;\n    filtered_skip += files_in_subtree - file_indexed;\n    mem_entries.extend(file_results);\n\n    eprintln!(\n        \"[win/mft +{}] files done: {} files in subtree, indexed={file_indexed} skip={} in {}ms\",\n        ts(), files_in_subtree,\n        files_in_subtree - file_indexed,\n        pass2_files_started.elapsed().as_millis()\n    );\n\n    // Collect FRNs of directories known to be outside scan_root.\n    // These pre-populate USN watcher's skip set to avoid syscalls.\n    let outside_scan_frns: HashSet<u64> = dir_entries\n        .iter()\n        .filter(|(frn, _)| !dir_subtree.contains(frn))\n        .map(|(frn, _)| *frn)\n        .collect();\n\n    // Free large temporaries before building MemIndex\n    drop(file_entries);   // ~100MB+\n    drop(dir_entries);    // ~2MB\n    drop(dir_subtree);    // ~2MB\n\n    let frn_cache = resolver.into_path_cache(); // also drops resolver.frn_map\n\n    let entry_count = mem_entries.len();\n    eprintln!(\n        \"[win/mft +{}] full index ready: indexed={indexed} skip={filtered_skip} \\\n         entries={entry_count}\",\n        ts(),\n    );\n\n    // Update status counts immediately (files done)\n    {\n        let mut status = state.status.lock();\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.entries_count = indexed;\n        status.last_updated = Some(now_epoch());\n    }\n    emit_index_progress(app, scanned, indexed, String::new());\n    emit_index_updated(app, indexed, now_epoch(), 0);\n\n    // ── Background: MemIndex build + DB upsert + USN watcher start ──\n    let bg_state = state.clone();\n    let bg_app = app.clone();\n    let bg_vol = vol;\n\n    eprintln!(\n        \"[win/mft +{}] passing {} FRN path entries + {} outside-scan FRNs to USN watcher\",\n        ts(), frn_cache.len(), outside_scan_frns.len()\n    );\n\n    let bg_started = started;\n    std::thread::spawn(move || {\n        let ts = || format!(\"{:.1}s\", bg_started.elapsed().as_secs_f32());\n\n        // Build full MemIndex (rayon-parallelized) in background\n        drop(early_idx);\n        eprintln!(\"[win/mft/bg +{}] building full MemIndex ({entry_count} entries)...\", ts());\n        let mem_idx = Arc::new(crate::mem_search::MemIndex::build(mem_entries));\n        eprintln!(\"[win/mft/bg +{}] full MemIndex built\", ts());\n        *bg_state.mem_index.write() = Some(Arc::clone(&mem_idx));\n\n        // DB upsert\n        eprintln!(\"[win/mft/bg +{}] starting DB upsert ({entry_count} entries)\", ts());\n        let bulk_result = background_db_bulk_insert(&bg_state, mem_idx.entries(), bg_started);\n\n        match bulk_result {\n            Ok((conn, current_run_id)) => {\n                if let Err(e) = background_db_finalize(\n                    conn, &bg_state, &bg_app, &bg_vol, current_run_id, entry_count > 0, bg_started,\n                    || {\n                        drop(mem_idx);\n                        *bg_state.mem_index.write() = None;\n                        eprintln!(\"[win/mft/bg +{}] MemIndex freed (name index ready, building remaining)\", format!(\"{:.1}s\", bg_started.elapsed().as_secs_f32()));\n                    },\n                ) {\n                    eprintln!(\"[win/mft/bg +{}] DB finalize FAILED: {e}\", ts());\n                }\n            }\n            Err(e) => {\n                eprintln!(\"[win/mft/bg +{}] DB bulk insert FAILED: {e}\", ts());\n                drop(mem_idx);\n                *bg_state.mem_index.write() = None;\n            }\n        }\n\n        bg_state\n            .indexing_active\n            .store(false, AtomicOrdering::Release);\n\n        eprintln!(\"[win/mft/bg +{}] background work done\", ts());\n\n        if let Err(e) = super::usn_watcher::start(bg_app.clone(), bg_state.clone(), frn_cache, outside_scan_frns) {\n            eprintln!(\"[win/mft/bg +{}] USN watcher failed ({e}), trying RDCW fallback\", format!(\"{:.1}s\", bg_started.elapsed().as_secs_f32()));\n            if let Err(e2) = super::rdcw_watcher::start(bg_app, bg_state) {\n                eprintln!(\"[win/mft/bg] RDCW watcher also failed ({e2}), no live updates\");\n            }\n        }\n    });\n\n    Ok(MftScanResult {\n        scanned,\n        indexed,\n        permission_errors: 0,\n    })\n}\n\n/// Batch-retrieve file size and mtime per directory using FindFirstFileW/FindNextFileW.\n/// Returns dir_path → (name_lowercase → (size, mtime)).\n/// Much faster than per-file fs::metadata() because it reads one directory listing at a time.\nfn build_dir_stat_cache(\n    entries: &[CompactEntry],\n) -> HashMap<String, HashMap<String, (i64, i64)>> {\n    use windows::Win32::Storage::FileSystem::{\n        FindClose, FindFirstFileW, FindNextFileW, WIN32_FIND_DATAW,\n    };\n    use windows::core::PCWSTR;\n\n    // Collect unique parent dirs from file entries\n    let unique_dirs: HashSet<&str> = entries\n        .iter()\n        .filter(|e| !e.is_dir)\n        .map(|e| e.dir.as_str())\n        .collect();\n\n    let dir_list: Vec<&str> = unique_dirs.into_iter().collect();\n\n    // Parallel enumeration via rayon\n    let results: Vec<(String, HashMap<String, (i64, i64)>)> = dir_list\n        .par_iter()\n        .filter_map(|&dir_path| {\n            let pattern = format!(\"{}\\\\*\", dir_path);\n            let wide: Vec<u16> = pattern.encode_utf16().chain(std::iter::once(0)).collect();\n\n            let mut find_data = WIN32_FIND_DATAW::default();\n            let handle = unsafe { FindFirstFileW(PCWSTR(wide.as_ptr()), &mut find_data) };\n\n            let handle = match handle {\n                Ok(h) => h,\n                Err(_) => return None,\n            };\n\n            let mut dir_map: HashMap<String, (i64, i64)> = HashMap::new();\n\n            loop {\n                let name = wide_name_to_string(&find_data.cFileName);\n                if name != \".\" && name != \"..\" {\n                    let is_dir = (find_data.dwFileAttributes & FILE_ATTRIBUTE_DIRECTORY) != 0;\n                    if !is_dir {\n                        let size = ((find_data.nFileSizeHigh as i64) << 32)\n                            | (find_data.nFileSizeLow as i64);\n                        let ft = ((find_data.ftLastWriteTime.dwHighDateTime as i64) << 32)\n                            | (find_data.ftLastWriteTime.dwLowDateTime as i64);\n                        let mtime = filetime_to_unix(ft);\n                        dir_map.insert(name.to_lowercase(), (size, mtime));\n                    }\n                }\n\n                let ok = unsafe { FindNextFileW(handle, &mut find_data) };\n                if ok.is_err() {\n                    break;\n                }\n            }\n\n            unsafe { let _ = FindClose(handle); }\n            Some((dir_path.to_string(), dir_map))\n        })\n        .collect();\n\n    results.into_iter().collect()\n}\n\n/// Extract a file name from WIN32_FIND_DATAW.cFileName (null-terminated UTF-16).\nfn wide_name_to_string(wide: &[u16]) -> String {\n    let len = wide.iter().position(|&c| c == 0).unwrap_or(wide.len());\n    String::from_utf16_lossy(&wide[..len])\n}\n\n/// Phase 1: Bulk insert entries into DB.\n/// Returns (conn, current_run_id) so the caller can free MemIndex before Phase 2.\nfn background_db_bulk_insert(\n    state: &AppState,\n    entries: &[CompactEntry],\n    scan_started: Instant,\n) -> Result<(rusqlite::Connection, i64), String> {\n    let ts = || format!(\"{:.1}s\", scan_started.elapsed().as_secs_f32());\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    let last_run_id: i64 = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    let indexed_at = now_epoch();\n\n    // Drop indexes for faster bulk insert\n    let _ = conn.execute_batch(\n        r#\"\n        DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n        DROP INDEX IF EXISTS idx_entries_mtime;\n        DROP INDEX IF EXISTS idx_entries_name_nocase;\n        DROP INDEX IF EXISTS idx_entries_ext_name;\n        \"#,\n    );\n    eprintln!(\"[win/mft/bg +{}] indexes dropped\", ts());\n\n    // Build dir stat cache: batch-retrieve file size+mtime via FindFirstFileW per directory\n    let cache_started = Instant::now();\n    let dir_stat_cache = build_dir_stat_cache(entries);\n    eprintln!(\n        \"[win/mft/bg +{}] dir_stat_cache built: {} dirs in {}ms\",\n        ts(), dir_stat_cache.len(), cache_started.elapsed().as_millis()\n    );\n\n    let upsert_started = Instant::now();\n\n    for chunk in entries.chunks(MFT_BATCH_SIZE) {\n        let chunk_rows: Vec<IndexRow> = chunk\n            .par_iter()\n            .map(|entry| {\n                let (size, mtime) = if entry.is_dir {\n                    // Dirs: use USN timestamp (already set in mtime)\n                    (None, entry.mtime)\n                } else if let Some(dir_cache) = dir_stat_cache.get(&entry.dir) {\n                    // Files: lookup from FindFirstFileW cache\n                    if let Some(&(sz, mt)) = dir_cache.get(&entry.name.to_lowercase()) {\n                        (Some(sz), Some(mt))\n                    } else {\n                        // Not found in cache — use USN timestamp, no size\n                        (None, entry.mtime)\n                    }\n                } else {\n                    // Dir enumeration failed — use USN timestamp fallback\n                    (None, entry.mtime)\n                };\n                IndexRow {\n                    path: entry.path(),\n                    name: entry.name.clone(),\n                    dir: entry.dir.clone(),\n                    is_dir: if entry.is_dir { 1 } else { 0 },\n                    ext: entry.ext.clone(),\n                    mtime,\n                    size,\n                    indexed_at,\n                    run_id: current_run_id,\n                }\n            })\n            .collect();\n        upsert_rows(&mut conn, &chunk_rows)?;\n    }\n    eprintln!(\"[win/mft/bg +{}] upsert done: {} entries in {}ms\", ts(), entries.len(), upsert_started.elapsed().as_millis());\n\n    Ok((conn, current_run_id))\n}\n\n/// Phase 2: Cleanup stale rows, recreate indexes, save USN position.\n/// `free_mem_index` is called after the primary name index is built, allowing\n/// MemIndex to be freed while remaining indexes are created (reduces peak memory).\nfn background_db_finalize(\n    conn: rusqlite::Connection,\n    state: &AppState,\n    app: &AppHandle,\n    vol: &volume::VolumeHandle,\n    current_run_id: i64,\n    has_entries: bool,\n    scan_started: Instant,\n    free_mem_index: impl FnOnce(),\n) -> Result<(), String> {\n    let ts = || format!(\"{:.1}s\", scan_started.elapsed().as_secs_f32());\n\n    // Cleanup stale entries\n    let cleanup_started = Instant::now();\n    let deleted_count: i64 = conn\n        .query_row(\n            \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n            |row| row.get(0),\n        )\n        .unwrap_or(0);\n    conn.execute(\n        \"DELETE FROM entries WHERE run_id < ?1\",\n        params![current_run_id],\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[win/mft/bg +{}] cleanup: deleted={deleted_count} in {}ms\", ts(), cleanup_started.elapsed().as_millis());\n\n    set_meta(&conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    // Create the primary name index FIRST — this allows DB search to work\n    let idx_started = Instant::now();\n    conn.execute_batch(\n        \"CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\",\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[win/mft/bg +{}] name index created in {}ms\", ts(), idx_started.elapsed().as_millis());\n\n    // Free MemIndex now — DB search can use the name index\n    free_mem_index();\n\n    // Create remaining indexes (MemIndex freed, lower peak memory)\n    let idx2_started = Instant::now();\n    conn.execute_batch(\n        r#\"\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[win/mft/bg +{}] remaining indexes in {}ms\", ts(), idx2_started.elapsed().as_millis());\n\n    let _ = restore_normal_pragmas(&conn);\n\n    // Save USN journal position for future resume\n    if let Ok(journal) = volume::query_usn_journal(vol) {\n        let _ = set_meta(&conn, \"win_last_usn\", &journal.next_usn.to_string());\n        let _ = set_meta(&conn, \"win_journal_id\", &journal.journal_id.to_string());\n    }\n\n    // Mark index as complete — startup will check this to decide catchup vs re-index\n    let _ = set_meta(&conn, \"index_complete\", \"1\");\n\n    if deleted_count > 0 || has_entries {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n    emit_index_updated(app, entries_count, updated_at, 0);\n    let _ = refresh_and_emit_status_counts(app, state);\n\n    Ok(())\n}\n\n/// Lightweight skip check for directories already in the pruned subtree.\n/// Subtree pruning already handles BUILTIN_SKIP_NAMES, ignored_roots, and\n/// AnySegment patterns. This only checks BUILTIN_SKIP_PATHS (multi-segment),\n/// BUILTIN_SKIP_SUFFIXES, gitignore, and Glob patterns — with zero heap allocations.\nfn should_skip_dir_in_pruned_subtree(\n    full_path: &str,\n    gi_filter: &gitignore_filter::GitignoreFilter,\n    glob_patterns: &[&IgnorePattern],\n    skip_path_infixes: &[String],\n    skip_path_suffixes: &[String],\n    in_gi_scope: bool,\n) -> bool {\n    // BUILTIN_SKIP_PATHS: pre-computed backslash patterns (no allocation)\n    if skip_path_infixes.iter().any(|infix| full_path.contains(infix.as_str()))\n        || skip_path_suffixes.iter().any(|suffix| full_path.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    // BUILTIN_SKIP_SUFFIXES: check last path segment\n    if let Some(last_seg) = full_path.rsplit('\\\\').next() {\n        if crate::BUILTIN_SKIP_SUFFIXES.iter().any(|suf| last_seg.ends_with(suf)) {\n            return true;\n        }\n    }\n\n    // Gitignore check — only if this dir is under a gitignore root\n    if in_gi_scope && gi_filter.is_ignored(Path::new(full_path), true) {\n        return true;\n    }\n\n    // Glob patterns (need forward-slash normalization)\n    if !glob_patterns.is_empty() {\n        thread_local! {\n            static BUF: RefCell<String> = RefCell::new(String::with_capacity(512));\n        }\n        return BUF.with(|buf| {\n            let mut buf = buf.borrow_mut();\n            buf.clear();\n            buf.push_str(full_path);\n            // SAFETY: replacing ASCII '\\' (0x5C) with '/' (0x2F) preserves UTF-8 validity.\n            unsafe { buf.as_bytes_mut().iter_mut().for_each(|b| if *b == b'\\\\' { *b = b'/'; }); }\n            glob_patterns.iter().any(|pat| matches_ignore_pattern(&buf, pat))\n        });\n    }\n\n    false\n}\n\n/// Lightweight skip check for files whose parent directory is already in the\n/// pruned subtree. Since subtree pruning already eliminates BUILTIN_SKIP_NAMES,\n/// BUILTIN_SKIP_PATHS, ignored_roots, and AnySegment patterns, this only needs\n/// to check gitignore rules and Glob patterns.\nfn should_skip_file_in_pruned_subtree(\n    parent_path: &str,\n    file_name: &str,\n    gi_filter: &gitignore_filter::GitignoreFilter,\n    glob_patterns: &[&IgnorePattern],\n    in_gi_scope: bool,\n) -> bool {\n    thread_local! {\n        static BUF: RefCell<String> = RefCell::new(String::with_capacity(512));\n    }\n\n    BUF.with(|buf| {\n        let mut buf = buf.borrow_mut();\n        buf.clear();\n        buf.push_str(parent_path);\n        buf.push('\\\\');\n        buf.push_str(file_name);\n\n        // Check gitignore — only if parent dir is under a gitignore root\n        if in_gi_scope && gi_filter.is_ignored(Path::new(buf.as_str()), false) {\n            return true;\n        }\n\n        // Check Glob patterns only (AnySegment handled by subtree pruning)\n        if !glob_patterns.is_empty() {\n            // SAFETY: replacing ASCII '\\' (0x5C) with '/' (0x2F) preserves UTF-8 validity.\n            unsafe { buf.as_bytes_mut().iter_mut().for_each(|b| if *b == b'\\\\' { *b = b'/'; }); }\n            for pat in glob_patterns {\n                if matches_ignore_pattern(&buf, pat) {\n                    return true;\n                }\n            }\n        }\n\n        false\n    })\n}\n\nfn enumerate_mft(\n    handle: HANDLE,\n    mut callback: impl FnMut(MftRecord),\n) -> Result<(), String> {\n    let mut med = MftEnumDataV0 {\n        start_file_reference_number: 0,\n        low_usn: 0,\n        high_usn: i64::MAX,\n    };\n\n    let mut buffer: Vec<u8> = vec![0u8; 64 * 1024];\n\n    loop {\n        let mut bytes_returned: u32 = 0;\n\n        let result = unsafe {\n            DeviceIoControl(\n                handle,\n                FSCTL_ENUM_USN_DATA,\n                Some(&med as *const _ as *const _),\n                mem::size_of::<MftEnumDataV0>() as u32,\n                Some(buffer.as_mut_ptr() as *mut _),\n                buffer.len() as u32,\n                Some(&mut bytes_returned),\n                None,\n            )\n        };\n\n        if result.is_err() {\n            break;\n        }\n\n        if bytes_returned < 8 {\n            break;\n        }\n\n        let next_frn = u64::from_le_bytes(buffer[0..8].try_into().unwrap());\n\n        let mut offset = 8usize;\n        while offset + 4 <= bytes_returned as usize {\n            let record_len =\n                u32::from_le_bytes(buffer[offset..offset + 4].try_into().unwrap()) as usize;\n\n            if record_len < 64 || offset + record_len > bytes_returned as usize {\n                break;\n            }\n\n            if let Some(record) = parse_usn_record_v2(&buffer[offset..offset + record_len]) {\n                callback(record);\n            }\n\n            offset += record_len;\n        }\n\n        med.start_file_reference_number = next_frn;\n    }\n\n    Ok(())\n}\n\nfn parse_usn_record_v2(data: &[u8]) -> Option<MftRecord> {\n    if data.len() < 64 {\n        return None;\n    }\n\n    let major = u16::from_le_bytes(data[4..6].try_into().ok()?);\n    if major != 2 {\n        return None;\n    }\n\n    let frn = u64::from_le_bytes(data[8..16].try_into().ok()?) & 0x0000_FFFF_FFFF_FFFF;\n    let parent_frn =\n        u64::from_le_bytes(data[16..24].try_into().ok()?) & 0x0000_FFFF_FFFF_FFFF;\n\n    // Bytes 32-40: TimeStamp (FILETIME) — last modification time from USN record\n    let filetime_raw = i64::from_le_bytes(data[32..40].try_into().ok()?);\n    let timestamp = if filetime_raw > 0 {\n        Some(filetime_to_unix(filetime_raw))\n    } else {\n        None\n    };\n\n    let attributes = u32::from_le_bytes(data[52..56].try_into().ok()?);\n\n    let name_len = u16::from_le_bytes(data[56..58].try_into().ok()?) as usize;\n    let name_offset = u16::from_le_bytes(data[58..60].try_into().ok()?) as usize;\n\n    if name_offset + name_len > data.len() || name_len == 0 {\n        return None;\n    }\n\n    let name_bytes = &data[name_offset..name_offset + name_len];\n    let utf16: Vec<u16> = name_bytes\n        .chunks_exact(2)\n        .map(|c| u16::from_le_bytes([c[0], c[1]]))\n        .collect();\n    let name = String::from_utf16_lossy(&utf16);\n\n    if name.starts_with('$') {\n        return None;\n    }\n\n    Some(MftRecord {\n        frn,\n        parent_frn,\n        name,\n        attributes,\n        timestamp,\n    })\n}\n\npub fn filetime_to_unix(filetime: i64) -> i64 {\n    const FILETIME_UNIX_DIFF: i64 = 116_444_736_000_000_000;\n    if filetime <= FILETIME_UNIX_DIFF {\n        return 0;\n    }\n    (filetime - FILETIME_UNIX_DIFF) / 10_000_000\n}\n","structuredPatch":[{"oldStart":144,"oldLines":7,"newStart":144,"newLines":7,"lines":[" ","     // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore","     let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {","-        if let IgnorePattern::AnySegment(name) = p { Some(name.clone()) } else { None }","+        if let IgnorePattern::AnySegment { segment, .. } = p { Some(segment.clone()) } else { None }","     }).collect();","     let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();","     for name in &extra_segment_names {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"72a35504-91b0-46de-98e7-cfa44ffbdd87"}
{"parentUuid":"a90d7602-f0f5-4732-95ef-61eafc953a6c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01ABCrrUroz8F3mUvjyxTL77","type":"message","role":"assistant","content":[{"type":"text","text":"Now check for any other AnySegment usages in the win module:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":237,"cache_read_input_tokens":130312,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":237},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkRruhKKbXzaFoHHUTq","type":"assistant","uuid":"103f7c12-6f69-4c8e-af5f-0b2d9e293e0f","timestamp":"2026-02-22T07:56:12.627Z"}
{"parentUuid":"103f7c12-6f69-4c8e-af5f-0b2d9e293e0f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01ABCrrUroz8F3mUvjyxTL77","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FuMrkZF6eML8MFFxRpVjhy","name":"Grep","input":{"pattern":"AnySegment","path":"/Users/al02402336/everything/src-tauri/src/win","output_mode":"content","context":2},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":237,"cache_read_input_tokens":130312,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":237},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkRruhKKbXzaFoHHUTq","type":"assistant","uuid":"af9043e4-5aa6-43ec-8252-e296e0d89a42","timestamp":"2026-02-22T07:56:13.624Z"}
{"parentUuid":"af9043e4-5aa6-43ec-8252-e296e0d89a42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01FuMrkZF6eML8MFFxRpVjhy","toolUseID":"toolu_01FuMrkZF6eML8MFFxRpVjhy","timestamp":"2026-02-22T07:56:14.339Z","uuid":"6b91f7f8-9a4a-43f7-86ce-c388855c432e"}
{"parentUuid":"af9043e4-5aa6-43ec-8252-e296e0d89a42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FuMrkZF6eML8MFFxRpVjhy","type":"tool_result","content":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-143-    let gi_filter = state.gitignore.get();\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-144-\nsrc-tauri/src/win/mft_indexer.rs:145:    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\nsrc-tauri/src/win/mft_indexer.rs-146-    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\nsrc-tauri/src/win/mft_indexer.rs:147:        if let IgnorePattern::AnySegment { segment, .. } = p { Some(segment.clone()) } else { None }\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-148-    }).collect();\nsrc-tauri/src/win/mft_indexer.rs-149-    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n--\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-699-/// Lightweight skip check for directories already in the pruned subtree.\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-700-/// Subtree pruning already handles BUILTIN_SKIP_NAMES, ignored_roots, and\nsrc-tauri/src/win/mft_indexer.rs:701:/// AnySegment patterns. This only checks BUILTIN_SKIP_PATHS (multi-segment),\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-702-/// BUILTIN_SKIP_SUFFIXES, gitignore, and Glob patterns — with zero heap allocations.\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-703-fn should_skip_dir_in_pruned_subtree(\n--\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-748-/// Lightweight skip check for files whose parent directory is already in the\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-749-/// pruned subtree. Since subtree pruning already eliminates BUILTIN_SKIP_NAMES,\nsrc-tauri/src/win/mft_indexer.rs:750:/// BUILTIN_SKIP_PATHS, ignored_roots, and AnySegment patterns, this only needs\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-751-/// to check gitignore rules and Glob patterns.\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-752-fn should_skip_file_in_pruned_subtree(\n--\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-773-        }\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-774-\nsrc-tauri/src/win/mft_indexer.rs:775:        // Check Glob patterns only (AnySegment handled by subtree pruning)\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-776-        if !glob_patterns.is_empty() {\nsrc-tauri/src/win/mft_indexer.rs-777-            / SAFETY: replacing ASCII '\\' (0x5C) with '/' (0x2F) preserves UTF-8 validity."}]},"uuid":"17cf9f25-1cea-4a54-9ea2-b015b549d53c","timestamp":"2026-02-22T07:56:14.337Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-143-    let gi_filter = state.gitignore.get();\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-144-\nsrc-tauri/src/win/mft_indexer.rs:145:    // Build enhanced skip names: BUILTIN_SKIP_NAMES + AnySegment patterns from pathignore\nsrc-tauri/src/win/mft_indexer.rs-146-    let extra_segment_names: Vec<String> = ignored_patterns.iter().filter_map(|p| {\nsrc-tauri/src/win/mft_indexer.rs:147:        if let IgnorePattern::AnySegment { segment, .. } = p { Some(segment.clone()) } else { None }\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-148-    }).collect();\nsrc-tauri/src/win/mft_indexer.rs-149-    let mut all_skip_names: Vec<&str> = BUILTIN_SKIP_NAMES.to_vec();\n--\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-699-/// Lightweight skip check for directories already in the pruned subtree.\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-700-/// Subtree pruning already handles BUILTIN_SKIP_NAMES, ignored_roots, and\nsrc-tauri/src/win/mft_indexer.rs:701:/// AnySegment patterns. This only checks BUILTIN_SKIP_PATHS (multi-segment),\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-702-/// BUILTIN_SKIP_SUFFIXES, gitignore, and Glob patterns — with zero heap allocations.\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-703-fn should_skip_dir_in_pruned_subtree(\n--\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-748-/// Lightweight skip check for files whose parent directory is already in the\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-749-/// pruned subtree. Since subtree pruning already eliminates BUILTIN_SKIP_NAMES,\nsrc-tauri/src/win/mft_indexer.rs:750:/// BUILTIN_SKIP_PATHS, ignored_roots, and AnySegment patterns, this only needs\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-751-/// to check gitignore rules and Glob patterns.\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-752-fn should_skip_file_in_pruned_subtree(\n--\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-773-        }\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-774-\nsrc-tauri/src/win/mft_indexer.rs:775:        // Check Glob patterns only (AnySegment handled by subtree pruning)\n/Users/al02402336/everything/src-tauri/src/win/mft_indexer.rs-776-        if !glob_patterns.is_empty() {\nsrc-tauri/src/win/mft_indexer.rs-777-            / SAFETY: replacing ASCII '\\' (0x5C) with '/' (0x2F) preserves UTF-8 validity.","numLines":25},"sourceToolAssistantUUID":"af9043e4-5aa6-43ec-8252-e296e0d89a42"}
{"parentUuid":"17cf9f25-1cea-4a54-9ea2-b015b549d53c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_011Bu2D66b4LNsu25R8ZfXEr","type":"message","role":"assistant","content":[{"type":"text","text":"Good. Now let me update `restore_normal_pragmas` to use PASSIVE checkpoint:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1127,"cache_read_input_tokens":130549,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1127},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkS7azaAuSgwjP5iWC2","type":"assistant","uuid":"1afd6bf6-3384-452a-95fa-0cf4d63487c1","timestamp":"2026-02-22T07:56:17.368Z"}
{"parentUuid":"1afd6bf6-3384-452a-95fa-0cf4d63487c1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_011Bu2D66b4LNsu25R8ZfXEr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013ioB3t3NmX6Z5pU7oQuWps","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}","new_string":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1127,"cache_read_input_tokens":130549,"output_tokens":516,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1127,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkS7azaAuSgwjP5iWC2","type":"assistant","uuid":"c2846729-71de-4fdb-aac7-95d98985c071","timestamp":"2026-02-22T07:56:22.528Z"}
{"parentUuid":"c2846729-71de-4fdb-aac7-95d98985c071","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_013ioB3t3NmX6Z5pU7oQuWps","toolUseID":"toolu_013ioB3t3NmX6Z5pU7oQuWps","timestamp":"2026-02-22T07:56:22.538Z","uuid":"211c5943-456f-4811-8386-249f7e13fde8"}
{"parentUuid":"c2846729-71de-4fdb-aac7-95d98985c071","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013ioB3t3NmX6Z5pU7oQuWps","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"7fdb9aa3-6b74-4995-bd36-05ac4683670b","timestamp":"2026-02-22T07:56:22.537Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}","newString":"pub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":465,"oldLines":7,"newStart":465,"newLines":10,"lines":["         \"#,","     )","     .map_err(|e| e.to_string())?;","-    conn.execute_batch(\"PRAGMA wal_checkpoint(TRUNCATE);\")","+    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many","+    // WAL frames as possible without waiting. The WAL will be fully checkpointed","+    // when the next auto-checkpoint threshold is hit.","+    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")","         .map_err(|e| e.to_string())?;","     Ok(())"," }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"c2846729-71de-4fdb-aac7-95d98985c071"}
{"parentUuid":"7fdb9aa3-6b74-4995-bd36-05ac4683670b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01CBJUmrSd1vbCZHyioWBRcc","type":"message","role":"assistant","content":[{"type":"text","text":"Now the main change: update the walker in `run_incremental_index_inner` to use parallel metadata fetching. First let me read the exact section again:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":554,"cache_read_input_tokens":131676,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":554},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkSioK6U43MTbUztZtW","type":"assistant","uuid":"9f75debe-c1b4-4112-91de-4b5eab38c0be","timestamp":"2026-02-22T07:56:25.180Z"}
{"parentUuid":"9f75debe-c1b4-4112-91de-4b5eab38c0be","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01CBJUmrSd1vbCZHyioWBRcc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01W8gEqkt5QXbWx2TtyRwbM2","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2215,"limit":70},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":554,"cache_read_input_tokens":131676,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":554},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkSioK6U43MTbUztZtW","type":"assistant","uuid":"0a6f257c-6057-4c0d-bc0d-aebab0059e92","timestamp":"2026-02-22T07:56:25.959Z"}
{"parentUuid":"0a6f257c-6057-4c0d-bc0d-aebab0059e92","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01W8gEqkt5QXbWx2TtyRwbM2","toolUseID":"toolu_01W8gEqkt5QXbWx2TtyRwbM2","timestamp":"2026-02-22T07:56:25.970Z","uuid":"9df3b281-a263-4553-9d7b-409fb346d0a3"}
{"parentUuid":"0a6f257c-6057-4c0d-bc0d-aebab0059e92","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01W8gEqkt5QXbWx2TtyRwbM2","type":"tool_result","content":"  2215→\n  2216→    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n  2217→    // Both passes use jwalk for parallel scanning\n  2218→    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n  2219→    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n  2220→\n  2221→\n  2222→    for pass in 0..2u8 {\n  2223→        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n  2224→        if pass == 1 && is_fresh {\n  2225→            break;\n  2226→        }\n  2227→        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n  2228→        let pass_started = Instant::now();\n  2229→        let mut pass_scanned = 0u64;\n  2230→        let mut pass_indexed = 0u64;\n  2231→\n  2232→        for root in &roots {\n  2233→            let root_started = Instant::now();\n  2234→            let mut root_scanned = 0u64;\n  2235→            let mut root_indexed = 0u64;\n  2236→            let mut root_permission_errors = 0u64;\n  2237→            let root_str = root.to_string_lossy().to_string();\n  2238→\n  2239→            // Fresh index: DB is empty, preload is unnecessary\n  2240→            let existing = if is_fresh {\n  2241→                HashMap::new()\n  2242→            } else {\n  2243→                let e = preload_existing_entries(conn, &root_str);\n  2244→                e\n  2245→            };\n  2246→\n  2247→            let gi_ref = gi_filter.clone();\n  2248→            let skip_roots = arc_ignored_roots.clone();\n  2249→            let skip_patterns = arc_ignored_patterns.clone();\n  2250→\n  2251→            let mut builder = jwalk::WalkDir::new(root)\n  2252→                .follow_links(false)\n  2253→                .skip_hidden(false)\n  2254→                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n  2255→            // Fresh index: no depth limit -- walk everything in one pass\n  2256→            if pass == 0 && !is_fresh {\n  2257→                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n  2258→            }\n  2259→            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n  2260→                children.retain(|entry_result| {\n  2261→                    entry_result\n  2262→                        .as_ref()\n  2263→                        .map(|entry| {\n  2264→                            let full_path = path.join(&entry.file_name);\n  2265→                            let is_dir = Some(entry.file_type.is_dir());\n  2266→                            !should_skip_path_ext(\n  2267→                                &full_path,\n  2268→                                &skip_roots,\n  2269→                                &skip_patterns,\n  2270→                                Some(&gi_ref),\n  2271→                                is_dir,\n  2272→                            )\n  2273→                        })\n  2274→                        .unwrap_or(false)\n  2275→                });\n  2276→            });\n  2277→\n  2278→            for result in walker {\n  2279→                match result {\n  2280→                    Ok(entry) => {\n  2281→                        let path = entry.path();\n  2282→                        if path == root.as_path() {\n  2283→                            continue;\n  2284→                        }\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c0316393-3775-4234-80c9-c190fd0a6acc","timestamp":"2026-02-22T07:56:25.969Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }","numLines":70,"startLine":2215,"totalLines":5821}},"sourceToolAssistantUUID":"0a6f257c-6057-4c0d-bc0d-aebab0059e92"}
{"parentUuid":"c0316393-3775-4234-80c9-c190fd0a6acc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01UhXE1z63xRRodFba6rCiE7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Jd7K86f4mga7kHyJ94zrKm","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2284,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1244,"cache_read_input_tokens":132230,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1244},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkSyh1tqqFFWZRzQioF","type":"assistant","uuid":"65b5987b-14c5-49d7-914e-d1ea2c02d944","timestamp":"2026-02-22T07:56:29.057Z"}
{"parentUuid":"65b5987b-14c5-49d7-914e-d1ea2c02d944","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Jd7K86f4mga7kHyJ94zrKm","toolUseID":"toolu_01Jd7K86f4mga7kHyJ94zrKm","timestamp":"2026-02-22T07:56:29.090Z","uuid":"bbdab8f3-8edb-47af-b63f-6522a8b67cce"}
{"parentUuid":"65b5987b-14c5-49d7-914e-d1ea2c02d944","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Jd7K86f4mga7kHyJ94zrKm","type":"tool_result","content":"  2284→                        }\n  2285→\n  2286→                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n  2287→                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n  2288→                            continue;\n  2289→                        }\n  2290→\n  2291→                        scanned += 1;\n  2292→                        root_scanned += 1;\n  2293→                        current_path = path.to_string_lossy().to_string();\n  2294→\n  2295→                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n  2296→                            row.run_id = current_run_id;\n  2297→                            if is_fresh {\n  2298→                                // Fresh index: all entries are new, skip existing check\n  2299→                                indexed += 1;\n  2300→                                root_indexed += 1;\n  2301→                                batch.push(row);\n  2302→                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n  2303→                                if *old_mtime == row.mtime && *old_size == row.size {\n  2304→                                    stamp_batch.push(row.path);\n  2305→                                } else {\n  2306→                                    indexed += 1;\n  2307→                                    root_indexed += 1;\n  2308→                                    batch.push(row);\n  2309→                                }\n  2310→                            } else {\n  2311→                                indexed += 1;\n  2312→                                root_indexed += 1;\n  2313→                                batch.push(row);\n  2314→                            }\n  2315→                        }\n  2316→\n  2317→                        if batch.len() >= flush_batch_size {\n  2318→                            upsert_rows(conn, &batch)?;\n  2319→                            batch.clear();\n  2320→                        }\n  2321→\n  2322→                        if stamp_batch.len() >= flush_batch_size {\n  2323→                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2324→                            stamp_batch.clear();\n  2325→                        }\n  2326→\n  2327→                        if last_emit.elapsed() >= Duration::from_millis(200) {\n  2328→                            set_progress(state, scanned, indexed, &current_path);\n  2329→                            emit_index_progress(app, scanned, indexed, current_path.clone());\n  2330→                            last_emit = Instant::now();\n  2331→                        }\n  2332→                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n  2333→                        {\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9d7f904a-67df-43c5-8721-82920ebc95df","timestamp":"2026-02-22T07:56:29.089Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {","numLines":50,"startLine":2284,"totalLines":5821}},"sourceToolAssistantUUID":"65b5987b-14c5-49d7-914e-d1ea2c02d944"}
{"parentUuid":"9d7f904a-67df-43c5-8721-82920ebc95df","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_018ETtJ2Xxzhu587RiUYAmhN","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll make the core change - replace the walker builder and process loop:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":948,"cache_read_input_tokens":133474,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":948},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkTCd8oqntExARym2K1","type":"assistant","uuid":"fa997f8a-7afa-4f4b-bf27-ef626182545b","timestamp":"2026-02-22T07:56:31.197Z"}
{"parentUuid":"fa997f8a-7afa-4f4b-bf27-ef626182545b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_018ETtJ2Xxzhu587RiUYAmhN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018CkM2qN8QWuojKcmsTTwiw","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;","new_string":"            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":948,"cache_read_input_tokens":133474,"output_tokens":1536,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":948,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkTCd8oqntExARym2K1","type":"assistant","uuid":"735fadf3-f1a4-46a4-8c83-3053a9eb05fb","timestamp":"2026-02-22T07:56:49.563Z"}
{"parentUuid":"735fadf3-f1a4-46a4-8c83-3053a9eb05fb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_018CkM2qN8QWuojKcmsTTwiw","toolUseID":"toolu_018CkM2qN8QWuojKcmsTTwiw","timestamp":"2026-02-22T07:56:49.578Z","uuid":"985e1911-782f-4446-add1-83ee94ff2855"}
{"parentUuid":"735fadf3-f1a4-46a4-8c83-3053a9eb05fb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018CkM2qN8QWuojKcmsTTwiw","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"8e93436d-e0d1-45e0-b45d-d15256eefb5a","timestamp":"2026-02-22T07:56:49.577Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;","newString":"            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            let mut builder = jwalk::WalkDir::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                children.retain(|entry_result| {\n                    entry_result\n                        .as_ref()\n                        .map(|entry| {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            !should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            )\n                        })\n                        .unwrap_or(false)\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2248,"oldLines":43,"newStart":2248,"newLines":59,"lines":["             let skip_roots = arc_ignored_roots.clone();","             let skip_patterns = arc_ignored_patterns.clone();"," ","-            let mut builder = jwalk::WalkDir::new(root)","+            // Use more threads for fresh index: stat() calls are the bottleneck,","+            // more rayon threads = more parallel stat() calls.","+            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };","+            let current_pass = pass;","+            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)","                 .follow_links(false)","                 .skip_hidden(false)","-                .parallelism(jwalk::Parallelism::RayonNewPool(jwalk_num_threads()));","+                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));","             // Fresh index: no depth limit -- walk everything in one pass","             if pass == 0 && !is_fresh {","                 builder = builder.max_depth(SHALLOW_SCAN_DEPTH);","             }","             let walker = builder.process_read_dir(move |_depth, path, _state, children| {","-                children.retain(|entry_result| {","-                    entry_result","-                        .as_ref()","-                        .map(|entry| {","+                // Combined filter + metadata pre-fetch in one pass using retain_mut.","+                // Running stat() here parallelizes it across rayon threads (one per directory).","+                children.retain_mut(|entry_result| {","+                    match entry_result {","+                        Ok(entry) => {","                             let full_path = path.join(&entry.file_name);","                             let is_dir = Some(entry.file_type.is_dir());","-                            !should_skip_path_ext(","+                            if should_skip_path_ext(","                                 &full_path,","                                 &skip_roots,","                                 &skip_patterns,","                                 Some(&gi_ref),","                                 is_dir,","-                            )","-                        })","-                        .unwrap_or(false)","+                            ) {","+                                return false;","+                            }","+                            // Pre-fetch metadata in rayon thread (avoids serial stat() on","+                            // main thread). Skip for pass-1 shallow entries that will be","+                            // discarded in the main loop anyway.","+                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {","+                                entry.client_state = fs::symlink_metadata(&full_path).ok();","+                            }","+                            true","+                        }","+                        Err(_) => false,","+                    }","                 });","             });"," ","             for result in walker {","                 match result {","                     Ok(entry) => {","+                        let entry_depth = entry.depth;","                         let path = entry.path();","                         if path == root.as_path() {","                             continue;","                         }"," ","                         // Pass 1 (incremental only): skip shallow entries already indexed in pass 0","-                        if pass == 1 && entry.depth <= SHALLOW_SCAN_DEPTH {","+                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {","                             continue;","                         }"," "]},{"oldStart":2292,"oldLines":7,"newStart":2308,"newLines":18,"lines":["                         root_scanned += 1;","                         current_path = path.to_string_lossy().to_string();"," ","-                        if let Some(mut row) = index_row_from_jwalk_entry(&entry) {","+                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.","+                        let metadata = match entry.client_state {","+                            Some(m) => m,","+                            None => {","+                                // pre-fetch failed (permission error or race condition)","+                                permission_errors += 1;","+                                root_permission_errors += 1;","+                                continue;","+                            }","+                        };","+","+                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {","                             row.run_id = current_run_id;","                             if is_fresh {","                                 // Fresh index: all entries are new, skip existing check"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"735fadf3-f1a4-46a4-8c83-3053a9eb05fb"}
{"parentUuid":"8e93436d-e0d1-45e0-b45d-d15256eefb5a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_013XW2QEtUitLuebHscQGBtw","type":"message","role":"assistant","content":[{"type":"text","text":"Now I need to check if the closing braces are correct. Let me read the section after the change:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1685,"cache_read_input_tokens":134422,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1685},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkUiWWP4QRCi7W8NR8Q","type":"assistant","uuid":"16d6c8ba-ca36-47ff-9a50-10a7446bbd6e","timestamp":"2026-02-22T07:56:51.421Z"}
{"parentUuid":"16d6c8ba-ca36-47ff-9a50-10a7446bbd6e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_013XW2QEtUitLuebHscQGBtw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0132apkAkLRWx1xM4AFKRrnD","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2295,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1685,"cache_read_input_tokens":134422,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1685},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkUiWWP4QRCi7W8NR8Q","type":"assistant","uuid":"97595ae2-1fbb-4385-8184-bfb96b4aba3e","timestamp":"2026-02-22T07:56:52.373Z"}
{"parentUuid":"97595ae2-1fbb-4385-8184-bfb96b4aba3e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_0132apkAkLRWx1xM4AFKRrnD","toolUseID":"toolu_0132apkAkLRWx1xM4AFKRrnD","timestamp":"2026-02-22T07:56:52.412Z","uuid":"ffe9b973-c2bf-478d-b5d2-98f8c9cf4e10"}
{"parentUuid":"97595ae2-1fbb-4385-8184-bfb96b4aba3e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0132apkAkLRWx1xM4AFKRrnD","type":"tool_result","content":"  2295→                    Ok(entry) => {\n  2296→                        let entry_depth = entry.depth;\n  2297→                        let path = entry.path();\n  2298→                        if path == root.as_path() {\n  2299→                            continue;\n  2300→                        }\n  2301→\n  2302→                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n  2303→                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n  2304→                            continue;\n  2305→                        }\n  2306→\n  2307→                        scanned += 1;\n  2308→                        root_scanned += 1;\n  2309→                        current_path = path.to_string_lossy().to_string();\n  2310→\n  2311→                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n  2312→                        let metadata = match entry.client_state {\n  2313→                            Some(m) => m,\n  2314→                            None => {\n  2315→                                // pre-fetch failed (permission error or race condition)\n  2316→                                permission_errors += 1;\n  2317→                                root_permission_errors += 1;\n  2318→                                continue;\n  2319→                            }\n  2320→                        };\n  2321→\n  2322→                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n  2323→                            row.run_id = current_run_id;\n  2324→                            if is_fresh {\n  2325→                                // Fresh index: all entries are new, skip existing check\n  2326→                                indexed += 1;\n  2327→                                root_indexed += 1;\n  2328→                                batch.push(row);\n  2329→                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n  2330→                                if *old_mtime == row.mtime && *old_size == row.size {\n  2331→                                    stamp_batch.push(row.path);\n  2332→                                } else {\n  2333→                                    indexed += 1;\n  2334→                                    root_indexed += 1;\n  2335→                                    batch.push(row);\n  2336→                                }\n  2337→                            } else {\n  2338→                                indexed += 1;\n  2339→                                root_indexed += 1;\n  2340→                                batch.push(row);\n  2341→                            }\n  2342→                        }\n  2343→\n  2344→                        if batch.len() >= flush_batch_size {\n  2345→                            upsert_rows(conn, &batch)?;\n  2346→                            batch.clear();\n  2347→                        }\n  2348→\n  2349→                        if stamp_batch.len() >= flush_batch_size {\n  2350→                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n  2351→                            stamp_batch.clear();\n  2352→                        }\n  2353→\n  2354→                        if last_emit.elapsed() >= Duration::from_millis(200) {\n  2355→                            set_progress(state, scanned, indexed, &current_path);\n  2356→                            emit_index_progress(app, scanned, indexed, current_path.clone());\n  2357→                            last_emit = Instant::now();\n  2358→                        }\n  2359→                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n  2360→                        {\n  2361→                            perf_log(format!(\n  2362→                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n  2363→                                pass_label, scanned, indexed, current_path\n  2364→                            ));\n  2365→                            last_perf_emit = Instant::now();\n  2366→                        }\n  2367→                    }\n  2368→                    Err(err) => {\n  2369→                        scanned += 1;\n  2370→                        root_scanned += 1;\n  2371→                        permission_errors += 1;\n  2372→                        root_permission_errors += 1;\n  2373→                        if permission_errors <= 20 || perf_log_enabled() {\n  2374→                            eprintln!(\"[index] permission error: {}\", err);\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d0853c3d-5da5-4232-a14c-56d48ec2b16d","timestamp":"2026-02-22T07:56:52.411Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);","numLines":80,"startLine":2295,"totalLines":5848}},"sourceToolAssistantUUID":"97595ae2-1fbb-4385-8184-bfb96b4aba3e"}
{"parentUuid":"d0853c3d-5da5-4232-a14c-56d48ec2b16d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Lnzig9aXeC6t8bvME1m1Dy","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The code looks correct. The main loop now:\n1. Extracts `entry_depth` (Copy, no allocation)\n2. Gets `entry.path()` (1 PathBuf allocation)\n3. Checks if it's root and passes skip check4. Gets metadata from `entry.client_state` (pre-fetched in rayon thread)\n5. Calls `index_row_from_path_and_metadata(&path, &metadata)`\n\nThis is a significant improvement because:\n- stat() calls now happen in rayon threads (parallel)\n- Main thread doesn't need to call stat() anymore\n- Entry processing on main thread is faster (just HashMap lookup + batch append)\n\n\n- I should add timing logs to `run_incremental_index` to track how long index creation and ANALYZE take","signature":"EroGCkYICxgCKkByuPqOTyD1jeguPvh8M0KzGwxs9/0HG4s4CSHlaC3TpiltsMSj/x18VPZa/ID7b5bv4h5myzAlEjS2qo+B0cS0Egy1f0G6gUKlXM/4WKMaDMsmdh7cnVOmUNFi6SIwz0eR5eX0ZF92J5/d3sS0RP5tKN3mtFvPcg8lpr2t7s1i/Fk91vj38FFdS1OBrswfKqEF5ATT4/E5dnIBtHtgVzy98pSo5rcGhf/bPVTl+d5X7ozF8m3mXMuMfnxvJL/22YBLmCf/fwmrcG7eLZFZ+Zm54HyNpXU1hKR08Mia8gsAnwKVX/64C7bBvYPP5vQKGUS7uLmia5g/3PEhryLZkvlqqVPVS+3H4vXeSeVGiyNaEx6VcR+6GGgBjsSQh3ni+EZUxbjBq6eVaUa0o7D9q6qIUCVLrIHBvXWlKK59VV4FmDsUJESLmWABMXDj1dS6XB3angqqLVOC3FNBNlyjVyo7oPSul1Lc1HhfUUQDCqh/QwoHO6uX4RZItlclDOXUh6QQMdP4AYx9wzbYPU+RB+S1KJySb2rRGsQ9lDA+dycDE5RwPL6cn9wPx2oOal1DtxKyQkiryalCz4yIZy8RcLvyX4vz5ogcLLEx1+59flKMwR8M+pyQDx9UAdiJ9UqGUhmqLBPtPI02y1gzyOQtHU8anegqVoTUH/OAL2SVuiG5N0EANecQt3sFkPKbjZOaC7+AsqumfLqTrp9HUR06cG9ZRke/mxSo5/cGk6i7Tp7gdZgO2aIYCmz8C5sLbunziPa8zFVdJoJn9IhXiURE9+1js+Lvp3+dzPf1wP42sl1Z2534evP38UJFUmGr7GsppO5A4XwBx4Oh8akGuK5wNKch8zSBvH57p0amkSNy5V6niKohELfaRwYbHVhzT1RPl5S6juOLKyM3RVpt1NDN9dIN6OzcMS+37y9uxi+1WGOexXXz65mnIt7IUxZOG7l0WmAtD/+9elE1cg4jJk9RzsoWv4EBcVm1yqbnRKLeA9lWGtIbMm9tKVkYrDEzKolgwy5CkRLKiBrQZETC5H/X+JoljDPfvWnavNEH0w7vaMagXgaweIirFWULFXAWncz8l8b/zBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1411,"cache_read_input_tokens":136107,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1411},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkUvZoC1noBKuo4rcgC","type":"assistant","uuid":"3ef8363d-3a94-4cf1-b5b3-58d168794c16","timestamp":"2026-02-22T07:56:59.140Z"}
{"parentUuid":"3ef8363d-3a94-4cf1-b5b3-58d168794c16","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Lnzig9aXeC6t8bvME1m1Dy","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me add timing logs around the post-scan phases (index creation and ANALYZE):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1411,"cache_read_input_tokens":136107,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1411},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkUvZoC1noBKuo4rcgC","type":"assistant","uuid":"e662ef25-9ef0-4d0f-a7b4-00d29f9a7e65","timestamp":"2026-02-22T07:56:59.151Z"}
{"parentUuid":"e662ef25-9ef0-4d0f-a7b4-00d29f9a7e65","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Lnzig9aXeC6t8bvME1m1Dy","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PzYKhWqk2PEtvxRwcMsdcZ","name":"Read","input":{"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","offset":2055,"limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1411,"cache_read_input_tokens":136107,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1411},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkUvZoC1noBKuo4rcgC","type":"assistant","uuid":"d4df0cf1-7897-42e5-a70e-5f590ffe1869","timestamp":"2026-02-22T07:57:00.044Z"}
{"parentUuid":"d4df0cf1-7897-42e5-a70e-5f590ffe1869","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01PzYKhWqk2PEtvxRwcMsdcZ","toolUseID":"toolu_01PzYKhWqk2PEtvxRwcMsdcZ","timestamp":"2026-02-22T07:57:00.062Z","uuid":"891fe478-6ed3-4978-a7dc-f7965a485b56"}
{"parentUuid":"d4df0cf1-7897-42e5-a70e-5f590ffe1869","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PzYKhWqk2PEtvxRwcMsdcZ","type":"tool_result","content":"  2055→        let _ = conn.execute_batch(\n  2056→            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n  2057→             DROP INDEX IF EXISTS idx_entries_mtime;\n  2058→             DROP INDEX IF EXISTS idx_entries_name_nocase;\n  2059→             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n  2060→        );\n  2061→    }\n  2062→\n  2063→    let result = run_incremental_index_inner(app, state, &mut conn);\n  2064→\n  2065→    if is_fresh_run {\n  2066→        let _ = conn.execute_batch(\n  2067→            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n  2068→             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n  2069→             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n  2070→             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n  2071→        );\n  2072→    }\n  2073→\n  2074→    let _ = conn.execute_batch(\"ANALYZE\");\n  2075→    let _ = restore_normal_pragmas(&conn);\n  2076→\n  2077→    match &result {\n  2078→        Ok(_) => {\n  2079→            let _ = set_meta(&conn, \"index_complete\", \"1\");\n  2080→            let snapshot = state.status.lock().clone();\n  2081→            perf_log(format!(\n  2082→                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n  2083→                started.elapsed().as_millis(),\n  2084→                snapshot.scanned,\n  2085→                snapshot.indexed,\n  2086→                snapshot.entries_count,\n  2087→                snapshot.permission_errors,\n  2088→                snapshot.message,\n  2089→            ));\n  2090→        }\n  2091→        Err(err) => {\n  2092→            perf_log(format!(\n  2093→                \"index_run_error elapsed_ms={} err={}\",\n  2094→                started.elapsed().as_millis(),\n  2095→                err,\n  2096→            ));\n  2097→        }\n  2098→    }\n  2099→\n  2100→    result\n  2101→}\n  2102→\n  2103→fn run_incremental_index_inner(\n  2104→    app: &AppHandle,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"39bed55e-3658-48cc-a111-280c002c9595","timestamp":"2026-02-22T07:57:00.061Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","content":"        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,","numLines":50,"startLine":2055,"totalLines":5848}},"sourceToolAssistantUUID":"d4df0cf1-7897-42e5-a70e-5f590ffe1869"}
{"parentUuid":"39bed55e-3658-48cc-a111-280c002c9595","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01W3c7W1ZSF8Lnfd578sGD5a","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GikupCHb1MHFKCeFALZm3W","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);","new_string":"    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1107,"cache_read_input_tokens":137518,"output_tokens":559,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1107,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYNkVVSURrBcMokL2NXs1","type":"assistant","uuid":"d73d6bd2-0655-4b0c-871c-3bc2553ce024","timestamp":"2026-02-22T07:57:06.130Z"}
{"parentUuid":"d73d6bd2-0655-4b0c-871c-3bc2553ce024","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01GikupCHb1MHFKCeFALZm3W","toolUseID":"toolu_01GikupCHb1MHFKCeFALZm3W","timestamp":"2026-02-22T07:57:06.139Z","uuid":"2ee56f7c-eb8a-4848-94f5-fb3a43f4f02d"}
{"parentUuid":"d73d6bd2-0655-4b0c-871c-3bc2553ce024","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GikupCHb1MHFKCeFALZm3W","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"3f74cf81-a2b8-4e20-bb2c-b23fad82d34e","timestamp":"2026-02-22T07:57:06.138Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);","newString":"    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n    }\n\n    let _ = conn.execute_batch(\"ANALYZE\");\n    let _ = restore_normal_pragmas(&conn);\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":2063,"oldLines":16,"newStart":2063,"newLines":22,"lines":["     let result = run_incremental_index_inner(app, state, &mut conn);"," ","     if is_fresh_run {","+        let t_idx = Instant::now();","         let _ = conn.execute_batch(","             \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);","              CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);","              CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);","              CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",","         );","+        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());","     }"," ","+    let t_analyze = Instant::now();","     let _ = conn.execute_batch(\"ANALYZE\");","+    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());","+    let t_checkpoint = Instant::now();","     let _ = restore_normal_pragmas(&conn);","+    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());"," ","     match &result {","         Ok(_) => {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"d73d6bd2-0655-4b0c-871c-3bc2553ce024"}
{"parentUuid":"3f74cf81-a2b8-4e20-bb2c-b23fad82d34e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01YGbo4QepPRtGQmj2k3tdeZ","type":"message","role":"assistant","content":[{"type":"text","text":"Now let's try to build and check for errors:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":597,"cache_read_input_tokens":138625,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":597},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkVwLTaCBwoMaPbNhAx","type":"assistant","uuid":"417751a0-e80a-464b-b7e5-c98e89c20af1","timestamp":"2026-02-22T07:57:08.178Z"}
{"parentUuid":"417751a0-e80a-464b-b7e5-c98e89c20af1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01YGbo4QepPRtGQmj2k3tdeZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014x9PYHz7tEwkXejs2vTRWs","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | head -80","description":"Check for compile errors","timeout":120000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":597,"cache_read_input_tokens":138625,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":597},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkVwLTaCBwoMaPbNhAx","type":"assistant","uuid":"5fc20110-1a49-4289-b29b-9d92ffff76fd","timestamp":"2026-02-22T07:57:09.336Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T07:57:12.387Z","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","content":"{\"task_id\":\"b8e4ead\",\"tool_use_id\":\"REDACTED\",\"description\":\"Check for compile errors\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"5fc20110-1a49-4289-b29b-9d92ffff76fd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b8e4ead","timeoutMs":120000},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_014x9PYHz7tEwkXejs2vTRWs","uuid":"5e2cb27b-a747-47f5-82ee-9130e819294c","timestamp":"2026-02-22T07:57:12.387Z"}
{"parentUuid":"5e2cb27b-a747-47f5-82ee-9130e819294c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":4,"totalLines":0,"totalBytes":0,"taskId":"b8e4ead","timeoutMs":120000},"toolUseID":"bash-progress-1","parentToolUseID":"toolu_014x9PYHz7tEwkXejs2vTRWs","uuid":"8854ecbe-d231-407d-8284-9b0211ca9140","timestamp":"2026-02-22T07:57:13.388Z"}
{"parentUuid":"8854ecbe-d231-407d-8284-9b0211ca9140","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":5,"totalLines":0,"totalBytes":0,"taskId":"b8e4ead","timeoutMs":120000},"toolUseID":"bash-progress-2","parentToolUseID":"toolu_014x9PYHz7tEwkXejs2vTRWs","uuid":"3ab3d8ae-9c4c-41cf-93a0-28dc94e360df","timestamp":"2026-02-22T07:57:14.388Z"}
{"parentUuid":"3ab3d8ae-9c4c-41cf-93a0-28dc94e360df","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":6,"totalLines":0,"totalBytes":0,"taskId":"b8e4ead","timeoutMs":120000},"toolUseID":"bash-progress-3","parentToolUseID":"toolu_014x9PYHz7tEwkXejs2vTRWs","uuid":"533473a5-31cc-4f3b-a333-7a24d5277230","timestamp":"2026-02-22T07:57:15.392Z"}
{"parentUuid":"5fc20110-1a49-4289-b29b-9d92ffff76fd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014x9PYHz7tEwkXejs2vTRWs","type":"tool_result","content":"    Blocking waiting for file lock on build directory\n   Compiling everything v0.2.0 (/Users/al02402336/everything/src-tauri)\nwarning: function `index_row_from_jwalk_entry` is never used\n    --> src/main.rs:1392:4\n     |\n1392 | fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n     |    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `#[warn(dead_code)]` on by default\n\nwarning: method `root_paths` is never used\n  --> src/gitignore_filter.rs:23:12\n   |\n17 | impl GitignoreFilter {\n   | -------------------- method in this implementation\n...\n23 |     pub fn root_paths(&self) -> Vec<&Path> {\n   |            ^^^^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 2 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 6.41s","is_error":false}]},"uuid":"e6aacb92-d923-4260-a25e-8b25bd81440b","timestamp":"2026-02-22T07:57:16.032Z","toolUseResult":{"stdout":"    Blocking waiting for file lock on build directory\n   Compiling everything v0.2.0 (/Users/al02402336/everything/src-tauri)\nwarning: function `index_row_from_jwalk_entry` is never used\n    --> src/main.rs:1392:4\n     |\n1392 | fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n     |    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `#[warn(dead_code)]` on by default\n\nwarning: method `root_paths` is never used\n  --> src/gitignore_filter.rs:23:12\n   |\n17 | impl GitignoreFilter {\n   | -------------------- method in this implementation\n...\n23 |     pub fn root_paths(&self) -> Vec<&Path> {\n   |            ^^^^^^^^^^\n\nwarning: `everything` (bin \"everything\") generated 2 warnings\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 6.41s","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"5fc20110-1a49-4289-b29b-9d92ffff76fd"}
{"parentUuid":"e6aacb92-d923-4260-a25e-8b25bd81440b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01JZyoz8cZHtmbjPFvgks8nL","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The code compiled successfully. There's just a warning about `index_row_from_jwalk_entry` being unused - I should remove it. Let me do that now.Let me also check the entry.client_state access - is this actually correct? The entry is `jwalk::DirEntry<((), Option<fs::Metadata>)>`. The `client_state` field is `C::DirEntryState = Option<fs::Metadata>`. So `entry.client_state` is `Option<fs::Metadata>`. Moving it out with `entry.client_state` should work since `DirEntry<C>` doesn't have a custom Drop.\n\n\nNow I'm verifying that the partial move works correctly - since `DirEntry` doesn't implement Drop, I can move the `client_state` field out while still accessing other fields like `depth` and calling methods like `path()` afterward. After the partial move of `client_state`, the remaining fields get dropped properly when `entry` goes out of scope, which is safe since `DirEntry` doesn't implement a custom `Drop`. The code compiled successfully, confirming this approach works. Now I'll clean up by removing the unused `index_row_from_jwalk_entry` function.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":404,"cache_read_input_tokens":139222,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":404},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkWfP3pmXzfa1RvtZ6x","type":"assistant","uuid":"ce43140e-ba61-4ae0-b24b-5cc3576a3df1","timestamp":"2026-02-22T07:57:33.161Z"}
{"parentUuid":"ce43140e-ba61-4ae0-b24b-5cc3576a3df1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01JZyoz8cZHtmbjPFvgks8nL","type":"message","role":"assistant","content":[{"type":"text","text":"Good, it compiles. Let me remove the now-unused function:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":404,"cache_read_input_tokens":139222,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":404},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkWfP3pmXzfa1RvtZ6x","type":"assistant","uuid":"ea6ca9ab-9bac-4c08-8bb4-0cd3ea0364cb","timestamp":"2026-02-22T07:57:33.161Z"}
{"parentUuid":"ea6ca9ab-9bac-4c08-8bb4-0cd3ea0364cb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01JZyoz8cZHtmbjPFvgks8nL","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015cUncAvd9TbpEa1CGwyWQ8","name":"Edit","input":{"replace_all":false,"file_path":"/Users/al02402336/everything/src-tauri/src/main.rs","old_string":"fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\n","new_string":"\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":404,"cache_read_input_tokens":139222,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":404},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkWfP3pmXzfa1RvtZ6x","type":"assistant","uuid":"8c37d427-85ac-4962-b7d4-0220f3d4b8e2","timestamp":"2026-02-22T07:57:33.708Z"}
{"parentUuid":"8c37d427-85ac-4962-b7d4-0220f3d4b8e2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_015cUncAvd9TbpEa1CGwyWQ8","toolUseID":"toolu_015cUncAvd9TbpEa1CGwyWQ8","timestamp":"2026-02-22T07:57:33.722Z","uuid":"3998d23e-ef17-4c0e-a2f6-364aaefadebb"}
{"parentUuid":"8c37d427-85ac-4962-b7d4-0220f3d4b8e2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015cUncAvd9TbpEa1CGwyWQ8","type":"tool_result","content":"The file /Users/al02402336/everything/src-tauri/src/main.rs has been updated successfully."}]},"uuid":"31d82131-b47d-4c76-b2d2-cfd992b74f27","timestamp":"2026-02-22T07:57:33.721Z","toolUseResult":{"filePath":"/Users/al02402336/everything/src-tauri/src/main.rs","oldString":"fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\n","newString":"\n","originalFile":"#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::{\n    cmp::Ordering,\n    collections::{HashMap, HashSet},\n    fs,\n    hash::{Hash, Hasher},\n    io::{self, BufRead, BufReader, Write},\n    path::{Path, PathBuf},\n    process::{Command, Stdio},\n    sync::{\n        atomic::{AtomicBool, Ordering as AtomicOrdering},\n        Arc, OnceLock,\n    },\n    time::{Duration, Instant, SystemTime, UNIX_EPOCH},\n};\n\nuse parking_lot::{Mutex, RwLock};\nuse rusqlite::{params, params_from_iter, types::Value as SqlValue, Connection};\nuse serde::Serialize;\nuse tauri::{AppHandle, Emitter, Manager, State};\n#[cfg(target_os = \"macos\")]\nuse tauri_plugin_global_shortcut::{Code, GlobalShortcutExt, Modifiers, Shortcut};\n#[cfg(target_os = \"windows\")]\nuse std::os::windows::process::CommandExt;\nuse walkdir::WalkDir;\n\nmod fd_search;\nmod gitignore_filter;\n#[cfg(target_os = \"macos\")]\nmod mac;\nmod mem_search;\nmod query;\n#[cfg(target_os = \"windows\")]\nmod win;\nuse fd_search::{FdSearchCache, FdSearchResultDto};\nuse query::{escape_like, parse_query, SearchMode};\n\nconst DEFAULT_LIMIT: u32 = 300;\nconst SHORT_QUERY_LIMIT: u32 = 100;\nconst MAX_LIMIT: u32 = 1000;\npub(crate) const BATCH_SIZE: usize = 10_000;\nconst RECENT_OP_TTL: Duration = Duration::from_secs(2);\npub(crate) const WATCH_DEBOUNCE: Duration = Duration::from_millis(300);\nconst NEGATIVE_CACHE_TTL: Duration = Duration::from_secs(60);\nconst NEGATIVE_CACHE_FALLBACK_WINDOW: Duration = Duration::from_millis(550);\nconst DB_VERSION: i32 = 4;\nconst DEFERRED_DIR_NAMES: &[&str] = &[\n    \"Library\", \".Trash\", \".Trashes\",\n    // Windows system directories (deferred when scan_root is C:\\)\n    \"Windows\", \"Program Files\", \"Program Files (x86)\",\n    \"$Recycle.Bin\", \"System Volume Information\", \"Recovery\", \"PerfLogs\",\n];\nconst SHALLOW_SCAN_DEPTH: usize = 6;\nfn jwalk_num_threads() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| (n.get() / 2).max(4).min(16))\n        .unwrap_or(8)\n}\n\nfn jwalk_num_threads_fresh() -> usize {\n    std::thread::available_parallelism()\n        .map(|n| n.get().max(4).min(16))\n        .unwrap_or(8)\n}\n\npub(crate) const BUILTIN_SKIP_NAMES: &[&str] = &[\n    \".git\",\n    \"node_modules\",\n    \".Trash\",\n    \".Trashes\",\n    \".npm\",\n    \".cache\",\n    \"CMakeFiles\",\n    \".qtc_clangd\",\n    \"__pycache__\",\n    \".gradle\",\n    \"DerivedData\",\n];\n\n/// Path segments whose name ends with one of these suffixes are skipped.\n/// e.g. \"*.build\" skips Xcode intermediate build directories like \"MyApp.build\".\npub(crate) const BUILTIN_SKIP_SUFFIXES: &[&str] = &[\n    \".build\", // Xcode intermediate build dir (MyApp.build, Objects-normal, etc.)\n];\n\npub(crate) const BUILTIN_SKIP_PATHS: &[&str] = &[\n    // macOS\n    \"Library/Caches\",\n    \"Library/Developer/CoreSimulator\",\n    \"Library/Logs\",\n    // Cross-platform\n    \".vscode/extensions\",\n    // Windows: noisy system directories under AppData\n    \"AppData/Local/Temp\",\n    \"AppData/Local/Microsoft\",\n    \"AppData/Local/Google\",\n    \"AppData/Local/Packages\",\n];\n\ntype AppResult<T> = Result<T, String>;\n\n// Pre-computed infix/suffix strings for BUILTIN_SKIP_PATHS to avoid hot-path allocations.\nstatic BUILTIN_SKIP_PATH_CHECKS: OnceLock<Vec<(String, String)>> = OnceLock::new();\nfn builtin_skip_path_checks() -> &'static [(String, String)] {\n    BUILTIN_SKIP_PATH_CHECKS.get_or_init(|| {\n        BUILTIN_SKIP_PATHS\n            .iter()\n            .map(|pat| (format!(\"/{pat}/\"), format!(\"/{pat}\")))\n            .collect()\n    })\n}\n\nstatic SEARCH_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic PERF_LOG_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic BENCH_MODE_ENABLED: OnceLock<bool> = OnceLock::new();\nstatic STARTUP_T0: OnceLock<Instant> = OnceLock::new();\n\nfn startup_elapsed_ms() -> u128 {\n    STARTUP_T0\n        .get()\n        .map(|started| started.elapsed().as_millis())\n        .unwrap_or(0)\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct EntryDto {\n    pub path: String,\n    pub name: String,\n    pub dir: String,\n    pub is_dir: bool,\n    pub ext: Option<String>,\n    pub size: Option<i64>,\n    pub mtime: Option<i64>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStatusDto {\n    state: String,\n    entries_count: u64,\n    last_updated: Option<i64>,\n    permission_errors: u64,\n    message: Option<String>,\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexProgressEvent {\n    scanned: u64,\n    indexed: u64,\n    current_path: String,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexStateEvent {\n    state: String,\n    message: Option<String>,\n    is_catchup: bool,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct IndexUpdatedEvent {\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n}\n\n#[derive(Debug, Clone)]\nstruct SearchExecution {\n    query: String,\n    sort_by: String,\n    sort_dir: String,\n    effective_limit: u32,\n    offset: u32,\n    mode_label: String,\n    results: Vec<EntryDto>,\n}\n\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct SearchResultDto {\n    entries: Vec<EntryDto>,\n    mode_label: String,\n    /// Total number of results matching the query (ignoring LIMIT/OFFSET).\n    total_count: u32,\n    /// True when total_count is exact. False means frontend should treat it as unknown.\n    total_known: bool,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone)]\nstruct BenchCase {\n    id: &'static str,\n    query: &'static str,\n    sort_by: &'static str,\n    sort_dir: &'static str,\n    limit: u32,\n    offset: u32,\n    expected_min_results: usize,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchCaseResult {\n    id: String,\n    query: String,\n    mode: String,\n    sort_by: String,\n    sort_dir: String,\n    limit: u32,\n    offset: u32,\n    elapsed_ms: f64,\n    result_count: usize,\n    expected_min_results: usize,\n    passed: bool,\n    top_results: Vec<String>,\n    error: Option<String>,\n}\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Serialize)]\n#[serde(rename_all = \"camelCase\")]\nstruct BenchReport {\n    run_label: String,\n    started_at: i64,\n    completed_at: i64,\n    home_dir: String,\n    db_path: String,\n    index_wait_ms: u128,\n    index_scanned: u64,\n    index_indexed: u64,\n    index_entries_count: u64,\n    index_permission_errors: u64,\n    index_message: Option<String>,\n    search_iterations: u32,\n    search_results: Vec<BenchCaseResult>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) enum IndexState {\n    Ready,\n    Indexing,\n    Error,\n}\n\nimpl IndexState {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Self::Ready => \"Ready\",\n            Self::Indexing => \"Indexing\",\n            Self::Error => \"Error\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexStatus {\n    pub(crate) state: IndexState,\n    pub(crate) entries_count: u64,\n    pub(crate) last_updated: Option<i64>,\n    pub(crate) permission_errors: u64,\n    pub(crate) message: Option<String>,\n    pub(crate) scanned: u64,\n    pub(crate) indexed: u64,\n    pub(crate) current_path: String,\n}\n\nimpl Default for IndexStatus {\n    fn default() -> Self {\n        Self {\n            state: IndexState::Indexing,\n            entries_count: 0,\n            last_updated: None,\n            permission_errors: 0,\n            message: None,\n            scanned: 0,\n            indexed: 0,\n            current_path: String::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)]\npub(crate) struct RecentOp {\n    old_path: Option<String>,\n    new_path: Option<String>,\n    op_type: &'static str,\n    at: Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub(crate) enum IgnorePattern {\n    /// Matches any path segment equal to `segment`.\n    /// `suffix` = `\"/{segment}\"`, `infix` = `\"/{segment}/\"` — pre-computed to avoid\n    /// per-call format! allocations in the hot path.\n    AnySegment {\n        segment: String,\n        suffix: String,\n        infix: String,\n    },\n    Glob(String),\n}\n\nimpl IgnorePattern {\n    pub(crate) fn any_segment(segment: &str) -> Self {\n        IgnorePattern::AnySegment {\n            suffix: format!(\"/{segment}\"),\n            infix: format!(\"/{segment}/\"),\n            segment: segment.to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IgnoreRulesCache {\n    roots: Vec<PathBuf>,\n    patterns: Vec<IgnorePattern>,\n    pathignore_mtime: Option<SystemTime>,\n    gitignore_mtime: Option<SystemTime>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct AppState {\n    pub(crate) db_path: PathBuf,\n    pub(crate) home_dir: PathBuf,\n    pub(crate) scan_root: PathBuf,\n    pub(crate) cwd: PathBuf,\n    pub(crate) path_ignores: Arc<Vec<PathBuf>>,\n    pub(crate) path_ignore_patterns: Arc<Vec<IgnorePattern>>,\n    pub(crate) db_ready: Arc<AtomicBool>,\n    pub(crate) indexing_active: Arc<AtomicBool>,\n    pub(crate) status: Arc<Mutex<IndexStatus>>,\n    pub(crate) recent_ops: Arc<Mutex<Vec<RecentOp>>>,\n    pub(crate) icon_cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,\n    pub(crate) fd_search_cache: Arc<Mutex<Option<FdSearchCache>>>,\n    pub(crate) negative_name_cache: Arc<Mutex<HashMap<String, NegativeNameEntry>>>,\n    pub(crate) ignore_cache: Arc<Mutex<Option<IgnoreRulesCache>>>,\n    pub(crate) gitignore: Arc<gitignore_filter::LazyGitignoreFilter>,\n    /// In-memory index for instant search while DB upsert runs in background.\n    /// Set by MFT scan, cleared after background DB upsert completes.\n    pub(crate) mem_index: Arc<RwLock<Option<Arc<mem_search::MemIndex>>>>,\n    /// Signal to stop the file watcher (RDCW / USN). Set to true on reset_index.\n    pub(crate) watcher_stop: Arc<AtomicBool>,\n    /// Set to true while a file watcher event loop is running.\n    pub(crate) watcher_active: Arc<AtomicBool>,\n    /// Set to true once frontend onMount has completed enough to accept user input.\n    pub(crate) frontend_ready: Arc<AtomicBool>,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct NegativeNameEntry {\n    created_at: Instant,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\nstruct NegativeCacheHit {\n    query_lower: String,\n    age: Duration,\n    fallback_checked: bool,\n}\n\n#[derive(Debug, Clone)]\npub(crate) struct IndexRow {\n    pub(crate) path: String,\n    pub(crate) name: String,\n    pub(crate) dir: String,\n    pub(crate) is_dir: i64,\n    pub(crate) ext: Option<String>,\n    pub(crate) mtime: Option<i64>,\n    pub(crate) size: Option<i64>,\n    pub(crate) indexed_at: i64,\n    pub(crate) run_id: i64,\n}\n\npub(crate) fn now_epoch() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or_default()\n}\n\nfn env_truthy(key: &str) -> bool {\n    std::env::var(key)\n        .ok()\n        .map(|value| {\n            matches!(\n                value.trim().to_ascii_lowercase().as_str(),\n                \"1\" | \"true\" | \"yes\" | \"on\"\n            )\n        })\n        .unwrap_or(false)\n}\n\nfn bench_mode_enabled() -> bool {\n    *BENCH_MODE_ENABLED.get_or_init(|| env_truthy(\"EVERYTHING_BENCH\"))\n}\n\nfn perf_log_enabled() -> bool {\n    *PERF_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_PERF_LOG\") || bench_mode_enabled())\n}\n\npub(crate) fn perf_log(message: impl AsRef<str>) {\n    if perf_log_enabled() {\n        eprintln!(\"[perf] {}\", message.as_ref());\n    }\n}\n\nfn db_connection_with_timeout(db_path: &Path, busy_timeout_ms: u32) -> AppResult<Connection> {\n    let conn = Connection::open(db_path).map_err(|e| e.to_string())?;\n    conn.execute_batch(&format!(\n        r#\"\n        PRAGMA journal_mode=WAL;\n        PRAGMA synchronous=NORMAL;\n        PRAGMA temp_store=MEMORY;\n        PRAGMA busy_timeout={busy_timeout_ms};\n        \"#,\n    ))\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn db_connection(db_path: &Path) -> AppResult<Connection> {\n    db_connection_with_timeout(db_path, 3000)\n}\n\nfn db_connection_for_search(db_path: &Path) -> AppResult<Connection> {\n    let conn = db_connection_with_timeout(db_path, 500)?;\n    conn.execute_batch(\n        \"PRAGMA cache_size = -32768;\n         PRAGMA mmap_size = 268435456;\",\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(conn)\n}\n\npub(crate) fn set_indexing_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = OFF;\n        PRAGMA cache_size = -131072;\n        PRAGMA mmap_size = 536870912;\n        PRAGMA wal_autocheckpoint = 0;\n        \"#,\n    )\n    .map_err(|e| e.to_string())\n}\n\npub(crate) fn restore_normal_pragmas(conn: &Connection) -> AppResult<()> {\n    conn.execute_batch(\n        r#\"\n        PRAGMA synchronous = NORMAL;\n        PRAGMA cache_size = -16384;\n        PRAGMA mmap_size = 268435456;\n        PRAGMA wal_autocheckpoint = 1000;\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    // PASSIVE checkpoint: does not block readers/writers; checkpoints as many\n    // WAL frames as possible without waiting. The WAL will be fully checkpointed\n    // when the next auto-checkpoint threshold is hit.\n    conn.execute_batch(\"PRAGMA wal_checkpoint(PASSIVE);\")\n        .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn init_db(db_path: &Path) -> AppResult<()> {\n    let t = Instant::now();\n    let conn = db_connection(db_path)?;\n    eprintln!(\"[init_db] +{}ms db_connection opened\", t.elapsed().as_millis());\n\n    let current_version: i32 = conn\n        .query_row(\"PRAGMA user_version\", [], |row| row.get(0))\n        .unwrap_or(0);\n    if current_version != DB_VERSION {\n        conn.execute_batch(\n            r#\"\n            DROP TRIGGER IF EXISTS entries_ai;\n            DROP TRIGGER IF EXISTS entries_ad;\n            DROP TRIGGER IF EXISTS entries_au;\n            DROP TABLE IF EXISTS entries_fts;\n            DROP TABLE IF EXISTS entries;\n            \"#,\n        )\n        .map_err(|e| e.to_string())?;\n        conn.execute_batch(&format!(\"PRAGMA user_version = {};\", DB_VERSION))\n            .map_err(|e| e.to_string())?;\n    }\n    eprintln!(\"[init_db] +{}ms version check done (v={})\", t.elapsed().as_millis(), current_version);\n\n    conn.execute_batch(\n        r#\"\n        CREATE TABLE IF NOT EXISTS entries (\n          id INTEGER PRIMARY KEY,\n          path TEXT NOT NULL UNIQUE,\n          name TEXT NOT NULL,\n          dir TEXT NOT NULL,\n          is_dir INTEGER NOT NULL,\n          ext TEXT,\n          mtime INTEGER,\n          size INTEGER,\n          indexed_at INTEGER NOT NULL,\n          run_id INTEGER NOT NULL DEFAULT 0\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n        CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n        CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\n\n        CREATE TABLE IF NOT EXISTS meta (\n          key TEXT PRIMARY KEY,\n          value TEXT NOT NULL\n        );\n        \"#,\n    )\n    .map_err(|e| e.to_string())?;\n    eprintln!(\"[init_db] +{}ms schema ensured\", t.elapsed().as_millis());\n\n    let legacy_index_migration_key = \"migration_drop_idx_entries_dir_name_nocase_v1\";\n    let migrated = get_meta(&conn, legacy_index_migration_key)\n        .map(|v| v == \"1\")\n        .unwrap_or(false);\n    if !migrated {\n        conn.execute_batch(\"DROP INDEX IF EXISTS idx_entries_dir_name_nocase;\")\n            .map_err(|e| e.to_string())?;\n        set_meta(&conn, legacy_index_migration_key, \"1\")?;\n    }\n    eprintln!(\"[init_db] +{}ms total\", t.elapsed().as_millis());\n\n    Ok(())\n}\n\npub(crate) fn get_meta(conn: &Connection, key: &str) -> Option<String> {\n    conn.query_row(\n        \"SELECT value FROM meta WHERE key = ?1\",\n        params![key],\n        |row| row.get(0),\n    )\n    .ok()\n}\n\npub(crate) fn set_meta(conn: &Connection, key: &str, value: &str) -> AppResult<()> {\n    conn.execute(\n        \"INSERT OR REPLACE INTO meta(key, value) VALUES(?1, ?2)\",\n        params![key, value],\n    )\n    .map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn update_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let conn = db_connection(&state.db_path)?;\n\n    let entries_count = conn\n        .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| {\n            row.get::<_, i64>(0)\n        })\n        .map_err(|e| e.to_string())?\n        .max(0) as u64;\n\n    let last_updated = conn\n        .query_row(\"SELECT MAX(indexed_at) FROM entries\", [], |row| {\n            row.get::<_, Option<i64>>(0)\n        })\n        .map_err(|e| e.to_string())?;\n\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn update_status_counts(state: &AppState) -> AppResult<(u64, Option<i64>)> {\n    let (entries_count, last_updated) = update_counts(state)?;\n    let mut status = state.status.lock();\n    status.entries_count = entries_count;\n    status.last_updated = last_updated;\n    Ok((entries_count, last_updated))\n}\n\npub(crate) fn invalidate_search_caches(state: &AppState) {\n    state.fd_search_cache.lock().take();\n    state.negative_name_cache.lock().clear();\n}\n\nfn prune_negative_name_cache(cache: &mut HashMap<String, NegativeNameEntry>) {\n    let now = Instant::now();\n    cache.retain(|_, entry| now.duration_since(entry.created_at) <= NEGATIVE_CACHE_TTL);\n}\n\nfn negative_name_cache_lookup(state: &AppState, query: &str) -> Option<NegativeCacheHit> {\n    if query.is_empty() {\n        return None;\n    }\n    let q = query.to_lowercase();\n    let now = Instant::now();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n    cache\n        .iter()\n        .filter(|(key, _)| q.contains(key.as_str()))\n        .max_by_key(|(key, _)| key.len())\n        .map(|(key, entry)| NegativeCacheHit {\n            query_lower: key.clone(),\n            age: now.duration_since(entry.created_at),\n            fallback_checked: entry.fallback_checked,\n        })\n}\n\nfn remember_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    let mut cache = state.negative_name_cache.lock();\n    prune_negative_name_cache(&mut cache);\n\n    if cache.contains_key(&normalized) {\n        return;\n    }\n\n    cache.insert(\n        normalized,\n        NegativeNameEntry {\n            created_at: Instant::now(),\n            fallback_checked: false,\n        },\n    );\n    const MAX_NEGATIVE_CACHE: usize = 512;\n    if cache.len() > MAX_NEGATIVE_CACHE {\n        let mut entries: Vec<_> =\n            cache.iter().map(|(k, v)| (k.clone(), v.created_at)).collect();\n        entries.sort_by_key(|(_, t)| *t);\n        let drop_count = cache.len() - MAX_NEGATIVE_CACHE;\n        for (key, _) in entries.into_iter().take(drop_count) {\n            cache.remove(&key);\n        }\n    }\n}\n\nfn remove_negative_name_query(state: &AppState, query: &str) {\n    if query.is_empty() {\n        return;\n    }\n    let normalized = query.to_lowercase();\n    state.negative_name_cache.lock().remove(&normalized);\n}\n\nfn mark_negative_name_fallback_checked(state: &AppState, query_lower: &str) {\n    let mut cache = state.negative_name_cache.lock();\n    if let Some(entry) = cache.get_mut(query_lower) {\n        entry.fallback_checked = true;\n    }\n}\n\nfn sort_clause(sort_by: &str, sort_dir: &str, prefix: &str) -> String {\n    match (sort_by, sort_dir) {\n        (\"name\", \"desc\") => {\n            format!(\"{prefix}name COLLATE NOCASE DESC, {prefix}path COLLATE NOCASE DESC\")\n        }\n        (\"mtime\", \"asc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"mtime\", \"desc\") => {\n            format!(\"COALESCE({prefix}mtime, 0) DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"asc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"dir\", \"desc\") => {\n            format!(\"{prefix}dir COLLATE NOCASE DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"asc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size ASC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        (\"size\", \"desc\") => {\n            format!(\"{prefix}size IS NULL ASC, {prefix}size DESC, {prefix}name COLLATE NOCASE ASC\")\n        }\n        _ => format!(\"{prefix}name COLLATE NOCASE ASC, {prefix}path COLLATE NOCASE ASC\"),\n    }\n}\n\nfn contains_glob_meta(s: &str) -> bool {\n    s.contains('*') || s.contains('?')\n}\n\n/// Detect if a LIKE pattern is a pure extension filter (e.g. `%.rs`).\n/// Returns the lowercase extension if matched, None otherwise.\nfn extract_ext_from_like(like_pattern: &str) -> Option<String> {\n    let rest = like_pattern.strip_prefix('%')?;\n    let ext = rest.strip_prefix('.')?;\n    if ext.is_empty()\n        || ext.contains('%')\n        || ext.contains('_')\n        || ext.contains('\\\\')\n        || ext.contains('/')\n        || ext.contains('.')\n    {\n        return None;\n    }\n    Some(ext.to_lowercase())\n}\n\nfn normalize_hint_to_native(dir_hint: &str) -> (String, bool) {\n    let native = dir_hint.replace('/', &std::path::MAIN_SEPARATOR.to_string());\n    let is_abs = Path::new(&native).is_absolute();\n    (native, is_abs)\n}\n\nfn last_segment(dir_hint: &str) -> &str {\n    dir_hint\n        .rsplit(|c| c == '/' || c == '\\\\')\n        .find(|seg| !seg.is_empty())\n        .unwrap_or(dir_hint)\n}\n\nfn resolve_dir_hint(home_dir: &Path, dir_hint: &str) -> Option<PathBuf> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return None;\n    }\n\n    let candidate = if dir_hint == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = dir_hint.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n        if is_absolute {\n            PathBuf::from(native_hint)\n        } else {\n            home_dir.join(native_hint)\n        }\n    };\n\n    if candidate.is_dir() {\n        Some(candidate)\n    } else {\n        None\n    }\n}\n\nconst RESOLVE_DIRS_MAX: usize = 20;\n\nfn resolve_dirs_from_db(conn: &Connection, dir_hint: &str) -> Vec<String> {\n    if dir_hint.is_empty() || contains_glob_meta(dir_hint) {\n        return Vec::new();\n    }\n    let last_seg = last_segment(dir_hint);\n    let sep = std::path::MAIN_SEPARATOR;\n    let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n    let sep_str = sep.to_string();\n    let escaped_sep = escape_like(&sep_str);\n    let path_pattern = if is_absolute {\n        format!(\"%{}\", escape_like(&native_hint))\n    } else {\n        format!(\"%{escaped_sep}{}\", escape_like(&native_hint))\n    };\n    let fetch_limit = (RESOLVE_DIRS_MAX + 1) as i64;\n    let mut stmt = match conn.prepare(\n        \"SELECT path FROM entries WHERE name = ?1 COLLATE NOCASE AND is_dir = 1 AND path LIKE ?2 ESCAPE '\\\\' LIMIT ?3\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return Vec::new(),\n    };\n    let rows = match stmt.query_map(params![last_seg, path_pattern, fetch_limit], |row| {\n        row.get::<_, String>(0)\n    }) {\n        Ok(r) => r,\n        Err(_) => return Vec::new(),\n    };\n    let dirs: Vec<String> = rows.filter_map(|r| r.ok()).collect();\n    if dirs.len() > RESOLVE_DIRS_MAX {\n        return Vec::new();\n    }\n    dirs\n}\n\nfn normalize_slashes(s: String) -> String {\n    if s.contains('\\\\') { s.replace('\\\\', \"/\") } else { s }\n}\n\nfn resolve_ignore_path(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<PathBuf> {\n    let trimmed = raw.trim();\n    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n        return None;\n    }\n\n    let mut path = if trimmed == \"~\" {\n        home_dir.to_path_buf()\n    } else if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        home_dir.join(rest)\n    } else {\n        PathBuf::from(trimmed)\n    };\n\n    if !path.is_absolute() {\n        path = base_dir.join(path);\n    }\n\n    Some(fs::canonicalize(&path).unwrap_or(path))\n}\n\nfn normalize_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> String {\n    let trimmed = raw.trim().trim_end_matches('/').to_string();\n    if trimmed == \"~\" {\n        return normalize_slashes(home_dir.to_string_lossy().to_string());\n    }\n    if let Some(rest) = trimmed.strip_prefix(\"~/\") {\n        return normalize_slashes(home_dir.join(rest).to_string_lossy().to_string());\n    }\n    if trimmed.starts_with('/') || trimmed.starts_with(\"**/\") {\n        return trimmed;\n    }\n    normalize_slashes(base_dir.join(&trimmed).to_string_lossy().to_string())\n}\n\nfn parse_ignore_pattern(raw: &str, base_dir: &Path, home_dir: &Path) -> Option<IgnorePattern> {\n    let trimmed = raw.trim().trim_end_matches('/');\n    if trimmed.is_empty() {\n        return None;\n    }\n\n    if let Some(segment) = trimmed.strip_prefix(\"**/\") {\n        if !segment.is_empty() && !segment.contains('/') && !contains_glob_meta(segment) {\n            return Some(IgnorePattern::any_segment(segment));\n        }\n    }\n\n    Some(IgnorePattern::Glob(normalize_ignore_pattern(\n        trimmed, base_dir, home_dir,\n    )))\n}\n\nfn ignore_pattern_key(pattern: &IgnorePattern) -> String {\n    match pattern {\n        IgnorePattern::AnySegment { segment, .. } => format!(\"seg:{segment}\"),\n        IgnorePattern::Glob(glob) => format!(\"glob:{glob}\"),\n    }\n}\n\nfn find_file_upward(start: &Path, file_name: &str) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let candidate = dir.join(file_name);\n        if candidate.is_file() {\n            return Some(candidate);\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn find_git_root(start: &Path) -> Option<PathBuf> {\n    let mut current = Some(start);\n    while let Some(dir) = current {\n        let marker = dir.join(\".git\");\n        if marker.is_dir() || marker.is_file() {\n            return Some(dir.to_path_buf());\n        }\n        current = dir.parent();\n    }\n    None\n}\n\nfn load_pathignore_rules(home_dir: &Path, cwd: &Path) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut files = Vec::new();\n    if let Some(file) = find_file_upward(cwd, \".pathignore\") {\n        files.push(file);\n    } else {\n        files.push(cwd.join(\".pathignore\"));\n    }\n    let home_file = home_dir.join(\".pathignore\");\n    if !files.iter().any(|p| p == &home_file) {\n        files.push(home_file);\n    }\n\n    let mut roots = Vec::new();\n    let mut patterns = Vec::new();\n    let mut seen_roots = HashSet::new();\n    let mut seen_patterns = HashSet::new();\n\n    for file in files {\n        let Ok(contents) = fs::read_to_string(&file) else {\n            continue;\n        };\n        let base_dir = file.parent().unwrap_or_else(|| Path::new(\"/\"));\n        for line in contents.lines() {\n            let trimmed = line.trim();\n            if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n                continue;\n            }\n\n            if contains_glob_meta(trimmed) {\n                let Some(pattern) = parse_ignore_pattern(trimmed, base_dir, home_dir) else {\n                    continue;\n                };\n                let key = ignore_pattern_key(&pattern);\n                if seen_patterns.insert(key) {\n                    patterns.push(pattern);\n                }\n                continue;\n            }\n\n            let Some(path) = resolve_ignore_path(trimmed, base_dir, home_dir) else {\n                continue;\n            };\n\n            let key = path.to_string_lossy().to_string();\n            if seen_roots.insert(key) {\n                roots.push(path);\n            }\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn load_gitignore_roots(home_dir: &Path, cwd: &Path) -> Vec<PathBuf> {\n    let gitignore = if let Some(root) = find_git_root(cwd) {\n        root.join(\".gitignore\")\n    } else if let Some(file) = find_file_upward(&cwd, \".gitignore\") {\n        file\n    } else {\n        return Vec::new();\n    };\n    let contents = match fs::read_to_string(&gitignore) {\n        Ok(contents) => contents,\n        Err(_) => return Vec::new(),\n    };\n\n    let mut roots = Vec::new();\n    let mut seen = HashSet::new();\n\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with('!') {\n            continue;\n        }\n        if contains_glob_meta(trimmed) || trimmed.contains('[') {\n            continue;\n        }\n\n        let normalized = trimmed.trim_start_matches('/').trim_end_matches('/');\n        if normalized.is_empty() {\n            continue;\n        }\n\n        let Some(path) = resolve_ignore_path(normalized, &cwd, home_dir) else {\n            continue;\n        };\n\n        let key = path.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(path);\n        }\n    }\n\n    roots\n}\n\n#[cfg(target_os = \"macos\")]\nfn macos_tcc_ignore_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let library = home_dir.join(\"Library\");\n    let app_support = library.join(\"Application Support\");\n    let caches = library.join(\"Caches\");\n\n    let dirs: Vec<PathBuf> = vec![\n        home_dir.join(\".Trash\"),\n        library.join(\"Accounts\"),\n        library.join(\"AppleMediaServices\"),\n        library.join(\"Assistant\").join(\"SiriVocabulary\"),\n        library.join(\"Autosave Information\"),\n        library.join(\"Biome\"),\n        library.join(\"Calendars\"),\n        library.join(\"com.apple.aiml.instrumentation\"),\n        library.join(\"ContainerManager\"),\n        library.join(\"Cookies\"),\n        library.join(\"CoreFollowUp\"),\n        library.join(\"Daemon Containers\"),\n        library.join(\"DoNotDisturb\"),\n        library.join(\"DuetExpertCenter\"),\n        library.join(\"Group Containers\"),\n        library.join(\"HomeKit\"),\n        library.join(\"Developer\").join(\"Xcode\").join(\"DerivedData\"),\n        library.join(\"IdentityServices\"),\n        library.join(\"IntelligencePlatform\"),\n        library.join(\"Mail\"),\n        library.join(\"Messages\"),\n        library.join(\"Metadata\").join(\"CoreSpotlight\"),\n        library.join(\"PersonalizationPortrait\"),\n        library.join(\"Reminders\"),\n        library.join(\"Safari\"),\n        library.join(\"Sharing\"),\n        library.join(\"Shortcuts\"),\n        library.join(\"StatusKit\"),\n        library.join(\"Suggestions\"),\n        library.join(\"Trial\"),\n        library.join(\"Weather\"),\n        app_support.join(\"AddressBook\"),\n        app_support.join(\"CallHistoryDB\"),\n        app_support.join(\"CallHistoryTransactions\"),\n        app_support.join(\"CloudDocs\"),\n        app_support.join(\"com.apple.avfoundation\"),\n        app_support.join(\"com.apple.sharedfilelist\"),\n        app_support.join(\"com.apple.TCC\"),\n        app_support.join(\"DifferentialPrivacy\"),\n        app_support.join(\"FaceTime\"),\n        app_support.join(\"FileProvider\"),\n        app_support.join(\"Knowledge\"),\n        caches.join(\"CloudKit\"),\n        caches.join(\"com.apple.ap.adprivacyd\"),\n        caches.join(\"com.apple.containermanagerd\"),\n        caches.join(\"com.apple.findmy.fmfcore\"),\n        caches.join(\"com.apple.findmy.fmipcore\"),\n        caches.join(\"com.apple.homed\"),\n        caches.join(\"com.apple.HomeKit\"),\n        caches.join(\"com.apple.Safari\"),\n        caches.join(\"FamilyCircle\"),\n    ];\n\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn macos_tcc_ignore_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\n/// Directories under home that generate heavy background I/O on Windows\n/// (browser caches, Windows Update temp files, UWP package state, etc.).\n/// Pruning these from the MFT subtree eliminates noisy USN records.\n#[cfg(target_os = \"windows\")]\nfn windows_noisy_roots(home_dir: &Path) -> Vec<PathBuf> {\n    let local = home_dir.join(\"AppData\").join(\"Local\");\n    let dirs = vec![\n        local.join(\"Temp\"),\n        local.join(\"Microsoft\"),\n        local.join(\"Google\"),\n        local.join(\"Packages\"),\n        // C:\\ system directories (Windows is deferred, not excluded)\n        PathBuf::from(\"C:\\\\$Recycle.Bin\"),\n        PathBuf::from(\"C:\\\\System Volume Information\"),\n        PathBuf::from(\"C:\\\\Recovery\"),\n        PathBuf::from(\"C:\\\\PerfLogs\"),\n    ];\n    dirs.into_iter().filter(|p| p.exists()).collect()\n}\n\n#[cfg(not(target_os = \"windows\"))]\nfn windows_noisy_roots(_home_dir: &Path) -> Vec<PathBuf> {\n    Vec::new()\n}\n\npub(crate) fn effective_ignore_rules(\n    home_dir: &Path,\n    cwd: &Path,\n    base_roots: &[PathBuf],\n    base_patterns: &[IgnorePattern],\n) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let mut roots = base_roots.to_vec();\n    let mut patterns = base_patterns.to_vec();\n    let mut seen: HashSet<String> = roots\n        .iter()\n        .map(|p| p.to_string_lossy().to_string())\n        .collect();\n    let mut seen_patterns: HashSet<String> = patterns.iter().map(ignore_pattern_key).collect();\n\n    let (pathignore_roots, pathignore_patterns) = load_pathignore_rules(home_dir, cwd);\n    for root in pathignore_roots\n        .into_iter()\n        .chain(load_gitignore_roots(home_dir, cwd).into_iter())\n        .chain(macos_tcc_ignore_roots(home_dir).into_iter())\n        .chain(windows_noisy_roots(home_dir).into_iter())\n    {\n        let key = root.to_string_lossy().to_string();\n        if seen.insert(key) {\n            roots.push(root);\n        }\n    }\n\n    for pattern in pathignore_patterns\n        .into_iter()\n        .chain(builtin_ignore_patterns(home_dir))\n    {\n        let key = ignore_pattern_key(&pattern);\n        if seen_patterns.insert(key) {\n            patterns.push(pattern);\n        }\n    }\n\n    (roots, patterns)\n}\n\nfn builtin_ignore_patterns(home_dir: &Path) -> Vec<IgnorePattern> {\n    let home = normalize_slashes(home_dir.to_string_lossy().to_string());\n    vec![\n        // ~/Library/Application Support/*/Cache*\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Cache*\")),\n        // ~/Library/Application Support/*/Code Cache\n        IgnorePattern::Glob(format!(\"{home}/Library/Application Support/*/Code Cache\")),\n        // ~/.rustup/toolchains/*/share/doc\n        IgnorePattern::Glob(format!(\"{home}/.rustup/toolchains/*/share/doc\")),\n        // ~/.pyenv/versions/*/lib\n        IgnorePattern::Glob(format!(\"{home}/.pyenv/versions/*/lib\")),\n    ]\n}\n\npub(crate) fn cached_effective_ignore_rules(state: &AppState) -> (Vec<PathBuf>, Vec<IgnorePattern>) {\n    let home_dir = &state.home_dir;\n    let cwd = &state.cwd;\n\n    let pathignore_mtime = find_file_upward(cwd, \".pathignore\")\n        .or_else(|| Some(home_dir.join(\".pathignore\")))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let gitignore_mtime = find_git_root(cwd)\n        .map(|root| root.join(\".gitignore\"))\n        .or_else(|| find_file_upward(cwd, \".gitignore\"))\n        .and_then(|p| fs::metadata(&p).ok())\n        .and_then(|m| m.modified().ok());\n\n    let mut cache = state.ignore_cache.lock();\n    if let Some(ref cached) = *cache {\n        if cached.pathignore_mtime == pathignore_mtime && cached.gitignore_mtime == gitignore_mtime\n        {\n            return (cached.roots.clone(), cached.patterns.clone());\n        }\n    }\n\n    let (roots, patterns) = effective_ignore_rules(\n        home_dir,\n        cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n\n    *cache = Some(IgnoreRulesCache {\n        roots: roots.clone(),\n        patterns: patterns.clone(),\n        pathignore_mtime,\n        gitignore_mtime,\n    });\n\n    (roots, patterns)\n}\n\nfn ignore_rules_fingerprint(roots: &[PathBuf], patterns: &[IgnorePattern]) -> u64 {\n    let mut hasher = std::collections::hash_map::DefaultHasher::new();\n    for root in roots {\n        normalize_slashes(root.to_string_lossy().to_string()).hash(&mut hasher);\n    }\n    for pattern in patterns {\n        ignore_pattern_key(pattern).hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn purge_ignored_entries(db_path: &Path, ignored_roots: &[PathBuf]) -> AppResult<()> {\n    if ignored_roots.is_empty() {\n        return Ok(());\n    }\n\n    let conn = db_connection(db_path)?;\n    for root in ignored_roots {\n        let root_str = root.to_string_lossy().to_string();\n        if root_str.is_empty() {\n            continue;\n        }\n\n        if root_str == \"/\" {\n            conn.execute(\"DELETE FROM entries\", [])\n                .map_err(|e| e.to_string())?;\n            break;\n        }\n\n        let prefix = root_str.trim_end_matches('/');\n        let descendant_like = format!(\"{}%\", escape_like(&format!(\"{prefix}/\")));\n        conn.execute(\n            \"DELETE FROM entries WHERE path = ?1 OR path LIKE ?2 ESCAPE '\\\\'\",\n            params![prefix, descendant_like],\n        )\n        .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n\nfn glob_match_path(pattern: &str, text: &str) -> bool {\n    let pat = pattern.as_bytes();\n    let txt = text.as_bytes();\n    let (pn, tn) = (pat.len(), txt.len());\n\n    let mut px = 0usize;\n    let mut tx = 0usize;\n    let mut star_px = usize::MAX;\n    let mut star_tx = 0usize;\n    let mut star_is_double = false;\n\n    while tx < tn {\n        if px < pn && px + 1 < pn && pat[px] == b'*' && pat[px + 1] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = true;\n            px += 2;\n        } else if px < pn && pat[px] == b'*' {\n            star_px = px;\n            star_tx = tx;\n            star_is_double = false;\n            px += 1;\n        } else if px < pn && (pat[px] == b'?' && txt[tx] != b'/') {\n            px += 1;\n            tx += 1;\n        } else if px < pn && pat[px] == txt[tx] {\n            px += 1;\n            tx += 1;\n        } else if star_px != usize::MAX {\n            star_tx += 1;\n            if !star_is_double && txt[star_tx - 1] == b'/' {\n                return false;\n            }\n            px = if star_is_double {\n                star_px + 2\n            } else {\n                star_px + 1\n            };\n            tx = star_tx;\n        } else {\n            return false;\n        }\n    }\n\n    while px < pn && pat[px] == b'*' {\n        px += 1;\n    }\n\n    px == pn\n}\n\npub(crate) fn matches_ignore_pattern(path: &str, pattern: &IgnorePattern) -> bool {\n    match pattern {\n        IgnorePattern::AnySegment { suffix, infix, .. } => {\n            path.ends_with(suffix.as_str()) || path.contains(infix.as_str())\n        }\n        IgnorePattern::Glob(glob) => {\n            let mut cur = path;\n            loop {\n                if glob_match_path(glob, cur) {\n                    return true;\n                }\n\n                if cur == \"/\" {\n                    break;\n                }\n\n                let Some(pos) = cur.rfind('/') else {\n                    break;\n                };\n\n                cur = if pos == 0 { \"/\" } else { &cur[..pos] };\n            }\n            false\n        }\n    }\n}\n\npub(crate) fn should_skip_path(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> bool {\n    should_skip_path_ext(path, ignored_roots, ignored_patterns, None, None)\n}\n\npub(crate) fn should_skip_path_ext(\n    path: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    gitignore: Option<&gitignore_filter::GitignoreFilter>,\n    is_dir_hint: Option<bool>,\n) -> bool {\n    let s = normalize_slashes(path.to_string_lossy().to_string());\n\n    // Single-component builtin names: check path segments\n    if s.split('/').any(|seg| {\n        BUILTIN_SKIP_NAMES.contains(&seg)\n            || BUILTIN_SKIP_SUFFIXES.iter().any(|suf| seg.ends_with(suf))\n    }) {\n        return true;\n    }\n\n    // Multi-component builtin paths\n    if builtin_skip_path_checks()\n        .iter()\n        .any(|(infix, suffix)| s.contains(infix.as_str()) || s.ends_with(suffix.as_str()))\n    {\n        return true;\n    }\n\n    if ignored_roots\n        .iter()\n        .any(|root| path == root || path.starts_with(root))\n    {\n        return true;\n    }\n    if ignored_patterns\n        .iter()\n        .any(|pattern| matches_ignore_pattern(&s, pattern))\n    {\n        return true;\n    }\n    if let Some(gi) = gitignore {\n        let is_dir = is_dir_hint.unwrap_or_else(|| path.is_dir());\n        if gi.is_ignored(path, is_dir) {\n            return true;\n        }\n    }\n    false\n}\n\nfn extension_for(path: &Path, is_dir: bool) -> Option<String> {\n    if is_dir {\n        return None;\n    }\n\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.to_lowercase())\n}\n\npub(crate) fn index_row_from_path_and_metadata(path: &Path, metadata: &fs::Metadata) -> Option<IndexRow> {\n    let is_dir = metadata.is_dir();\n\n    let name = path\n        .file_name()\n        .map(|v| v.to_string_lossy().to_string())\n        .or_else(|| {\n            if path == Path::new(\"/\") {\n                Some(\"/\".to_string())\n            } else {\n                None\n            }\n        })?;\n\n    let dir = path\n        .parent()\n        .map(|p| p.to_string_lossy().to_string())\n        .unwrap_or_else(|| \"/\".to_string());\n\n    let mtime = metadata\n        .modified()\n        .ok()\n        .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n        .map(|d| d.as_secs() as i64);\n\n    let size = if metadata.is_file() {\n        Some(metadata.len() as i64)\n    } else {\n        None\n    };\n\n    Some(IndexRow {\n        path: path.to_string_lossy().to_string(),\n        name,\n        dir,\n        is_dir: if is_dir { 1 } else { 0 },\n        ext: extension_for(path, is_dir),\n        mtime,\n        size,\n        indexed_at: now_epoch(),\n        run_id: 0,\n    })\n}\n\nfn index_row_from_path(path: &Path) -> Option<IndexRow> {\n    let metadata = fs::symlink_metadata(path).ok()?;\n    index_row_from_path_and_metadata(path, &metadata)\n}\n\nfn index_row_from_walkdir_entry(entry: &walkdir::DirEntry) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(entry.path(), &metadata)\n}\n\nfn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {\n    let metadata = entry.metadata().ok()?;\n    index_row_from_path_and_metadata(&entry.path(), &metadata)\n}\n\nfn collect_rows_recursive(\n    root: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<IndexRow> {\n    let mut rows = Vec::new();\n\n    let iter = WalkDir::new(root)\n        .follow_links(false)\n        .into_iter()\n        .filter_entry(|entry| !should_skip_path(entry.path(), ignored_roots, ignored_patterns));\n\n    for entry in iter.flatten() {\n        if let Some(row) = index_row_from_walkdir_entry(&entry) {\n            rows.push(row);\n        }\n    }\n\n    rows\n}\n\nfn entry_from_index_row(row: IndexRow) -> EntryDto {\n    EntryDto {\n        path: row.path,\n        name: row.name,\n        dir: row.dir,\n        is_dir: row.is_dir == 1,\n        ext: row.ext,\n        size: row.size,\n        mtime: row.mtime,\n    }\n}\n\npub fn entry_from_path(path: &Path) -> Option<EntryDto> {\n    index_row_from_path(path).map(entry_from_index_row)\n}\n\nfn entry_cmp(a: &EntryDto, b: &EntryDto, sort_by: &str, sort_dir: &str) -> Ordering {\n    match sort_by {\n        \"mtime\" => {\n            let lhs = a.mtime.unwrap_or(0);\n            let rhs = b.mtime.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        \"dir\" => {\n            let lhs = a.dir.to_lowercase();\n            let rhs = b.dir.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name.to_lowercase().cmp(&b.name.to_lowercase())\n        }\n        \"size\" => {\n            let lhs = a.size.unwrap_or(0);\n            let rhs = b.size.unwrap_or(0);\n            let primary = if sort_dir == \"desc\" {\n                rhs.cmp(&lhs)\n            } else {\n                lhs.cmp(&rhs)\n            };\n            if primary != Ordering::Equal {\n                return primary;\n            }\n            a.name\n                .to_lowercase()\n                .cmp(&b.name.to_lowercase())\n                .then(a.path.to_lowercase().cmp(&b.path.to_lowercase()))\n        }\n        _ => {\n            let lhs_name = a.name.to_lowercase();\n            let rhs_name = b.name.to_lowercase();\n            let primary = if sort_dir == \"desc\" {\n                rhs_name.cmp(&lhs_name)\n            } else {\n                lhs_name.cmp(&rhs_name)\n            };\n\n            if primary != Ordering::Equal {\n                return primary;\n            }\n\n            let lhs_path = a.path.to_lowercase();\n            let rhs_path = b.path.to_lowercase();\n            if sort_dir == \"desc\" {\n                rhs_path.cmp(&lhs_path)\n            } else {\n                lhs_path.cmp(&rhs_path)\n            }\n        }\n    }\n}\n\nfn relevance_rank(entry: &EntryDto, query_lower: &str, path_suffix: &str) -> u8 {\n    if query_lower.is_empty() {\n        return 255;\n    }\n\n    let name = entry.name.to_lowercase();\n    let path = entry.path.to_lowercase();\n\n    if name == query_lower {\n        return 0;\n    }\n    if name.starts_with(query_lower) {\n        return 1;\n    }\n    if name.contains(query_lower) {\n        return 2;\n    }\n    if path.ends_with(path_suffix) {\n        return 3;\n    }\n    if path.contains(query_lower) {\n        return 4;\n    }\n\n    5\n}\n\nfn path_depth(path: &str) -> usize {\n    Path::new(path).components().count()\n}\n\npub fn sort_entries(entries: &mut Vec<EntryDto>, sort_by: &str, sort_dir: &str) {\n    entries.sort_by(|a, b| entry_cmp(a, b, sort_by, sort_dir));\n}\n\nfn sort_entries_with_relevance(\n    entries: &mut Vec<EntryDto>,\n    query: &str,\n    sort_by: &str,\n    sort_dir: &str,\n) {\n    let query_lower = query.trim().to_lowercase();\n    if query_lower.is_empty() {\n        sort_entries(entries, sort_by, sort_dir);\n        return;\n    }\n    let path_suffix = format!(\"/{query_lower}\");\n\n    entries.sort_by(|a, b| {\n        let ra = relevance_rank(a, &query_lower, &path_suffix);\n        let rb = relevance_rank(b, &query_lower, &path_suffix);\n        if ra != rb {\n            return ra.cmp(&rb);\n        }\n\n        // For highly-relevant matches, prefer shallower paths first\n        // so `~/name` ranks above deep descendants with the same name.\n        if ra <= 3 {\n            let da = path_depth(&a.path);\n            let db = path_depth(&b.path);\n            if da != db {\n                return da.cmp(&db);\n            }\n        }\n\n        entry_cmp(a, b, sort_by, sort_dir)\n    });\n}\n\nfn filter_ignored_entries(\n    entries: Vec<EntryDto>,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n) -> Vec<EntryDto> {\n    entries\n        .into_iter()\n        .filter(|entry| !should_skip_path(Path::new(&entry.path), ignored_roots, ignored_patterns))\n        .collect()\n}\n\nfn find_search(\n    home_dir: &Path,\n    ignored_roots: &[PathBuf],\n    ignored_patterns: &[IgnorePattern],\n    query: &str,\n    limit: usize,\n    sort_by: &str,\n    sort_dir: &str,\n) -> Vec<EntryDto> {\n    let trimmed = query.trim();\n    if trimmed.is_empty() || limit == 0 {\n        return Vec::new();\n    }\n\n    let mut search_root = home_dir.to_path_buf();\n    let mut dir_filter_pattern: Option<String> = None;\n    let mut name_filter_pattern: Option<String> = None;\n    let mut name_filter_glob = false;\n\n    if trimmed.contains('/') {\n        let last_slash = trimmed.rfind('/').unwrap();\n        let dir_part = trimmed[..last_slash].trim();\n        let name_part = trimmed[last_slash + 1..].trim();\n\n        if !dir_part.is_empty() {\n            let mut hinted = if dir_part == \"~\" {\n                Some(home_dir.to_path_buf())\n            } else if let Some(rest) = dir_part.strip_prefix(\"~/\") {\n                Some(home_dir.join(rest))\n            } else {\n                let p = PathBuf::from(dir_part);\n                if p.is_absolute() {\n                    Some(p)\n                } else if !dir_part.contains('*')\n                    && !dir_part.contains('?')\n                    && !dir_part.contains('[')\n                {\n                    Some(home_dir.join(dir_part))\n                } else {\n                    None\n                }\n            };\n\n            if let Some(path) = hinted.take() {\n                if path.exists() && path.is_dir() {\n                    search_root = path;\n                } else {\n                    dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n                }\n            } else {\n                dir_filter_pattern = Some(format!(\"*{}/*\", dir_part));\n            }\n        }\n\n        if !name_part.is_empty() {\n            if name_part.contains('*') || name_part.contains('?') {\n                name_filter_pattern = Some(name_part.to_string());\n                name_filter_glob = true;\n            } else {\n                name_filter_pattern = Some(format!(\"*{}*\", name_part));\n            }\n        }\n    } else if trimmed.contains('*') || trimmed.contains('?') {\n        name_filter_pattern = Some(trimmed.to_string());\n        name_filter_glob = true;\n    } else {\n        name_filter_pattern = Some(format!(\"*{}*\", trimmed));\n    }\n\n    let mut cmd = Command::new(\"find\");\n    cmd.arg(&search_root);\n\n    if search_root == home_dir {\n        cmd.args([\"-maxdepth\", \"8\"]);\n    }\n\n    if let Some(dir_pattern) = dir_filter_pattern.as_deref() {\n        cmd.args([\"-ipath\", dir_pattern]);\n    }\n    if let Some(name_pattern) = name_filter_pattern.as_deref() {\n        cmd.args([\"-iname\", name_pattern]);\n    }\n    if name_filter_glob {\n        cmd.args([\"-type\", \"f\"]);\n    }\n\n    cmd.args([\"!\", \"-path\", \"*/.git/*\"])\n        .args([\"!\", \"-path\", \"*/node_modules/*\"])\n        .args([\"!\", \"-path\", \"*/.Trash/*\"])\n        .args([\"!\", \"-path\", \"*/.Trashes/*\"])\n        .args([\"!\", \"-path\", \"*/Library/Caches/*\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::null());\n\n    let mut child = match cmd.spawn() {\n        Ok(c) => c,\n        Err(_) => return Vec::new(),\n    };\n\n    let stdout = match child.stdout.take() {\n        Some(s) => s,\n        None => return Vec::new(),\n    };\n\n    let reader = BufReader::new(stdout);\n    let mut entries = Vec::with_capacity(limit);\n\n    for line in reader.lines() {\n        let Ok(line) = line else { continue };\n        let path = PathBuf::from(&line);\n        if should_skip_path(&path, ignored_roots, ignored_patterns) {\n            continue;\n        }\n\n        if let Some(entry) = entry_from_path(&path) {\n            entries.push(entry);\n            if entries.len() >= limit {\n                break;\n            }\n        }\n    }\n\n    let _ = child.kill();\n    let _ = child.wait();\n\n    sort_entries_with_relevance(&mut entries, trimmed, sort_by, sort_dir);\n    entries\n}\n\npub(crate) fn upsert_rows(conn: &mut Connection, rows: &[IndexRow]) -> AppResult<usize> {\n    if rows.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\n                r#\"\n                INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                VALUES(?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)\n                ON CONFLICT(path) DO UPDATE SET\n                  name = excluded.name,\n                  dir = excluded.dir,\n                  is_dir = excluded.is_dir,\n                  ext = excluded.ext,\n                  mtime = excluded.mtime,\n                  size = excluded.size,\n                  indexed_at = excluded.indexed_at,\n                  run_id = excluded.run_id\n                \"#,\n            )\n            .map_err(|e| e.to_string())?;\n\n        for row in rows {\n            stmt.execute(params![\n                row.path,\n                row.name,\n                row.dir,\n                row.is_dir,\n                row.ext,\n                row.mtime,\n                row.size,\n                row.indexed_at,\n                row.run_id\n            ])\n            .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(rows.len())\n}\n\npub(crate) fn delete_paths(conn: &mut Connection, raw_paths: &[String]) -> AppResult<usize> {\n    if raw_paths.is_empty() {\n        return Ok(0);\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    let mut deleted = 0;\n\n    {\n        let mut stmt_exact = tx\n            .prepare(\"DELETE FROM entries WHERE path = ?1\")\n            .map_err(|e| e.to_string())?;\n        let mut stmt_children = tx\n            .prepare(\"DELETE FROM entries WHERE path >= ?1 AND path < ?2\")\n            .map_err(|e| e.to_string())?;\n\n        for path in raw_paths {\n            let is_root = path == \"/\" || path == \"\\\\\";\n            let normalized = if is_root {\n                path.clone()\n            } else {\n                path.trim_end_matches(&['/', '\\\\'][..]).to_string()\n            };\n\n            if normalized.is_empty() {\n                continue;\n            }\n\n            if is_root {\n                deleted += tx\n                    .execute(\"DELETE FROM entries\", [])\n                    .map_err(|e| e.to_string())?;\n                continue;\n            }\n\n            deleted += stmt_exact\n                .execute(params![&normalized])\n                .map_err(|e| e.to_string())?;\n\n            // Delete children using B-tree range scan: path >= \"{normalized}{sep}\" AND path < \"{normalized}\\x7F\"\n            // \\x7F (127) is higher than both '/' (47) and '\\' (92), so this captures all children.\n            let sep = std::path::MAIN_SEPARATOR;\n            let range_start = format!(\"{normalized}{sep}\");\n            let range_end = format!(\"{normalized}\\x7F\");\n            deleted += stmt_children\n                .execute(params![&range_start, &range_end])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(deleted)\n}\n\npub(crate) fn emit_index_state(app: &AppHandle, state: &str, message: Option<String>) {\n    let is_catchup = message.as_ref().map_or(false, |m| m.starts_with(\"Catchup:\"));\n    let _ = app.emit(\n        \"index_state\",\n        IndexStateEvent {\n            state: state.to_string(),\n            message,\n            is_catchup,\n        },\n    );\n}\n\npub(crate) fn emit_index_updated(\n    app: &AppHandle,\n    entries_count: u64,\n    last_updated: i64,\n    permission_errors: u64,\n) {\n    let _ = app.emit(\n        \"index_updated\",\n        IndexUpdatedEvent {\n            entries_count,\n            last_updated,\n            permission_errors,\n        },\n    );\n}\n\npub(crate) fn emit_index_progress(app: &AppHandle, scanned: u64, indexed: u64, current_path: String) {\n    let _ = app.emit(\n        \"index_progress\",\n        IndexProgressEvent {\n            scanned,\n            indexed,\n            current_path,\n        },\n    );\n}\n\npub(crate) fn set_state(state: &AppState, next: IndexState, message: Option<String>) {\n    let mut status = state.status.lock();\n    status.state = next;\n    status.message = message;\n}\n\npub(crate) fn set_progress(state: &AppState, scanned: u64, indexed: u64, current_path: &str) {\n    let mut status = state.status.lock();\n    status.scanned = scanned;\n    status.indexed = indexed;\n    status.current_path = current_path.to_string();\n}\n\nfn emit_status_counts(app: &AppHandle, state: &AppState) {\n    let status = state.status.lock();\n    emit_index_updated(\n        app,\n        status.entries_count,\n        status.last_updated.unwrap_or_else(now_epoch),\n        status.permission_errors,\n    );\n}\n\npub(crate) fn refresh_and_emit_status_counts(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts so next startup can read them instantly\n    if let Ok(conn) = db_connection(&state.db_path) {\n        let _ = set_meta(&conn, \"cached_entries_count\", &entries_count.to_string());\n        if let Some(lu) = last_updated {\n            let _ = set_meta(&conn, \"cached_last_updated\", &lu.to_string());\n        }\n    }\n    emit_status_counts(app, state);\n    Ok(())\n}\n\n/// Load cached entries count from meta table (instant) and emit Ready state + counts.\n/// Used on Windows startup paths where the index is already complete from a prior run.\n#[cfg(target_os = \"windows\")]\npub(crate) fn set_ready_with_cached_counts(app: &AppHandle, state: &AppState) {\n    let (count, last_updated) = db_connection(&state.db_path)\n        .ok()\n        .map(|conn| {\n            let c = get_meta(&conn, \"cached_entries_count\")\n                .and_then(|v| v.parse::<u64>().ok())\n                .unwrap_or(0);\n            let lu = get_meta(&conn, \"cached_last_updated\")\n                .and_then(|v| v.parse::<i64>().ok());\n            (c, lu)\n        })\n        .unwrap_or((0, None));\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.entries_count = count;\n        status.last_updated = last_updated;\n    }\n\n    emit_index_state(app, \"Ready\", None);\n    emit_index_updated(app, count, last_updated.unwrap_or_else(now_epoch), 0);\n}\n\n#[cfg(target_os = \"macos\")]\nfn touch_status_updated(state: &AppState) {\n    state.status.lock().last_updated = Some(now_epoch());\n}\n\n#[cfg(not(target_os = \"windows\"))]\npub(crate) fn start_full_index_worker(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, false)\n}\n\n#[cfg(target_os = \"windows\")]\npub(crate) fn start_full_index_worker_silent(app: AppHandle, state: AppState) -> AppResult<()> {\n    start_full_index_worker_inner(app, state, true)\n}\n\nfn start_full_index_worker_inner(app: AppHandle, state: AppState, silent: bool) -> AppResult<()> {\n    if state\n        .indexing_active\n        .compare_exchange(false, true, AtomicOrdering::AcqRel, AtomicOrdering::Acquire)\n        .is_err()\n    {\n        perf_log(\"index_start_skipped already_active=true\");\n        return Ok(());\n    }\n\n    // Mark index as incomplete -- cleared when run_incremental_index succeeds\n    if let Ok(c) = db_connection(&state.db_path) {\n        let _ = set_meta(&c, \"index_complete\", \"0\");\n    }\n\n    if !silent {\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        emit_index_state(&app, \"Indexing\", None);\n        perf_log(\"index_state=Indexing\");\n    } else {\n        perf_log(\"index_start silent=true (background reindex)\");\n    }\n\n    std::thread::spawn(move || {\n        let result = run_incremental_index(&app, &state);\n        if let Err(ref err) = result {\n            eprintln!(\"[index] run_incremental_index failed: {err}\");\n            if !silent {\n                set_state(&state, IndexState::Error, Some(err.clone()));\n                emit_index_state(&app, \"Error\", Some(err.clone()));\n            }\n            // Silent mode: keep Ready state, just log the error\n        }\n        state.indexing_active.store(false, AtomicOrdering::Release);\n    });\n\n    Ok(())\n}\n\nfn is_deferred_dir(path: &Path, home_dir: &Path) -> bool {\n    path.parent() == Some(home_dir)\n        && path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .map(|name| DEFERRED_DIR_NAMES.contains(&name))\n            .unwrap_or(false)\n}\n\nfn preload_existing_entries(\n    conn: &Connection,\n    dir_prefix: &str,\n) -> HashMap<String, (Option<i64>, Option<i64>)> {\n    let like_pattern = format!(\"{}/%\", escape_like(dir_prefix));\n    let mut stmt = match conn.prepare(\n        \"SELECT path, mtime, size FROM entries WHERE path LIKE ?1 ESCAPE '\\\\' OR path = ?2\",\n    ) {\n        Ok(s) => s,\n        Err(_) => return HashMap::new(),\n    };\n\n    let mut map = HashMap::new();\n    let rows = match stmt.query_map(params![like_pattern, dir_prefix], |row| {\n        Ok((\n            row.get::<_, String>(0)?,\n            row.get::<_, Option<i64>>(1)?,\n            row.get::<_, Option<i64>>(2)?,\n        ))\n    }) {\n        Ok(r) => r,\n        Err(_) => return map,\n    };\n\n    for row in rows.flatten() {\n        map.insert(row.0, (row.1, row.2));\n    }\n    map\n}\n\nfn stamp_run_id_batch(conn: &mut Connection, paths: &[String], run_id: i64) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    let tx = conn.transaction().map_err(|e| e.to_string())?;\n    {\n        let mut stmt = tx\n            .prepare(\"UPDATE entries SET run_id = ?1 WHERE path = ?2\")\n            .map_err(|e| e.to_string())?;\n        for path in paths {\n            stmt.execute(params![run_id, path])\n                .map_err(|e| e.to_string())?;\n        }\n    }\n    tx.commit().map_err(|e| e.to_string())?;\n    Ok(())\n}\n\nfn run_incremental_index(app: &AppHandle, state: &AppState) -> AppResult<()> {\n    let started = Instant::now();\n    perf_log(format!(\n        \"index_run_start home={} db={}\",\n        state.home_dir.to_string_lossy(),\n        state.db_path.to_string_lossy(),\n    ));\n\n    let mut conn = db_connection(&state.db_path)?;\n    set_indexing_pragmas(&conn)?;\n\n    // For fresh index (empty DB), drop secondary indexes before bulk insert and\n    // recreate them after. This avoids per-row BTREE maintenance on every insert,\n    // which can be 3-5x faster when loading hundreds of thousands of rows.\n    let is_fresh_run: bool = get_meta(&conn, \"last_run_id\")\n        .and_then(|v| v.parse::<i64>().ok())\n        .unwrap_or(0)\n        == 0;\n    if is_fresh_run {\n        let _ = conn.execute_batch(\n            \"DROP INDEX IF EXISTS idx_entries_dir_ext_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_mtime;\n             DROP INDEX IF EXISTS idx_entries_name_nocase;\n             DROP INDEX IF EXISTS idx_entries_ext_name;\",\n        );\n    }\n\n    let result = run_incremental_index_inner(app, state, &mut conn);\n\n    if is_fresh_run {\n        let t_idx = Instant::now();\n        let _ = conn.execute_batch(\n            \"CREATE INDEX IF NOT EXISTS idx_entries_dir_ext_name_nocase ON entries(dir, ext, name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_mtime ON entries(mtime);\n             CREATE INDEX IF NOT EXISTS idx_entries_name_nocase ON entries(name COLLATE NOCASE);\n             CREATE INDEX IF NOT EXISTS idx_entries_ext_name ON entries(ext, name COLLATE NOCASE);\",\n        );\n        eprintln!(\"[timing] create_indexes {}ms\", t_idx.elapsed().as_millis());\n    }\n\n    let t_analyze = Instant::now();\n    let _ = conn.execute_batch(\"ANALYZE\");\n    eprintln!(\"[timing] analyze {}ms\", t_analyze.elapsed().as_millis());\n    let t_checkpoint = Instant::now();\n    let _ = restore_normal_pragmas(&conn);\n    eprintln!(\"[timing] checkpoint {}ms\", t_checkpoint.elapsed().as_millis());\n\n    match &result {\n        Ok(_) => {\n            let _ = set_meta(&conn, \"index_complete\", \"1\");\n            let snapshot = state.status.lock().clone();\n            perf_log(format!(\n                \"index_run_done elapsed_ms={} scanned={} indexed={} entries={} permission_errors={} message={:?}\",\n                started.elapsed().as_millis(),\n                snapshot.scanned,\n                snapshot.indexed,\n                snapshot.entries_count,\n                snapshot.permission_errors,\n                snapshot.message,\n            ));\n        }\n        Err(err) => {\n            perf_log(format!(\n                \"index_run_error elapsed_ms={} err={}\",\n                started.elapsed().as_millis(),\n                err,\n            ));\n        }\n    }\n\n    result\n}\n\nfn run_incremental_index_inner(\n    app: &AppHandle,\n    state: &AppState,\n    conn: &mut Connection,\n) -> AppResult<()> {\n\n    let (runtime_ignored_roots, runtime_ignored_patterns) = effective_ignore_rules(\n        &state.home_dir,\n        &state.cwd,\n        state.path_ignores.as_ref(),\n        state.path_ignore_patterns.as_ref(),\n    );\n    let gi_filter = state.gitignore.get();\n\n    let last_run_id: i64 = get_meta(conn, \"last_run_id\")\n        .and_then(|v| v.parse().ok())\n        .unwrap_or(0);\n    let current_run_id = last_run_id + 1;\n    // Fresh index: DB was empty, skip preload/stamp, single unlimited-depth pass\n    let is_fresh = last_run_id == 0;\n\n    // Fresh index has no secondary indexes to maintain, so we can use larger\n    // batches to reduce transaction overhead (fewer commits = faster).\n    let flush_batch_size = if is_fresh { BATCH_SIZE * 5 } else { BATCH_SIZE };\n\n    let mut scanned: u64 = 0;\n    let mut indexed: u64 = 0;\n    let mut permission_errors: u64 = 0;\n    let mut current_path = String::new();\n    let mut batch: Vec<IndexRow> = Vec::with_capacity(flush_batch_size);\n    let mut stamp_batch: Vec<String> = Vec::with_capacity(flush_batch_size);\n    let mut last_emit = Instant::now();\n    let mut last_perf_emit = Instant::now();\n\n    // Preload scan_root-level entries (direct children only, not recursive)\n    let scan_str = state.scan_root.to_string_lossy().to_string();\n    let root_existing = preload_existing_entries(conn, &scan_str);\n\n    // Index scan_root itself\n    if let Some(mut row) = index_row_from_path(&state.scan_root) {\n        scanned += 1;\n        row.run_id = current_run_id;\n        if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n            if *old_mtime == row.mtime && *old_size == row.size {\n                stamp_batch.push(row.path);\n            } else {\n                batch.push(row);\n            }\n        } else {\n            batch.push(row);\n        }\n    }\n\n    // Partition direct children into priority vs deferred\n    let mut priority_roots: Vec<PathBuf> = Vec::new();\n    let mut deferred_roots: Vec<PathBuf> = Vec::new();\n\n    if let Ok(entries) = fs::read_dir(&state.scan_root) {\n        for dir_entry in entries.flatten() {\n            let child_path = dir_entry.path();\n\n            if should_skip_path_ext(\n                &child_path,\n                &runtime_ignored_roots,\n                &runtime_ignored_patterns,\n                Some(&gi_filter),\n                None,\n            ) {\n                continue;\n            }\n\n            scanned += 1;\n            current_path = child_path.to_string_lossy().to_string();\n\n            if let Some(mut row) = index_row_from_path(&child_path) {\n                row.run_id = current_run_id;\n                if let Some((old_mtime, old_size)) = root_existing.get(&row.path) {\n                    if *old_mtime == row.mtime && *old_size == row.size {\n                        stamp_batch.push(row.path);\n                    } else {\n                        batch.push(row);\n                    }\n                } else {\n                    batch.push(row);\n                }\n            }\n\n            if child_path.is_dir() {\n                if is_deferred_dir(&child_path, &state.scan_root) {\n                    deferred_roots.push(child_path);\n                } else {\n                    priority_roots.push(child_path);\n                }\n            }\n        }\n    }\n\n\n    // Flush home-level stamp batch\n    if stamp_batch.len() >= flush_batch_size {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n        stamp_batch.clear();\n    }\n\n    priority_roots.sort();\n    deferred_roots.sort();\n\n    let roots: Vec<PathBuf> = priority_roots.into_iter().chain(deferred_roots).collect();\n    perf_log(format!(\n        \"index_scan_roots total={} priority+deferred\",\n        roots.len()\n    ));\n\n    // 2-pass indexing: shallow first (depth <= SHALLOW_SCAN_DEPTH), then deep\n    // Both passes use jwalk for parallel scanning\n    let arc_ignored_roots = Arc::new(runtime_ignored_roots.clone());\n    let arc_ignored_patterns = Arc::new(runtime_ignored_patterns.clone());\n\n\n    for pass in 0..2u8 {\n        // Fresh index: single unlimited-depth pass -- avoids double filesystem traversal\n        if pass == 1 && is_fresh {\n            break;\n        }\n        let pass_label = if pass == 0 { \"shallow\" } else { \"deep\" };\n        let pass_started = Instant::now();\n        let mut pass_scanned = 0u64;\n        let mut pass_indexed = 0u64;\n\n        for root in &roots {\n            let root_started = Instant::now();\n            let mut root_scanned = 0u64;\n            let mut root_indexed = 0u64;\n            let mut root_permission_errors = 0u64;\n            let root_str = root.to_string_lossy().to_string();\n\n            // Fresh index: DB is empty, preload is unnecessary\n            let existing = if is_fresh {\n                HashMap::new()\n            } else {\n                let e = preload_existing_entries(conn, &root_str);\n                e\n            };\n\n            let gi_ref = gi_filter.clone();\n            let skip_roots = arc_ignored_roots.clone();\n            let skip_patterns = arc_ignored_patterns.clone();\n\n            // Use more threads for fresh index: stat() calls are the bottleneck,\n            // more rayon threads = more parallel stat() calls.\n            let num_threads = if is_fresh { jwalk_num_threads_fresh() } else { jwalk_num_threads() };\n            let current_pass = pass;\n            let mut builder = jwalk::WalkDirGeneric::<((), Option<fs::Metadata>)>::new(root)\n                .follow_links(false)\n                .skip_hidden(false)\n                .parallelism(jwalk::Parallelism::RayonNewPool(num_threads));\n            // Fresh index: no depth limit -- walk everything in one pass\n            if pass == 0 && !is_fresh {\n                builder = builder.max_depth(SHALLOW_SCAN_DEPTH);\n            }\n            let walker = builder.process_read_dir(move |_depth, path, _state, children| {\n                // Combined filter + metadata pre-fetch in one pass using retain_mut.\n                // Running stat() here parallelizes it across rayon threads (one per directory).\n                children.retain_mut(|entry_result| {\n                    match entry_result {\n                        Ok(entry) => {\n                            let full_path = path.join(&entry.file_name);\n                            let is_dir = Some(entry.file_type.is_dir());\n                            if should_skip_path_ext(\n                                &full_path,\n                                &skip_roots,\n                                &skip_patterns,\n                                Some(&gi_ref),\n                                is_dir,\n                            ) {\n                                return false;\n                            }\n                            // Pre-fetch metadata in rayon thread (avoids serial stat() on\n                            // main thread). Skip for pass-1 shallow entries that will be\n                            // discarded in the main loop anyway.\n                            if current_pass != 1 || entry.depth > SHALLOW_SCAN_DEPTH {\n                                entry.client_state = fs::symlink_metadata(&full_path).ok();\n                            }\n                            true\n                        }\n                        Err(_) => false,\n                    }\n                });\n            });\n\n            for result in walker {\n                match result {\n                    Ok(entry) => {\n                        let entry_depth = entry.depth;\n                        let path = entry.path();\n                        if path == root.as_path() {\n                            continue;\n                        }\n\n                        // Pass 1 (incremental only): skip shallow entries already indexed in pass 0\n                        if pass == 1 && entry_depth <= SHALLOW_SCAN_DEPTH {\n                            continue;\n                        }\n\n                        scanned += 1;\n                        root_scanned += 1;\n                        current_path = path.to_string_lossy().to_string();\n\n                        // Use metadata pre-fetched in rayon thread; fall back to stat on failure.\n                        let metadata = match entry.client_state {\n                            Some(m) => m,\n                            None => {\n                                // pre-fetch failed (permission error or race condition)\n                                permission_errors += 1;\n                                root_permission_errors += 1;\n                                continue;\n                            }\n                        };\n\n                        if let Some(mut row) = index_row_from_path_and_metadata(&path, &metadata) {\n                            row.run_id = current_run_id;\n                            if is_fresh {\n                                // Fresh index: all entries are new, skip existing check\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            } else if let Some((old_mtime, old_size)) = existing.get(&row.path) {\n                                if *old_mtime == row.mtime && *old_size == row.size {\n                                    stamp_batch.push(row.path);\n                                } else {\n                                    indexed += 1;\n                                    root_indexed += 1;\n                                    batch.push(row);\n                                }\n                            } else {\n                                indexed += 1;\n                                root_indexed += 1;\n                                batch.push(row);\n                            }\n                        }\n\n                        if batch.len() >= flush_batch_size {\n                            upsert_rows(conn, &batch)?;\n                            batch.clear();\n                        }\n\n                        if stamp_batch.len() >= flush_batch_size {\n                            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n                            stamp_batch.clear();\n                        }\n\n                        if last_emit.elapsed() >= Duration::from_millis(200) {\n                            set_progress(state, scanned, indexed, &current_path);\n                            emit_index_progress(app, scanned, indexed, current_path.clone());\n                            last_emit = Instant::now();\n                        }\n                        if perf_log_enabled() && last_perf_emit.elapsed() >= Duration::from_secs(1)\n                        {\n                            perf_log(format!(\n                                \"index_progress pass={} scanned={} indexed={} current_path={}\",\n                                pass_label, scanned, indexed, current_path\n                            ));\n                            last_perf_emit = Instant::now();\n                        }\n                    }\n                    Err(err) => {\n                        scanned += 1;\n                        root_scanned += 1;\n                        permission_errors += 1;\n                        root_permission_errors += 1;\n                        if permission_errors <= 20 || perf_log_enabled() {\n                            eprintln!(\"[index] permission error: {}\", err);\n                        }\n                    }\n                }\n            }\n\n            pass_scanned += root_scanned;\n            pass_indexed += root_indexed;\n\n            eprintln!(\"[timing]   walk_{} {} {}ms scanned={} indexed={} err={}\",\n                pass_label, root_str, root_started.elapsed().as_millis(),\n                root_scanned, root_indexed, root_permission_errors);\n            perf_log(format!(\n                \"index_root_done pass={} root={} elapsed_ms={} scanned={} indexed={} permission_errors={}\",\n                pass_label,\n                root.to_string_lossy(),\n                root_started.elapsed().as_millis(),\n                root_scanned,\n                root_indexed,\n                root_permission_errors,\n            ));\n        }\n\n        // Flush between passes\n        if !batch.is_empty() {\n            upsert_rows(conn, &batch)?;\n            batch.clear();\n        }\n        if !stamp_batch.is_empty() {\n            stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n            stamp_batch.clear();\n        }\n\n        perf_log(format!(\n            \"index_pass_done pass={} elapsed_ms={} scanned={} indexed={}\",\n            pass_label,\n            pass_started.elapsed().as_millis(),\n            pass_scanned,\n            pass_indexed,\n        ));\n\n        // After shallow pass (incremental only), emit progress so UI shows searchable state early\n        // Fresh index uses per-root emit above instead.\n        if pass == 0 && !is_fresh {\n            let _ = refresh_and_emit_status_counts(app, state);\n            let _ = app.emit(\n                \"index_updated\",\n                IndexUpdatedEvent {\n                    entries_count: state.status.lock().entries_count,\n                    last_updated: now_epoch(),\n                    permission_errors,\n                },\n            );\n        }\n    }\n\n    if !batch.is_empty() {\n        upsert_rows(conn, &batch)?;\n    }\n\n    if !stamp_batch.is_empty() {\n        stamp_run_id_batch(conn, &stamp_batch, current_run_id)?;\n    }\n\n    set_progress(state, scanned, indexed, &current_path);\n    emit_index_progress(app, scanned, indexed, current_path.clone());\n\n    // Remove entries not seen in this run (deleted files)\n    // Fresh index: DB was empty before this run, no stale entries possible\n    let deleted_count: i64 = if is_fresh {\n        0\n    } else {\n        let count = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE run_id < ?1\",\n                params![current_run_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n        conn.execute(\n            \"DELETE FROM entries WHERE run_id < ?1\",\n            params![current_run_id],\n        )\n        .map_err(|e| e.to_string())?;\n        count\n    };\n\n    set_meta(conn, \"last_run_id\", &current_run_id.to_string())?;\n\n    if deleted_count > 0 || indexed > 0 {\n        invalidate_search_caches(state);\n    }\n\n    let (entries_count, last_updated) = update_status_counts(state)?;\n    // Persist cached counts for instant startup next time\n    let _ = set_meta(conn, \"cached_entries_count\", &entries_count.to_string());\n    if let Some(lu) = last_updated {\n        let _ = set_meta(conn, \"cached_last_updated\", &lu.to_string());\n    }\n    let updated_at = last_updated.unwrap_or_else(now_epoch);\n\n    {\n        let mut status = state.status.lock();\n        status.state = IndexState::Ready;\n        status.permission_errors = permission_errors;\n        status.scanned = scanned;\n        status.indexed = indexed;\n        status.current_path = current_path.clone();\n        status.message = if permission_errors > 0 {\n            Some(format!(\n                \"{} permission/access error(s) occurred.\",\n                permission_errors\n            ))\n        } else {\n            None\n        };\n    }\n    emit_index_progress(app, scanned, indexed, current_path);\n    emit_index_updated(app, entries_count, updated_at, permission_errors);\n    emit_index_state(\n        app,\n        \"Ready\",\n        if permission_errors > 0 {\n            Some(format!(\"{} permission/access error(s)\", permission_errors))\n        } else {\n            None\n        },\n    );\n    perf_log(format!(\n        \"index_state=Ready scanned={} indexed={} deleted={} entries={} permission_errors={}\",\n        scanned, indexed, deleted_count, entries_count, permission_errors\n    ));\n\n    Ok(())\n}\n\nfn trim_recent_ops(ops: &mut Vec<RecentOp>) {\n    let now = Instant::now();\n    ops.retain(|op| now.duration_since(op.at) <= RECENT_OP_TTL);\n}\n\nfn remember_op(\n    state: &AppState,\n    op_type: &'static str,\n    old_path: Option<String>,\n    new_path: Option<String>,\n) {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n    ops.push(RecentOp {\n        old_path,\n        new_path,\n        op_type,\n        at: Instant::now(),\n    });\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"windows\"))]\npub(crate) fn is_recently_touched(state: &AppState, path: &str) -> bool {\n    let mut ops = state.recent_ops.lock();\n    trim_recent_ops(&mut ops);\n\n    ops.iter().any(|op| match op.op_type {\n        \"rename\" | \"trash\" => {\n            op.old_path\n                .as_deref()\n                .map(|old| old == path)\n                .unwrap_or(false)\n                || op\n                    .new_path\n                    .as_deref()\n                    .map(|new| new == path)\n                    .unwrap_or(false)\n        }\n        _ => false,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn apply_path_changes(state: &AppState, paths: &[PathBuf]) -> AppResult<usize> {\n    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(state);\n    let mut to_upsert_map: HashMap<String, IndexRow> = HashMap::new();\n    let mut to_delete = Vec::new();\n\n    for path in paths {\n        if should_skip_path(path, &ignored_roots, &ignored_patterns) {\n            continue;\n        }\n\n        let path_str = path.to_string_lossy().to_string();\n        if path_str.is_empty() {\n            continue;\n        }\n\n        if is_recently_touched(state, &path_str) {\n            continue;\n        }\n\n        match fs::symlink_metadata(path) {\n            Ok(metadata) => {\n                if let Some(row) = index_row_from_path_and_metadata(path, &metadata) {\n                    to_upsert_map.insert(row.path.clone(), row);\n                }\n            }\n            Err(_) => {\n                to_delete.push(path_str);\n            }\n        }\n    }\n\n    let to_upsert = to_upsert_map.into_values().collect::<Vec<_>>();\n\n    if to_upsert.is_empty() && to_delete.is_empty() {\n        return Ok(0);\n    }\n\n    let op_start = std::time::Instant::now();\n    let mut conn = db_connection(&state.db_path).map_err(|e| {\n        eprintln!(\n            \"[watcher] db_connection FAILED after {}ms: {} (upsert={} delete={} indexing_active={})\",\n            op_start.elapsed().as_millis(),\n            e,\n            to_upsert.len(),\n            to_delete.len(),\n            state.indexing_active.load(AtomicOrdering::Acquire)\n        );\n        e\n    })?;\n    let mut changed = 0;\n\n    changed += upsert_rows(&mut conn, &to_upsert)?;\n    changed += delete_paths(&mut conn, &to_delete)?;\n\n    Ok(changed)\n}\n\n#[cfg(target_os = \"macos\")]\nconst STATUS_EMIT_MIN_INTERVAL: Duration = Duration::from_secs(2);\n\n#[cfg(target_os = \"macos\")]\nconst DB_BUSY_RETRY_DELAY: Duration = Duration::from_secs(3);\n\n#[cfg(target_os = \"macos\")]\nfn process_watcher_paths(\n    app: &AppHandle,\n    state: &AppState,\n    pending: &mut HashSet<PathBuf>,\n    deadline: &mut Option<Instant>,\n    last_status_emit: &mut Instant,\n    pending_status_emit: &mut bool,\n) {\n    if pending.is_empty() {\n        return;\n    }\n\n    if state.indexing_active.load(AtomicOrdering::Acquire) {\n        return;\n    }\n\n    let mut batch: Vec<PathBuf> = pending.drain().collect();\n    batch.sort();\n\n    match apply_path_changes(state, &batch) {\n        Ok(changed) => {\n            *deadline = None;\n            if changed > 0 {\n                invalidate_search_caches(state);\n                touch_status_updated(state);\n                if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                    let _ = refresh_and_emit_status_counts(app, state);\n                    *last_status_emit = Instant::now();\n                    *pending_status_emit = false;\n                } else {\n                    *pending_status_emit = true;\n                }\n            }\n        }\n        Err(err) => {\n            let is_busy = err.contains(\"locked\") || err.contains(\"busy\");\n            if is_busy {\n                eprintln!(\n                    \"[watcher] DB busy, will retry in {}s: {} | batch_size={}\",\n                    DB_BUSY_RETRY_DELAY.as_secs(),\n                    err,\n                    batch.len()\n                );\n                for path in batch {\n                    pending.insert(path);\n                }\n                *deadline = Some(Instant::now() + DB_BUSY_RETRY_DELAY);\n                return;\n            }\n            eprintln!(\n                \"[watcher] process_watcher_paths ERROR: {} | batch_size={} indexing_active={}\",\n                err,\n                batch.len(),\n                state.indexing_active.load(AtomicOrdering::Acquire)\n            );\n            *deadline = None;\n            if state.indexing_active.load(AtomicOrdering::Acquire) {\n                return;\n            }\n            let mut status = state.status.lock();\n            if !matches!(status.state, IndexState::Indexing) {\n                status.state = IndexState::Error;\n            }\n            status.message = Some(format!(\"Watcher update failed: {err}\"));\n            drop(status);\n            emit_index_state(app, \"Error\", Some(format!(\"Watcher update failed: {err}\")));\n        }\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nconst EVENT_ID_FLUSH_INTERVAL: Duration = Duration::from_secs(30);\n\n#[cfg(target_os = \"macos\")]\nfn persist_event_id(db_path: &Path, event_id: u64) -> AppResult<()> {\n    let conn = db_connection(db_path)?;\n    set_meta(&conn, \"last_event_id\", &event_id.to_string())\n}\n\n#[cfg(target_os = \"macos\")]\nconst MUST_SCAN_THRESHOLD: usize = 10;\n\n#[cfg(target_os = \"macos\")]\nfn start_fsevent_watcher_worker(\n    app: AppHandle,\n    state: AppState,\n    since_event_id: Option<u64>,\n    conditional: bool,\n) {\n    use std::sync::mpsc::{self, RecvTimeoutError};\n    std::thread::spawn(move || {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher =\n            match mac::fsevent_watcher::FsEventWatcher::new(&state.home_dir, since_event_id, tx) {\n                Ok(w) => w,\n                Err(err) => {\n                    set_state(\n                        &state,\n                        IndexState::Error,\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    emit_index_state(\n                        &app,\n                        \"Error\",\n                        Some(format!(\"FSEvents watcher initialization failed: {err}\")),\n                    );\n                    return;\n                }\n            };\n\n        if conditional {\n            perf_log(\"conditional_startup: watcher started, awaiting history replay\");\n            set_state(&state, IndexState::Ready, None);\n            emit_index_state(&app, \"Ready\", None);\n        }\n\n        let mut pending_paths: HashSet<PathBuf> = HashSet::new();\n        let mut deadline: Option<Instant> = None;\n        let mut last_flush = Instant::now();\n        let mut last_status_emit = Instant::now();\n        let mut pending_status_emit = false;\n        let mut last_count_refresh = Instant::now();\n        let mut must_scan_count: usize = 0;\n        let mut replay_phase = conditional;\n        let mut full_scan_triggered = false;\n\n        loop {\n            let wait = match deadline {\n                Some(due) => {\n                    let now = Instant::now();\n                    if now >= due {\n                        Duration::from_millis(0)\n                    } else {\n                        due - now\n                    }\n                }\n                None => Duration::from_secs(1),\n            };\n            match rx.recv_timeout(wait) {\n                Ok(mac::fsevent_watcher::FsEvent::Paths(paths)) => {\n                    let (ignored_roots, ignored_patterns) = cached_effective_ignore_rules(&state);\n                    let prev_len = pending_paths.len();\n                    for path in paths {\n                        if !should_skip_path(&path, &ignored_roots, &ignored_patterns) {\n                            pending_paths.insert(path);\n                        }\n                    }\n                    if pending_paths.len() > prev_len {\n                        deadline = Some(Instant::now() + WATCH_DEBOUNCE);\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::MustScanSubDirs(path)) => {\n                    must_scan_count += 1;\n                    if replay_phase\n                        && must_scan_count >= MUST_SCAN_THRESHOLD\n                        && !full_scan_triggered\n                    {\n                        perf_log(format!(\n                            \"conditional_startup: MustScanSubDirs={} >= threshold, triggering full scan\",\n                            must_scan_count\n                        ));\n                        full_scan_triggered = true;\n                        let _ = start_full_index_worker(app.clone(), state.clone());\n                    }\n                    if !state.indexing_active.load(AtomicOrdering::Acquire) {\n                        let (ignored_roots, ignored_patterns) =\n                            cached_effective_ignore_rules(&state);\n                        let rows = collect_rows_recursive(&path, &ignored_roots, &ignored_patterns);\n                        if !rows.is_empty() {\n                            eprintln!(\n                                \"[watcher] MustScanSubDirs DB write: rows={} path={}\",\n                                rows.len(),\n                                path.display()\n                            );\n                            if let Ok(mut conn) = db_connection(&state.db_path) {\n                                if upsert_rows(&mut conn, &rows).is_ok() {\n                                    invalidate_search_caches(&state);\n                                    touch_status_updated(&state);\n                                    if last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                                        let _ = refresh_and_emit_status_counts(&app, &state);\n                                        last_status_emit = Instant::now();\n                                        pending_status_emit = false;\n                                    } else {\n                                        pending_status_emit = true;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Ok(mac::fsevent_watcher::FsEvent::HistoryDone) => {\n                    eprintln!(\n                        \"[watcher] HistoryDone: pending_paths={} indexing_active={}\",\n                        pending_paths.len(),\n                        state.indexing_active.load(AtomicOrdering::Acquire)\n                    );\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                    if replay_phase {\n                        replay_phase = false;\n                        if !full_scan_triggered {\n                            perf_log(format!(\n                                \"conditional_startup: HistoryDone, MustScanSubDirs={}, skipping full scan\",\n                                must_scan_count\n                            ));\n                            let _ = refresh_and_emit_status_counts(&app, &state);\n                            last_status_emit = Instant::now();\n                            pending_status_emit = false;\n                        }\n                    }\n                }\n                Err(RecvTimeoutError::Timeout) => {}\n                Err(RecvTimeoutError::Disconnected) => break,\n            }\n\n            if let Some(due) = deadline {\n                if Instant::now() >= due {\n                    process_watcher_paths(\n                        &app,\n                        &state,\n                        &mut pending_paths,\n                        &mut deadline,\n                        &mut last_status_emit,\n                        &mut pending_status_emit,\n                    );\n                }\n            }\n\n            if pending_status_emit && last_status_emit.elapsed() >= STATUS_EMIT_MIN_INTERVAL {\n                let _ = refresh_and_emit_status_counts(&app, &state);\n                last_status_emit = Instant::now();\n                pending_status_emit = false;\n            }\n\n            // Periodic event_id flush\n            if last_flush.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let eid = watcher.last_event_id();\n                let _ = persist_event_id(&state.db_path, eid);\n                last_flush = Instant::now();\n            }\n\n            // Periodic count refresh to keep in-memory counts accurate\n            if last_count_refresh.elapsed() >= EVENT_ID_FLUSH_INTERVAL {\n                let _ = update_status_counts(&state);\n                last_count_refresh = Instant::now();\n            }\n        }\n\n        // Final flush on shutdown\n        let eid = watcher.last_event_id();\n        let _ = persist_event_id(&state.db_path, eid);\n        watcher.stop();\n    });\n}\n\nfn validate_new_name(new_name: &str) -> AppResult<String> {\n    let trimmed = new_name.trim();\n\n    if trimmed.is_empty() {\n        return Err(\"New name cannot be empty.\".to_string());\n    }\n    if trimmed.contains('/') {\n        return Err(\"New name cannot contain '/'.\".to_string());\n    }\n    if trimmed == \".\" || trimmed == \"..\" {\n        return Err(\"Invalid name.\".to_string());\n    }\n\n    Ok(trimmed.to_string())\n}\n\nfn row_to_entry(row: &rusqlite::Row<'_>) -> rusqlite::Result<EntryDto> {\n    Ok(EntryDto {\n        path: row.get(0)?,\n        name: row.get(1)?,\n        dir: row.get(2)?,\n        is_dir: row.get::<_, i64>(3)? == 1,\n        ext: row.get(4)?,\n        size: row.get(5)?,\n        mtime: row.get(6)?,\n    })\n}\n\n#[cfg(target_os = \"macos\")]\nfn safe_file_type(ext: &str) -> String {\n    if ext.eq_ignore_ascii_case(\"folder\") {\n        return \"public.folder\".to_string();\n    }\n\n    let filtered: String = ext\n        .chars()\n        .filter(|c| c.is_ascii_alphanumeric())\n        .collect::<String>()\n        .to_lowercase();\n\n    if filtered.is_empty() {\n        \"public.data\".to_string()\n    } else {\n        filtered\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    let file_type = safe_file_type(ext);\n    let script = format!(\n        r#\"import AppKit\nimport Foundation\nlet image = NSWorkspace.shared.icon(forFileType: \"{file_type}\")\nimage.size = NSSize(width: 16, height: 16)\nif let tiff = image.tiffRepresentation,\n   let rep = NSBitmapImageRep(data: tiff),\n   let png = rep.representation(using: .png, properties: [:]) {{\n  FileHandle.standardOutput.write(png)\n}} else {{\n  exit(1)\n}}\n\"#\n    );\n\n    let output = Command::new(\"swift\").arg(\"-e\").arg(script).output().ok()?;\n    if output.status.success() && !output.stdout.is_empty() {\n        Some(output.stdout)\n    } else {\n        None\n    }\n}\n\n#[cfg(target_os = \"windows\")]\nfn load_system_icon_png(ext: &str) -> Option<Vec<u8>> {\n    win::icon::load_icon_png_by_ext(ext)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\nfn load_system_icon_png(_ext: &str) -> Option<Vec<u8>> {\n    None\n}\n\n#[cfg(target_os = \"windows\")]\nfn is_per_file_icon_ext(ext: &str) -> bool {\n    matches!(ext, \"exe\" | \"lnk\" | \"ico\" | \"url\" | \"scr\" | \"appx\")\n}\n\n#[tauri::command]\nfn get_index_status(state: State<'_, AppState>) -> IndexStatusDto {\n    let started = Instant::now();\n    let snapshot = state.status.lock().clone();\n    let snapshot_state = snapshot.state.as_str().to_string();\n    let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n    let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n    let state_label = if matches!(snapshot.state, IndexState::Error) {\n        snapshot.state.as_str().to_string()\n    } else if matches!(snapshot.state, IndexState::Ready) {\n        \"Ready\".to_string()\n    } else if indexing_active || !db_ready {\n        \"Indexing\".to_string()\n    } else {\n        snapshot.state.as_str().to_string()\n    };\n    let dto = IndexStatusDto {\n        state: state_label,\n        entries_count: snapshot.entries_count,\n        last_updated: snapshot.last_updated,\n        permission_errors: snapshot.permission_errors,\n        message: snapshot.message,\n        scanned: snapshot.scanned,\n        indexed: snapshot.indexed,\n        current_path: snapshot.current_path,\n    };\n    if cfg!(debug_assertions) {\n        eprintln!(\n            \"[rpc/get_index_status] elapsed={}ms state={} snapshot_state={} db_ready={} indexing_active={} entries={} scanned={} indexed={}\",\n            started.elapsed().as_millis(),\n            dto.state,\n            snapshot_state,\n            db_ready,\n            indexing_active,\n            dto.entries_count,\n            dto.scanned,\n            dto.indexed,\n        );\n    }\n    dto\n}\n\n#[tauri::command]\nfn get_home_dir(state: State<'_, AppState>) -> String {\n    state.home_dir.to_string_lossy().to_string()\n}\n\n#[tauri::command]\nfn start_full_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    #[cfg(target_os = \"windows\")]\n    {\n        win::start_windows_indexing(app, state.inner().clone());\n        Ok(())\n    }\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        start_full_index_worker(app, state.inner().clone())\n    }\n}\n\n#[tauri::command]\nasync fn reset_index(app: AppHandle, state: State<'_, AppState>) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        if state.indexing_active.load(AtomicOrdering::Acquire) {\n            return Err(\"Cannot reset while indexing is in progress.\".to_string());\n        }\n\n        // Stop existing file watcher and wait for it to fully exit\n        state.watcher_stop.store(true, AtomicOrdering::Release);\n        let deadline = std::time::Instant::now() + std::time::Duration::from_secs(5);\n        while state.watcher_active.load(AtomicOrdering::Acquire) {\n            if std::time::Instant::now() >= deadline {\n                eprintln!(\"[reset] watcher did not stop within 5s, proceeding anyway\");\n                break;\n            }\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n\n        let conn = db_connection(&state.db_path)?;\n        // Use synchronous=OFF + large cache to make the bulk DELETE fast\n        let _ = conn.execute_batch(\n            \"PRAGMA synchronous=OFF; PRAGMA cache_size=-131072;\",\n        );\n        conn.execute(\"DELETE FROM entries\", [])\n            .map_err(|e| e.to_string())?;\n        conn.execute(\"DELETE FROM meta\", [])\n            .map_err(|e| e.to_string())?;\n\n        {\n            let mut status = state.status.lock();\n            status.state = IndexState::Indexing;\n            status.entries_count = 0;\n            status.last_updated = None;\n            status.permission_errors = 0;\n            status.message = None;\n            status.scanned = 0;\n            status.indexed = 0;\n            status.current_path.clear();\n        }\n\n        invalidate_search_caches(&state);\n\n        emit_index_state(&app, \"Indexing\", None);\n        emit_index_updated(&app, 0, now_epoch(), 0);\n\n        // Allow new watcher to start\n        state.watcher_stop.store(false, AtomicOrdering::Release);\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app, state);\n            Ok(())\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        {\n            start_full_index_worker(app, state)\n        }\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn log_search(db_path: &Path, query: &str, mode: &str, results: &[EntryDto]) {\n    if !search_log_enabled() {\n        return;\n    }\n\n    let log_path = db_path.with_file_name(\"search.log\");\n    let Ok(mut f) = fs::OpenOptions::new()\n        .create(true)\n        .append(true)\n        .open(&log_path)\n    else {\n        return;\n    };\n    let top: Vec<&str> = results.iter().take(10).map(|e| e.name.as_str()).collect();\n    let _ = writeln!(\n        f,\n        \"[{}] Q={:?} MODE={} COUNT={} TOP={:?}\",\n        now_epoch(),\n        query,\n        mode,\n        results.len(),\n        top,\n    );\n}\n\nfn search_log_enabled() -> bool {\n    *SEARCH_LOG_ENABLED.get_or_init(|| env_truthy(\"FASTFIND_SEARCH_LOG\"))\n}\n\n/// Returns the total number of entries matching `query` without LIMIT/OFFSET.\n/// Returns `None` when the total is unknown or intentionally skipped.\nfn compute_total_count(\n    db_path: &Path,\n    home_dir: &Path,\n    execution: &SearchExecution,\n) -> Option<u32> {\n    // When fewer results than the limit were returned the total is exact.\n    if (execution.results.len() as u32) < execution.effective_limit {\n        return Some(\n            execution\n                .offset\n                .saturating_add(execution.results.len() as u32),\n        );\n    }\n    // For paginated pages after the first we leave total tracking to the frontend.\n    if execution.offset > 0 {\n        return None;\n    }\n    // Non-SQL fast paths already return all matching entries.\n    if execution.mode_label.starts_with(\"mem_\")\n        || execution.mode_label == \"spotlight\"\n        || execution.mode_label == \"spotlight_timeout\"\n        || execution.mode_label == \"find_fallback\"\n        || execution.mode_label == \"name_neg_cache\"\n    {\n        return Some(execution.results.len() as u32);\n    }\n    let Ok(conn) = db_connection_for_search(db_path) else {\n        return None;\n    };\n    let mode = parse_query(&execution.query);\n    let total = match mode {\n        SearchMode::Empty => conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |r| r.get(0))\n            .unwrap_or(0),\n        SearchMode::NameSearch { name_like } => {\n            let escaped = escape_like(&execution.query);\n            let prefix_like = format!(\"{}%\", escaped);\n            let prefix_count: u32 = conn\n                .query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![prefix_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0);\n            if prefix_count > 0 {\n                prefix_count\n            } else {\n                // Phase-2 contains fallback was used.\n                conn.query_row(\n                    \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                    params![name_like],\n                    |r| r.get(0),\n                )\n                .unwrap_or(0)\n            }\n        }\n        SearchMode::GlobName { name_like } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE name LIKE ?1 ESCAPE '\\\\'\",\n                params![name_like],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::ExtSearch { ext, .. } => conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entries WHERE ext = ?1\",\n                params![ext],\n                |r| r.get(0),\n            )\n            .unwrap_or(0),\n        SearchMode::PathSearch {\n            name_like,\n            dir_hint,\n            ..\n        } => {\n            let resolved_dirs = resolve_dir_hint(home_dir, &dir_hint)\n                .map(|p| vec![p.to_string_lossy().to_string()])\n                .unwrap_or_default();\n            let resolved_dirs = if resolved_dirs.is_empty() {\n                resolve_dirs_from_db(&conn, &dir_hint)\n            } else {\n                resolved_dirs\n            };\n\n            if !resolved_dirs.is_empty() {\n                let mut sql_params: Vec<SqlValue> = Vec::new();\n                let mut dir_conditions = Vec::new();\n                let sep = std::path::MAIN_SEPARATOR;\n                for d in &resolved_dirs {\n                    let i = sql_params.len();\n                    let pfx = format!(\"{d}{sep}\");\n                    let pfx_end = format!(\"{d}\\x7F\");\n                    sql_params.push(SqlValue::Text(d.clone()));\n                    sql_params.push(SqlValue::Text(pfx));\n                    sql_params.push(SqlValue::Text(pfx_end));\n                    dir_conditions.push(format!(\n                        \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                        i + 1,\n                        i + 2,\n                        i + 3\n                    ));\n                }\n                let dir_where = dir_conditions.join(\" OR \");\n                let name_filter = if name_like == \"%\" {\n                    String::new()\n                } else {\n                    let ext_shortcut = extract_ext_from_like(&name_like);\n                    if let Some(ext_val) = ext_shortcut {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(ext_val));\n                        format!(\" AND e.ext = ?{}\", i + 1)\n                    } else {\n                        let i = sql_params.len();\n                        sql_params.push(SqlValue::Text(name_like.clone()));\n                        format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                    }\n                };\n                let sql =\n                    format!(\"SELECT COUNT(*) FROM entries e WHERE ({dir_where}){name_filter}\");\n                conn.query_row(&sql, params_from_iter(sql_params.iter()), |r| r.get(0))\n                    .unwrap_or(0)\n            } else {\n                let sep = std::path::MAIN_SEPARATOR;\n                let native_hint = dir_hint.replace('/', &sep.to_string());\n                let escaped_sep = escape_like(&sep.to_string());\n                let dir_suffix = escape_like(&native_hint);\n                let dir_like_exact = format!(\"%{escaped_sep}{dir_suffix}\");\n                let dir_like_sub = format!(\"%{escaped_sep}{dir_suffix}{escaped_sep}%\");\n                let ext_shortcut = extract_ext_from_like(&name_like);\n                if let Some(ext_val) = ext_shortcut {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.ext = ?1 AND (e.dir LIKE ?2 ESCAPE '\\\\' OR e.dir LIKE ?3 ESCAPE '\\\\')\",\n                        params![ext_val, dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else if name_like == \"%\" {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                } else {\n                    conn.query_row(\n                        \"SELECT COUNT(*) FROM entries e WHERE (e.dir LIKE ?1 ESCAPE '\\\\' OR e.dir LIKE ?2 ESCAPE '\\\\') AND e.name LIKE ?3 ESCAPE '\\\\'\",\n                        params![dir_like_exact, dir_like_sub, name_like],\n                        |r| r.get(0),\n                    )\n                    .unwrap_or(0)\n                }\n            }\n        }\n    };\n\n    Some(total)\n}\n\nfn execute_search(\n    state: &AppState,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n) -> AppResult<SearchExecution> {\n    let query = query.trim().to_string();\n    let base_limit = limit.unwrap_or(DEFAULT_LIMIT).clamp(1, MAX_LIMIT);\n    let effective_limit = if !query.is_empty() && query.chars().count() <= 1 {\n        base_limit.min(SHORT_QUERY_LIMIT)\n    } else {\n        base_limit\n    };\n    let offset = offset.unwrap_or(0);\n\n    let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n    let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n    let (runtime_ignored_roots, runtime_ignored_patterns) = cached_effective_ignore_rules(state);\n\n    #[cfg(target_os = \"macos\")]\n    if !state.db_ready.load(AtomicOrdering::Acquire) {\n        let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n        let mode_label = if spotlight.entries.is_empty() {\n            \"db_not_ready\".to_string()\n        } else if spotlight.timed_out {\n            \"spotlight_timeout\".to_string()\n        } else {\n            \"spotlight\".to_string()\n        };\n        perf_log(format!(\n            \"spotlight_fallback db_not_ready query={:?} results={} timed_out={}\",\n            query,\n            spotlight.entries.len(),\n            spotlight.timed_out\n        ));\n        return Ok(SearchExecution {\n            query,\n            sort_by,\n            sort_dir,\n            effective_limit,\n            offset,\n            mode_label,\n            results: spotlight.entries,\n        });\n    }\n\n    let is_indexing = matches!(state.status.lock().state, IndexState::Indexing);\n    let order_by = sort_clause(&sort_by, &sort_dir, \"e.\");\n\n    let mut results = Vec::with_capacity(effective_limit as usize);\n    let mode = parse_query(&query);\n    let is_name_mode = matches!(&mode, SearchMode::NameSearch { .. });\n    let allow_find_fallback = !is_indexing\n        && matches!(\n            &mode,\n            SearchMode::GlobName { .. } | SearchMode::ExtSearch { .. }\n        );\n    let mut mode_label = match &mode {\n        SearchMode::Empty => \"empty\",\n        SearchMode::NameSearch { .. } => \"name\",\n        SearchMode::GlobName { .. } => \"glob\",\n        SearchMode::ExtSearch { .. } => \"ext\",\n        SearchMode::PathSearch { .. } => \"path\",\n    }\n    .to_string();\n\n    // Fast path: search in-memory index if available (DB upsert still in progress)\n    {\n        let guard = state.mem_index.read();\n        if let Some(ref mi) = *guard {\n            let mem_results = mem_search::search_mem_index(\n                mi, &query, &mode, effective_limit, offset, &sort_by, &sort_dir,\n            );\n            mode_label = format!(\"mem_{mode_label}\");\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label,\n                results: mem_results,\n            });\n        }\n    }\n\n    if is_name_mode && !is_indexing && offset == 0 {\n        if let Some(cache_hit) = negative_name_cache_lookup(state, &query) {\n            if cache_hit.age >= WATCH_DEBOUNCE\n                && cache_hit.age <= NEGATIVE_CACHE_FALLBACK_WINDOW\n                && !cache_hit.fallback_checked\n            {\n                let fallback_results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                if !fallback_results.is_empty() {\n                    remove_negative_name_query(state, &cache_hit.query_lower);\n                    perf_log(format!(\n                        \"search_negative_cache_fallback_hit query={:?} age_ms={} results={}\",\n                        query,\n                        cache_hit.age.as_millis(),\n                        fallback_results.len()\n                    ));\n                    return Ok(SearchExecution {\n                        query,\n                        sort_by,\n                        sort_dir,\n                        effective_limit,\n                        offset,\n                        mode_label: \"find_fallback\".to_string(),\n                        results: fallback_results,\n                    });\n                }\n                mark_negative_name_fallback_checked(state, &cache_hit.query_lower);\n            }\n\n            perf_log(format!(\n                \"search_negative_cache_hit query={:?} age_ms={}\",\n                query,\n                cache_hit.age.as_millis()\n            ));\n            return Ok(SearchExecution {\n                query,\n                sort_by,\n                sort_dir,\n                effective_limit,\n                offset,\n                mode_label: \"name_neg_cache\".to_string(),\n                results: Vec::new(),\n            });\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    let db_unavailable;\n    match db_connection_for_search(&state.db_path) {\n        Ok(conn) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = false; }\n            match &mode {\n                SearchMode::Empty => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        ORDER BY {order_by}\n                        LIMIT ?1 OFFSET ?2\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::NameSearch { name_like } => {\n                    let escaped_query = escape_like(&query);\n                    let exact_query = query.clone();\n                    let prefix_like = format!(\"{}%\", escaped_query);\n                    let bare_order = sort_clause(&sort_by, &sort_dir, \"\");\n\n                    if offset == 0 {\n                        let exact_sql = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name COLLATE NOCASE = ?1\n                            ORDER BY {bare_order}\n                            LIMIT ?2\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&exact_sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params![exact_query, effective_limit], row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if (results.len() as u32) < effective_limit {\n                        let remaining = effective_limit - results.len() as u32;\n                        let adj_offset = if offset > 0 {\n                            offset.saturating_sub(results.len() as u32)\n                        } else {\n                            0\n                        };\n\n                        // Try indexed prefix search first; fall back to unindexed if\n                        // the index is temporarily unavailable (during background DB\n                        // rebuild the index may be dropped then recreated).\n                        let prefix_sql_indexed = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries INDEXED BY idx_entries_name_nocase\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let prefix_sql_fallback = format!(\n                            r#\"\n                            SELECT path, name, dir, is_dir, ext, size, mtime\n                            FROM entries\n                            WHERE name LIKE ?1 ESCAPE '\\'\n                              AND name COLLATE NOCASE != ?2\n                            ORDER BY {bare_order}\n                            LIMIT ?3 OFFSET ?4\n                            \"#,\n                        );\n                        let mut stmt = match conn.prepare(&prefix_sql_indexed) {\n                            Ok(s) => s,\n                            Err(_) => {\n                                eprintln!(\"[search] idx_entries_name_nocase unavailable, using fallback\");\n                                conn.prepare(&prefix_sql_fallback).map_err(|e| e.to_string())?\n                            }\n                        };\n                        let rows = stmt\n                            .query_map(\n                                params![prefix_like, exact_query, remaining, adj_offset],\n                                row_to_entry,\n                            )\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    }\n\n                    if results.is_empty() && offset == 0 {\n                        // Phase 2: contains-match (LIKE '%q%') with tight time budget.\n                        // Combines probe + fetch in one pass to avoid double scan overhead.\n                        let phase2_start = Instant::now();\n                        conn.progress_handler(\n                            2_000,\n                            Some(move || phase2_start.elapsed().as_millis() > 5),\n                        );\n\n                        {\n\n                            let phase2_sql = format!(\n                                r#\"\n                                SELECT path, name, dir, is_dir, ext, size, mtime\n                                FROM entries\n                                WHERE name LIKE ?1 ESCAPE '\\'\n                                  AND name COLLATE NOCASE != ?2\n                                  AND name NOT LIKE ?3 ESCAPE '\\'\n                                ORDER BY {bare_order}\n                                LIMIT ?4\n                                \"#,\n                            );\n                            if let Ok(mut stmt2) = conn.prepare(&phase2_sql) {\n                                if let Ok(rows2) = stmt2.query_map(\n                                    params![name_like, exact_query, prefix_like, effective_limit],\n                                    row_to_entry,\n                                ) {\n                                    for row in rows2 {\n                                        match row {\n                                            Ok(entry) => results.push(entry),\n                                            Err(_) => break,\n                                        }\n                                    }\n                                }\n                            }\n                        }\n\n                        conn.progress_handler(0, None::<fn() -> bool>);\n                    }\n                }\n\n                SearchMode::GlobName { name_like } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![name_like, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::ExtSearch { ext, name_like: _ } => {\n                    let sql = format!(\n                        r#\"\n                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                        FROM entries e\n                        WHERE e.ext = ?1\n                        ORDER BY {order_by}\n                        LIMIT ?2 OFFSET ?3\n                        \"#,\n                    );\n                    let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                    let rows = stmt\n                        .query_map(params![ext, effective_limit, offset], row_to_entry)\n                        .map_err(|e| e.to_string())?;\n                    for row in rows {\n                        results.push(row.map_err(|e| e.to_string())?);\n                    }\n                }\n\n                SearchMode::PathSearch {\n                    path_like: _,\n                    name_like,\n                    dir_hint,\n                } => {\n                    let resolved_dirs: Vec<String> = resolve_dir_hint(&state.home_dir, dir_hint)\n                        .map(|p| vec![p.to_string_lossy().to_string()])\n                        .unwrap_or_default();\n                    let resolved_dirs = if resolved_dirs.is_empty() {\n                        resolve_dirs_from_db(&conn, dir_hint)\n                    } else {\n                        resolved_dirs\n                    };\n\n                    if !resolved_dirs.is_empty() {\n                        let ext_shortcut = extract_ext_from_like(name_like);\n                        let mut sql_params: Vec<SqlValue> = Vec::new();\n                        let mut dir_conditions = Vec::new();\n                        let sep = std::path::MAIN_SEPARATOR;\n\n                        for d in &resolved_dirs {\n                            let i = sql_params.len();\n                            let pfx = format!(\"{d}{sep}\");\n                            let pfx_end = format!(\"{d}\\x7F\");\n                            sql_params.push(SqlValue::Text(d.clone()));\n                            sql_params.push(SqlValue::Text(pfx));\n                            sql_params.push(SqlValue::Text(pfx_end));\n                            dir_conditions.push(format!(\n                                \"(e.dir = ?{} OR (e.dir >= ?{} AND e.dir < ?{}))\",\n                                i + 1,\n                                i + 2,\n                                i + 3\n                            ));\n                        }\n                        let dir_where = dir_conditions.join(\" OR \");\n\n                        let name_filter = if name_like == \"%\" {\n                            String::new()\n                        } else if let Some(ref ext_val) = ext_shortcut {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(ext_val.clone()));\n                            format!(\" AND e.ext = ?{}\", i + 1)\n                        } else {\n                            let i = sql_params.len();\n                            sql_params.push(SqlValue::Text(name_like.clone()));\n                            format!(\" AND e.name LIKE ?{} ESCAPE '\\\\'\", i + 1)\n                        };\n\n                        let limit_idx = sql_params.len() + 1;\n                        let offset_idx = sql_params.len() + 2;\n                        sql_params.push(SqlValue::Integer(effective_limit as i64));\n                        sql_params.push(SqlValue::Integer(offset as i64));\n\n                        let sql = format!(\n                            r#\"\n                            SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                            FROM entries e\n                            WHERE ({dir_where}){name_filter}\n                            ORDER BY {order_by}\n                            LIMIT ?{limit_idx} OFFSET ?{offset_idx}\n                            \"#,\n                        );\n                        let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                        let rows = stmt\n                            .query_map(params_from_iter(sql_params.iter()), row_to_entry)\n                            .map_err(|e| e.to_string())?;\n                        for row in rows {\n                            results.push(row.map_err(|e| e.to_string())?);\n                        }\n                    } else {\n                        let sep = std::path::MAIN_SEPARATOR;\n                        let sep_str = sep.to_string();\n                        let escaped_sep = escape_like(&sep_str);\n                        let (native_hint, is_absolute) = normalize_hint_to_native(dir_hint);\n                        let dir_suffix = escape_like(&native_hint);\n                        let dir_prefix = if is_absolute {\n                            String::new()\n                        } else {\n                            escaped_sep.clone()\n                        };\n                        let dir_like_exact = format!(\"%{dir_prefix}{dir_suffix}\");\n                        let dir_like_sub = format!(\"%{dir_prefix}{dir_suffix}{escaped_sep}%\");\n                        let ext_shortcut = extract_ext_from_like(name_like);\n\n                        if let Some(ext_val) = ext_shortcut {\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.ext = ?1\n                                  AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                ORDER BY {order_by}\n                                LIMIT ?4 OFFSET ?5\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![\n                                        ext_val,\n                                        dir_like_exact,\n                                        dir_like_sub,\n                                        effective_limit,\n                                        offset\n                                    ],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else if name_like == \"%\" {\n                            // Directory listing: no name filter needed, no time budget\n                            let sql = format!(\n                                r#\"\n                                SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                FROM entries e\n                                WHERE e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\'\n                                ORDER BY {order_by}\n                                LIMIT ?3 OFFSET ?4\n                                \"#,\n                            );\n                            let mut stmt = conn.prepare(&sql).map_err(|e| e.to_string())?;\n                            let rows = stmt\n                                .query_map(\n                                    params![dir_like_exact, dir_like_sub, effective_limit, offset],\n                                    row_to_entry,\n                                )\n                                .map_err(|e| e.to_string())?;\n                            for row in rows {\n                                results.push(row.map_err(|e| e.to_string())?);\n                            }\n                        } else {\n                            // Phase A: fast prefix search via name index\n                            // \"%main%\" -> strip leading '%' -> \"main%\" can use idx_entries_name_nocase\n                            let prefix_like = if name_like.starts_with('%') {\n                                let rest = &name_like[1..];\n                                if !rest.is_empty() && !rest.starts_with('%') {\n                                    Some(rest.to_string())\n                                } else {\n                                    None\n                                }\n                            } else {\n                                // Already a prefix pattern (e.g. \"test%\"), use as-is\n                                Some(name_like.clone())\n                            };\n\n                            if offset == 0 {\n                                if let Some(ref pfx) = prefix_like {\n                                    let sql = format!(\n                                        r#\"\n                                        SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                        FROM entries e INDEXED BY idx_entries_name_nocase\n                                        WHERE e.name LIKE ?1 ESCAPE '\\'\n                                          AND (e.dir LIKE ?2 ESCAPE '\\' OR e.dir LIKE ?3 ESCAPE '\\')\n                                        ORDER BY {order_by}\n                                        LIMIT ?4\n                                        \"#,\n                                    );\n                                    if let Ok(mut stmt) = conn.prepare(&sql) {\n                                        if let Ok(rows) = stmt.query_map(\n                                            params![\n                                                pfx,\n                                                dir_like_exact,\n                                                dir_like_sub,\n                                                effective_limit\n                                            ],\n                                            row_to_entry,\n                                        ) {\n                                            for row in rows {\n                                                match row {\n                                                    Ok(entry) => results.push(entry),\n                                                    Err(_) => break,\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n\n                            // Phase B: time-budgeted contains fallback if prefix found too few\n                            if results.len() < effective_limit as usize {\n                                let path_start = Instant::now();\n                                conn.progress_handler(\n                                    2_000,\n                                    Some(move || path_start.elapsed().as_millis() > 5),\n                                );\n\n                                let sql = format!(\n                                    r#\"\n                                    SELECT e.path, e.name, e.dir, e.is_dir, e.ext, e.size, e.mtime\n                                    FROM entries e\n                                    WHERE (e.dir LIKE ?1 ESCAPE '\\' OR e.dir LIKE ?2 ESCAPE '\\')\n                                      AND e.name LIKE ?3 ESCAPE '\\'\n                                    ORDER BY {order_by}\n                                    LIMIT ?4 OFFSET ?5\n                                    \"#,\n                                );\n                                if let Ok(mut stmt) = conn.prepare(&sql) {\n                                    if let Ok(rows) = stmt.query_map(\n                                        params![\n                                            dir_like_exact,\n                                            dir_like_sub,\n                                            name_like,\n                                            effective_limit,\n                                            offset\n                                        ],\n                                        row_to_entry,\n                                    ) {\n                                        for row in rows {\n                                            match row {\n                                                Ok(entry) => results.push(entry),\n                                                Err(_) => break,\n                                            }\n                                        }\n                                    }\n                                }\n\n                                conn.progress_handler(0, None::<fn() -> bool>);\n\n                                // Deduplicate (Phase A prefix results overlap with Phase B contains)\n                                let mut seen = std::collections::HashSet::new();\n                                results.retain(|e| seen.insert(e.path.clone()));\n                                results.truncate(effective_limit as usize);\n                            }\n                        }\n                    }\n                }\n            }\n\n            if results.is_empty() && !query.is_empty() && offset == 0 && allow_find_fallback {\n                results = find_search(\n                    &state.home_dir,\n                    &runtime_ignored_roots,\n                    &runtime_ignored_patterns,\n                    &query,\n                    effective_limit as usize,\n                    &sort_by,\n                    &sort_dir,\n                );\n                mode_label = \"find_fallback\".to_string();\n            }\n        }\n        Err(_) => {\n            #[cfg(target_os = \"macos\")]\n            { db_unavailable = true; }\n            perf_log(format!(\"search_db_unavailable query={:?}\", query));\n        }\n    }\n\n    #[cfg(target_os = \"macos\")]\n    if !query.is_empty() && offset == 0 {\n        let should_spotlight = if results.is_empty() {\n            true\n        } else if results.len() >= effective_limit as usize {\n            false\n        } else {\n            is_indexing || db_unavailable\n        };\n        if should_spotlight {\n            let spotlight = mac::spotlight_search::search_spotlight(&state.home_dir, &query);\n            if !spotlight.entries.is_empty() {\n                if results.is_empty() {\n                    perf_log(format!(\n                        \"spotlight_fallback empty_results query={:?} results={} timed_out={}\",\n                        query,\n                        spotlight.entries.len(),\n                        spotlight.timed_out\n                    ));\n                    results = spotlight.entries;\n                    mode_label = if spotlight.timed_out {\n                        \"spotlight_timeout\".to_string()\n                    } else {\n                        \"spotlight\".to_string()\n                    };\n                } else {\n                    let existing_paths: std::collections::HashSet<String> =\n                        results.iter().map(|e| e.path.clone()).collect();\n                    let mut merged_count = 0usize;\n                    for entry in spotlight.entries {\n                        if !existing_paths.contains(&entry.path) {\n                            results.push(entry);\n                            merged_count += 1;\n                        }\n                    }\n                    if merged_count > 0 {\n                        perf_log(format!(\n                            \"spotlight_merge indexing query={:?} merged={} timed_out={}\",\n                            query, merged_count, spotlight.timed_out\n                        ));\n                        mode_label = format!(\"{}_+spotlight\", mode_label);\n                    }\n                }\n            }\n        }\n    }\n\n    results = filter_ignored_entries(results, &runtime_ignored_roots, &runtime_ignored_patterns);\n    results.truncate(effective_limit as usize);\n    if offset == 0 {\n        if sort_by == \"name\" {\n            sort_entries_with_relevance(&mut results, &query, &sort_by, &sort_dir);\n        } else {\n            sort_entries(&mut results, &sort_by, &sort_dir);\n        }\n    }\n    if is_name_mode && !is_indexing && offset == 0 && results.is_empty() && !query.is_empty() {\n        remember_negative_name_query(state, &query);\n    }\n\n    Ok(SearchExecution {\n        query,\n        sort_by,\n        sort_dir,\n        effective_limit,\n        offset,\n        mode_label,\n        results,\n    })\n}\n\n#[tauri::command]\nasync fn search(\n    _app: AppHandle,\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    include_total: Option<bool>,\n    state: State<'_, AppState>,\n) -> AppResult<SearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let rpc_started = Instant::now();\n        let execute_started = Instant::now();\n        let execution = execute_search(&state, query, limit, offset, sort_by, sort_dir)?;\n        let execute_elapsed_ms = execute_started.elapsed().as_secs_f64() * 1000.0;\n\n        log_search(\n            &state.db_path,\n            &execution.query,\n            &execution.mode_label,\n            &execution.results,\n        );\n\n        if perf_log_enabled() {\n            let top: Vec<&str> = execution\n                .results\n                .iter()\n                .take(5)\n                .map(|entry| entry.name.as_str())\n                .collect();\n            perf_log(format!(\n                \"search query={:?} mode={} sort={}/{} limit={} offset={} results={} elapsed_ms={:.3} top={:?}\",\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                execute_elapsed_ms,\n                top,\n            ));\n        }\n\n        let include_total = include_total.unwrap_or(true);\n        let count_started = Instant::now();\n        let (total_count, total_known) = if include_total {\n            match compute_total_count(&state.db_path, &state.home_dir, &execution) {\n                Some(v) => (v, true),\n                None => (0, false),\n            }\n        } else {\n            (0, false)\n        };\n        let count_elapsed_ms = if include_total {\n            count_started.elapsed().as_secs_f64() * 1000.0\n        } else {\n            0.0\n        };\n\n        let rpc_elapsed_ms = rpc_started.elapsed().as_secs_f64() * 1000.0;\n        if cfg!(debug_assertions) {\n            let db_ready = state.db_ready.load(AtomicOrdering::Acquire);\n            let indexing_active = state.indexing_active.load(AtomicOrdering::Acquire);\n            eprintln!(\n                \"[rpc/search] total={:.3}ms execute={:.3}ms total_count={:.3}ms include_total={} query={:?} mode={} sort={}/{} limit={} offset={} results={} total_count={} total_known={} db_ready={} indexing_active={}\",\n                rpc_elapsed_ms,\n                execute_elapsed_ms,\n                count_elapsed_ms,\n                include_total,\n                execution.query,\n                execution.mode_label,\n                execution.sort_by,\n                execution.sort_dir,\n                execution.effective_limit,\n                execution.offset,\n                execution.results.len(),\n                total_count,\n                total_known,\n                db_ready,\n                indexing_active,\n            );\n        }\n        Ok(SearchResultDto {\n            entries: execution.results,\n            mode_label: execution.mode_label,\n            total_count,\n            total_known,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn quick_look(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        #[cfg(target_os = \"macos\")]\n        {\n            Command::new(\"qlmanage\")\n                .args([\"-p\", &path])\n                .stdout(std::process::Stdio::null())\n                .stderr(std::process::Stdio::null())\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(target_os = \"windows\")]\n        {\n            Command::new(\"explorer\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            Command::new(\"xdg-open\")\n                .arg(&path)\n                .spawn()\n                .map_err(|e| e.to_string())?;\n        }\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn open(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || {\n        for path in &paths {\n            #[cfg(target_os = \"macos\")]\n            {\n                let output = Command::new(\"open\")\n                    .arg(path)\n                    .output()\n                    .map_err(|e| e.to_string())?;\n\n                if !output.status.success() && Path::new(path).is_dir() {\n                    let fallback = Command::new(\"open\")\n                        .args([\"-R\", path])\n                        .status()\n                        .map_err(|e| e.to_string())?;\n\n                    if !fallback.success() {\n                        return Err(format!(\"Failed to open: {path}\"));\n                    }\n                } else if !output.status.success() {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    return Err(format!(\"Failed to open: {path} ({stderr})\",));\n                }\n            }\n            #[cfg(target_os = \"windows\")]\n            {\n                let mut cmd = Command::new(\"cmd\");\n                cmd.raw_arg(format!(\"/C start \\\"\\\" \\\"{}\\\"\", path.replace('\"', \"\")));\n                let status = cmd.status().map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n            #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n            {\n                let status = Command::new(\"xdg-open\")\n                    .arg(path)\n                    .status()\n                    .map_err(|e| e.to_string())?;\n                if !status.success() {\n                    return Err(format!(\"Failed to open: {path}\"));\n                }\n            }\n        }\n\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\nfn reveal_in_finder_impl(paths: Vec<String>) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        if paths.len() == 1 {\n            let status = Command::new(\"open\")\n                .arg(\"-R\")\n                .arg(&paths[0])\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\"Failed to reveal in Finder: {}\", paths[0]));\n            }\n\n            return Ok(());\n        }\n\n        let mut unique_parents: HashSet<PathBuf> = HashSet::new();\n        for path in &paths {\n            let p = PathBuf::from(path);\n            if let Some(parent) = p.parent() {\n                unique_parents.insert(parent.to_path_buf());\n            }\n        }\n\n        for parent in unique_parents {\n            let status = Command::new(\"open\")\n                .arg(&parent)\n                .status()\n                .map_err(|e| e.to_string())?;\n\n            if !status.success() {\n                return Err(format!(\n                    \"Failed to open in Finder: {}\",\n                    parent.to_string_lossy()\n                ));\n            }\n        }\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        for path in &paths {\n            let mut cmd = Command::new(\"explorer\");\n            cmd.raw_arg(format!(\"/select,\\\"{}\\\"\", path.replace('\"', \"\")));\n            let _ = cmd.status();\n        }\n    }\n\n    #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n    {\n        for path in &paths {\n            let target = Path::new(path);\n            let dir = if target.is_dir() {\n                path.as_str()\n            } else {\n                target\n                    .parent()\n                    .map(|p| p.to_str().unwrap_or(\"/\"))\n                    .unwrap_or(\"/\")\n            };\n            let _ = Command::new(\"xdg-open\").arg(dir).status();\n        }\n    }\n\n    Ok(())\n}\n\nfn copy_with_command(program: &str, args: &[&str], text: &str) -> AppResult<()> {\n    let mut child = Command::new(program)\n        .args(args)\n        .stdin(Stdio::piped())\n        .spawn()\n        .map_err(|e| format!(\"Failed to run {program}: {e}\"))?;\n\n    if let Some(mut stdin) = child.stdin.take() {\n        stdin\n            .write_all(text.as_bytes())\n            .map_err(|e| format!(\"Failed to write to clipboard: {e}\"))?;\n    } else {\n        return Err(\"Cannot open clipboard input stream.\".to_string());\n    }\n\n    let status = child\n        .wait()\n        .map_err(|e| format!(\"Failed to wait for {program}: {e}\"))?;\n\n    if status.success() {\n        Ok(())\n    } else {\n        Err(format!(\"{program} execution failed.\"))\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"pbcopy\", &[], text)\n}\n\n#[cfg(target_os = \"windows\")]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    copy_with_command(\"cmd\", &[\"/C\", \"clip\"], text)\n}\n\n#[cfg(all(unix, not(target_os = \"macos\")))]\nfn copy_text_to_clipboard(text: &str) -> AppResult<()> {\n    let mut last_error = None;\n\n    match copy_with_command(\"wl-copy\", &[], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xclip\", &[\"-selection\", \"clipboard\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n    match copy_with_command(\"xsel\", &[\"--clipboard\", \"--input\"], text) {\n        Ok(()) => return Ok(()),\n        Err(err) => last_error = Some(err),\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        \"No supported clipboard tool found. Please install wl-copy, xclip, or xsel.\".to_string()\n    }))\n}\n\n#[tauri::command]\nasync fn open_with(path: String) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(vec![path]))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn reveal_in_finder(paths: Vec<String>) -> AppResult<()> {\n    tauri::async_runtime::spawn_blocking(move || reveal_in_finder_impl(paths))\n        .await\n        .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn copy_paths(paths: Vec<String>) -> AppResult<()> {\n    copy_text_to_clipboard(&paths.join(\"\\n\"))\n}\n\n#[cfg(target_os = \"macos\")]\nfn copy_files_to_clipboard(paths: &[String]) -> AppResult<()> {\n    if paths.is_empty() {\n        return Ok(());\n    }\n    let file_exprs: Vec<String> = paths\n        .iter()\n        .map(|p| {\n            let escaped = p.replace('\\\\', \"\\\\\\\\\").replace('\"', \"\\\\\\\"\");\n            format!(\"POSIX file \\\"{}\\\"\", escaped)\n        })\n        .collect();\n    let script = if file_exprs.len() == 1 {\n        format!(\"set the clipboard to {}\", file_exprs[0])\n    } else {\n        format!(\"set the clipboard to {{{}}}\", file_exprs.join(\", \"))\n    };\n    let status = Command::new(\"osascript\")\n        .arg(\"-e\")\n        .arg(&script)\n        .status()\n        .map_err(|e| e.to_string())?;\n    if !status.success() {\n        return Err(\"Failed to copy files to clipboard\".to_string());\n    }\n    Ok(())\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nfn copy_files(paths: Vec<String>) -> AppResult<()> {\n    copy_files_to_clipboard(&paths)\n}\n\n#[cfg(not(target_os = \"macos\"))]\n#[tauri::command]\nfn copy_files(_paths: Vec<String>) -> AppResult<()> {\n    Err(\"copy_files is only supported on macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn move_to_trash(\n    paths: Vec<String>,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<()> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let mut deleted_targets = Vec::new();\n\n        for path in &paths {\n            trash::delete(path).map_err(|e| e.to_string())?;\n            remember_op(&state, \"trash\", Some(path.clone()), None);\n            deleted_targets.push(path.clone());\n        }\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &deleted_targets)?;\n        invalidate_search_caches(&state);\n\n        refresh_and_emit_status_counts(&app, &state)?;\n        Ok(())\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn rename(\n    path: String,\n    new_name: String,\n    app: AppHandle,\n    state: State<'_, AppState>,\n) -> AppResult<EntryDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let validated_name = validate_new_name(&new_name)?;\n        let old_path = PathBuf::from(&path);\n\n        if !old_path.exists() {\n            return Err(\"Source file does not exist.\".to_string());\n        }\n\n        let parent = old_path\n            .parent()\n            .ok_or_else(|| \"Parent directory not found.\".to_string())?;\n\n        let new_path = parent.join(&validated_name);\n        if new_path == old_path {\n            let meta = fs::symlink_metadata(&old_path).ok();\n            return Ok(EntryDto {\n                path: path.clone(),\n                name: old_path\n                    .file_name()\n                    .map(|v| v.to_string_lossy().to_string())\n                    .unwrap_or_else(|| validated_name.clone()),\n                dir: parent.to_string_lossy().to_string(),\n                is_dir: old_path.is_dir(),\n                ext: extension_for(&old_path, old_path.is_dir()),\n                size: meta\n                    .as_ref()\n                    .filter(|m| m.is_file())\n                    .map(|m| m.len() as i64),\n                mtime: meta\n                    .and_then(|m| m.modified().ok())\n                    .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                    .map(|d| d.as_secs() as i64),\n            });\n        }\n\n        if new_path.exists() {\n            return Err(\"A file/folder with the same name already exists.\".to_string());\n        }\n\n        let original_is_dir = old_path.is_dir();\n        fs::rename(&old_path, &new_path).map_err(|e| e.to_string())?;\n\n        let mut conn = db_connection(&state.db_path)?;\n        let _ = delete_paths(&mut conn, &[path.clone()])?;\n\n        if original_is_dir {\n            let rows =\n                collect_rows_recursive(&new_path, &state.path_ignores, &state.path_ignore_patterns);\n            for chunk in rows.chunks(BATCH_SIZE) {\n                let _ = upsert_rows(&mut conn, chunk)?;\n            }\n        } else {\n            let row = index_row_from_path(&new_path)\n                .ok_or_else(|| \"Cannot read renamed file info.\".to_string())?;\n            let _ = upsert_rows(&mut conn, &[row])?;\n        }\n\n        invalidate_search_caches(&state);\n\n        remember_op(\n            &state,\n            \"rename\",\n            Some(old_path.to_string_lossy().to_string()),\n            Some(new_path.to_string_lossy().to_string()),\n        );\n\n        refresh_and_emit_status_counts(&app, &state)?;\n\n        let new_meta = fs::symlink_metadata(&new_path).ok();\n        Ok(EntryDto {\n            path: new_path.to_string_lossy().to_string(),\n            name: validated_name,\n            dir: parent.to_string_lossy().to_string(),\n            is_dir: original_is_dir,\n            ext: extension_for(&new_path, original_is_dir),\n            size: new_meta\n                .as_ref()\n                .filter(|m| m.is_file())\n                .map(|m| m.len() as i64),\n            mtime: new_meta\n                .and_then(|m| m.modified().ok())\n                .and_then(|m| m.duration_since(UNIX_EPOCH).ok())\n                .map(|d| d.as_secs() as i64),\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nasync fn fd_search(\n    query: String,\n    limit: Option<u32>,\n    offset: Option<u32>,\n    sort_by: Option<String>,\n    sort_dir: Option<String>,\n    state: State<'_, AppState>,\n) -> AppResult<FdSearchResultDto> {\n    let state = state.inner().clone();\n    tauri::async_runtime::spawn_blocking(move || {\n        let query = query.trim().to_string();\n        let limit = limit.unwrap_or(500).clamp(1, 5000) as usize;\n        let offset = offset.unwrap_or(0) as usize;\n        let sort_by = sort_by.unwrap_or_else(|| \"name\".to_string());\n        let sort_dir = sort_dir.unwrap_or_else(|| \"asc\".to_string());\n        let (runtime_ignored_roots, runtime_ignored_patterns) =\n            cached_effective_ignore_rules(&state);\n        let ignore_fingerprint =\n            ignore_rules_fingerprint(&runtime_ignored_roots, &runtime_ignored_patterns);\n\n        if query.is_empty() {\n            return Ok(FdSearchResultDto {\n                entries: Vec::new(),\n                total: 0,\n                timed_out: false,\n            });\n        }\n\n        {\n            let cache = state.fd_search_cache.lock();\n            if let Some(cached) = cache.as_ref() {\n                let cache_hit = cached.query == query\n                    && cached.sort_by == sort_by\n                    && cached.sort_dir == sort_dir\n                    && cached.ignore_fingerprint == ignore_fingerprint;\n                if cache_hit {\n                    let total = cached.entries.len() as u64;\n                    let end = (offset + limit).min(cached.entries.len());\n                    let page = if offset < cached.entries.len() {\n                        cached.entries[offset..end].to_vec()\n                    } else {\n                        Vec::new()\n                    };\n                    return Ok(FdSearchResultDto {\n                        entries: page,\n                        total,\n                        timed_out: false,\n                    });\n                }\n            }\n        }\n\n        let result = fd_search::run_fd_search(\n            &state.scan_root,\n            &runtime_ignored_roots,\n            &runtime_ignored_patterns,\n            &query,\n            &sort_by,\n            &sort_dir,\n        );\n        let total = result.entries.len() as u64;\n        let end = (offset + limit).min(result.entries.len());\n        let page = if offset < result.entries.len() {\n            result.entries[offset..end].to_vec()\n        } else {\n            Vec::new()\n        };\n\n        {\n            let mut cache = state.fd_search_cache.lock();\n            *cache = Some(FdSearchCache {\n                query: query.clone(),\n                sort_by: sort_by.clone(),\n                sort_dir: sort_dir.clone(),\n                ignore_fingerprint,\n                entries: result.entries,\n            });\n        }\n\n        Ok(FdSearchResultDto {\n            entries: page,\n            total,\n            timed_out: result.timed_out,\n        })\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[tauri::command]\nfn frontend_log(msg: String) {\n    eprintln!(\"{msg}\");\n}\n\n#[tauri::command]\nfn mark_frontend_ready(state: State<'_, AppState>) {\n    state.frontend_ready.store(true, AtomicOrdering::Release);\n    if cfg!(debug_assertions) {\n        eprintln!(\"[startup] frontend_ready=true\");\n    }\n}\n\n#[tauri::command]\nfn get_platform() -> String {\n    if cfg!(target_os = \"windows\") {\n        \"windows\".to_string()\n    } else if cfg!(target_os = \"macos\") {\n        \"macos\".to_string()\n    } else {\n        \"linux\".to_string()\n    }\n}\n\n#[cfg(target_os = \"windows\")]\n#[tauri::command]\nasync fn show_context_menu(\n    paths: Vec<String>,\n    x: f64,\n    y: f64,\n    _single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let scale = window.scale_factor().map_err(|e| e.to_string())?;\n    let win_pos = window.inner_position().map_err(|e| e.to_string())?;\n    let screen_x = win_pos.x + (x * scale) as i32;\n    let screen_y = win_pos.y + (y * scale) as i32;\n\n    let hwnd_raw = window.hwnd().map_err(|e| e.to_string())?.0 as isize;\n\n    // TrackPopupMenu must run on the thread that owns the HWND (main UI thread).\n    // Use a channel to relay the result back to the async context.\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    app.run_on_main_thread(move || {\n        let result = win::context_menu::show(hwnd_raw, &paths, screen_x, screen_y);\n        let _ = tx.send(result);\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(target_os = \"macos\")]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    x: f64,\n    y: f64,\n    single_selection: bool,\n    app: AppHandle,\n) -> AppResult<()> {\n    use tauri::menu::{IsMenuItem, Menu, MenuItem, PredefinedMenuItem};\n\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n\n    let (tx, rx) = std::sync::mpsc::sync_channel::<Result<(), String>>(1);\n\n    let app_clone = app.clone();\n    app.run_on_main_thread(move || {\n        let app = app_clone;\n        let result = (|| -> Result<(), tauri::Error> {\n            let open = MenuItem::with_id(&app, \"ctx_open\", \"Open\", true, None::<&str>)?;\n            let quick_look =\n                MenuItem::with_id(&app, \"ctx_quick_look\", \"Quick Look\", true, None::<&str>)?;\n            let open_with =\n                MenuItem::with_id(&app, \"ctx_open_with\", \"Open With...\", true, None::<&str>)?;\n            let sep1 = PredefinedMenuItem::separator(&app)?;\n            let reveal = MenuItem::with_id(\n                &app,\n                \"ctx_reveal\",\n                \"Reveal in Finder\",\n                true,\n                None::<&str>,\n            )?;\n            let sep2 = PredefinedMenuItem::separator(&app)?;\n            let copy_files =\n                MenuItem::with_id(&app, \"ctx_copy_files\", \"Copy\", true, None::<&str>)?;\n            let copy_path =\n                MenuItem::with_id(&app, \"ctx_copy_path\", \"Copy Path\", true, None::<&str>)?;\n            let sep3 = PredefinedMenuItem::separator(&app)?;\n            let trash = MenuItem::with_id(\n                &app,\n                \"ctx_trash\",\n                \"Move to Trash\",\n                true,\n                None::<&str>,\n            )?;\n            let rename =\n                MenuItem::with_id(&app, \"ctx_rename\", \"Rename\", true, None::<&str>)?;\n\n            let mut items: Vec<&dyn IsMenuItem<tauri::Wry>> = vec![\n                &open, &quick_look, &open_with, &sep1, &reveal, &sep2, &copy_files, &copy_path, &sep3, &trash,\n            ];\n            if single_selection {\n                items.push(&rename);\n            }\n\n            let menu = Menu::with_items(&app, &items)?;\n            // Position is window-relative logical pixels, matching clientX/clientY.\n            window.popup_menu_at(&menu, tauri::LogicalPosition::new(x, y))?;\n            Ok(())\n        })();\n        let _ = tx.send(result.map_err(|e| e.to_string()));\n    })\n    .map_err(|e| e.to_string())?;\n\n    tauri::async_runtime::spawn_blocking(move || {\n        rx.recv().map_err(|e| format!(\"context menu channel: {e}\"))?\n    })\n    .await\n    .map_err(|e| e.to_string())?\n}\n\n#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n#[tauri::command]\nasync fn show_context_menu(\n    _paths: Vec<String>,\n    _x: f64,\n    _y: f64,\n    _single_selection: bool,\n    _app: AppHandle,\n) -> AppResult<()> {\n    Err(\"Native context menu is only supported on Windows and macOS\".to_string())\n}\n\n#[tauri::command]\nasync fn set_native_theme(theme: String, app: AppHandle) -> AppResult<()> {\n    let window = app\n        .get_webview_window(\"main\")\n        .ok_or_else(|| \"Main window not found\".to_string())?;\n    let t = if theme == \"light\" {\n        tauri::Theme::Light\n    } else {\n        tauri::Theme::Dark\n    };\n    window.set_theme(Some(t)).map_err(|e| e.to_string())\n}\n\n#[tauri::command]\nasync fn get_file_icon(\n    path: Option<String>,\n    ext: String,\n    state: State<'_, AppState>,\n) -> AppResult<Vec<u8>> {\n    let state = state.inner().clone();\n    Ok(tauri::async_runtime::spawn_blocking(move || {\n        let ext_lower = if ext.trim().is_empty() {\n            \"__default__\".to_string()\n        } else {\n            ext.to_lowercase()\n        };\n\n        #[cfg(target_os = \"windows\")]\n        let cache_key = {\n            if is_per_file_icon_ext(&ext_lower) {\n                path.as_deref().unwrap_or(&ext_lower).to_string()\n            } else {\n                ext_lower.clone()\n            }\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let cache_key = ext_lower.clone();\n\n        if let Some(cached) = state.icon_cache.lock().get(&cache_key).cloned() {\n            return cached;\n        }\n\n        #[cfg(target_os = \"windows\")]\n        let icon = {\n            let from_path = path\n                .as_deref()\n                .filter(|p| !p.is_empty())\n                .and_then(win::icon::load_icon_png);\n            from_path.or_else(|| load_system_icon_png(&ext_lower))\n        };\n        #[cfg(not(target_os = \"windows\"))]\n        let icon = {\n            let _ = path;\n            load_system_icon_png(&ext_lower)\n        };\n\n        let icon = icon.unwrap_or_default();\n        state.icon_cache.lock().insert(cache_key, icon.clone());\n        icon\n    })\n    .await\n    .unwrap_or_default())\n}\n\nfn default_bench_cases() -> Vec<BenchCase> {\n    vec![\n        BenchCase {\n            id: \"TC01_exact_name\",\n            query: \"report_00042\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC02_prefix_name\",\n            query: \"report_00\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 10,\n        },\n        BenchCase {\n            id: \"TC03_contains_name\",\n            query: \"invoice\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC04_ext_md\",\n            query: \"*.md\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC05_path_glob_png\",\n            query: \"Desktop/ *.png\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC06_path_term\",\n            query: \"Projects/rust\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC07_path_ext_rs\",\n            query: \"Projects/ *.rs\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 1,\n        },\n        BenchCase {\n            id: \"TC08_no_match\",\n            query: \"zzzz_not_exists_12345\",\n            sort_by: \"name\",\n            sort_dir: \"asc\",\n            limit: 300,\n            offset: 0,\n            expected_min_results: 0,\n        },\n    ]\n}\n\nfn bench_iterations() -> u32 {\n    std::env::var(\"EVERYTHING_BENCH_ITERATIONS\")\n        .ok()\n        .and_then(|v| v.parse::<u32>().ok())\n        .map(|v| v.clamp(1, 50))\n        .unwrap_or(5)\n}\n\nfn bench_wait_timeout() -> Duration {\n    let seconds = std::env::var(\"EVERYTHING_BENCH_WAIT_SEC\")\n        .ok()\n        .and_then(|v| v.parse::<u64>().ok())\n        .map(|v| v.clamp(10, 7200))\n        .unwrap_or(1800);\n    Duration::from_secs(seconds)\n}\n\nfn bench_run_label() -> String {\n    std::env::var(\"EVERYTHING_BENCH_RUN_LABEL\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .unwrap_or_else(|| format!(\"run-{}\", now_epoch()))\n}\n\nfn bench_output_path(db_path: &Path, run_label: &str) -> PathBuf {\n    std::env::var(\"EVERYTHING_BENCH_OUTPUT\")\n        .ok()\n        .filter(|v| !v.trim().is_empty())\n        .map(PathBuf::from)\n        .unwrap_or_else(|| db_path.with_file_name(format!(\"bench-report-{run_label}.json\")))\n}\n\nfn write_bench_report(path: &Path, report: &BenchReport) -> AppResult<()> {\n    let json = serde_json::to_string_pretty(report).map_err(|e| e.to_string())?;\n    fs::write(path, json).map_err(|e| e.to_string())\n}\n\nfn start_bench_runner(app_handle: AppHandle, state: AppState) {\n    std::thread::spawn(move || {\n        let run_label = bench_run_label();\n        let output_path = bench_output_path(&state.db_path, &run_label);\n        let iterations = bench_iterations();\n        let wait_timeout = bench_wait_timeout();\n        let started_at = now_epoch();\n\n        perf_log(format!(\n            \"bench_start run_label={} output={} iterations={} wait_timeout_s={}\",\n            run_label,\n            output_path.to_string_lossy(),\n            iterations,\n            wait_timeout.as_secs(),\n        ));\n\n        let wait_started = Instant::now();\n        let mut saw_indexing = false;\n        let index_snapshot: IndexStatus;\n        loop {\n            let snapshot = state.status.lock().clone();\n            let active = state.indexing_active.load(AtomicOrdering::Acquire)\n                || matches!(snapshot.state, IndexState::Indexing);\n\n            if active {\n                saw_indexing = true;\n            }\n\n            if state.db_ready.load(AtomicOrdering::Acquire) && saw_indexing && !active {\n                index_snapshot = snapshot;\n                break;\n            }\n\n            if wait_started.elapsed() >= wait_timeout {\n                let report = BenchReport {\n                    run_label: run_label.clone(),\n                    started_at,\n                    completed_at: now_epoch(),\n                    home_dir: state.home_dir.to_string_lossy().to_string(),\n                    db_path: state.db_path.to_string_lossy().to_string(),\n                    index_wait_ms: wait_started.elapsed().as_millis(),\n                    index_scanned: snapshot.scanned,\n                    index_indexed: snapshot.indexed,\n                    index_entries_count: snapshot.entries_count,\n                    index_permission_errors: snapshot.permission_errors,\n                    index_message: Some(\"Timed out waiting for index ready\".to_string()),\n                    search_iterations: iterations,\n                    search_results: Vec::new(),\n                };\n                let _ = write_bench_report(&output_path, &report);\n                perf_log(format!(\n                    \"bench_timeout run_label={} waited_ms={}\",\n                    run_label,\n                    wait_started.elapsed().as_millis()\n                ));\n                if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n                    app_handle.exit(2);\n                }\n                return;\n            }\n\n            std::thread::sleep(Duration::from_millis(200));\n        }\n\n        let index_wait_ms = wait_started.elapsed().as_millis();\n        perf_log(format!(\n            \"bench_index_ready run_label={} waited_ms={} scanned={} indexed={} entries={} permission_errors={}\",\n            run_label,\n            index_wait_ms,\n            index_snapshot.scanned,\n            index_snapshot.indexed,\n            index_snapshot.entries_count,\n            index_snapshot.permission_errors,\n        ));\n\n        let mut search_results = Vec::new();\n        for case in default_bench_cases() {\n            let mut elapsed_sum = 0.0f64;\n            let mut success_count = 0u32;\n            let mut result_count = 0usize;\n            let mut mode = String::new();\n            let mut top_results = Vec::new();\n            let mut case_error = None;\n\n            for iter in 1..=iterations {\n                let started = Instant::now();\n                match execute_search(\n                    &state,\n                    case.query.to_string(),\n                    Some(case.limit),\n                    Some(case.offset),\n                    Some(case.sort_by.to_string()),\n                    Some(case.sort_dir.to_string()),\n                ) {\n                    Ok(execution) => {\n                        let elapsed_ms = started.elapsed().as_secs_f64() * 1000.0;\n                        elapsed_sum += elapsed_ms;\n                        success_count += 1;\n                        result_count = execution.results.len();\n                        mode = execution.mode_label;\n                        top_results = execution\n                            .results\n                            .iter()\n                            .take(5)\n                            .map(|entry| entry.path.clone())\n                            .collect();\n\n                        perf_log(format!(\n                            \"bench_query run_label={} case={} iter={}/{} query={:?} mode={} results={} elapsed_ms={:.3}\",\n                            run_label,\n                            case.id,\n                            iter,\n                            iterations,\n                            case.query,\n                            mode,\n                            result_count,\n                            elapsed_ms\n                        ));\n                    }\n                    Err(err) => {\n                        case_error = Some(err);\n                        break;\n                    }\n                }\n            }\n\n            let elapsed_ms = if success_count > 0 {\n                elapsed_sum / success_count as f64\n            } else {\n                0.0\n            };\n            let passed = case_error.is_none() && result_count >= case.expected_min_results;\n\n            search_results.push(BenchCaseResult {\n                id: case.id.to_string(),\n                query: case.query.to_string(),\n                mode,\n                sort_by: case.sort_by.to_string(),\n                sort_dir: case.sort_dir.to_string(),\n                limit: case.limit,\n                offset: case.offset,\n                elapsed_ms,\n                result_count,\n                expected_min_results: case.expected_min_results,\n                passed,\n                top_results,\n                error: case_error,\n            });\n        }\n\n        let report = BenchReport {\n            run_label: run_label.clone(),\n            started_at,\n            completed_at: now_epoch(),\n            home_dir: state.home_dir.to_string_lossy().to_string(),\n            db_path: state.db_path.to_string_lossy().to_string(),\n            index_wait_ms,\n            index_scanned: index_snapshot.scanned,\n            index_indexed: index_snapshot.indexed,\n            index_entries_count: index_snapshot.entries_count,\n            index_permission_errors: index_snapshot.permission_errors,\n            index_message: index_snapshot.message.clone(),\n            search_iterations: iterations,\n            search_results,\n        };\n\n        match write_bench_report(&output_path, &report) {\n            Ok(()) => perf_log(format!(\n                \"bench_report_written run_label={} path={}\",\n                run_label,\n                output_path.to_string_lossy()\n            )),\n            Err(err) => perf_log(format!(\n                \"bench_report_write_error run_label={} path={} err={}\",\n                run_label,\n                output_path.to_string_lossy(),\n                err\n            )),\n        }\n\n        if env_truthy(\"EVERYTHING_BENCH_EXIT\") {\n            app_handle.exit(0);\n        }\n    });\n}\n\n#[cfg(target_os = \"macos\")]\nfn register_global_shortcut(app: &AppHandle) -> AppResult<()> {\n    let shortcut = Shortcut::new(Some(Modifiers::SUPER | Modifiers::SHIFT), Code::Space);\n\n    app.global_shortcut()\n        .on_shortcut(shortcut, move |app_handle, _, _| {\n            if let Some(window) = app_handle.get_webview_window(\"main\") {\n                let _ = window.show();\n                let _ = window.unminimize();\n                let _ = window.set_focus();\n            }\n            let _ = app_handle.emit(\"focus_search\", ());\n        })\n        .map_err(|e| format!(\"Failed to register global shortcut: {e}\"))\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn register_global_shortcut(_app: &AppHandle) -> AppResult<()> {\n    Ok(())\n}\n\nfn setup_app(app: &mut tauri::App) -> AppResult<()> {\n    let setup_started = std::time::Instant::now();\n    eprintln!(\"[startup] setup_app() entered\");\n    let bench_mode = bench_mode_enabled();\n\n    #[cfg(target_os = \"macos\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        use tauri::window::Color;\n        let is_dark = window\n            .theme()\n            .map(|t| t == tauri::Theme::Dark)\n            .unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        let _ = window.show();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    if let Some(window) = app.get_webview_window(\"main\") {\n        eprintln!(\"[startup +{}ms] windows setup: before window.show()\", startup_elapsed_ms());\n        use tauri::window::Color;\n        let is_dark = window.theme().map(|t| t == tauri::Theme::Dark).unwrap_or(false);\n        let bg = if is_dark {\n            Color(0x1f, 0x1f, 0x1f, 0xff)\n        } else {\n            Color(0xf4, 0xf5, 0xf7, 0xff)\n        };\n        let _ = window.set_background_color(Some(bg));\n        if let Err(e) = window.set_decorations(false) {\n            eprintln!(\n                \"[startup +{}ms] windows setup: set_decorations(false) failed: {}\",\n                startup_elapsed_ms(),\n                e\n            );\n        }\n        let _ = window.show();\n        eprintln!(\"[startup +{}ms] windows setup: window.show() returned\", startup_elapsed_ms());\n    }\n\n    let app_data_dir = app\n        .path()\n        .app_data_dir()\n        .map_err(|e| format!(\"Failed to get app data dir: {e}\"))?;\n    fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;\n\n    let db_path = app_data_dir.join(\"index.db\");\n    let home_dir = PathBuf::from(\n        std::env::var(\"HOME\")\n            .or_else(|_| std::env::var(\"USERPROFILE\"))\n            .unwrap_or_else(|_| if cfg!(windows) { \"C:\\\\\".to_string() } else { \"/\".to_string() }),\n    );\n    let scan_root = if cfg!(windows) {\n        PathBuf::from(\"C:\\\\\")\n    } else {\n        home_dir.clone()\n    };\n    let cwd = std::env::current_dir().unwrap_or_else(|_| home_dir.clone());\n    eprintln!(\"[startup] +{}ms loading pathignore rules...\", setup_started.elapsed().as_millis());\n    let (mut path_ignores, path_ignore_patterns) = load_pathignore_rules(&home_dir, &cwd);\n    if !path_ignores.iter().any(|r| r == &app_data_dir) {\n        path_ignores.push(app_data_dir.clone());\n    }\n    for root in load_gitignore_roots(&home_dir, &cwd) {\n        if !path_ignores.iter().any(|r| r == &root) {\n            path_ignores.push(root);\n        }\n    }\n    eprintln!(\"[startup] +{}ms pathignore done\", setup_started.elapsed().as_millis());\n\n    let gitignore = Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone()));\n\n    let state = AppState {\n        db_path,\n        home_dir,\n        scan_root,\n        cwd,\n        path_ignores: Arc::new(path_ignores),\n        path_ignore_patterns: Arc::new(path_ignore_patterns),\n        db_ready: Arc::new(AtomicBool::new(false)),\n        indexing_active: Arc::new(AtomicBool::new(false)),\n        status: Arc::new(Mutex::new(IndexStatus::default())),\n        recent_ops: Arc::new(Mutex::new(Vec::new())),\n        icon_cache: Arc::new(Mutex::new(HashMap::new())),\n        fd_search_cache: Arc::new(Mutex::new(None)),\n        negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n        ignore_cache: Arc::new(Mutex::new(None)),\n        gitignore,\n        mem_index: Arc::new(RwLock::new(None)),\n        watcher_stop: Arc::new(AtomicBool::new(false)),\n        watcher_active: Arc::new(AtomicBool::new(false)),\n        frontend_ready: Arc::new(AtomicBool::new(false)),\n    };\n\n    eprintln!(\"[startup] +{}ms AppState created\", setup_started.elapsed().as_millis());\n    app.manage(state.clone());\n    if !bench_mode {\n        register_global_shortcut(&app.handle())?;\n    }\n    // Context menu item IDs use the \"ctx_\" prefix by convention.\n    // All matching IDs are forwarded as \"context_menu_action\" events to the frontend.\n    #[cfg(target_os = \"macos\")]\n    {\n        app.handle().on_menu_event(|app, event| {\n            let action = match event.id().as_ref() {\n                \"ctx_open\" => \"open\",\n                \"ctx_quick_look\" => \"quick_look\",\n                \"ctx_open_with\" => \"open_with\",\n                \"ctx_reveal\" => \"reveal\",\n                \"ctx_copy_files\" => \"copy_files\",\n                \"ctx_copy_path\" => \"copy_path\",\n                \"ctx_trash\" => \"trash\",\n                \"ctx_rename\" => \"rename\",\n                _ => return,\n            };\n            let _ = app.emit(\"context_menu_action\", action);\n        });\n    }\n    eprintln!(\"[startup] +{}ms global shortcut registered\", setup_started.elapsed().as_millis());\n    if bench_mode {\n        if let Some(window) = app.get_webview_window(\"main\") {\n            let _ = window.hide();\n        }\n    }\n\n    eprintln!(\"[startup] +{}ms setup_app() done, spawning init thread\", setup_started.elapsed().as_millis());\n\n    let app_handle = app.handle().clone();\n    std::thread::spawn(move || {\n        let thread_started = std::time::Instant::now();\n        eprintln!(\"[startup/thread] init thread started\");\n\n        eprintln!(\"[startup/thread] +{}ms calling init_db...\", thread_started.elapsed().as_millis());\n        if let Err(err) = init_db(&state.db_path) {\n            set_state(&state, IndexState::Error, Some(err.clone()));\n            emit_index_state(&app_handle, \"Error\", Some(err));\n            return;\n        }\n        eprintln!(\"[startup/thread] +{}ms init_db done\", thread_started.elapsed().as_millis());\n\n        state.db_ready.store(true, AtomicOrdering::Release);\n        eprintln!(\"[startup/thread] +{}ms db_ready=true -- launching indexing immediately\", thread_started.elapsed().as_millis());\n\n        // Deferred housekeeping -- purge + status counts run in background\n        {\n            let hk_app = app_handle.clone();\n            let hk_state = state.clone();\n            std::thread::spawn(move || {\n                // Brief pause so indexing thread can start first\n                std::thread::sleep(std::time::Duration::from_millis(500));\n                let hk_started = std::time::Instant::now();\n                let _ = refresh_and_emit_status_counts(&hk_app, &hk_state);\n                eprintln!(\"[startup/housekeeping] refresh_and_emit_status_counts done in {}ms\", hk_started.elapsed().as_millis());\n                // Wait for frontend readiness so initial paint and first input are not contended by purge I/O.\n                const FRONTEND_READY_TIMEOUT: Duration = Duration::from_secs(180);\n                const POST_READY_GRACE: Duration = Duration::from_secs(2);\n                let wait_started = std::time::Instant::now();\n                while !hk_state.frontend_ready.load(AtomicOrdering::Acquire)\n                    && wait_started.elapsed() < FRONTEND_READY_TIMEOUT\n                {\n                    std::thread::sleep(Duration::from_millis(50));\n                }\n                if hk_state.frontend_ready.load(AtomicOrdering::Acquire) {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready observed after {}ms; purging in {}ms\",\n                        wait_started.elapsed().as_millis(),\n                        POST_READY_GRACE.as_millis()\n                    );\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] frontend_ready wait timed out after {}ms; proceeding with purge\",\n                        FRONTEND_READY_TIMEOUT.as_millis()\n                    );\n                }\n                std::thread::sleep(POST_READY_GRACE);\n                let purge_started = std::time::Instant::now();\n                if let Err(err) = purge_ignored_entries(&hk_state.db_path, &hk_state.path_ignores) {\n                    eprintln!(\"[startup/housekeeping] purge_ignored_entries failed: {err}\");\n                } else {\n                    eprintln!(\n                        \"[startup/housekeeping] purge_ignored_entries done in {}ms\",\n                        purge_started.elapsed().as_millis()\n                    );\n                }\n                eprintln!(\"[startup/housekeeping] all done in {}ms\", hk_started.elapsed().as_millis());\n            });\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            if bench_mode {\n                let _ = start_full_index_worker(app_handle.clone(), state.clone());\n            } else {\n                let (stored_event_id, index_complete) = db_connection(&state.db_path)\n                    .ok()\n                    .map(|c| {\n                        let eid = get_meta(&c, \"last_event_id\")\n                            .and_then(|v| v.parse::<u64>().ok());\n                        let complete = get_meta(&c, \"index_complete\")\n                            .map(|v| v == \"1\")\n                            .unwrap_or(false);\n                        (eid, complete)\n                    })\n                    .unwrap_or((None, false));\n\n                if stored_event_id.is_some() && index_complete {\n                    // Conditional startup: try watcher replay first, skip full scan if OK\n                    start_fsevent_watcher_worker(\n                        app_handle.clone(),\n                        state.clone(),\n                        stored_event_id,\n                        true,\n                    );\n                } else {\n                    if !index_complete {\n                        eprintln!(\"[mac] index incomplete; starting full index\");\n                    }\n                    let _ = start_full_index_worker(app_handle.clone(), state.clone());\n                    start_fsevent_watcher_worker(app_handle.clone(), state.clone(), None, false);\n                }\n            }\n        }\n\n        #[cfg(target_os = \"windows\")]\n        {\n            win::start_windows_indexing(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(any(target_os = \"macos\", target_os = \"windows\")))]\n        {\n            let _ = start_full_index_worker(app_handle.clone(), state.clone());\n        }\n\n        if bench_mode {\n            start_bench_runner(app_handle.clone(), state.clone());\n        }\n\n        #[cfg(not(target_os = \"windows\"))]\n        if !bench_mode {\n            let icon_cache = state.icon_cache.clone();\n            std::thread::spawn(move || {\n                let exts = [\n                    \"txt\", \"pdf\", \"png\", \"jpg\", \"md\", \"json\", \"swift\", \"rs\", \"js\", \"ts\", \"html\",\n                    \"css\", \"py\", \"zip\", \"dmg\", \"app\", \"doc\", \"xls\", \"ppt\", \"mov\",\n                ];\n                for ext in &exts {\n                    let key = ext.to_string();\n                    if icon_cache.lock().contains_key(&key) {\n                        continue;\n                    }\n                    if let Some(icon) = load_system_icon_png(ext) {\n                        icon_cache.lock().insert(key, icon);\n                    }\n                }\n            });\n        }\n    });\n\n    Ok(())\n}\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n    let _ = STARTUP_T0.set(Instant::now());\n    eprintln!(\"[startup +{}ms] run() entered\", startup_elapsed_ms());\n    #[cfg(target_os = \"windows\")]\n    if cfg!(debug_assertions) {\n        // Safety: called at program start before any threads are spawned.\n        // Will require `unsafe` block when migrating to Rust edition 2024.\n        std::env::set_var(\n            \"WEBVIEW2_ADDITIONAL_BROWSER_ARGUMENTS\",\n            \"--no-proxy-server --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n        );\n        eprintln!(\n            \"[startup +{}ms] set REDACTED --disable-http-cache --disk-cache-size=1 --media-cache-size=1\",\n            startup_elapsed_ms()\n        );\n    }\n    let mut builder = tauri::Builder::default()\n        .plugin(tauri_plugin_decorum::init())\n        .plugin(tauri_plugin_drag::init())\n        .plugin(tauri_plugin_global_shortcut::Builder::new().build());\n\n    if !cfg!(debug_assertions) {\n        builder = builder.plugin(tauri_plugin_window_state::Builder::default().build());\n    } else {\n        eprintln!(\n            \"[startup +{}ms] debug mode: window-state plugin disabled for startup A/B test\",\n            startup_elapsed_ms()\n        );\n    }\n\n    builder\n        .on_page_load(|window, payload| {\n            eprintln!(\n                \"[startup/page +{}ms] on_page_load label={} event={:?} url={}\",\n                startup_elapsed_ms(),\n                window.label(),\n                payload.event(),\n                payload.url()\n            );\n        })\n        .setup(|app| {\n            setup_app(app).map_err(|e| {\n                Box::<dyn std::error::Error>::from(io::Error::new(io::ErrorKind::Other, e))\n            })\n        })\n        .invoke_handler(tauri::generate_handler![\n            get_index_status,\n            get_home_dir,\n            start_full_index,\n            reset_index,\n            search,\n            fd_search,\n            quick_look,\n            open,\n            open_with,\n            reveal_in_finder,\n            copy_paths,\n            copy_files,\n            move_to_trash,\n            rename,\n            get_file_icon,\n            get_platform,\n            show_context_menu,\n            set_native_theme,\n            frontend_log,\n            mark_frontend_ready\n        ])\n        .run(tauri::generate_context!())\n        .expect(\"error while running tauri application\");\n}\n\nfn main() {\n    run();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::time::{SystemTime, UNIX_EPOCH};\n\n    fn mk_entry(path: &str, name: &str) -> EntryDto {\n        let parent = Path::new(path)\n            .parent()\n            .map(|p| p.to_string_lossy().to_string())\n            .unwrap_or_else(|| \"/\".to_string());\n        EntryDto {\n            path: path.to_string(),\n            name: name.to_string(),\n            dir: parent,\n            is_dir: false,\n            ext: None,\n            size: None,\n            mtime: None,\n        }\n    }\n\n    fn temp_case_dir(case: &str) -> PathBuf {\n        let stamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_nanos())\n            .unwrap_or(0);\n        let base = if cfg!(target_os = \"windows\") {\n            std::env::current_dir()\n                .map(|dir| dir.join(\"tmp-test-dirs\"))\n                .unwrap_or_else(|_| std::env::temp_dir())\n        } else {\n            std::env::temp_dir()\n        };\n        base.join(format!(\n            \"everything_{case}_{}_{}\",\n            std::process::id(),\n            stamp\n        ))\n    }\n\n    fn test_state_for(db_path: PathBuf, home_dir: PathBuf, cwd: PathBuf) -> AppState {\n        AppState {\n            db_path,\n            home_dir: home_dir.clone(),\n            scan_root: home_dir.clone(),\n            cwd,\n            path_ignores: Arc::new(Vec::new()),\n            path_ignore_patterns: Arc::new(Vec::new()),\n            db_ready: Arc::new(AtomicBool::new(true)),\n            indexing_active: Arc::new(AtomicBool::new(false)),\n            status: Arc::new(Mutex::new(IndexStatus::default())),\n            recent_ops: Arc::new(Mutex::new(Vec::new())),\n            icon_cache: Arc::new(Mutex::new(HashMap::new())),\n            fd_search_cache: Arc::new(Mutex::new(None)),\n            negative_name_cache: Arc::new(Mutex::new(HashMap::new())),\n            ignore_cache: Arc::new(Mutex::new(None)),\n            gitignore: Arc::new(gitignore_filter::LazyGitignoreFilter::new(home_dir.clone())),\n            mem_index: Arc::new(RwLock::new(None)),\n            watcher_stop: Arc::new(AtomicBool::new(false)),\n            watcher_active: Arc::new(AtomicBool::new(false)),\n            frontend_ready: Arc::new(AtomicBool::new(true)),\n        }\n    }\n\n    #[test]\n    fn should_skip_path_for_ignored_descendant() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let target = Path::new(\n            \"REDACTED\",\n        );\n\n        assert!(should_skip_path(target, &ignored, &[]));\n    }\n\n    #[test]\n    fn filter_ignored_entries_removes_pathignore_matches() {\n        let ignored = vec![PathBuf::from(\n            \"/Users/al02402336/Library/Developer/Xcode/DerivedData\",\n        )];\n        let entries = vec![\n            mk_entry(\n                \"REDACTED\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n        ];\n\n        let filtered = filter_ignored_entries(entries, &ignored, &[]);\n\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn should_skip_path_for_glob_any_segment_target() {\n        let patterns = vec![IgnorePattern::any_segment(\"target\")];\n\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target\"),\n            &[],\n            &patterns\n        ));\n        assert!(should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/target/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n        assert!(!should_skip_path(\n            Path::new(\"/Users/al02402336/work/rust/targets/debug/deps/foo.o\"),\n            &[],\n            &patterns\n        ));\n    }\n\n    #[test]\n    fn relevance_sort_prefers_shallow_exact_match() {\n        let mut entries = vec![\n            mk_entry(\"/Users/al02402336/work/a_desktop\", \"a_desktop\"),\n            mk_entry(\"/Users/al02402336/a_desktop\", \"a_desktop\"),\n            mk_entry(\n                \"/Users/al02402336/Library/Developer/Xcode/DerivedData/-Users-al02402336-a_desktop\",\n                \"-Users-al02402336-a_desktop\",\n            ),\n        ];\n\n        sort_entries_with_relevance(&mut entries, \"a_desktop\", \"name\", \"asc\");\n\n        assert_eq!(entries[0].path, \"/Users/al02402336/a_desktop\");\n    }\n\n    #[test]\n    fn resolved_dir_range_excludes_sibling_with_same_prefix() {\n        let dir_exact = \"/Users/user/Projects\";\n        let dir_prefix = format!(\"{}/\", dir_exact);\n        let dir_prefix_end = format!(\"{}0\", dir_exact);\n\n        let in_scope = |dir: &str| {\n            dir == dir_exact || (dir >= dir_prefix.as_str() && dir < dir_prefix_end.as_str())\n        };\n\n        assert!(in_scope(\"/Users/user/Projects\"));\n        assert!(in_scope(\"/Users/user/Projects/src\"));\n        assert!(in_scope(\"/Users/user/Projects/src/deeper\"));\n\n        assert!(!in_scope(\"/Users/user/Projects-archived\"));\n        assert!(!in_scope(\"/Users/user/Projects.archived\"));\n        assert!(!in_scope(\"/Users/user/Projects_archived\"));\n        assert!(!in_scope(\"/Users/user/Projectz\"));\n    }\n\n    #[test]\n    fn delete_paths_root_clears_all_entries() {\n        let root = temp_case_dir(\"delete_paths_root\");\n        let dir_a = root.join(\"alpha\");\n        let dir_b = root.join(\"beta\").join(\"nested\");\n        fs::create_dir_all(&dir_a).unwrap();\n        fs::create_dir_all(&dir_b).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let mut conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        for (path, name, dir, ext) in [\n            (dir_a.join(\"a.txt\"), \"a.txt\", dir_a.clone(), \"txt\"),\n            (dir_b.join(\"b.rs\"), \"b.rs\", dir_b.clone(), \"rs\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let deleted = delete_paths(&mut conn, &[\"/\".to_string()]).unwrap();\n        assert!(deleted >= 2);\n\n        let remaining: i64 = conn\n            .query_row(\"SELECT COUNT(*) FROM entries\", [], |row| row.get(0))\n            .unwrap();\n        assert_eq!(remaining, 0);\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn execute_search_resolved_path_does_not_include_prefixed_sibling_dirs() {\n        let root = temp_case_dir(\"resolved_path_scope_execute\");\n        let projects_src = root.join(\"Projects\").join(\"src\");\n        let archived_src = root.join(\"Projects-archived\").join(\"src\");\n        fs::create_dir_all(&projects_src).unwrap();\n        fs::create_dir_all(&archived_src).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let project_path = projects_src.join(\"main.rs\");\n        let archived_path = archived_src.join(\"legacy.rs\");\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                project_path.to_string_lossy().to_string(),\n                \"main.rs\",\n                projects_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                archived_path.to_string_lossy().to_string(),\n                \"legacy.rs\",\n                archived_src.to_string_lossy().to_string(),\n                \"rs\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path.clone(), root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.rs\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert!(result\n            .results\n            .iter()\n            .any(|entry| entry.path == project_path.to_string_lossy()));\n        assert!(result\n            .results\n            .iter()\n            .all(|entry| !entry.path.contains(\"Projects-archived\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_file_upward_locates_repo_level_pathignore() {\n        let root = temp_case_dir(\"pathignore_upward\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::write(root.join(\".pathignore\"), \"node_modules\\n\").unwrap();\n\n        let found = find_file_upward(&nested, \".pathignore\");\n        assert_eq!(found, Some(root.join(\".pathignore\")));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn find_git_root_works_from_nested_directory() {\n        let root = temp_case_dir(\"git_root\");\n        let nested = root.join(\"src-tauri\").join(\"target\");\n        fs::create_dir_all(&nested).unwrap();\n        fs::create_dir_all(root.join(\".git\")).unwrap();\n\n        let found = find_git_root(&nested);\n        assert_eq!(found, Some(root.clone()));\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn extract_ext_from_like_rejects_multi_dot() {\n        assert_eq!(extract_ext_from_like(\"%.tar.gz\"), None);\n        assert_eq!(extract_ext_from_like(\"%.d.ts\"), None);\n        assert_eq!(extract_ext_from_like(\"%.rs\"), Some(\"rs\".to_string()));\n        assert_eq!(extract_ext_from_like(\"%.png\"), Some(\"png\".to_string()));\n    }\n\n    #[test]\n    fn negative_cache_fallback_removes_matched_key_not_query() {\n        let state = test_state_for(\n            PathBuf::from(\"/tmp/neg_cache_test.db\"),\n            PathBuf::from(\"/tmp\"),\n            PathBuf::from(\"/tmp\"),\n        );\n\n        remember_negative_name_query(&state, \"abc\");\n\n        let hit = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit.is_some());\n        assert_eq!(hit.unwrap().query_lower, \"abc\");\n\n        remove_negative_name_query(&state, \"abc\");\n\n        let hit_after = negative_name_cache_lookup(&state, \"xabc\");\n        assert!(hit_after.is_none());\n    }\n\n    #[test]\n    fn dir_listing_deep_nested_path_without_time_budget() {\n        let root = temp_case_dir(\"dir_listing_deep\");\n        // Simulate: ~/Library/Containers/jp.naver.line.mac/Data/Library/Containers/jp.naver.line/log/\n        let deep_dir = root\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line.mac\")\n            .join(\"Data\")\n            .join(\"Library\")\n            .join(\"Containers\")\n            .join(\"jp.naver.line\")\n            .join(\"log\");\n        let sub_dir = deep_dir.join(\"archive\");\n        fs::create_dir_all(&deep_dir).unwrap();\n        fs::create_dir_all(&sub_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file1 = deep_dir.join(\"20260211_14.txt\");\n        let file2 = sub_dir.join(\"old.log\");\n        for (path, name, dir, ext) in [\n            (&file1, \"20260211_14.txt\", &deep_dir, \"txt\"),\n            (&file2, \"old.log\", &sub_dir, \"log\"),\n        ] {\n            conn.execute(\n                \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n                 VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n                params![\n                    path.to_string_lossy().to_string(),\n                    name,\n                    dir.to_string_lossy().to_string(),\n                    ext,\n                    now\n                ],\n            )\n            .unwrap();\n        }\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n\n        // Query: \"jp.naver.line/log/\" - dir listing, name_like = \"%\"\n        let result = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result.results.len(),\n            2,\n            \"should find both files under log/ and log/archive/\"\n        );\n        let names: Vec<&str> = result.results.iter().map(|e| e.name.as_str()).collect();\n        assert!(names.contains(&\"20260211_14.txt\"));\n        assert!(names.contains(&\"old.log\"));\n\n        // Query with glob: \"jp.naver.line/log/ *\"\n        let result2 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result2.results.len(),\n            2,\n            \"glob * should also list all files\"\n        );\n\n        // Query with trailing dot: \"jp.naver.line/log/ *.\" - name_like becomes \"%.\"\n        let result3 = execute_search(\n            &state,\n            \"jp.naver.line/log/ *.\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        // \"*.\" matches files ending with \".\" - none of our test files end with \".\"\n        // so this correctly returns 0 (this is expected, NOT a bug)\n        assert_eq!(\n            result3.results.len(),\n            0,\n            \"*. matches only files ending with dot\"\n        );\n\n        // But plain \"/\" at end should list all\n        let result4 = execute_search(\n            &state,\n            \"jp.naver.line/log/\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(\n            result4.results.len(),\n            2,\n            \"trailing slash should list all files\"\n        );\n\n        let _ = fs::remove_dir_all(root);\n    }\n\n    #[test]\n    fn path_search_multi_dot_ext_uses_like_not_ext_shortcut() {\n        let root = temp_case_dir(\"multi_dot_ext\");\n        let proj_dir = root.join(\"Projects\");\n        fs::create_dir_all(&proj_dir).unwrap();\n\n        let db_path = root.join(\"index.db\");\n        init_db(&db_path).unwrap();\n        let conn = db_connection(&db_path).unwrap();\n        let now = now_epoch();\n\n        let file_path = proj_dir.join(\"archive.tar.gz\");\n        conn.execute(\n            \"INSERT INTO entries(path, name, dir, is_dir, ext, mtime, size, indexed_at, run_id)\n             VALUES(?1, ?2, ?3, 0, ?4, NULL, NULL, ?5, 1)\",\n            params![\n                file_path.to_string_lossy().to_string(),\n                \"archive.tar.gz\",\n                proj_dir.to_string_lossy().to_string(),\n                \"gz\",\n                now\n            ],\n        )\n        .unwrap();\n\n        let state = test_state_for(db_path, root.clone(), root.clone());\n        let result = execute_search(\n            &state,\n            \"Projects/ *.tar.gz\".to_string(),\n            Some(300),\n            Some(0),\n            Some(\"name\".to_string()),\n            Some(\"asc\".to_string()),\n        )\n        .unwrap();\n\n        assert_eq!(result.results.len(), 1);\n        assert!(result.results[0].name == \"archive.tar.gz\");\n\n        let _ = fs::remove_dir_all(root);\n    }\n}\n","structuredPatch":[{"oldStart":1389,"oldLines":10,"newStart":1389,"newLines":6,"lines":["     index_row_from_path_and_metadata(entry.path(), &metadata)"," }"," ","-fn index_row_from_jwalk_entry(entry: &jwalk::DirEntry<((), ())>) -> Option<IndexRow> {","-    let metadata = entry.metadata().ok()?;","-    index_row_from_path_and_metadata(&entry.path(), &metadata)","-}"," "," fn collect_rows_recursive(","     root: &Path,"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"8c37d427-85ac-4962-b7d4-0220f3d4b8e2"}
{"parentUuid":"31d82131-b47d-4c76-b2d2-cfd992b74f27","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01AnRQaATDoVUY1JZpJM9eEz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YJ1VRBizV1sSsJ3yMG8GFt","name":"Bash","input":{"command":"cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | head -30","description":"Verify clean compile","timeout":120000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":920,"cache_read_input_tokens":139626,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":920},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkXy7veCG9UKpiyurfk","type":"assistant","uuid":"a761f3cf-cb2c-4f33-9d01-888c6e893ba8","timestamp":"2026-02-22T07:57:36.340Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T07:57:39.387Z","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","content":"{\"task_id\":\"b702fe8\",\"tool_use_id\":\"toolu_01YJ1VRBizV1sSsJ3yMG8GFt\",\"description\":\"Verify clean compile\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"a761f3cf-cb2c-4f33-9d01-888c6e893ba8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b702fe8","timeoutMs":120000},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_01YJ1VRBizV1sSsJ3yMG8GFt","uuid":"ebb71800-4773-4432-9342-68ecc55fb085","timestamp":"2026-02-22T07:57:39.388Z"}
{"parentUuid":"a761f3cf-cb2c-4f33-9d01-888c6e893ba8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YJ1VRBizV1sSsJ3yMG8GFt","type":"tool_result","content":"    Blocking waiting for file lock on build directory\n    Checking everything v0.2.0 (/Users/al02402336/everything/src-tauri)\nwarning: method `root_paths` is never used\n  --> src/gitignore_filter.rs:23:12\n   |\n17 | impl GitignoreFilter {\n   | -------------------- method in this implementation\n...\n23 |     pub fn root_paths(&self) -> Vec<&Path> {\n   |            ^^^^^^^^^^\n   |\n   = note: `#[warn(dead_code)]` on by default\n\nwarning: `everything` (bin \"everything\") generated 1 warning\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 3.49s","is_error":false}]},"uuid":"2cd94fcd-161f-48b5-aaa9-eab1ccefa73d","timestamp":"2026-02-22T07:57:40.105Z","toolUseResult":{"stdout":"    Blocking waiting for file lock on build directory\n    Checking everything v0.2.0 (/Users/al02402336/everything/src-tauri)\nwarning: method `root_paths` is never used\n  --> src/gitignore_filter.rs:23:12\n   |\n17 | impl GitignoreFilter {\n   | -------------------- method in this implementation\n...\n23 |     pub fn root_paths(&self) -> Vec<&Path> {\n   |            ^^^^^^^^^^\n   |\n   = note: `#[warn(dead_code)]` on by default\n\nwarning: `everything` (bin \"everything\") generated 1 warning\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 3.49s","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"a761f3cf-cb2c-4f33-9d01-888c6e893ba8"}
{"parentUuid":"2cd94fcd-161f-48b5-aaa9-eab1ccefa73d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01QWJoFvbyqrsf9qj3SQZEUk","type":"message","role":"assistant","content":[{"type":"text","text":"Clean compile with only the pre-existing `root_paths` warning. Now build the production release and test:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":417,"cache_read_input_tokens":140546,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":417},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkYS8P7GmNrjvZFgfMU","type":"assistant","uuid":"a5b916fe-75bb-424d-a545-783952e824e5","timestamp":"2026-02-22T07:57:42.473Z"}
{"parentUuid":"a5b916fe-75bb-424d-a545-783952e824e5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01QWJoFvbyqrsf9qj3SQZEUk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","name":"Bash","input":{"command":"npm run tauri build 2>&1 | tail -20","description":"Build production release","timeout":300000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":417,"cache_read_input_tokens":140546,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":417},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkYS8P7GmNrjvZFgfMU","type":"assistant","uuid":"de0214d4-57d0-4550-831c-f2fe5a23deb7","timestamp":"2026-02-22T07:57:43.359Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T07:57:48.083Z","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","content":"{\"task_id\":\"b33e669\",\"tool_use_id\":\"toolu_01SDeR4jrrU2ujKMQ3fh9ruw\",\"description\":\"Build production release\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"de0214d4-57d0-4550-831c-f2fe5a23deb7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e7daae9d-0c21-4fca-ae01-46dc588e03a4","timestamp":"2026-02-22T07:57:48.084Z"}
{"parentUuid":"e7daae9d-0c21-4fca-ae01-46dc588e03a4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":4,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-1","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"546b9232-016d-4877-ac77-577c547df4f0","timestamp":"2026-02-22T07:57:49.087Z"}
{"parentUuid":"546b9232-016d-4877-ac77-577c547df4f0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":5,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-2","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"314a560b-59ff-4306-ba22-c6d783dcb4b5","timestamp":"2026-02-22T07:57:50.084Z"}
{"parentUuid":"314a560b-59ff-4306-ba22-c6d783dcb4b5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":6,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-3","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3052ba42-3d90-4a35-a429-963ec3f3919f","timestamp":"2026-02-22T07:57:51.089Z"}
{"parentUuid":"3052ba42-3d90-4a35-a429-963ec3f3919f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":7,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-4","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"c4d31e39-2b5a-4b6a-b8a9-6af389b333cb","timestamp":"2026-02-22T07:57:52.087Z"}
{"parentUuid":"c4d31e39-2b5a-4b6a-b8a9-6af389b333cb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":8,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-5","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1f74a688-1932-49fd-8817-c01b2b426afa","timestamp":"2026-02-22T07:57:53.087Z"}
{"parentUuid":"1f74a688-1932-49fd-8817-c01b2b426afa","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":9,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-6","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"785ea142-b675-48ca-ab6c-58f99d6a98d2","timestamp":"2026-02-22T07:57:54.087Z"}
{"parentUuid":"785ea142-b675-48ca-ab6c-58f99d6a98d2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":10,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-7","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"16107201-bf4f-4fc4-892e-968f5b0b8ba1","timestamp":"2026-02-22T07:57:55.109Z"}
{"parentUuid":"16107201-bf4f-4fc4-892e-968f5b0b8ba1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":11,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-8","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d9326cb8-e456-4ad0-b0fc-36f87b0649da","timestamp":"2026-02-22T07:57:56.114Z"}
{"parentUuid":"d9326cb8-e456-4ad0-b0fc-36f87b0649da","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":12,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-9","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"38a15c8f-1fb7-4b3a-b2b1-1e0a1ecd5ab4","timestamp":"2026-02-22T07:57:57.110Z"}
{"parentUuid":"38a15c8f-1fb7-4b3a-b2b1-1e0a1ecd5ab4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":13,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-10","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3b00e224-d168-4ad5-aa30-fe228fa76322","timestamp":"2026-02-22T07:57:58.116Z"}
{"parentUuid":"3b00e224-d168-4ad5-aa30-fe228fa76322","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":14,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-11","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0e6f48a1-04c6-49cc-a758-47fa44b54e15","timestamp":"2026-02-22T07:57:59.127Z"}
{"parentUuid":"0e6f48a1-04c6-49cc-a758-47fa44b54e15","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":15,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-12","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"ae875ea9-1238-4b39-ad1e-62834fcc12f0","timestamp":"2026-02-22T07:58:00.122Z"}
{"parentUuid":"ae875ea9-1238-4b39-ad1e-62834fcc12f0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":16,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-13","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"eee5b4ba-5c82-478d-a589-e94699136c42","timestamp":"2026-02-22T07:58:01.128Z"}
{"parentUuid":"eee5b4ba-5c82-478d-a589-e94699136c42","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":17,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-14","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a48731c0-f622-4d2d-93e8-cb43158da3ee","timestamp":"2026-02-22T07:58:02.119Z"}
{"parentUuid":"a48731c0-f622-4d2d-93e8-cb43158da3ee","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":18,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-15","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"fd8bb4f4-5ed3-4b62-b1ae-75cbba59ab4d","timestamp":"2026-02-22T07:58:03.121Z"}
{"parentUuid":"fd8bb4f4-5ed3-4b62-b1ae-75cbba59ab4d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":19,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-16","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0f10fabc-4e9b-4b81-b88e-b58a484350c7","timestamp":"2026-02-22T07:58:04.120Z"}
{"parentUuid":"0f10fabc-4e9b-4b81-b88e-b58a484350c7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":20,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-17","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"cb3d9472-1eb2-4c89-a882-a3f23d61257e","timestamp":"2026-02-22T07:58:05.122Z"}
{"parentUuid":"cb3d9472-1eb2-4c89-a882-a3f23d61257e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":21,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-18","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d4cacde0-90fd-4a4b-abdd-7a99b3c6a7d5","timestamp":"2026-02-22T07:58:06.122Z"}
{"parentUuid":"d4cacde0-90fd-4a4b-abdd-7a99b3c6a7d5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":22,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-19","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"f5f314ff-3d7c-460c-922a-06081b85c441","timestamp":"2026-02-22T07:58:07.124Z"}
{"parentUuid":"f5f314ff-3d7c-460c-922a-06081b85c441","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":23,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-20","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"60ff93cf-30a6-4974-b13b-8f61b2f64da5","timestamp":"2026-02-22T07:58:08.126Z"}
{"parentUuid":"60ff93cf-30a6-4974-b13b-8f61b2f64da5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":24,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-21","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"7fd45591-404e-4c96-af5f-0ade045c98b2","timestamp":"2026-02-22T07:58:09.129Z"}
{"parentUuid":"7fd45591-404e-4c96-af5f-0ade045c98b2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":25,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-22","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"ddf20262-1357-43f0-a293-326e6795dce2","timestamp":"2026-02-22T07:58:10.159Z"}
{"parentUuid":"ddf20262-1357-43f0-a293-326e6795dce2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":26,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-23","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"705e2694-0bd4-4f2f-be3d-00a0fcf01e27","timestamp":"2026-02-22T07:58:11.137Z"}
{"parentUuid":"705e2694-0bd4-4f2f-be3d-00a0fcf01e27","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":27,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-24","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"98d4c4ef-a671-470c-94cc-17ae2f0881d8","timestamp":"2026-02-22T07:58:12.145Z"}
{"parentUuid":"98d4c4ef-a671-470c-94cc-17ae2f0881d8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":28,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-25","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"06909296-8b8e-4bac-b6f3-43811c9e275a","timestamp":"2026-02-22T07:58:13.186Z"}
{"parentUuid":"06909296-8b8e-4bac-b6f3-43811c9e275a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":29,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-26","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1242c26c-aa89-47eb-94a7-68dc8b249e65","timestamp":"2026-02-22T07:58:14.169Z"}
{"parentUuid":"1242c26c-aa89-47eb-94a7-68dc8b249e65","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":30,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-27","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"05c9442c-fb4d-4805-8d81-7b732530c9c1","timestamp":"2026-02-22T07:58:15.237Z"}
{"parentUuid":"05c9442c-fb4d-4805-8d81-7b732530c9c1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":31,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-28","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"95d60911-f7fe-42e9-b0d7-8d9da3e5d0b9","timestamp":"2026-02-22T07:58:16.199Z"}
{"parentUuid":"95d60911-f7fe-42e9-b0d7-8d9da3e5d0b9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":32,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-29","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"f457a41b-e457-44f2-a6da-653efd52e64d","timestamp":"2026-02-22T07:58:17.195Z"}
{"parentUuid":"f457a41b-e457-44f2-a6da-653efd52e64d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":33,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-30","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"c379648e-458c-4b37-9ef1-da802e8502c4","timestamp":"2026-02-22T07:58:18.195Z"}
{"parentUuid":"c379648e-458c-4b37-9ef1-da802e8502c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":34,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-31","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1ded9f45-d1ae-48db-b2c9-df6093181fbc","timestamp":"2026-02-22T07:58:19.196Z"}
{"parentUuid":"1ded9f45-d1ae-48db-b2c9-df6093181fbc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":35,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-32","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"2ba24863-30f4-4c51-a4e9-f289e74d9161","timestamp":"2026-02-22T07:58:20.215Z"}
{"parentUuid":"2ba24863-30f4-4c51-a4e9-f289e74d9161","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":36,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-33","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a0b16aae-35bc-4913-8c13-e752727e537a","timestamp":"2026-02-22T07:58:21.199Z"}
{"parentUuid":"a0b16aae-35bc-4913-8c13-e752727e537a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":37,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-34","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"571d21ab-308a-4fa1-a597-cbe5110ec1b2","timestamp":"2026-02-22T07:58:22.199Z"}
{"parentUuid":"571d21ab-308a-4fa1-a597-cbe5110ec1b2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":38,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-35","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1100fa52-eda0-43fb-b5a1-765afc94f415","timestamp":"2026-02-22T07:58:23.207Z"}
{"parentUuid":"1100fa52-eda0-43fb-b5a1-765afc94f415","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":39,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-36","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"55ddeaf4-e40f-468d-aff4-418f7dc43ea0","timestamp":"2026-02-22T07:58:24.203Z"}
{"parentUuid":"55ddeaf4-e40f-468d-aff4-418f7dc43ea0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":40,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-37","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"783dbbea-fea3-445e-8153-15cac09bb52d","timestamp":"2026-02-22T07:58:25.219Z"}
{"parentUuid":"783dbbea-fea3-445e-8153-15cac09bb52d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":41,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-38","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"dc2ce0ab-98a1-495f-807c-5850e5d3a545","timestamp":"2026-02-22T07:58:26.237Z"}
{"parentUuid":"dc2ce0ab-98a1-495f-807c-5850e5d3a545","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":42,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-39","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"06512a1e-e691-4edf-be10-3aa4fec71282","timestamp":"2026-02-22T07:58:27.221Z"}
{"parentUuid":"06512a1e-e691-4edf-be10-3aa4fec71282","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":43,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-40","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"beb8b67e-2480-48d1-bac4-0d40ae3cd356","timestamp":"2026-02-22T07:58:28.216Z"}
{"parentUuid":"beb8b67e-2480-48d1-bac4-0d40ae3cd356","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":44,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-41","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1307d285-7dd1-409c-9779-f36597ebb671","timestamp":"2026-02-22T07:58:29.219Z"}
{"parentUuid":"1307d285-7dd1-409c-9779-f36597ebb671","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":45,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-42","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"916a4636-608a-46f3-a59c-b447d643173f","timestamp":"2026-02-22T07:58:30.225Z"}
{"parentUuid":"916a4636-608a-46f3-a59c-b447d643173f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":46,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-43","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"fb8c679e-6a47-482f-8cfe-161880c49539","timestamp":"2026-02-22T07:58:31.223Z"}
{"parentUuid":"fb8c679e-6a47-482f-8cfe-161880c49539","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":47,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-44","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"49decfb6-6b13-4fb4-9f33-9674b5715291","timestamp":"2026-02-22T07:58:32.224Z"}
{"parentUuid":"49decfb6-6b13-4fb4-9f33-9674b5715291","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":48,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-45","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"240923ec-ead1-400c-a97a-c579c4ceed0c","timestamp":"2026-02-22T07:58:33.226Z"}
{"parentUuid":"240923ec-ead1-400c-a97a-c579c4ceed0c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":49,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-46","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a77189d6-8be0-4bb9-9b82-d55986a12ecd","timestamp":"2026-02-22T07:58:34.226Z"}
{"parentUuid":"a77189d6-8be0-4bb9-9b82-d55986a12ecd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":50,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-47","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a8f4f70a-f8b5-43e1-b463-2eeae3ccb835","timestamp":"2026-02-22T07:58:35.226Z"}
{"parentUuid":"a8f4f70a-f8b5-43e1-b463-2eeae3ccb835","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":51,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-48","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"5b80470f-894b-4d31-8c70-16530e3e86c4","timestamp":"2026-02-22T07:58:36.229Z"}
{"parentUuid":"5b80470f-894b-4d31-8c70-16530e3e86c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":52,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-49","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"74dcdafa-2f49-422e-a7f7-2eda2dc9553b","timestamp":"2026-02-22T07:58:37.231Z"}
{"parentUuid":"74dcdafa-2f49-422e-a7f7-2eda2dc9553b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":53,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-50","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"12d0e6fc-b803-4a85-bd31-7136565469c0","timestamp":"2026-02-22T07:58:38.232Z"}
{"parentUuid":"12d0e6fc-b803-4a85-bd31-7136565469c0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":54,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-51","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"924b6184-b7c4-4576-8e6f-d384c919a9d1","timestamp":"2026-02-22T07:58:39.233Z"}
{"parentUuid":"924b6184-b7c4-4576-8e6f-d384c919a9d1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":55,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-52","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3cbdeedc-35a6-4a23-8d87-1c2f3a8c9520","timestamp":"2026-02-22T07:58:40.233Z"}
{"parentUuid":"3cbdeedc-35a6-4a23-8d87-1c2f3a8c9520","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":56,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-53","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d4e46cee-8323-41ed-8986-e94c7d18ca40","timestamp":"2026-02-22T07:58:41.234Z"}
{"parentUuid":"d4e46cee-8323-41ed-8986-e94c7d18ca40","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":57,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-54","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"834ff6ad-a90d-4eb5-b69d-27daedb8ec91","timestamp":"2026-02-22T07:58:42.234Z"}
{"parentUuid":"834ff6ad-a90d-4eb5-b69d-27daedb8ec91","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":58,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-55","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"4267d72b-f9a0-4d2e-b284-0af784256037","timestamp":"2026-02-22T07:58:43.235Z"}
{"parentUuid":"4267d72b-f9a0-4d2e-b284-0af784256037","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":59,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-56","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"de969996-7452-4a7b-b98a-ba7179da13af","timestamp":"2026-02-22T07:58:44.237Z"}
{"parentUuid":"de969996-7452-4a7b-b98a-ba7179da13af","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":60,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-57","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3d56451d-3ab6-4d87-b18f-cbbac49bb480","timestamp":"2026-02-22T07:58:45.238Z"}
{"parentUuid":"3d56451d-3ab6-4d87-b18f-cbbac49bb480","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":61,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-58","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e5ba1c4a-1d59-4c52-866f-671fd7ca7cd6","timestamp":"2026-02-22T07:58:46.238Z"}
{"parentUuid":"e5ba1c4a-1d59-4c52-866f-671fd7ca7cd6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":62,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-59","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"9875ba58-21f8-433d-a552-01613a51164a","timestamp":"2026-02-22T07:58:47.239Z"}
{"parentUuid":"9875ba58-21f8-433d-a552-01613a51164a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":63,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-60","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"8612f03c-e0d3-4f84-a8ec-c259e062bc74","timestamp":"2026-02-22T07:58:48.239Z"}
{"parentUuid":"8612f03c-e0d3-4f84-a8ec-c259e062bc74","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":64,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-61","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"6707a0b3-58c6-46b5-8fd4-68dcbbf0eebc","timestamp":"2026-02-22T07:58:49.241Z"}
{"parentUuid":"6707a0b3-58c6-46b5-8fd4-68dcbbf0eebc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":65,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-62","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"b8ef7334-0088-4c21-854e-3f4c23a42f8b","timestamp":"2026-02-22T07:58:50.241Z"}
{"parentUuid":"b8ef7334-0088-4c21-854e-3f4c23a42f8b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":66,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-63","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"4e79b280-5f66-4949-99c0-536c77e4a003","timestamp":"2026-02-22T07:58:51.243Z"}
{"parentUuid":"4e79b280-5f66-4949-99c0-536c77e4a003","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":67,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-64","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"abadd44c-7afa-470d-8876-061c1654ec05","timestamp":"2026-02-22T07:58:52.243Z"}
{"parentUuid":"abadd44c-7afa-470d-8876-061c1654ec05","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":68,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-65","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"728f4c8e-cf8d-41ad-87fa-4d9978b45e2d","timestamp":"2026-02-22T07:58:53.246Z"}
{"parentUuid":"728f4c8e-cf8d-41ad-87fa-4d9978b45e2d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":69,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-66","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"6a5201a6-4888-44b2-97f1-59cee09079fb","timestamp":"2026-02-22T07:58:54.245Z"}
{"parentUuid":"6a5201a6-4888-44b2-97f1-59cee09079fb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":70,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-67","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1cc00291-8dcf-4b2e-82d5-d1f9e8529cf7","timestamp":"2026-02-22T07:58:55.247Z"}
{"parentUuid":"1cc00291-8dcf-4b2e-82d5-d1f9e8529cf7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":71,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-68","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1dc9561b-5a5c-4d6d-a2ef-c5a3ae07d920","timestamp":"2026-02-22T07:58:56.249Z"}
{"parentUuid":"1dc9561b-5a5c-4d6d-a2ef-c5a3ae07d920","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":72,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-69","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"87f0bd97-5db6-4c94-88a1-a00666fbf197","timestamp":"2026-02-22T07:58:57.249Z"}
{"parentUuid":"87f0bd97-5db6-4c94-88a1-a00666fbf197","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":73,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-70","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"bbb9cf28-b3f3-4f55-85b4-361471371d9d","timestamp":"2026-02-22T07:58:58.249Z"}
{"parentUuid":"bbb9cf28-b3f3-4f55-85b4-361471371d9d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":74,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-71","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"c3e5a5fe-9c9a-4011-99fd-0d6f061ba529","timestamp":"2026-02-22T07:58:59.249Z"}
{"parentUuid":"c3e5a5fe-9c9a-4011-99fd-0d6f061ba529","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":75,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-72","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"67c01414-4f43-4e3d-9e55-e6d8248c4807","timestamp":"2026-02-22T07:59:00.250Z"}
{"parentUuid":"67c01414-4f43-4e3d-9e55-e6d8248c4807","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":76,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-73","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"b11acfb3-19aa-4af0-87fb-4fc0fce77d1c","timestamp":"2026-02-22T07:59:01.251Z"}
{"parentUuid":"b11acfb3-19aa-4af0-87fb-4fc0fce77d1c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":77,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-74","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e76ec4ff-2bfb-4d0c-aa3c-68a9903cb4da","timestamp":"2026-02-22T07:59:02.253Z"}
{"parentUuid":"e76ec4ff-2bfb-4d0c-aa3c-68a9903cb4da","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":78,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-75","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"69c643bb-a675-4593-9303-63b01d1302de","timestamp":"2026-02-22T07:59:03.254Z"}
{"parentUuid":"69c643bb-a675-4593-9303-63b01d1302de","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":79,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-76","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"aace2fd4-a29f-4b46-b7e7-0efc226e9a4a","timestamp":"2026-02-22T07:59:04.255Z"}
{"parentUuid":"aace2fd4-a29f-4b46-b7e7-0efc226e9a4a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":80,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-77","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"6044316b-212c-447d-964f-6a4c05e0ab95","timestamp":"2026-02-22T07:59:05.256Z"}
{"parentUuid":"6044316b-212c-447d-964f-6a4c05e0ab95","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":81,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-78","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"fcadc299-ac35-4bc9-a421-cd784d76f9ac","timestamp":"2026-02-22T07:59:06.257Z"}
{"parentUuid":"fcadc299-ac35-4bc9-a421-cd784d76f9ac","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":82,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-79","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"23e79361-c425-4def-bb9c-4a556592736f","timestamp":"2026-02-22T07:59:07.257Z"}
{"parentUuid":"23e79361-c425-4def-bb9c-4a556592736f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":83,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-80","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"b54cc9dc-5895-4fab-8fe1-a08ed195915b","timestamp":"2026-02-22T07:59:08.258Z"}
{"parentUuid":"b54cc9dc-5895-4fab-8fe1-a08ed195915b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":84,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-81","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"93a511ca-2c46-45e1-890c-4e5c64f19caa","timestamp":"2026-02-22T07:59:09.260Z"}
{"parentUuid":"93a511ca-2c46-45e1-890c-4e5c64f19caa","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":85,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-82","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"5efa051d-3af1-45b7-bef7-f47df907740b","timestamp":"2026-02-22T07:59:10.259Z"}
{"parentUuid":"5efa051d-3af1-45b7-bef7-f47df907740b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":86,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-83","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"4ae07c36-3c13-41d0-88f7-bd92dfc51254","timestamp":"2026-02-22T07:59:11.260Z"}
{"parentUuid":"4ae07c36-3c13-41d0-88f7-bd92dfc51254","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":87,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-84","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"9bf29603-8dfe-42d8-8c09-bcd7dcfa72d4","timestamp":"2026-02-22T07:59:12.261Z"}
{"parentUuid":"9bf29603-8dfe-42d8-8c09-bcd7dcfa72d4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":88,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-85","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"39549b03-265c-4450-8ae4-875c96aaeba6","timestamp":"2026-02-22T07:59:13.263Z"}
{"parentUuid":"39549b03-265c-4450-8ae4-875c96aaeba6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":89,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-86","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"18a9afc9-51ff-44c1-8f32-37ed6c5cc1c4","timestamp":"2026-02-22T07:59:14.264Z"}
{"parentUuid":"18a9afc9-51ff-44c1-8f32-37ed6c5cc1c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":90,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-87","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d7a95018-cece-4154-b64e-1064ae794559","timestamp":"2026-02-22T07:59:15.265Z"}
{"parentUuid":"d7a95018-cece-4154-b64e-1064ae794559","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":91,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-88","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3703eaad-dc9d-40c8-97cc-9b38d6e5d6f7","timestamp":"2026-02-22T07:59:16.265Z"}
{"parentUuid":"3703eaad-dc9d-40c8-97cc-9b38d6e5d6f7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":92,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-89","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d668b6bb-4ba8-492b-947b-f3226de0fa8d","timestamp":"2026-02-22T07:59:17.266Z"}
{"parentUuid":"d668b6bb-4ba8-492b-947b-f3226de0fa8d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":93,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-90","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3e55e677-0714-4981-b062-a13095abbc69","timestamp":"2026-02-22T07:59:18.267Z"}
{"parentUuid":"3e55e677-0714-4981-b062-a13095abbc69","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":94,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-91","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"28c6d256-3fe8-4ae7-bbeb-8fb0acda412b","timestamp":"2026-02-22T07:59:19.271Z"}
{"parentUuid":"28c6d256-3fe8-4ae7-bbeb-8fb0acda412b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":95,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-92","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0971e8ba-f1eb-4380-9802-6104edef1c56","timestamp":"2026-02-22T07:59:20.270Z"}
{"parentUuid":"0971e8ba-f1eb-4380-9802-6104edef1c56","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":96,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-93","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"5ec29173-bfe9-4733-ac47-600d90162625","timestamp":"2026-02-22T07:59:21.271Z"}
{"parentUuid":"5ec29173-bfe9-4733-ac47-600d90162625","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":97,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-94","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e4967178-1032-454f-b9df-0c40e6042bcd","timestamp":"2026-02-22T07:59:22.271Z"}
{"parentUuid":"e4967178-1032-454f-b9df-0c40e6042bcd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":98,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-95","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"8bf0213c-b2ff-4fbc-bc60-e27836e20eda","timestamp":"2026-02-22T07:59:23.273Z"}
{"parentUuid":"8bf0213c-b2ff-4fbc-bc60-e27836e20eda","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":99,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-96","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"bdee028d-0b91-48bd-a92c-4a8ecbbeea32","timestamp":"2026-02-22T07:59:24.274Z"}
{"parentUuid":"bdee028d-0b91-48bd-a92c-4a8ecbbeea32","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":100,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-97","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"b83df0a4-3e27-421c-8014-0405722f7fc8","timestamp":"2026-02-22T07:59:25.275Z"}
{"parentUuid":"b83df0a4-3e27-421c-8014-0405722f7fc8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":101,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-98","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"ecb0c8c7-a49a-44d2-8a16-75d250242372","timestamp":"2026-02-22T07:59:26.276Z"}
{"parentUuid":"ecb0c8c7-a49a-44d2-8a16-75d250242372","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":102,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-99","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"00d6c3b8-72e4-47cd-9c35-4691ae6e48f9","timestamp":"2026-02-22T07:59:27.276Z"}
{"parentUuid":"00d6c3b8-72e4-47cd-9c35-4691ae6e48f9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":103,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-100","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d7126143-f645-4060-a228-89a99678e59b","timestamp":"2026-02-22T07:59:28.276Z"}
{"parentUuid":"d7126143-f645-4060-a228-89a99678e59b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":104,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-101","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"2cb2e2d5-74e6-472c-a4f1-db3417f3357e","timestamp":"2026-02-22T07:59:29.277Z"}
{"parentUuid":"2cb2e2d5-74e6-472c-a4f1-db3417f3357e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":105,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-102","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"fa00f01c-3437-421c-b3b6-f559adeeb09b","timestamp":"2026-02-22T07:59:30.279Z"}
{"parentUuid":"fa00f01c-3437-421c-b3b6-f559adeeb09b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":106,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-103","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0ecb87d7-2256-499b-8385-b6bd8f27df57","timestamp":"2026-02-22T07:59:31.279Z"}
{"parentUuid":"0ecb87d7-2256-499b-8385-b6bd8f27df57","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":107,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-104","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a91ae24e-51af-42ad-beb0-5f62a71f7c7d","timestamp":"2026-02-22T07:59:32.279Z"}
{"parentUuid":"a91ae24e-51af-42ad-beb0-5f62a71f7c7d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":108,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-105","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"4667f15d-38ac-406b-8243-9bf79b4527bc","timestamp":"2026-02-22T07:59:33.279Z"}
{"parentUuid":"4667f15d-38ac-406b-8243-9bf79b4527bc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":109,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-106","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"346a7b65-f9a2-4804-abc4-88d9cec799d4","timestamp":"2026-02-22T07:59:34.282Z"}
{"parentUuid":"346a7b65-f9a2-4804-abc4-88d9cec799d4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":110,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-107","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"1946780d-3c90-4ded-8975-ad3267f84bce","timestamp":"2026-02-22T07:59:35.284Z"}
{"parentUuid":"1946780d-3c90-4ded-8975-ad3267f84bce","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":111,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-108","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a1a040e8-7aa5-4e8a-b52f-3e29960e93b0","timestamp":"2026-02-22T07:59:36.285Z"}
{"parentUuid":"a1a040e8-7aa5-4e8a-b52f-3e29960e93b0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":112,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-109","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"5c5d7446-2703-4b43-8c62-1466ede670e8","timestamp":"2026-02-22T07:59:37.287Z"}
{"parentUuid":"5c5d7446-2703-4b43-8c62-1466ede670e8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":113,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-110","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"241e2a5a-dbc1-422a-ae09-d4e824360ba5","timestamp":"2026-02-22T07:59:38.286Z"}
{"parentUuid":"241e2a5a-dbc1-422a-ae09-d4e824360ba5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":114,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-111","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e04c2b39-4749-4806-997a-4a862185a5ed","timestamp":"2026-02-22T07:59:39.287Z"}
{"parentUuid":"e04c2b39-4749-4806-997a-4a862185a5ed","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":115,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-112","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"f26315af-ebfe-4186-9762-cd3315cca1d9","timestamp":"2026-02-22T07:59:40.287Z"}
{"parentUuid":"f26315af-ebfe-4186-9762-cd3315cca1d9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":116,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-113","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a30284cf-dbf5-4e2f-a3d1-889a07032833","timestamp":"2026-02-22T07:59:41.289Z"}
{"parentUuid":"a30284cf-dbf5-4e2f-a3d1-889a07032833","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":117,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-114","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0b462ef6-0f31-400b-a6f9-c6ec5d393708","timestamp":"2026-02-22T07:59:42.291Z"}
{"parentUuid":"0b462ef6-0f31-400b-a6f9-c6ec5d393708","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":118,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-115","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"c832e277-957e-4754-971a-ce850fbda33b","timestamp":"2026-02-22T07:59:43.291Z"}
{"parentUuid":"c832e277-957e-4754-971a-ce850fbda33b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":119,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-116","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"94e66508-35ab-4f87-9855-07821a09fa03","timestamp":"2026-02-22T07:59:44.292Z"}
{"parentUuid":"94e66508-35ab-4f87-9855-07821a09fa03","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":120,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-117","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"5791bef0-5eb4-47b6-8716-71bdb9916da0","timestamp":"2026-02-22T07:59:45.294Z"}
{"parentUuid":"5791bef0-5eb4-47b6-8716-71bdb9916da0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":121,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-118","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"44e528f7-db8e-4c8f-a116-db44cc3a4bf1","timestamp":"2026-02-22T07:59:46.298Z"}
{"parentUuid":"44e528f7-db8e-4c8f-a116-db44cc3a4bf1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":122,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-119","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"b54b7856-4538-48f7-b15b-27eb17f3fb86","timestamp":"2026-02-22T07:59:47.298Z"}
{"parentUuid":"b54b7856-4538-48f7-b15b-27eb17f3fb86","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":123,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-120","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"7cb60016-7a75-4c5e-8753-f09fcf2b1642","timestamp":"2026-02-22T07:59:48.299Z"}
{"parentUuid":"7cb60016-7a75-4c5e-8753-f09fcf2b1642","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":124,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-121","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"8d74b854-39fa-45cc-a2d6-db9ee56181bf","timestamp":"2026-02-22T07:59:49.300Z"}
{"parentUuid":"8d74b854-39fa-45cc-a2d6-db9ee56181bf","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":125,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-122","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"24ea28bb-6a06-4a51-ae3f-00e205ec74f8","timestamp":"2026-02-22T07:59:50.315Z"}
{"parentUuid":"24ea28bb-6a06-4a51-ae3f-00e205ec74f8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":126,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-123","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"8eb10fac-a1cf-4c0c-afd6-7ad1b07cb9a2","timestamp":"2026-02-22T07:59:51.310Z"}
{"parentUuid":"8eb10fac-a1cf-4c0c-afd6-7ad1b07cb9a2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":127,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-124","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"083f7fab-ebaf-4342-b756-538b22f3cff6","timestamp":"2026-02-22T07:59:52.309Z"}
{"parentUuid":"083f7fab-ebaf-4342-b756-538b22f3cff6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":128,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-125","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"72d9307e-79c5-44ba-9b5a-dbaea9a9b92f","timestamp":"2026-02-22T07:59:53.310Z"}
{"parentUuid":"72d9307e-79c5-44ba-9b5a-dbaea9a9b92f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":129,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-126","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"cfa126ba-4854-44e4-b04c-93f2997e985c","timestamp":"2026-02-22T07:59:54.310Z"}
{"parentUuid":"cfa126ba-4854-44e4-b04c-93f2997e985c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":130,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-127","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"11a96d3f-b5f5-4fa0-bd09-5568142ee4a2","timestamp":"2026-02-22T07:59:55.311Z"}
{"parentUuid":"11a96d3f-b5f5-4fa0-bd09-5568142ee4a2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":131,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-128","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e77a93f4-0b59-4d38-975b-8c00486ad985","timestamp":"2026-02-22T07:59:56.316Z"}
{"parentUuid":"e77a93f4-0b59-4d38-975b-8c00486ad985","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":132,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-129","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a4b3e154-51b8-46a3-89cb-5cd562125967","timestamp":"2026-02-22T07:59:57.314Z"}
{"parentUuid":"a4b3e154-51b8-46a3-89cb-5cd562125967","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":133,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-130","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"520b0c09-c4cf-401c-a62d-ece01d57f9de","timestamp":"2026-02-22T07:59:58.315Z"}
{"parentUuid":"520b0c09-c4cf-401c-a62d-ece01d57f9de","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":134,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-131","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"2abf0aba-f5a9-4acc-9664-ec2fbf8d3e05","timestamp":"2026-02-22T07:59:59.317Z"}
{"parentUuid":"2abf0aba-f5a9-4acc-9664-ec2fbf8d3e05","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":135,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-132","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"89e14455-f111-417a-a5d4-ea32201c1da9","timestamp":"2026-02-22T08:00:00.318Z"}
{"parentUuid":"89e14455-f111-417a-a5d4-ea32201c1da9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":136,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-133","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"16e12ed2-c00d-44b8-a0e1-40c1bd97d371","timestamp":"2026-02-22T08:00:01.319Z"}
{"parentUuid":"16e12ed2-c00d-44b8-a0e1-40c1bd97d371","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":137,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-134","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"2ad6ef4d-232b-49e3-98e6-73211529ff40","timestamp":"2026-02-22T08:00:02.319Z"}
{"parentUuid":"2ad6ef4d-232b-49e3-98e6-73211529ff40","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":138,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-135","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"19f8762d-f02d-47a3-8edb-b72949cf3f53","timestamp":"2026-02-22T08:00:03.319Z"}
{"parentUuid":"19f8762d-f02d-47a3-8edb-b72949cf3f53","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":139,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-136","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"2dd0a498-c96d-4bf5-a393-899dbcc8c9b9","timestamp":"2026-02-22T08:00:04.334Z"}
{"parentUuid":"2dd0a498-c96d-4bf5-a393-899dbcc8c9b9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":140,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-137","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"235ee444-9c8a-4443-8b8e-07a115a875a3","timestamp":"2026-02-22T08:00:05.320Z"}
{"parentUuid":"235ee444-9c8a-4443-8b8e-07a115a875a3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":141,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-138","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"7c8de851-278b-4965-8b22-a168b54a779b","timestamp":"2026-02-22T08:00:06.321Z"}
{"parentUuid":"7c8de851-278b-4965-8b22-a168b54a779b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":142,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-139","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"04b5ae7e-163f-40e4-b94f-cb2e8a841b5f","timestamp":"2026-02-22T08:00:07.321Z"}
{"parentUuid":"04b5ae7e-163f-40e4-b94f-cb2e8a841b5f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":143,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-140","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"6b9fd5a2-7c3c-4daa-ac95-4d4ae32575cc","timestamp":"2026-02-22T08:00:08.322Z"}
{"parentUuid":"6b9fd5a2-7c3c-4daa-ac95-4d4ae32575cc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":144,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-141","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"55a028c0-1141-4d5e-8454-e185e0e7c645","timestamp":"2026-02-22T08:00:09.323Z"}
{"parentUuid":"55a028c0-1141-4d5e-8454-e185e0e7c645","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":145,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-142","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e0f70ed3-3fdb-4e1c-9094-b6a0cbbb0314","timestamp":"2026-02-22T08:00:10.323Z"}
{"parentUuid":"e0f70ed3-3fdb-4e1c-9094-b6a0cbbb0314","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":146,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-143","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"cf7ca782-a37d-4f03-a704-3f78a186f77b","timestamp":"2026-02-22T08:00:11.323Z"}
{"parentUuid":"cf7ca782-a37d-4f03-a704-3f78a186f77b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":147,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-144","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"774089b4-72c9-47fa-bb08-ad02c19a9024","timestamp":"2026-02-22T08:00:12.323Z"}
{"parentUuid":"774089b4-72c9-47fa-bb08-ad02c19a9024","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":148,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-145","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"c7b76679-86db-4055-8aee-d5b5af4f9659","timestamp":"2026-02-22T08:00:13.324Z"}
{"parentUuid":"c7b76679-86db-4055-8aee-d5b5af4f9659","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":149,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-146","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"2efc4dec-f3f2-4839-af95-f9f800374f87","timestamp":"2026-02-22T08:00:14.327Z"}
{"parentUuid":"2efc4dec-f3f2-4839-af95-f9f800374f87","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":150,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-147","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"629d6123-7868-4890-b198-ac1709bc9410","timestamp":"2026-02-22T08:00:15.329Z"}
{"parentUuid":"629d6123-7868-4890-b198-ac1709bc9410","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":151,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-148","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"d8e6ccbc-78ee-4688-a21d-2899a4aba0b1","timestamp":"2026-02-22T08:00:16.330Z"}
{"parentUuid":"d8e6ccbc-78ee-4688-a21d-2899a4aba0b1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":152,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-149","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"f1bbe984-178f-41a3-ba52-6880b064e6c4","timestamp":"2026-02-22T08:00:17.331Z"}
{"parentUuid":"f1bbe984-178f-41a3-ba52-6880b064e6c4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":153,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-150","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"cf1a95a5-f4e8-4d5a-8ed2-76cdd45f8203","timestamp":"2026-02-22T08:00:18.336Z"}
{"parentUuid":"cf1a95a5-f4e8-4d5a-8ed2-76cdd45f8203","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":154,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-151","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"7937a5a5-22b1-432d-8a10-f38d4cd94d03","timestamp":"2026-02-22T08:00:19.335Z"}
{"parentUuid":"7937a5a5-22b1-432d-8a10-f38d4cd94d03","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":155,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-152","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"aeefce74-a927-4864-986c-cfadf0e816df","timestamp":"2026-02-22T08:00:20.335Z"}
{"parentUuid":"aeefce74-a927-4864-986c-cfadf0e816df","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":156,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-153","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0a6dce7c-e75b-48eb-9085-3ea278b3eaa7","timestamp":"2026-02-22T08:00:21.337Z"}
{"parentUuid":"0a6dce7c-e75b-48eb-9085-3ea278b3eaa7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":157,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-154","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"95f220fe-bed1-4216-8383-3e04c306b043","timestamp":"2026-02-22T08:00:22.338Z"}
{"parentUuid":"95f220fe-bed1-4216-8383-3e04c306b043","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":158,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-155","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"f5a21856-bf8c-4e68-9ed0-1f001b2e2b47","timestamp":"2026-02-22T08:00:23.338Z"}
{"parentUuid":"f5a21856-bf8c-4e68-9ed0-1f001b2e2b47","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":159,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-156","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"f4dae125-4304-43da-9d66-d2c41115eaac","timestamp":"2026-02-22T08:00:24.339Z"}
{"parentUuid":"f4dae125-4304-43da-9d66-d2c41115eaac","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":160,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-157","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"86785773-9423-4e4a-b619-b2cedd983201","timestamp":"2026-02-22T08:00:25.342Z"}
{"parentUuid":"86785773-9423-4e4a-b619-b2cedd983201","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":161,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-158","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"63f98f09-dc5d-42ac-ad88-1e97a4092b69","timestamp":"2026-02-22T08:00:26.342Z"}
{"parentUuid":"63f98f09-dc5d-42ac-ad88-1e97a4092b69","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":162,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-159","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"4722291e-a995-4fa9-a5f6-04e86d97c990","timestamp":"2026-02-22T08:00:27.344Z"}
{"parentUuid":"4722291e-a995-4fa9-a5f6-04e86d97c990","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":163,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-160","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"fb2235db-9436-45fa-b26c-c802ad53c918","timestamp":"2026-02-22T08:00:28.344Z"}
{"parentUuid":"fb2235db-9436-45fa-b26c-c802ad53c918","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":164,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-161","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0ff07758-b450-4794-ac4f-54b778f657bd","timestamp":"2026-02-22T08:00:29.344Z"}
{"parentUuid":"0ff07758-b450-4794-ac4f-54b778f657bd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":165,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-162","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"82814aa6-9ffe-44a5-9d4a-5240c667954c","timestamp":"2026-02-22T08:00:30.347Z"}
{"parentUuid":"82814aa6-9ffe-44a5-9d4a-5240c667954c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":166,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-163","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"9f145c9f-b46f-42f9-a16c-86aa3a95589a","timestamp":"2026-02-22T08:00:31.347Z"}
{"parentUuid":"9f145c9f-b46f-42f9-a16c-86aa3a95589a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":167,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-164","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a6d382c5-bd30-4d71-9dd2-1df80fff7127","timestamp":"2026-02-22T08:00:32.348Z"}
{"parentUuid":"a6d382c5-bd30-4d71-9dd2-1df80fff7127","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":168,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-165","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"c0094ac9-6c89-451d-89a0-fe30fc81a1c7","timestamp":"2026-02-22T08:00:33.470Z"}
{"parentUuid":"c0094ac9-6c89-451d-89a0-fe30fc81a1c7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":169,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-166","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"a535ba0a-2103-46a2-b9aa-b2eaf4e187b5","timestamp":"2026-02-22T08:00:34.357Z"}
{"parentUuid":"a535ba0a-2103-46a2-b9aa-b2eaf4e187b5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":170,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-167","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"166a0680-c7d6-4642-a877-28ffd51fb2a3","timestamp":"2026-02-22T08:00:35.361Z"}
{"parentUuid":"166a0680-c7d6-4642-a877-28ffd51fb2a3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":171,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-168","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"641ae096-aa1e-4193-92f8-76fadf1fa8f5","timestamp":"2026-02-22T08:00:36.361Z"}
{"parentUuid":"641ae096-aa1e-4193-92f8-76fadf1fa8f5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":172,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-169","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"3a6f4926-5fbc-4381-9ebe-3879345d09c3","timestamp":"2026-02-22T08:00:37.371Z"}
{"parentUuid":"3a6f4926-5fbc-4381-9ebe-3879345d09c3","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":173,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-170","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"0e884c33-a38e-4ff3-92f6-bb1ae68b0ea5","timestamp":"2026-02-22T08:00:38.382Z"}
{"parentUuid":"0e884c33-a38e-4ff3-92f6-bb1ae68b0ea5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":174,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-171","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"745afd9d-84b6-48f8-b9d4-d876478e2dd0","timestamp":"2026-02-22T08:00:39.378Z"}
{"parentUuid":"745afd9d-84b6-48f8-b9d4-d876478e2dd0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":175,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-172","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"509df829-f0e1-4b24-8bc1-bac7f8006e01","timestamp":"2026-02-22T08:00:40.381Z"}
{"parentUuid":"509df829-f0e1-4b24-8bc1-bac7f8006e01","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":176,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-173","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"506a72cf-7c0e-48d0-82f2-0260c30d3097","timestamp":"2026-02-22T08:00:41.379Z"}
{"parentUuid":"506a72cf-7c0e-48d0-82f2-0260c30d3097","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":177,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-174","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e3ae7ad9-ef70-4f58-b545-9de4ea6b39f8","timestamp":"2026-02-22T08:00:42.381Z"}
{"parentUuid":"e3ae7ad9-ef70-4f58-b545-9de4ea6b39f8","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":178,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-175","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"ee2bf1f2-81cf-41dc-9865-02e87e6ed490","timestamp":"2026-02-22T08:00:43.382Z"}
{"parentUuid":"ee2bf1f2-81cf-41dc-9865-02e87e6ed490","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":179,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-176","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"19fc0e59-d363-4f87-b340-59c10accee2d","timestamp":"2026-02-22T08:00:44.390Z"}
{"parentUuid":"19fc0e59-d363-4f87-b340-59c10accee2d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":180,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-177","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"8733a1f5-5f31-4da7-985d-af8a289bcba4","timestamp":"2026-02-22T08:00:45.391Z"}
{"parentUuid":"8733a1f5-5f31-4da7-985d-af8a289bcba4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":181,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-178","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"b06b8e6d-5cd7-4f64-bebc-7c7d5a1612ef","timestamp":"2026-02-22T08:00:46.392Z"}
{"parentUuid":"b06b8e6d-5cd7-4f64-bebc-7c7d5a1612ef","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":182,"totalLines":0,"totalBytes":0,"taskId":"b33e669","timeoutMs":300000},"toolUseID":"bash-progress-179","parentToolUseID":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","uuid":"e5dc288c-bfb3-4225-9cb8-21c6d58d45bc","timestamp":"2026-02-22T08:00:47.392Z"}
{"parentUuid":"de0214d4-57d0-4550-831c-f2fe5a23deb7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SDeR4jrrU2ujKMQ3fh9ruw","type":"tool_result","content":"  --> src/gitignore_filter.rs:23:12\n   |\n17 | impl GitignoreFilter {\n   | -------------------- method in this implementation\n...\n23 |     pub fn root_paths(&self) -> Vec<&Path> {\n   |            ^^^^^^^^^^\n   |\n   = note: `#[warn(dead_code)]` on by default\n\nwarning: `everything` (bin \"everything\") generated 1 warning\n    Finished `release` profile [optimized] target(s) in 2m 34s\n       Built application at: /Users/al02402336/everything/src-tauri/target/release/everything\n    Bundling Everything.app (/Users/al02402336/everything/src-tauri/target/release/bundle/macos/Everything.app)\n    Bundling Everything_0.2.0_aarch64.dmg (/Users/al02402336/everything/src-tauri/target/release/bundle/dmg/Everything_0.2.0_aarch64.dmg)\n     Running bundle_dmg.sh\n    Finished 2 bundles at:\n        /Users/al02402336/everything/src-tauri/target/release/bundle/macos/Everything.app\n        /Users/al02402336/everything/src-tauri/target/release/bundle/dmg/Everything_0.2.0_aarch64.dmg","is_error":false}]},"uuid":"d96520d6-1179-4c54-8929-6b24c9bbc48e","timestamp":"2026-02-22T08:00:48.175Z","toolUseResult":{"stdout":"  --> src/gitignore_filter.rs:23:12\n   |\n17 | impl GitignoreFilter {\n   | -------------------- method in this implementation\n...\n23 |     pub fn root_paths(&self) -> Vec<&Path> {\n   |            ^^^^^^^^^^\n   |\n   = note: `#[warn(dead_code)]` on by default\n\nwarning: `everything` (bin \"everything\") generated 1 warning\n    Finished `release` profile [optimized] target(s) in 2m 34s\n       Built application at: /Users/al02402336/everything/src-tauri/target/release/everything\n    Bundling Everything.app (/Users/al02402336/everything/src-tauri/target/release/bundle/macos/Everything.app)\n    Bundling Everything_0.2.0_aarch64.dmg (/Users/al02402336/everything/src-tauri/target/release/bundle/dmg/Everything_0.2.0_aarch64.dmg)\n     Running bundle_dmg.sh\n    Finished 2 bundles at:\n        /Users/al02402336/everything/src-tauri/target/release/bundle/macos/Everything.app\n        /Users/al02402336/everything/src-tauri/target/release/bundle/dmg/Everything_0.2.0_aarch64.dmg","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"de0214d4-57d0-4550-831c-f2fe5a23deb7"}
{"parentUuid":"d96520d6-1179-4c54-8929-6b24c9bbc48e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Dyr9A5ZUGopvtaUVbHbDr5","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Build succeeded. Now the user needs to test it. But I can't run the app directly and measure the time. Let me provide instructions for the user to test.\n\nActually, wait - the user said \"50초 미만이 될 때까지 테스트하고 시간 측정과 개선을 반복해\" - \"Test and repeat improvements until it's under 50 seconds.\" So I need to continue this loop.\n\nSince I can't run the app interactively, I should try to run it from the terminal to get the timing output, or at least run the Rust tests to validate correctness.\n\n\nLet me attempt to execute the release binary directly and capture the timing information from its output.","signature":"EsIHCkYICxgCKkCBFBHOo8m6rsR6ilzMf18lK+NztSNS/OhPb7ALBD5zXNI8rRUPPf4XTyNY+M26ExK1yR8k8zYxcGvEUczs9ud1EgwHTMc/1UlxgzqZSkYaDFIdS28dka89NBphyiIwDuP2eGv6/QT9+q3V0CgZiTdogixVeXSt6UtZicmS1n7wP+QU4qETuLsmAq31jdXIKqkGtKC6nQnbketk7YSDLdTJWvx3dlTqfUSqziVthzrV0xuyW2NAZ2oo+bSH4ba7xtQwFQ8bqRP1rMP4NTlKPeZinIVTRVRVeo4/NbaFrhTBn6gY/Hu1cwm8ct+F74MIHo/hBKHbL77W/QotwJ5mDZO5C2p2fZEUXj5ls7GbS3jhM40kLP1UAY3BTb377UyrIXPPXcUtUJc2ihaoFs/A1gZjrH9bEDsnHCA8chpNtx9MaOVWG1bAX9xb8mAzbuIoXqfUmorvbelI+G7+lkG2FDFfdKtxSfVMntscOBVBp8V2Dnjd3+kTeQ8sOlJrhE/0TOHCMm7XAI8ZnumQQY3y2OmUvGIILdlM1M4XQphJaaaXlMvWk8ZDsMEwuUhUoYaP/QxXRHKzTBiPasIBk6E0My4+T0QKyq2IZwaZQAJiNRxYOZ4sHQpkYRyrTr6APZknuLRBk7JWcuC8+QB+8iLmp+MIfP/WbdvSYgoYLNdDQpBTYxHtrgWymQlDUFQvuWQrezinCQxDWfjHpFECKEF4l9Bj89Or8jR4EEz8uUaKK38f4WnazxqOoHqmeY66b4AXvWWTzhZV6sVX4vfyqbQb5iftCyaVOTL3vxQ3T0nA6zmdeyLCOzfugJ99gXDdAXnQYanG4w7YdZyA5M4aSECp+YM1Bjfyp4xJUy8yawBzIe1YcPu4DR1yKJrZ+Z0XQ3pxdbuL5AZSs7NopN3pA9DxbFcyKnw/ghs3/OM1xlaECsgRsDZZtQq2izMQ4HrfJ3lHgTfuhY5P5fDN+elNMxc7sPjTm0cbJC8dKuRtmKwg4n3oCbnSmkNbVdupQ5RDIqjvhRpNfjNRQ9MXGct/5O8JYftLwa8Sy6FU2FRuggdQyBfLs3etkgLWOqYd0IOsDtVPqETuu7gC07PkYGDNQqNs6tvtwQQoa8RZko8ASyNYBGvqGp9PrJlRpzEp8GZxzwr7+luUVews4FP9ty68FQmyUjtbNPAlY2oeaqQM+kAQu/i2wC+cWJuz4Q8i2FTFIevPYf3XBfYAa9tcnKOVFt1mMlYqjvTv5+hwa/sx1pSKABh8XURHMICc5V0lFNcYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":140963,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":476},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNknJUPx1Yx5cpEui3RC","type":"assistant","uuid":"926e2abc-9647-4524-b638-01e44a6802cc","timestamp":"2026-02-22T08:00:55.280Z"}
{"parentUuid":"926e2abc-9647-4524-b638-01e44a6802cc","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Dyr9A5ZUGopvtaUVbHbDr5","type":"message","role":"assistant","content":[{"type":"text","text":"Build succeeded. Let me now run a quick test to measure the timing output:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":140963,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":476},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNknJUPx1Yx5cpEui3RC","type":"assistant","uuid":"cd894801-8159-420f-a724-767c6d6e0192","timestamp":"2026-02-22T08:00:55.296Z"}
{"parentUuid":"cd894801-8159-420f-a724-767c6d6e0192","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01Dyr9A5ZUGopvtaUVbHbDr5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01AU8RmWTueRVtvTc1MdSHF4","name":"Bash","input":{"command":"cargo test --manifest-path src-tauri/Cargo.toml 2>&1 | tail -20","description":"Run Rust unit tests","timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":140963,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":476},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNknJUPx1Yx5cpEui3RC","type":"assistant","uuid":"b53cbba4-5248-439f-a360-05e2151e9978","timestamp":"2026-02-22T08:00:55.902Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T08:00:59.658Z","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","content":"{\"task_id\":\"b48a3de\",\"tool_use_id\":\"REDACTED\",\"description\":\"Run Rust unit tests\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"b53cbba4-5248-439f-a360-05e2151e9978","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":3,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-0","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"aaf36658-0652-4978-af59-985b6ad57de4","timestamp":"2026-02-22T08:00:59.658Z"}
{"parentUuid":"aaf36658-0652-4978-af59-985b6ad57de4","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":4,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-1","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"c259cefd-054c-45a2-a95b-8f5a6bf402d6","timestamp":"2026-02-22T08:01:00.649Z"}
{"parentUuid":"c259cefd-054c-45a2-a95b-8f5a6bf402d6","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":5,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-2","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"211f0efd-5d60-4dd7-927f-034b253fcf99","timestamp":"2026-02-22T08:01:01.649Z"}
{"parentUuid":"211f0efd-5d60-4dd7-927f-034b253fcf99","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":6,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-3","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"f3ba00d9-8c55-47f2-abb7-8486666a6a65","timestamp":"2026-02-22T08:01:02.656Z"}
{"parentUuid":"f3ba00d9-8c55-47f2-abb7-8486666a6a65","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":7,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-4","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"aac7b4e5-bb9e-42f8-8a0c-8660545e320c","timestamp":"2026-02-22T08:01:03.652Z"}
{"parentUuid":"aac7b4e5-bb9e-42f8-8a0c-8660545e320c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":8,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-5","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"c4c6bc16-b5ae-4970-84bd-8373813f4b66","timestamp":"2026-02-22T08:01:04.653Z"}
{"parentUuid":"c4c6bc16-b5ae-4970-84bd-8373813f4b66","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":9,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-6","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"6aaafaaa-d66f-4e95-8415-2b014bd3f94b","timestamp":"2026-02-22T08:01:05.659Z"}
{"parentUuid":"6aaafaaa-d66f-4e95-8415-2b014bd3f94b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":10,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-7","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"25a42a8e-1b9b-4f54-b745-848b31d5ac2e","timestamp":"2026-02-22T08:01:06.656Z"}
{"parentUuid":"25a42a8e-1b9b-4f54-b745-848b31d5ac2e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":11,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-8","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"45578032-1490-4132-8425-6bd5cb6d3c98","timestamp":"2026-02-22T08:01:07.656Z"}
{"parentUuid":"45578032-1490-4132-8425-6bd5cb6d3c98","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":12,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-9","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"55c19da3-dbcd-4bc7-bea0-3ca3363cb4b2","timestamp":"2026-02-22T08:01:08.657Z"}
{"parentUuid":"55c19da3-dbcd-4bc7-bea0-3ca3363cb4b2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":13,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-10","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"a8e7d86e-fea1-4ada-994b-c125e39ee92d","timestamp":"2026-02-22T08:01:09.658Z"}
{"parentUuid":"a8e7d86e-fea1-4ada-994b-c125e39ee92d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":14,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-11","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"4cdf918f-0cd6-437a-b4fb-782854909544","timestamp":"2026-02-22T08:01:10.658Z"}
{"parentUuid":"4cdf918f-0cd6-437a-b4fb-782854909544","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":15,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-12","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"ec3430de-0057-4f10-bf7b-0c951a23d29b","timestamp":"2026-02-22T08:01:11.659Z"}
{"parentUuid":"ec3430de-0057-4f10-bf7b-0c951a23d29b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":16,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-13","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"f4ba95c3-4bd5-4220-bee4-b826ec14f09c","timestamp":"2026-02-22T08:01:12.660Z"}
{"parentUuid":"f4ba95c3-4bd5-4220-bee4-b826ec14f09c","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":17,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-14","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"2cc91646-f540-4a4c-a0e7-d721da691f14","timestamp":"2026-02-22T08:01:13.661Z"}
{"parentUuid":"2cc91646-f540-4a4c-a0e7-d721da691f14","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":18,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-15","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"2034ea4d-6dee-43c7-a847-8d0b06aa4b9a","timestamp":"2026-02-22T08:01:14.661Z"}
{"parentUuid":"2034ea4d-6dee-43c7-a847-8d0b06aa4b9a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":19,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-16","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"85d77b94-e678-4e07-aed3-f5d27a49cebe","timestamp":"2026-02-22T08:01:15.661Z"}
{"parentUuid":"85d77b94-e678-4e07-aed3-f5d27a49cebe","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":20,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-17","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"42b7312f-af51-4249-a86b-8b1b2a9bec74","timestamp":"2026-02-22T08:01:16.663Z"}
{"parentUuid":"42b7312f-af51-4249-a86b-8b1b2a9bec74","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":21,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-18","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"dd63a658-698f-411f-9e2c-05f3f4427955","timestamp":"2026-02-22T08:01:17.662Z"}
{"parentUuid":"dd63a658-698f-411f-9e2c-05f3f4427955","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":22,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-19","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"4b734ad4-fe5b-47b9-ae4d-f06be901fdac","timestamp":"2026-02-22T08:01:18.663Z"}
{"parentUuid":"4b734ad4-fe5b-47b9-ae4d-f06be901fdac","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":23,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-20","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"20dd62d3-3a17-4352-8989-1c29b56f2abb","timestamp":"2026-02-22T08:01:19.664Z"}
{"parentUuid":"20dd62d3-3a17-4352-8989-1c29b56f2abb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":24,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-21","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"c0f2f355-3a66-4854-8290-deeca4357820","timestamp":"2026-02-22T08:01:20.664Z"}
{"parentUuid":"c0f2f355-3a66-4854-8290-deeca4357820","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":25,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-22","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"1b3f9a39-47d0-4412-ac50-963bad3528ca","timestamp":"2026-02-22T08:01:21.665Z"}
{"parentUuid":"1b3f9a39-47d0-4412-ac50-963bad3528ca","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":26,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-23","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"13a58d5b-4164-40f9-b3b6-432b3167e7cd","timestamp":"2026-02-22T08:01:22.665Z"}
{"parentUuid":"13a58d5b-4164-40f9-b3b6-432b3167e7cd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":27,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-24","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"c797b92a-d7f3-4cbc-ba65-fabb885b5a02","timestamp":"2026-02-22T08:01:23.666Z"}
{"parentUuid":"c797b92a-d7f3-4cbc-ba65-fabb885b5a02","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":28,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-25","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"5bf27201-d20b-4f5d-a337-95791f3d7b68","timestamp":"2026-02-22T08:01:24.666Z"}
{"parentUuid":"5bf27201-d20b-4f5d-a337-95791f3d7b68","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":29,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-26","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"cb3ffe8d-1123-4b15-8c83-fdef043c7bbd","timestamp":"2026-02-22T08:01:25.667Z"}
{"parentUuid":"cb3ffe8d-1123-4b15-8c83-fdef043c7bbd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":30,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-27","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"3e7f442c-cf5a-45bf-bd32-fd626ea49945","timestamp":"2026-02-22T08:01:26.668Z"}
{"parentUuid":"3e7f442c-cf5a-45bf-bd32-fd626ea49945","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":31,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-28","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"99f48a81-cfa8-4b24-b6a3-281dce282051","timestamp":"2026-02-22T08:01:27.669Z"}
{"parentUuid":"99f48a81-cfa8-4b24-b6a3-281dce282051","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":32,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-29","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"398e6971-e31d-4830-b6fa-fe0aeea8697b","timestamp":"2026-02-22T08:01:28.675Z"}
{"parentUuid":"398e6971-e31d-4830-b6fa-fe0aeea8697b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":33,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-30","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"759039d3-d98a-4906-ab25-5dcb71dd036a","timestamp":"2026-02-22T08:01:29.672Z"}
{"parentUuid":"759039d3-d98a-4906-ab25-5dcb71dd036a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":34,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-31","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"ea8cdb57-2525-463f-807f-c621f8060672","timestamp":"2026-02-22T08:01:30.673Z"}
{"parentUuid":"ea8cdb57-2525-463f-807f-c621f8060672","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":35,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-32","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"5e421a3c-aa74-4bc6-8e7c-b4cc2e8dede1","timestamp":"2026-02-22T08:01:31.674Z"}
{"parentUuid":"5e421a3c-aa74-4bc6-8e7c-b4cc2e8dede1","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":36,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-33","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"2b8f1520-6bb9-4941-a3be-83b48ad6cb57","timestamp":"2026-02-22T08:01:32.675Z"}
{"parentUuid":"2b8f1520-6bb9-4941-a3be-83b48ad6cb57","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":37,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-34","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"cae1f8dd-95f7-474c-af3a-d1f946fd1a73","timestamp":"2026-02-22T08:01:33.676Z"}
{"parentUuid":"cae1f8dd-95f7-474c-af3a-d1f946fd1a73","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":38,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-35","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"cf664373-15ad-4b03-ac30-12f1d66f29ac","timestamp":"2026-02-22T08:01:34.676Z"}
{"parentUuid":"cf664373-15ad-4b03-ac30-12f1d66f29ac","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":39,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-36","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"5aa3fdda-8958-48a7-a143-36aa510cb094","timestamp":"2026-02-22T08:01:35.676Z"}
{"parentUuid":"5aa3fdda-8958-48a7-a143-36aa510cb094","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":40,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-37","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"003306c7-4a29-4cc2-8c11-45b1857d3e5f","timestamp":"2026-02-22T08:01:36.677Z"}
{"parentUuid":"003306c7-4a29-4cc2-8c11-45b1857d3e5f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":41,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-38","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"f2d45a8e-cf0c-467c-8d1e-64970e12c563","timestamp":"2026-02-22T08:01:37.679Z"}
{"parentUuid":"f2d45a8e-cf0c-467c-8d1e-64970e12c563","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":42,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-39","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"cebf50fe-1121-4623-9c37-796871a91032","timestamp":"2026-02-22T08:01:38.680Z"}
{"parentUuid":"cebf50fe-1121-4623-9c37-796871a91032","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":43,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-40","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"9d81af3d-c939-4afb-bfa2-3759d35c56fb","timestamp":"2026-02-22T08:01:39.680Z"}
{"parentUuid":"9d81af3d-c939-4afb-bfa2-3759d35c56fb","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":44,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-41","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"9f2637a4-02ec-4ce1-b0f9-e814de1201ef","timestamp":"2026-02-22T08:01:40.680Z"}
{"parentUuid":"9f2637a4-02ec-4ce1-b0f9-e814de1201ef","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":45,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-42","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"f1336a11-3baf-4b4c-aae4-0ef8f9c5f859","timestamp":"2026-02-22T08:01:41.681Z"}
{"parentUuid":"f1336a11-3baf-4b4c-aae4-0ef8f9c5f859","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":46,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-43","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"df98a108-b257-4d81-b155-0500ed57da1b","timestamp":"2026-02-22T08:01:42.683Z"}
{"parentUuid":"df98a108-b257-4d81-b155-0500ed57da1b","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":47,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-44","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"a80306d4-ab36-4a6b-aa70-9a882e2e06fd","timestamp":"2026-02-22T08:01:43.685Z"}
{"parentUuid":"a80306d4-ab36-4a6b-aa70-9a882e2e06fd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":48,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-45","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"7949673d-0bbe-4f78-9f56-4eba306927c5","timestamp":"2026-02-22T08:01:44.686Z"}
{"parentUuid":"7949673d-0bbe-4f78-9f56-4eba306927c5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":49,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-46","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"acc32445-44db-40a7-92c7-0951e899596a","timestamp":"2026-02-22T08:01:45.688Z"}
{"parentUuid":"acc32445-44db-40a7-92c7-0951e899596a","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":50,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-47","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"22502269-380e-4902-8b30-d100d25da259","timestamp":"2026-02-22T08:01:46.688Z"}
{"parentUuid":"22502269-380e-4902-8b30-d100d25da259","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":51,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-48","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"1f981fca-e282-4325-b486-d000c9a766a5","timestamp":"2026-02-22T08:01:47.689Z"}
{"parentUuid":"1f981fca-e282-4325-b486-d000c9a766a5","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":52,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-49","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"b1acffe5-b910-4d6d-af95-656c32f5af43","timestamp":"2026-02-22T08:01:48.690Z"}
{"parentUuid":"b1acffe5-b910-4d6d-af95-656c32f5af43","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":53,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-50","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"f5d7533e-87b2-4ecc-bb56-9cb37dc6adb2","timestamp":"2026-02-22T08:01:49.691Z"}
{"parentUuid":"f5d7533e-87b2-4ecc-bb56-9cb37dc6adb2","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":54,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-51","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"f6d76bb2-cc0d-40d1-8aeb-4f5b99ca0dcd","timestamp":"2026-02-22T08:01:50.694Z"}
{"parentUuid":"f6d76bb2-cc0d-40d1-8aeb-4f5b99ca0dcd","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":55,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-52","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"b6fe93a2-461f-4aba-86dd-0613322fcf87","timestamp":"2026-02-22T08:01:51.696Z"}
{"parentUuid":"b6fe93a2-461f-4aba-86dd-0613322fcf87","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":56,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-53","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"2ab8c1a5-1911-42ee-a352-900d6a31c80f","timestamp":"2026-02-22T08:01:52.696Z"}
{"parentUuid":"2ab8c1a5-1911-42ee-a352-900d6a31c80f","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":57,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-54","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"fe27e0b8-d657-4c9a-a54d-2fe4772dace9","timestamp":"2026-02-22T08:01:53.698Z"}
{"parentUuid":"fe27e0b8-d657-4c9a-a54d-2fe4772dace9","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":58,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-55","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"766d1be4-99f6-4ab2-8718-e0909011574e","timestamp":"2026-02-22T08:01:54.698Z"}
{"parentUuid":"766d1be4-99f6-4ab2-8718-e0909011574e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"bash_progress","output":"","fullOutput":"","elapsedTimeSeconds":59,"totalLines":0,"totalBytes":0,"taskId":"b48a3de","timeoutMs":60000},"toolUseID":"bash-progress-56","parentToolUseID":"toolu_01AU8RmWTueRVtvTc1MdSHF4","uuid":"ca5529e1-cd4d-44df-bcf5-8a79fc7b4a1b","timestamp":"2026-02-22T08:01:55.700Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-22T08:01:56.642Z","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","content":"{\"task_id\":\"b48a3de\",\"tool_use_id\":\"REDACTED\",\"description\":\"Run Rust unit tests\",\"task_type\":\"local_bash\"}"}
{"parentUuid":"b53cbba4-5248-439f-a360-05e2151e9978","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AU8RmWTueRVtvTc1MdSHF4","type":"tool_result","content":"Command running in background with ID: b48a3de. Output is being written to: REDACTED.output","is_error":false}]},"uuid":"6f5e83ed-9233-4224-b012-6e8c2b8f185e","timestamp":"2026-02-22T08:01:56.705Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false,"backgroundTaskId":"b48a3de"},"sourceToolAssistantUUID":"b53cbba4-5248-439f-a360-05e2151e9978"}
{"parentUuid":"6f5e83ed-9233-4224-b012-6e8c2b8f185e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01UbGDmVCdAoKPg6aooBfmGw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UJme1B5ss9bn8vScSgj6M8","name":"TaskOutput","input":{"task_id":"b48a3de","block":true,"timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":399,"cache_read_input_tokens":141439,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":399},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNksMoCxvWtcacQ3r4t8","type":"assistant","uuid":"3d0f67dd-8cd3-4f0f-afd6-d3f4750fe987","timestamp":"2026-02-22T08:01:58.910Z"}
{"parentUuid":"3d0f67dd-8cd3-4f0f-afd6-d3f4750fe987","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"waiting_for_task","taskDescription":"Run Rust unit tests","taskType":"local_bash"},"toolUseID":"task-output-waiting-1771747318913","parentToolUseID":"toolu_01UJme1B5ss9bn8vScSgj6M8","uuid":"8cefab3e-4328-4f1c-bdb0-ccdc8886e819","timestamp":"2026-02-22T08:01:58.913Z"}
{"parentUuid":"3d0f67dd-8cd3-4f0f-afd6-d3f4750fe987","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UJme1B5ss9bn8vScSgj6M8","type":"tool_result","content":"<retrieval_status>timeout</retrieval_status>\n\n<task_id>b48a3de</task_id>\n\n<task_type>local_bash</task_type>\n\n<status>running</status>"}]},"uuid":"c0e58ca7-4f55-436d-9584-f531a6001ae0","timestamp":"2026-02-22T08:02:58.960Z","toolUseResult":{"retrieval_status":"timeout","task":{"task_id":"b48a3de","task_type":"local_bash","status":"running","description":"Run Rust unit tests","output":"","exitCode":null}},"sourceToolAssistantUUID":"3d0f67dd-8cd3-4f0f-afd6-d3f4750fe987"}
{"parentUuid":"c0e58ca7-4f55-436d-9584-f531a6001ae0","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01W7U3eLwajSbpAU9ozShzJh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VLJp91ho2bNMNxEaLc3bBS","name":"TaskOutput","input":{"task_id":"b48a3de","block":false,"timeout":30000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":154,"cache_read_input_tokens":141838,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":154},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkwwkVB2DkatswkWDEz","type":"assistant","uuid":"e4715c42-4219-4abf-a0ca-8e96cfa5500d","timestamp":"2026-02-22T08:03:00.912Z"}
{"parentUuid":"e4715c42-4219-4abf-a0ca-8e96cfa5500d","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VLJp91ho2bNMNxEaLc3bBS","type":"tool_result","content":"<retrieval_status>not_ready</retrieval_status>\n\n<task_id>b48a3de</task_id>\n\n<task_type>local_bash</task_type>\n\n<status>running</status>"}]},"uuid":"07925b0d-ec88-4c35-b2fa-fcaceeb94bd7","timestamp":"2026-02-22T08:03:00.958Z","toolUseResult":{"retrieval_status":"not_ready","task":{"task_id":"b48a3de","task_type":"local_bash","status":"running","description":"Run Rust unit tests","output":"","exitCode":null}},"sourceToolAssistantUUID":"e4715c42-4219-4abf-a0ca-8e96cfa5500d"}
{"parentUuid":"07925b0d-ec88-4c35-b2fa-fcaceeb94bd7","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01WYQ9iZamBuRSvNct5ahCHU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PCjUFiEfMfzZyghsUuP1sg","name":"Bash","input":{"command":"\n# Run the app with timing measurement from the stderr output\n# First, test via a benchmark-like invocation\n/Users/al02402336/everything/src-tauri/target/release/everything --bench 2>&1 | head -5 &\nsleep 2\nkill %1 2>/dev/null\necho \"App test done\"","description":"Quick test of app invocation","timeout":10000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":156,"cache_read_input_tokens":141992,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":156},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkx7bL1KHcJVPA6fYYF","type":"assistant","uuid":"71a011a7-807c-45e5-b702-d43fa8c97c07","timestamp":"2026-02-22T08:03:04.897Z"}
{"parentUuid":"71a011a7-807c-45e5-b702-d43fa8c97c07","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PCjUFiEfMfzZyghsUuP1sg","type":"tool_result","content":"[startup +0ms] run() entered\n[startup] setup_app() entered\n[startup] +7ms loading pathignore rules...\n[startup] +8ms pathignore done\n[startup] +8ms AppState created\nApp test done","is_error":false}]},"uuid":"27c33a2a-3969-49a8-acd3-f85dcd141a9e","timestamp":"2026-02-22T08:03:07.165Z","toolUseResult":{"stdout":"[startup +0ms] run() entered\n[startup] setup_app() entered\n[startup] +7ms loading pathignore rules...\n[startup] +8ms pathignore done\n[startup] +8ms AppState created\nApp test done","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"71a011a7-807c-45e5-b702-d43fa8c97c07"}
{"parentUuid":"27c33a2a-3969-49a8-acd3-f85dcd141a9e","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","message":{"model":"claude-sonnet-4-6","id":"msg_01VhksaoGsq5gnStzgqb7DvS","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0157HpBBU15Jm3KHAHuGhUx6","name":"TaskOutput","input":{"task_id":"b48a3de","block":true,"timeout":60000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":237,"cache_read_input_tokens":142148,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":237},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYNkxYntrfDu83oW6xCNQ","type":"assistant","uuid":"e958607c-780d-4b29-a389-b6f2185aae52","timestamp":"2026-02-22T08:03:09.341Z"}
{"parentUuid":"e958607c-780d-4b29-a389-b6f2185aae52","isSidechain":false,"userType":"external","cwd":"/Users/al02402336/everything","sessionId":"8c7c52ff-d14e-4185-a9e9-6c25fcb26ad1","version":"2.1.49","gitBranch":"main","slug":"gleaming-squishing-meteor","type":"progress","data":{"type":"waiting_for_task","taskDescription":"Run Rust unit tests","taskType":"local_bash"},"toolUseID":"task-output-waiting-1771747389342","parentToolUseID":"toolu_0157HpBBU15Jm3KHAHuGhUx6","uuid":"47c482f1-b5fa-4037-b076-2e6b3fc50ae5","timestamp":"2026-02-22T08:03:09.342Z"}
